{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4947,"status":"ok","timestamp":1650814765333,"user":{"displayName":"A立志做大白","userId":"07587136654976679727"},"user_tz":-480},"id":"KWNZR8VJDYAU","outputId":"5618706f-4cf0-4321-818c-3e1c48b71e95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation_models\n","  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n","Collecting image-classifiers==1.0.0\n","  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n","Collecting efficientnet==1.0.0\n","  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n","Collecting keras-applications<=1.0.8,>=1.0.7\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 8.2 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.18.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.21.6)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.5.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.6.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.1.2)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.0)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.15.0)\n","Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n","Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"]}],"source":["!pip install segmentation_models"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33920,"status":"ok","timestamp":1650814799243,"user":{"displayName":"A立志做大白","userId":"07587136654976679727"},"user_tz":-480},"id":"GXiEFJWkYpo2","outputId":"2c4a4064-35ea-4b2b-8023-b783f3fc5bd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["['TransUNet-single',\n"," 'data',\n"," 'predictions',\n"," 'Xception_Gray_flow.ipynb',\n"," 'Xception_Event_flow.ipynb',\n"," 'Xception_Dual_flow.ipynb',\n"," 'old_loss',\n"," 'Grayscale_output',\n"," 'Event_output',\n"," 'Xcep_loss_record_train_Gray.npy',\n"," 'Xcep_loss_record_train_Event.npy',\n"," 'Xcep_iou_record_test_Gray.npy',\n"," 'Xception_Grayscale.ipynb',\n"," 'Xcep_iou_record_test_Event.npy',\n"," 'Xception_Event.ipynb',\n"," 'Dual_output',\n"," 'Xcep_loss_record_train_Dual.npy',\n"," 'Xcep_iou_record_test_Dual.npy',\n"," 'Xception_Final_old.ipynb',\n"," 'Xception_Final.ipynb',\n"," 'Xception_Dual_try.ipynb',\n"," 'Xception_Dual.ipynb',\n"," 'Xcep_iou_record_test_Final.npy',\n"," 'loss_plot',\n"," 'predict_helper.ipynb',\n"," 'Final_output',\n"," 'Xcep_loss_record_train_Final.npy',\n"," 'Xception_Final_flowdir.ipynb']"]},"metadata":{},"execution_count":2}],"source":["import os\n","from google.colab.patches import cv2_imshow\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#drive.mount(\"/content/drive\", force_remount=True)\n","\n","path = \"/content/drive/My Drive/Master_Project\"\n","path_prefix = path\n","\n","os.chdir(path)\n","os.listdir(path)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2353,"status":"ok","timestamp":1650814801571,"user":{"displayName":"A立志做大白","userId":"07587136654976679727"},"user_tz":-480},"id":"i8HvGAtTDYVI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ddea563-480c-4762-b97c-eaade6b6f7c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Segmentation Models: using `keras` framework.\n"]}],"source":["# Set GPU environment\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","\n","# ==============================================================================\n","# =                                   param                                    =\n","# ==============================================================================\n","import numpy as np\n","import tensorflow as tf\n","import tqdm\n","import cv2\n","import copy\n","import random\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from segmentation_models.losses import bce_jaccard_loss\n","\n","# ==============================================================================\n","# =                                   model                                    =\n","# ==============================================================================\n","def xception_final(Input_Shape, NUM_CHANNELS):\n","    input = tf.keras.layers.Input(Input_Shape)\n","    # s = tf.keras.layers.Lambda(lambda x: x / 255)(input)\n","\n","    base_model = tf.keras.applications.xception.Xception(\n","        include_top=False, weights=None, input_tensor=input,\n","        input_shape=(320, 320, NUM_CHANNELS), pooling=max\n","    )\n","    output_1 = base_model.get_layer('block2_sepconv2_bn').output\n","    output_2 = base_model.get_layer('block3_sepconv2_bn').output\n","    output_3 = base_model.get_layer('block4_sepconv2_bn').output\n","    output_4 = base_model.get_layer('block13_sepconv2_bn').output\n","    output_5 = base_model.get_layer('block14_sepconv2_bn').output\n","\n","    decoder_0 = tf.keras.layers.Conv2DTranspose(filters=2048, kernel_size=3, strides=2, activation='relu',\n","                                                padding='same')(output_5)\n","    decoder_0 = layers.BatchNormalization()(decoder_0)\n","    decoder_0 = tf.image.resize(decoder_0, (tf.shape(output_5)[1], tf.shape(output_5)[2]))\n","    decoder_0 = tf.concat([decoder_0, output_5], 3)\n","\n","    decoder_1 = tf.keras.layers.Conv2D(filters=2048, kernel_size=3, activation='relu', padding='same')(decoder_0)\n","    decoder_1 = tf.keras.layers.Conv2DTranspose(filters=1024, kernel_size=3, strides=2, activation='relu',\n","                                                padding='same')(decoder_1)\n","    decoder_1 = layers.BatchNormalization()(decoder_1)\n","    decoder_1 = tf.image.resize(decoder_1, (tf.shape(output_4)[1], tf.shape(output_4)[2]))\n","    decoder_1 = tf.concat([decoder_1, output_4], 3)\n","    #\n","    decoder_2 = tf.keras.layers.Conv2D(filters=1024, kernel_size=3, activation='relu', padding='same')(decoder_1)\n","    decoder_2 = tf.keras.layers.Conv2DTranspose(filters=728, kernel_size=3, strides=2, activation='relu',\n","                                                padding='same')(decoder_2)\n","    decoder_2 = layers.BatchNormalization()(decoder_2)\n","    decoder_2 = tf.image.resize(decoder_2, (tf.shape(output_3)[1], tf.shape(output_3)[2]))\n","    decoder_2 = tf.concat([decoder_2, output_3], 3)\n","    #\n","    decoder_3 = tf.keras.layers.Conv2D(filters=728, kernel_size=3, activation='relu', padding='same')(decoder_2)\n","    decoder_3 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=3, strides=2, activation='relu',\n","                                                padding='same')(decoder_3)\n","    decoder_3 = layers.BatchNormalization()(decoder_3)\n","    decoder_3 = tf.image.resize(decoder_3, (tf.shape(output_2)[1], tf.shape(output_2)[2]))\n","    decoder_3 = tf.concat([decoder_3, output_2], 3)\n","    #\n","    decoder_4 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(decoder_3)\n","    decoder_4 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, activation='relu',\n","                                                padding='same')(decoder_4)\n","    decoder_4 = layers.BatchNormalization()(decoder_4)\n","    decoder_4 = tf.image.resize(decoder_4, (tf.shape(output_1)[1], tf.shape(output_1)[2]))\n","    decoder_4 = tf.concat([decoder_4, output_1], 3)\n","    decoder_4 = tf.image.resize(decoder_4, [320, 320])\n","    #\n","    output = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(decoder_4)\n","    #\n","    model = Model(inputs=base_model.input, outputs=output)\n","\n","    # model.compile(optimizer='adam', loss=bce_jaccard_loss, metrics=[iou_score])\n","\n","    return model\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"sWTwX1yBz3t-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650807162050,"user_tz":-480,"elapsed":2822555,"user":{"displayName":"A立志做大白","userId":"07587136654976679727"}},"outputId":"4f157af7-ac07-4a90-f090-02d68534567a"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/applications/xception.py:133: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 8 input channels.\n","  weights=weights)\n","Epoch Loop:   0%|          | 0/150 [00:00<?, ?it/s]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Found 420 images belonging to 1 classes.\n","Found 420 images belonging to 1 classes.\n","Found 420 images belonging to 1 classes.\n","Found 420 images belonging to 1 classes.\n","Found 420 images belonging to 1 classes.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","Training loss: 1.9587209, IoU: 0.1418688358031422 |:   0%|          | 0/26 [01:18<?, ?it/s]\u001b[A\n","Training loss: 1.9587209, IoU: 0.1418688358031422 |:   4%|▍         | 1/26 [01:18<32:51, 78.85s/it]\u001b[A\n","Training loss: 1.0874667, IoU: 0.6800378472300732 |:   4%|▍         | 1/26 [01:44<32:51, 78.85s/it]\u001b[A\n","Training loss: 1.0874667, IoU: 0.6800378472300732 |:   8%|▊         | 2/26 [01:44<18:55, 47.33s/it]\u001b[A\n","Training loss: 0.862264, IoU: 0.8067213885751268 |:   8%|▊         | 2/26 [02:09<18:55, 47.33s/it] \u001b[A\n","Training loss: 0.862264, IoU: 0.8067213885751268 |:  12%|█▏        | 3/26 [02:09<14:21, 37.44s/it]\u001b[A\n","Training loss: 0.70265603, IoU: 0.8678280286856567 |:  12%|█▏        | 3/26 [02:34<14:21, 37.44s/it]\u001b[A\n","Training loss: 0.70265603, IoU: 0.8678280286856567 |:  15%|█▌        | 4/26 [02:34<11:54, 32.46s/it]\u001b[A\n","Training loss: 0.7245443, IoU: 0.8632687427912341 |:  15%|█▌        | 4/26 [03:00<11:54, 32.46s/it] \u001b[A\n","Training loss: 0.7245443, IoU: 0.8632687427912341 |:  19%|█▉        | 5/26 [03:00<10:30, 30.00s/it]\u001b[A\n","Training loss: 0.6342052, IoU: 0.8523023836391124 |:  19%|█▉        | 5/26 [03:25<10:30, 30.00s/it]\u001b[A\n","Training loss: 0.6342052, IoU: 0.8523023836391124 |:  23%|██▎       | 6/26 [03:25<09:26, 28.31s/it]\u001b[A\n","Training loss: 0.5872327, IoU: 0.8705937198228497 |:  23%|██▎       | 6/26 [03:50<09:26, 28.31s/it]\u001b[A\n","Training loss: 0.5872327, IoU: 0.8705937198228497 |:  27%|██▋       | 7/26 [03:50<08:37, 27.26s/it]\u001b[A\n","Training loss: 0.5422301, IoU: 0.8737728182424647 |:  27%|██▋       | 7/26 [04:15<08:37, 27.26s/it]\u001b[A\n","Training loss: 0.5422301, IoU: 0.8737728182424647 |:  31%|███       | 8/26 [04:15<07:58, 26.58s/it]\u001b[A\n","Training loss: 0.5621495, IoU: 0.8771427046125174 |:  31%|███       | 8/26 [04:41<07:58, 26.58s/it]\u001b[A\n","Training loss: 0.5621495, IoU: 0.8771427046125174 |:  35%|███▍      | 9/26 [04:41<07:26, 26.28s/it]\u001b[A\n","Training loss: 0.6533314, IoU: 0.8807352473148315 |:  35%|███▍      | 9/26 [05:06<07:26, 26.28s/it]\u001b[A\n","Training loss: 0.6533314, IoU: 0.8807352473148315 |:  38%|███▊      | 10/26 [05:06<06:55, 26.00s/it]\u001b[A\n","Training loss: 0.64676017, IoU: 0.8740071390292451 |:  38%|███▊      | 10/26 [05:31<06:55, 26.00s/it]\u001b[A\n","Training loss: 0.64676017, IoU: 0.8740071390292451 |:  42%|████▏     | 11/26 [05:31<06:25, 25.69s/it]\u001b[A\n","Training loss: 0.6176672, IoU: 0.8991551970094419 |:  42%|████▏     | 11/26 [05:56<06:25, 25.69s/it] \u001b[A\n","Training loss: 0.6176672, IoU: 0.8991551970094419 |:  46%|████▌     | 12/26 [05:56<05:57, 25.50s/it]\u001b[A\n","Training loss: 0.59101367, IoU: 0.8858825921194309 |:  46%|████▌     | 12/26 [06:21<05:57, 25.50s/it]\u001b[A\n","Training loss: 0.59101367, IoU: 0.8858825921194309 |:  50%|█████     | 13/26 [06:21<05:30, 25.45s/it]\u001b[A\n","Training loss: 0.57076204, IoU: 0.8762567759567786 |:  50%|█████     | 13/26 [06:47<05:30, 25.45s/it]\u001b[A\n","Training loss: 0.57076204, IoU: 0.8762567759567786 |:  54%|█████▍    | 14/26 [06:47<05:05, 25.45s/it]\u001b[A\n","Training loss: 0.6095245, IoU: 0.8808125908856046 |:  54%|█████▍    | 14/26 [07:12<05:05, 25.45s/it] \u001b[A\n","Training loss: 0.6095245, IoU: 0.8808125908856046 |:  58%|█████▊    | 15/26 [07:12<04:40, 25.50s/it]\u001b[A\n","Training loss: 0.5354966, IoU: 0.894597197655143 |:  58%|█████▊    | 15/26 [07:38<04:40, 25.50s/it] \u001b[A\n","Training loss: 0.5354966, IoU: 0.894597197655143 |:  62%|██████▏   | 16/26 [07:38<04:14, 25.43s/it]\u001b[A\n","Training loss: 0.6416859, IoU: 0.9000863377891571 |:  62%|██████▏   | 16/26 [08:03<04:14, 25.43s/it]\u001b[A\n","Training loss: 0.6416859, IoU: 0.9000863377891571 |:  65%|██████▌   | 17/26 [08:03<03:48, 25.40s/it]\u001b[A\n","Training loss: 0.58856565, IoU: 0.8986677634878915 |:  65%|██████▌   | 17/26 [08:28<03:48, 25.40s/it]\u001b[A\n","Training loss: 0.58856565, IoU: 0.8986677634878915 |:  69%|██████▉   | 18/26 [08:28<03:22, 25.37s/it]\u001b[A\n","Training loss: 0.5271092, IoU: 0.8846269874316987 |:  69%|██████▉   | 18/26 [08:53<03:22, 25.37s/it] \u001b[A\n","Training loss: 0.5271092, IoU: 0.8846269874316987 |:  73%|███████▎  | 19/26 [08:53<02:56, 25.26s/it]\u001b[A\n","Training loss: 0.56532466, IoU: 0.8824114487649048 |:  73%|███████▎  | 19/26 [09:18<02:56, 25.26s/it]\u001b[A\n","Training loss: 0.56532466, IoU: 0.8824114487649048 |:  77%|███████▋  | 20/26 [09:18<02:30, 25.15s/it]\u001b[A\n","Training loss: 0.52061903, IoU: 0.8711236701642169 |:  77%|███████▋  | 20/26 [09:43<02:30, 25.15s/it]\u001b[A\n","Training loss: 0.52061903, IoU: 0.8711236701642169 |:  81%|████████  | 21/26 [09:43<02:05, 25.05s/it]\u001b[A\n","Training loss: 0.43412197, IoU: 0.883249958357289 |:  81%|████████  | 21/26 [10:08<02:05, 25.05s/it] \u001b[A\n","Training loss: 0.43412197, IoU: 0.883249958357289 |:  85%|████████▍ | 22/26 [10:08<01:40, 25.03s/it]\u001b[A\n","Training loss: 0.58294445, IoU: 0.8785837597191429 |:  85%|████████▍ | 22/26 [10:33<01:40, 25.03s/it]\u001b[A\n","Training loss: 0.58294445, IoU: 0.8785837597191429 |:  88%|████████▊ | 23/26 [10:33<01:14, 24.97s/it]\u001b[A\n","Training loss: 0.61688536, IoU: 0.9002713589042823 |:  88%|████████▊ | 23/26 [10:58<01:14, 24.97s/it]\u001b[A\n","Training loss: 0.61688536, IoU: 0.9002713589042823 |:  92%|█████████▏| 24/26 [10:58<00:50, 25.12s/it]\u001b[A\n","Training loss: 0.5835226, IoU: 0.8496916957532288 |:  92%|█████████▏| 24/26 [11:24<00:50, 25.12s/it] \u001b[A\n","Training loss: 0.5835226, IoU: 0.8496916957532288 |:  96%|█████████▌| 25/26 [11:24<00:25, 25.16s/it]\u001b[A\n","Training loss: 0.5518709, IoU: 0.9155419544470383 |:  96%|█████████▌| 25/26 [11:49<00:25, 25.16s/it]\u001b[A\n","Training loss: 0.5518709, IoU: 0.9155419544470383 |: 100%|██████████| 26/26 [11:49<00:00, 27.28s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Found 60 images belonging to 1 classes.\n","Found 60 images belonging to 1 classes.\n","Found 60 images belonging to 1 classes.\n","Found 60 images belonging to 1 classes.\n","Found 60 images belonging to 1 classes.\n","Validation metric improved from -inf to 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:   1%|          | 1/150 [13:51<34:25:09, 831.60s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4672638, IoU: 0.9013289246641552 |:   0%|          | 0/26 [00:16<?, ?it/s]\u001b[A\n","Training loss: 0.4672638, IoU: 0.9013289246641552 |:   4%|▍         | 1/26 [00:16<06:54, 16.58s/it]\u001b[A\n","Training loss: 0.5939432, IoU: 0.8840634408694384 |:   4%|▍         | 1/26 [00:19<06:54, 16.58s/it]\u001b[A\n","Training loss: 0.5939432, IoU: 0.8840634408694384 |:   8%|▊         | 2/26 [00:19<03:24,  8.51s/it]\u001b[A\n","Training loss: 0.5108085, IoU: 0.9110326229625564 |:   8%|▊         | 2/26 [00:22<03:24,  8.51s/it]\u001b[A\n","Training loss: 0.5108085, IoU: 0.9110326229625564 |:  12%|█▏        | 3/26 [00:22<02:16,  5.95s/it]\u001b[A\n","Training loss: 0.49417168, IoU: 0.9285179329283515 |:  12%|█▏        | 3/26 [00:25<02:16,  5.95s/it]\u001b[A\n","Training loss: 0.49417168, IoU: 0.9285179329283515 |:  15%|█▌        | 4/26 [00:25<01:43,  4.72s/it]\u001b[A\n","Training loss: 0.5567972, IoU: 0.9011840209921738 |:  15%|█▌        | 4/26 [00:28<01:43,  4.72s/it] \u001b[A\n","Training loss: 0.5567972, IoU: 0.9011840209921738 |:  19%|█▉        | 5/26 [00:28<01:25,  4.05s/it]\u001b[A\n","Training loss: 0.47600377, IoU: 0.8932663821487588 |:  19%|█▉        | 5/26 [00:30<01:25,  4.05s/it]\u001b[A\n","Training loss: 0.47600377, IoU: 0.8932663821487588 |:  23%|██▎       | 6/26 [00:30<01:13,  3.65s/it]\u001b[A\n","Training loss: 0.50047356, IoU: 0.9045529706455363 |:  23%|██▎       | 6/26 [00:33<01:13,  3.65s/it]\u001b[A\n","Training loss: 0.50047356, IoU: 0.9045529706455363 |:  27%|██▋       | 7/26 [00:33<01:04,  3.39s/it]\u001b[A\n","Training loss: 0.58289057, IoU: 0.906744151377368 |:  27%|██▋       | 7/26 [00:36<01:04,  3.39s/it] \u001b[A\n","Training loss: 0.58289057, IoU: 0.906744151377368 |:  31%|███       | 8/26 [00:36<00:58,  3.23s/it]\u001b[A\n","Training loss: 0.5580268, IoU: 0.9068334857062484 |:  31%|███       | 8/26 [00:39<00:58,  3.23s/it]\u001b[A\n","Training loss: 0.5580268, IoU: 0.9068334857062484 |:  35%|███▍      | 9/26 [00:39<00:52,  3.11s/it]\u001b[A\n","Training loss: 0.5137881, IoU: 0.8973075674310658 |:  35%|███▍      | 9/26 [00:42<00:52,  3.11s/it]\u001b[A\n","Training loss: 0.5137881, IoU: 0.8973075674310658 |:  38%|███▊      | 10/26 [00:42<00:48,  3.03s/it]\u001b[A\n","Training loss: 0.5405605, IoU: 0.901923454140561 |:  38%|███▊      | 10/26 [00:45<00:48,  3.03s/it] \u001b[A\n","Training loss: 0.5405605, IoU: 0.901923454140561 |:  42%|████▏     | 11/26 [00:45<00:44,  2.97s/it]\u001b[A\n","Training loss: 0.49895215, IoU: 0.9205488561512701 |:  42%|████▏     | 11/26 [00:48<00:44,  2.97s/it]\u001b[A\n","Training loss: 0.49895215, IoU: 0.9205488561512701 |:  46%|████▌     | 12/26 [00:48<00:40,  2.92s/it]\u001b[A\n","Training loss: 0.54562354, IoU: 0.9059548951163732 |:  46%|████▌     | 12/26 [00:50<00:40,  2.92s/it]\u001b[A\n","Training loss: 0.54562354, IoU: 0.9059548951163732 |:  50%|█████     | 13/26 [00:50<00:37,  2.89s/it]\u001b[A\n","Training loss: 0.5329783, IoU: 0.9185449424556978 |:  50%|█████     | 13/26 [00:53<00:37,  2.89s/it] \u001b[A\n","Training loss: 0.5329783, IoU: 0.9185449424556978 |:  54%|█████▍    | 14/26 [00:53<00:34,  2.85s/it]\u001b[A\n","Training loss: 0.48747903, IoU: 0.9249735505480853 |:  54%|█████▍    | 14/26 [00:56<00:34,  2.85s/it]\u001b[A\n","Training loss: 0.48747903, IoU: 0.9249735505480853 |:  58%|█████▊    | 15/26 [00:56<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.5645832, IoU: 0.9093272423636328 |:  58%|█████▊    | 15/26 [00:59<00:31,  2.83s/it] \u001b[A\n","Training loss: 0.5645832, IoU: 0.9093272423636328 |:  62%|██████▏   | 16/26 [00:59<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.5098385, IoU: 0.9198973244954418 |:  62%|██████▏   | 16/26 [01:01<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.5098385, IoU: 0.9198973244954418 |:  65%|██████▌   | 17/26 [01:01<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.53936017, IoU: 0.9303309477679808 |:  65%|██████▌   | 17/26 [01:04<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.53936017, IoU: 0.9303309477679808 |:  69%|██████▉   | 18/26 [01:04<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.4758861, IoU: 0.9102797940893267 |:  69%|██████▉   | 18/26 [01:07<00:22,  2.79s/it] \u001b[A\n","Training loss: 0.4758861, IoU: 0.9102797940893267 |:  73%|███████▎  | 19/26 [01:07<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.48121813, IoU: 0.9172143449447981 |:  73%|███████▎  | 19/26 [01:10<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.48121813, IoU: 0.9172143449447981 |:  77%|███████▋  | 20/26 [01:10<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.48903036, IoU: 0.9059267182854809 |:  77%|███████▋  | 20/26 [01:12<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.48903036, IoU: 0.9059267182854809 |:  81%|████████  | 21/26 [01:12<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.50320095, IoU: 0.9164380409963448 |:  81%|████████  | 21/26 [01:15<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.50320095, IoU: 0.9164380409963448 |:  85%|████████▍ | 22/26 [01:15<00:11,  2.75s/it]\u001b[A\n","Training loss: 0.563413, IoU: 0.9094458166470828 |:  85%|████████▍ | 22/26 [01:18<00:11,  2.75s/it]  \u001b[A\n","Training loss: 0.563413, IoU: 0.9094458166470828 |:  88%|████████▊ | 23/26 [01:18<00:08,  2.74s/it]\u001b[A\n","Training loss: 0.55317944, IoU: 0.9087096498761935 |:  88%|████████▊ | 23/26 [01:21<00:08,  2.74s/it]\u001b[A\n","Training loss: 0.55317944, IoU: 0.9087096498761935 |:  92%|█████████▏| 24/26 [01:21<00:05,  2.74s/it]\u001b[A\n","Training loss: 0.47858685, IoU: 0.931342936802974 |:  92%|█████████▏| 24/26 [01:23<00:05,  2.74s/it] \u001b[A\n","Training loss: 0.47858685, IoU: 0.931342936802974 |:  96%|█████████▌| 25/26 [01:23<00:02,  2.73s/it]\u001b[A\n","Training loss: 0.5143175, IoU: 0.9286702346078056 |:  96%|█████████▌| 25/26 [01:26<00:02,  2.73s/it]\u001b[A\n","Training loss: 0.5143175, IoU: 0.9286702346078056 |: 100%|██████████| 26/26 [01:26<00:00,  3.33s/it]\n","Epoch Loop:   1%|▏         | 2/150 [15:25<16:21:20, 397.84s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48799855, IoU: 0.9126995668353712 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48799855, IoU: 0.9126995668353712 |:   4%|▍         | 1/26 [00:02<01:07,  2.72s/it]\u001b[A\n","Training loss: 0.6537211, IoU: 0.9484117663638328 |:   4%|▍         | 1/26 [00:03<01:07,  2.72s/it] \u001b[A\n","Training loss: 0.6537211, IoU: 0.9484117663638328 |:   8%|▊         | 2/26 [00:03<00:39,  1.66s/it]\u001b[A\n","Training loss: 0.48458648, IoU: 0.922917246791383 |:   8%|▊         | 2/26 [00:06<00:39,  1.66s/it]\u001b[A\n","Training loss: 0.48458648, IoU: 0.922917246791383 |:  12%|█▏        | 3/26 [00:06<00:49,  2.15s/it]\u001b[A\n","Training loss: 0.5202689, IoU: 0.9174619990572686 |:  12%|█▏        | 3/26 [00:09<00:49,  2.15s/it]\u001b[A\n","Training loss: 0.5202689, IoU: 0.9174619990572686 |:  15%|█▌        | 4/26 [00:09<00:52,  2.37s/it]\u001b[A\n","Training loss: 0.50231624, IoU: 0.9231688054143175 |:  15%|█▌        | 4/26 [00:11<00:52,  2.37s/it]\u001b[A\n","Training loss: 0.50231624, IoU: 0.9231688054143175 |:  19%|█▉        | 5/26 [00:11<00:52,  2.50s/it]\u001b[A\n","Training loss: 0.48330003, IoU: 0.9248606763875105 |:  19%|█▉        | 5/26 [00:14<00:52,  2.50s/it]\u001b[A\n","Training loss: 0.48330003, IoU: 0.9248606763875105 |:  23%|██▎       | 6/26 [00:14<00:51,  2.58s/it]\u001b[A\n","Training loss: 0.53837454, IoU: 0.9241307282902204 |:  23%|██▎       | 6/26 [00:17<00:51,  2.58s/it]\u001b[A\n","Training loss: 0.53837454, IoU: 0.9241307282902204 |:  27%|██▋       | 7/26 [00:17<00:49,  2.63s/it]\u001b[A\n","Training loss: 0.50531745, IoU: 0.9422487563194636 |:  27%|██▋       | 7/26 [00:20<00:49,  2.63s/it]\u001b[A\n","Training loss: 0.50531745, IoU: 0.9422487563194636 |:  31%|███       | 8/26 [00:20<00:48,  2.67s/it]\u001b[A\n","Training loss: 0.5132137, IoU: 0.9264862546359862 |:  31%|███       | 8/26 [00:22<00:48,  2.67s/it] \u001b[A\n","Training loss: 0.5132137, IoU: 0.9264862546359862 |:  35%|███▍      | 9/26 [00:22<00:45,  2.69s/it]\u001b[A\n","Training loss: 0.5654813, IoU: 0.9131899961009302 |:  35%|███▍      | 9/26 [00:25<00:45,  2.69s/it]\u001b[A\n","Training loss: 0.5654813, IoU: 0.9131899961009302 |:  38%|███▊      | 10/26 [00:25<00:43,  2.71s/it]\u001b[A\n","Training loss: 0.54961157, IoU: 0.9276789596053154 |:  38%|███▊      | 10/26 [00:28<00:43,  2.71s/it]\u001b[A\n","Training loss: 0.54961157, IoU: 0.9276789596053154 |:  42%|████▏     | 11/26 [00:28<00:40,  2.72s/it]\u001b[A\n","Training loss: 0.5309945, IoU: 0.8986138754620415 |:  42%|████▏     | 11/26 [00:31<00:40,  2.72s/it] \u001b[A\n","Training loss: 0.5309945, IoU: 0.8986138754620415 |:  46%|████▌     | 12/26 [00:31<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.44600835, IoU: 0.9219807093710026 |:  46%|████▌     | 12/26 [00:33<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.44600835, IoU: 0.9219807093710026 |:  50%|█████     | 13/26 [00:33<00:35,  2.74s/it]\u001b[A\n","Training loss: 0.5381843, IoU: 0.9210115102416213 |:  50%|█████     | 13/26 [00:36<00:35,  2.74s/it] \u001b[A\n","Training loss: 0.5381843, IoU: 0.9210115102416213 |:  54%|█████▍    | 14/26 [00:36<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.42072964, IoU: 0.9067560940269063 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.42072964, IoU: 0.9067560940269063 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.74s/it]\u001b[A\n","Training loss: 0.5053631, IoU: 0.9112791362456302 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.74s/it] \u001b[A\n","Training loss: 0.5053631, IoU: 0.9112791362456302 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.74s/it]\u001b[A\n","Training loss: 0.5285358, IoU: 0.9228836475902061 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.74s/it]\u001b[A\n","Training loss: 0.5285358, IoU: 0.9228836475902061 |:  65%|██████▌   | 17/26 [00:44<00:24,  2.74s/it]\u001b[A\n","Training loss: 0.46520185, IoU: 0.9202175792543524 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.74s/it]\u001b[A\n","Training loss: 0.46520185, IoU: 0.9202175792543524 |:  69%|██████▉   | 18/26 [00:47<00:21,  2.74s/it]\u001b[A\n","Training loss: 0.4684223, IoU: 0.9136543029802761 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.74s/it] \u001b[A\n","Training loss: 0.4684223, IoU: 0.9136543029802761 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.74s/it]\u001b[A\n","Training loss: 0.51617455, IoU: 0.9091719315865788 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.74s/it]\u001b[A\n","Training loss: 0.51617455, IoU: 0.9091719315865788 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.73s/it]\u001b[A\n","Training loss: 0.5309398, IoU: 0.9144904747099467 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.73s/it] \u001b[A\n","Training loss: 0.5309398, IoU: 0.9144904747099467 |:  81%|████████  | 21/26 [00:55<00:13,  2.73s/it]\u001b[A\n","Training loss: 0.481897, IoU: 0.9220431066555902 |:  81%|████████  | 21/26 [00:58<00:13,  2.73s/it] \u001b[A\n","Training loss: 0.481897, IoU: 0.9220431066555902 |:  85%|████████▍ | 22/26 [00:58<00:10,  2.73s/it]\u001b[A\n","Training loss: 0.4657801, IoU: 0.9203533727500373 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.73s/it]\u001b[A\n","Training loss: 0.4657801, IoU: 0.9203533727500373 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.49750113, IoU: 0.9165751258954842 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.49750113, IoU: 0.9165751258954842 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.472382, IoU: 0.9254694007601447 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.73s/it]  \u001b[A\n","Training loss: 0.472382, IoU: 0.9254694007601447 |:  96%|█████████▌| 25/26 [01:06<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.4976737, IoU: 0.9323951199111403 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.4976737, IoU: 0.9323951199111403 |: 100%|██████████| 26/26 [01:09<00:00,  2.66s/it]\n","Epoch Loop:   2%|▏         | 3/150 [16:42<10:15:45, 251.33s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.50096273, IoU: 0.9331717705808915 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.50096273, IoU: 0.9331717705808915 |:   4%|▍         | 1/26 [00:02<01:07,  2.71s/it]\u001b[A\n","Training loss: 0.5059736, IoU: 0.930831652224687 |:   4%|▍         | 1/26 [00:05<01:07,  2.71s/it]  \u001b[A\n","Training loss: 0.5059736, IoU: 0.930831652224687 |:   8%|▊         | 2/26 [00:05<01:04,  2.70s/it]\u001b[A\n","Training loss: 0.48959187, IoU: 0.9436228647310919 |:   8%|▊         | 2/26 [00:06<01:04,  2.70s/it]\u001b[A\n","Training loss: 0.48959187, IoU: 0.9436228647310919 |:  12%|█▏        | 3/26 [00:06<00:43,  1.89s/it]\u001b[A\n","Training loss: 0.5146586, IoU: 0.9264435418750678 |:  12%|█▏        | 3/26 [00:09<00:43,  1.89s/it] \u001b[A\n","Training loss: 0.5146586, IoU: 0.9264435418750678 |:  15%|█▌        | 4/26 [00:09<00:48,  2.21s/it]\u001b[A\n","Training loss: 0.5263665, IoU: 0.9231171068790439 |:  15%|█▌        | 4/26 [00:11<00:48,  2.21s/it]\u001b[A\n","Training loss: 0.5263665, IoU: 0.9231171068790439 |:  19%|█▉        | 5/26 [00:11<00:50,  2.39s/it]\u001b[A\n","Training loss: 0.49405012, IoU: 0.9328923601627714 |:  19%|█▉        | 5/26 [00:14<00:50,  2.39s/it]\u001b[A\n","Training loss: 0.49405012, IoU: 0.9328923601627714 |:  23%|██▎       | 6/26 [00:14<00:50,  2.50s/it]\u001b[A\n","Training loss: 0.5267943, IoU: 0.929444306382427 |:  23%|██▎       | 6/26 [00:17<00:50,  2.50s/it]  \u001b[A\n","Training loss: 0.5267943, IoU: 0.929444306382427 |:  27%|██▋       | 7/26 [00:17<00:48,  2.57s/it]\u001b[A\n","Training loss: 0.47065794, IoU: 0.9183748304904936 |:  27%|██▋       | 7/26 [00:19<00:48,  2.57s/it]\u001b[A\n","Training loss: 0.47065794, IoU: 0.9183748304904936 |:  31%|███       | 8/26 [00:19<00:47,  2.62s/it]\u001b[A\n","Training loss: 0.48531523, IoU: 0.926706937673672 |:  31%|███       | 8/26 [00:22<00:47,  2.62s/it] \u001b[A\n","Training loss: 0.48531523, IoU: 0.926706937673672 |:  35%|███▍      | 9/26 [00:22<00:44,  2.64s/it]\u001b[A\n","Training loss: 0.48877525, IoU: 0.9338041849499944 |:  35%|███▍      | 9/26 [00:25<00:44,  2.64s/it]\u001b[A\n","Training loss: 0.48877525, IoU: 0.9338041849499944 |:  38%|███▊      | 10/26 [00:25<00:42,  2.66s/it]\u001b[A\n","Training loss: 0.5601637, IoU: 0.9177285072611912 |:  38%|███▊      | 10/26 [00:27<00:42,  2.66s/it] \u001b[A\n","Training loss: 0.5601637, IoU: 0.9177285072611912 |:  42%|████▏     | 11/26 [00:27<00:40,  2.68s/it]\u001b[A\n","Training loss: 0.61070156, IoU: 0.921444976248833 |:  42%|████▏     | 11/26 [00:30<00:40,  2.68s/it]\u001b[A\n","Training loss: 0.61070156, IoU: 0.921444976248833 |:  46%|████▌     | 12/26 [00:30<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.4808622, IoU: 0.9334615663617623 |:  46%|████▌     | 12/26 [00:33<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.4808622, IoU: 0.9334615663617623 |:  50%|█████     | 13/26 [00:33<00:34,  2.69s/it]\u001b[A\n","Training loss: 0.49122652, IoU: 0.9196509661543604 |:  50%|█████     | 13/26 [00:36<00:34,  2.69s/it]\u001b[A\n","Training loss: 0.49122652, IoU: 0.9196509661543604 |:  54%|█████▍    | 14/26 [00:36<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.53117085, IoU: 0.9394212690099655 |:  54%|█████▍    | 14/26 [00:38<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.53117085, IoU: 0.9394212690099655 |:  58%|█████▊    | 15/26 [00:38<00:29,  2.70s/it]\u001b[A\n","Training loss: 0.51658124, IoU: 0.9342461752746388 |:  58%|█████▊    | 15/26 [00:41<00:29,  2.70s/it]\u001b[A\n","Training loss: 0.51658124, IoU: 0.9342461752746388 |:  62%|██████▏   | 16/26 [00:41<00:27,  2.70s/it]\u001b[A\n","Training loss: 0.51364243, IoU: 0.9130821771103549 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.70s/it]\u001b[A\n","Training loss: 0.51364243, IoU: 0.9130821771103549 |:  65%|██████▌   | 17/26 [00:44<00:24,  2.70s/it]\u001b[A\n","Training loss: 0.49511722, IoU: 0.9299335588469159 |:  65%|██████▌   | 17/26 [00:46<00:24,  2.70s/it]\u001b[A\n","Training loss: 0.49511722, IoU: 0.9299335588469159 |:  69%|██████▉   | 18/26 [00:46<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.50090575, IoU: 0.9063175170859564 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.50090575, IoU: 0.9063175170859564 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.71s/it]\u001b[A\n","Training loss: 0.5186777, IoU: 0.9272311274775262 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.71s/it] \u001b[A\n","Training loss: 0.5186777, IoU: 0.9272311274775262 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.5247475, IoU: 0.9298459095201305 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.5247475, IoU: 0.9298459095201305 |:  81%|████████  | 21/26 [00:55<00:13,  2.70s/it]\u001b[A\n","Training loss: 0.5000262, IoU: 0.945081143593827 |:  81%|████████  | 21/26 [00:57<00:13,  2.70s/it] \u001b[A\n","Training loss: 0.5000262, IoU: 0.945081143593827 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.5048556, IoU: 0.9400467502388742 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.5048556, IoU: 0.9400467502388742 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.71s/it]\u001b[A\n","Training loss: 0.49925226, IoU: 0.9244204606991598 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.71s/it]\u001b[A\n","Training loss: 0.49925226, IoU: 0.9244204606991598 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.71s/it]\u001b[A\n","Training loss: 0.4882217, IoU: 0.9229437294523294 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.71s/it] \u001b[A\n","Training loss: 0.4882217, IoU: 0.9229437294523294 |:  96%|█████████▌| 25/26 [01:05<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.4841663, IoU: 0.918987199926653 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.70s/it] \u001b[A\n","Training loss: 0.4841663, IoU: 0.918987199926653 |: 100%|██████████| 26/26 [01:08<00:00,  2.64s/it]\n","Epoch Loop:   3%|▎         | 4/150 [17:59<7:23:32, 182.28s/it] "]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4756788, IoU: 0.9195802843748507 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4756788, IoU: 0.9195802843748507 |:   4%|▍         | 1/26 [00:02<01:07,  2.72s/it]\u001b[A\n","Training loss: 0.496531, IoU: 0.9345516313899983 |:   4%|▍         | 1/26 [00:05<01:07,  2.72s/it] \u001b[A\n","Training loss: 0.496531, IoU: 0.9345516313899983 |:   8%|▊         | 2/26 [00:05<01:05,  2.71s/it]\u001b[A\n","Training loss: 0.48568428, IoU: 0.9269718471599357 |:   8%|▊         | 2/26 [00:08<01:05,  2.71s/it]\u001b[A\n","Training loss: 0.48568428, IoU: 0.9269718471599357 |:  12%|█▏        | 3/26 [00:08<01:02,  2.71s/it]\u001b[A\n","Training loss: 0.5128971, IoU: 0.9268183378465998 |:  12%|█▏        | 3/26 [00:09<01:02,  2.71s/it] \u001b[A\n","Training loss: 0.5128971, IoU: 0.9268183378465998 |:  15%|█▌        | 4/26 [00:09<00:44,  2.00s/it]\u001b[A\n","Training loss: 0.40971583, IoU: 0.9236824710053483 |:  15%|█▌        | 4/26 [00:11<00:44,  2.00s/it]\u001b[A\n","Training loss: 0.40971583, IoU: 0.9236824710053483 |:  19%|█▉        | 5/26 [00:11<00:47,  2.26s/it]\u001b[A\n","Training loss: 0.5515166, IoU: 0.9116989062381444 |:  19%|█▉        | 5/26 [00:14<00:47,  2.26s/it] \u001b[A\n","Training loss: 0.5515166, IoU: 0.9116989062381444 |:  23%|██▎       | 6/26 [00:14<00:48,  2.42s/it]\u001b[A\n","Training loss: 0.5391668, IoU: 0.9347780657025829 |:  23%|██▎       | 6/26 [00:17<00:48,  2.42s/it]\u001b[A\n","Training loss: 0.5391668, IoU: 0.9347780657025829 |:  27%|██▋       | 7/26 [00:17<00:47,  2.51s/it]\u001b[A\n","Training loss: 0.49455455, IoU: 0.9297233868687251 |:  27%|██▋       | 7/26 [00:19<00:47,  2.51s/it]\u001b[A\n","Training loss: 0.49455455, IoU: 0.9297233868687251 |:  31%|███       | 8/26 [00:19<00:46,  2.57s/it]\u001b[A\n","Training loss: 0.49543083, IoU: 0.9294063672398185 |:  31%|███       | 8/26 [00:22<00:46,  2.57s/it]\u001b[A\n","Training loss: 0.49543083, IoU: 0.9294063672398185 |:  35%|███▍      | 9/26 [00:22<00:44,  2.62s/it]\u001b[A\n","Training loss: 0.4928633, IoU: 0.9342742153557715 |:  35%|███▍      | 9/26 [00:25<00:44,  2.62s/it] \u001b[A\n","Training loss: 0.4928633, IoU: 0.9342742153557715 |:  38%|███▊      | 10/26 [00:25<00:42,  2.65s/it]\u001b[A\n","Training loss: 0.5256698, IoU: 0.9339205428316615 |:  38%|███▊      | 10/26 [00:28<00:42,  2.65s/it]\u001b[A\n","Training loss: 0.5256698, IoU: 0.9339205428316615 |:  42%|████▏     | 11/26 [00:28<00:40,  2.67s/it]\u001b[A\n","Training loss: 0.50271803, IoU: 0.935497318753706 |:  42%|████▏     | 11/26 [00:30<00:40,  2.67s/it]\u001b[A\n","Training loss: 0.50271803, IoU: 0.935497318753706 |:  46%|████▌     | 12/26 [00:30<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.48119074, IoU: 0.9294903242092428 |:  46%|████▌     | 12/26 [00:33<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.48119074, IoU: 0.9294903242092428 |:  50%|█████     | 13/26 [00:33<00:34,  2.69s/it]\u001b[A\n","Training loss: 0.45310268, IoU: 0.9223463237487394 |:  50%|█████     | 13/26 [00:36<00:34,  2.69s/it]\u001b[A\n","Training loss: 0.45310268, IoU: 0.9223463237487394 |:  54%|█████▍    | 14/26 [00:36<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.42585737, IoU: 0.9187316243350344 |:  54%|█████▍    | 14/26 [00:38<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.42585737, IoU: 0.9187316243350344 |:  58%|█████▊    | 15/26 [00:38<00:29,  2.70s/it]\u001b[A\n","Training loss: 0.5218418, IoU: 0.9293668954996186 |:  58%|█████▊    | 15/26 [00:41<00:29,  2.70s/it] \u001b[A\n","Training loss: 0.5218418, IoU: 0.9293668954996186 |:  62%|██████▏   | 16/26 [00:41<00:26,  2.69s/it]\u001b[A\n","Training loss: 0.49400765, IoU: 0.9263270912128573 |:  62%|██████▏   | 16/26 [00:44<00:26,  2.69s/it]\u001b[A\n","Training loss: 0.49400765, IoU: 0.9263270912128573 |:  65%|██████▌   | 17/26 [00:44<00:24,  2.69s/it]\u001b[A\n","Training loss: 0.5330862, IoU: 0.9458844434115509 |:  65%|██████▌   | 17/26 [00:46<00:24,  2.69s/it] \u001b[A\n","Training loss: 0.5330862, IoU: 0.9458844434115509 |:  69%|██████▉   | 18/26 [00:46<00:21,  2.69s/it]\u001b[A\n","Training loss: 0.46839494, IoU: 0.9116140073050497 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.69s/it]\u001b[A\n","Training loss: 0.46839494, IoU: 0.9116140073050497 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.70s/it]\u001b[A\n","Training loss: 0.4460057, IoU: 0.9130518682068266 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.70s/it] \u001b[A\n","Training loss: 0.4460057, IoU: 0.9130518682068266 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.71s/it]\u001b[A\n","Training loss: 0.53491807, IoU: 0.9402912737412441 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.71s/it]\u001b[A\n","Training loss: 0.53491807, IoU: 0.9402912737412441 |:  81%|████████  | 21/26 [00:55<00:13,  2.70s/it]\u001b[A\n","Training loss: 0.50970745, IoU: 0.9142055454816164 |:  81%|████████  | 21/26 [00:57<00:13,  2.70s/it]\u001b[A\n","Training loss: 0.50970745, IoU: 0.9142055454816164 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.49419603, IoU: 0.9289500946031859 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.49419603, IoU: 0.9289500946031859 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.70s/it]\u001b[A\n","Training loss: 0.49823287, IoU: 0.9328505426244791 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.70s/it]\u001b[A\n","Training loss: 0.49823287, IoU: 0.9328505426244791 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.4717789, IoU: 0.9155984622801271 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.70s/it] \u001b[A\n","Training loss: 0.4717789, IoU: 0.9155984622801271 |:  96%|█████████▌| 25/26 [01:05<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.42995122, IoU: 0.9072316275895276 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.42995122, IoU: 0.9072316275895276 |: 100%|██████████| 26/26 [01:08<00:00,  2.64s/it]\n","Epoch Loop:   3%|▎         | 5/150 [19:15<5:48:14, 144.10s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5323048, IoU: 0.9222354977444136 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5323048, IoU: 0.9222354977444136 |:   4%|▍         | 1/26 [00:02<01:07,  2.70s/it]\u001b[A\n","Training loss: 0.55899984, IoU: 0.91965419645125 |:   4%|▍         | 1/26 [00:05<01:07,  2.70s/it] \u001b[A\n","Training loss: 0.55899984, IoU: 0.91965419645125 |:   8%|▊         | 2/26 [00:05<01:04,  2.69s/it]\u001b[A\n","Training loss: 0.4549052, IoU: 0.9192691266562188 |:   8%|▊         | 2/26 [00:08<01:04,  2.69s/it]\u001b[A\n","Training loss: 0.4549052, IoU: 0.9192691266562188 |:  12%|█▏        | 3/26 [00:08<01:02,  2.70s/it]\u001b[A\n","Training loss: 0.5342611, IoU: 0.9232460033646978 |:  12%|█▏        | 3/26 [00:10<01:02,  2.70s/it]\u001b[A\n","Training loss: 0.5342611, IoU: 0.9232460033646978 |:  15%|█▌        | 4/26 [00:10<00:59,  2.72s/it]\u001b[A\n","Training loss: 0.5085151, IoU: 0.9160994042614741 |:  15%|█▌        | 4/26 [00:11<00:59,  2.72s/it]\u001b[A\n","Training loss: 0.5085151, IoU: 0.9160994042614741 |:  19%|█▉        | 5/26 [00:11<00:43,  2.07s/it]\u001b[A\n","Training loss: 0.4871291, IoU: 0.9260083577791075 |:  19%|█▉        | 5/26 [00:14<00:43,  2.07s/it]\u001b[A\n","Training loss: 0.4871291, IoU: 0.9260083577791075 |:  23%|██▎       | 6/26 [00:14<00:45,  2.29s/it]\u001b[A\n","Training loss: 0.48175547, IoU: 0.9287232917640653 |:  23%|██▎       | 6/26 [00:17<00:45,  2.29s/it]\u001b[A\n","Training loss: 0.48175547, IoU: 0.9287232917640653 |:  27%|██▋       | 7/26 [00:17<00:46,  2.43s/it]\u001b[A\n","Training loss: 0.49530357, IoU: 0.9388322836811087 |:  27%|██▋       | 7/26 [00:19<00:46,  2.43s/it]\u001b[A\n","Training loss: 0.49530357, IoU: 0.9388322836811087 |:  31%|███       | 8/26 [00:19<00:45,  2.51s/it]\u001b[A\n","Training loss: 0.5437203, IoU: 0.9404664123341092 |:  31%|███       | 8/26 [00:22<00:45,  2.51s/it] \u001b[A\n","Training loss: 0.5437203, IoU: 0.9404664123341092 |:  35%|███▍      | 9/26 [00:22<00:43,  2.57s/it]\u001b[A\n","Training loss: 0.49368137, IoU: 0.9228909036147208 |:  35%|███▍      | 9/26 [00:25<00:43,  2.57s/it]\u001b[A\n","Training loss: 0.49368137, IoU: 0.9228909036147208 |:  38%|███▊      | 10/26 [00:25<00:41,  2.61s/it]\u001b[A\n","Training loss: 0.58273137, IoU: 0.9229670949002153 |:  38%|███▊      | 10/26 [00:27<00:41,  2.61s/it]\u001b[A\n","Training loss: 0.58273137, IoU: 0.9229670949002153 |:  42%|████▏     | 11/26 [00:27<00:39,  2.64s/it]\u001b[A\n","Training loss: 0.47870153, IoU: 0.9363332410690357 |:  42%|████▏     | 11/26 [00:30<00:39,  2.64s/it]\u001b[A\n","Training loss: 0.47870153, IoU: 0.9363332410690357 |:  46%|████▌     | 12/26 [00:30<00:37,  2.66s/it]\u001b[A\n","Training loss: 0.4823391, IoU: 0.9262330767934386 |:  46%|████▌     | 12/26 [00:33<00:37,  2.66s/it] \u001b[A\n","Training loss: 0.4823391, IoU: 0.9262330767934386 |:  50%|█████     | 13/26 [00:33<00:34,  2.68s/it]\u001b[A\n","Training loss: 0.42226985, IoU: 0.9257664805676289 |:  50%|█████     | 13/26 [00:36<00:34,  2.68s/it]\u001b[A\n","Training loss: 0.42226985, IoU: 0.9257664805676289 |:  54%|█████▍    | 14/26 [00:36<00:32,  2.69s/it]\u001b[A\n","Training loss: 0.47757065, IoU: 0.9334770427531824 |:  54%|█████▍    | 14/26 [00:38<00:32,  2.69s/it]\u001b[A\n","Training loss: 0.47757065, IoU: 0.9334770427531824 |:  58%|█████▊    | 15/26 [00:38<00:29,  2.69s/it]\u001b[A\n","Training loss: 0.4477081, IoU: 0.9298701062104899 |:  58%|█████▊    | 15/26 [00:41<00:29,  2.69s/it] \u001b[A\n","Training loss: 0.4477081, IoU: 0.9298701062104899 |:  62%|██████▏   | 16/26 [00:41<00:26,  2.70s/it]\u001b[A\n","Training loss: 0.48989153, IoU: 0.9357538269615614 |:  62%|██████▏   | 16/26 [00:44<00:26,  2.70s/it]\u001b[A\n","Training loss: 0.48989153, IoU: 0.9357538269615614 |:  65%|██████▌   | 17/26 [00:44<00:24,  2.70s/it]\u001b[A\n","Training loss: 0.51317626, IoU: 0.9282990650733126 |:  65%|██████▌   | 17/26 [00:46<00:24,  2.70s/it]\u001b[A\n","Training loss: 0.51317626, IoU: 0.9282990650733126 |:  69%|██████▉   | 18/26 [00:46<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.47336096, IoU: 0.9346439283113899 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.47336096, IoU: 0.9346439283113899 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.69s/it]\u001b[A\n","Training loss: 0.53042334, IoU: 0.9286837906970526 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.69s/it]\u001b[A\n","Training loss: 0.53042334, IoU: 0.9286837906970526 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.56265676, IoU: 0.9106211732830409 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.56265676, IoU: 0.9106211732830409 |:  81%|████████  | 21/26 [00:55<00:13,  2.70s/it]\u001b[A\n","Training loss: 0.48095936, IoU: 0.9392703314578741 |:  81%|████████  | 21/26 [00:57<00:13,  2.70s/it]\u001b[A\n","Training loss: 0.48095936, IoU: 0.9392703314578741 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.5008936, IoU: 0.915440370574675 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.70s/it]  \u001b[A\n","Training loss: 0.5008936, IoU: 0.915440370574675 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4756891, IoU: 0.9216191515515801 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4756891, IoU: 0.9216191515515801 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.5660054, IoU: 0.9304194470037506 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.5660054, IoU: 0.9304194470037506 |:  96%|█████████▌| 25/26 [01:05<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.48700786, IoU: 0.9320784621750321 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.48700786, IoU: 0.9320784621750321 |: 100%|██████████| 26/26 [01:08<00:00,  2.64s/it]\n","Epoch Loop:   4%|▍         | 6/150 [20:31<4:50:31, 121.05s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5219521, IoU: 0.9261127049470883 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5219521, IoU: 0.9261127049470883 |:   4%|▍         | 1/26 [00:02<01:07,  2.71s/it]\u001b[A\n","Training loss: 0.5292127, IoU: 0.9396374332773464 |:   4%|▍         | 1/26 [00:05<01:07,  2.71s/it]\u001b[A\n","Training loss: 0.5292127, IoU: 0.9396374332773464 |:   8%|▊         | 2/26 [00:05<01:04,  2.70s/it]\u001b[A\n","Training loss: 0.5476132, IoU: 0.9247273597483847 |:   8%|▊         | 2/26 [00:08<01:04,  2.70s/it]\u001b[A\n","Training loss: 0.5476132, IoU: 0.9247273597483847 |:  12%|█▏        | 3/26 [00:08<01:02,  2.70s/it]\u001b[A\n","Training loss: 0.46735293, IoU: 0.9447191933938592 |:  12%|█▏        | 3/26 [00:10<01:02,  2.70s/it]\u001b[A\n","Training loss: 0.46735293, IoU: 0.9447191933938592 |:  15%|█▌        | 4/26 [00:10<00:59,  2.69s/it]\u001b[A\n","Training loss: 0.5006154, IoU: 0.9426432590053737 |:  15%|█▌        | 4/26 [00:13<00:59,  2.69s/it] \u001b[A\n","Training loss: 0.5006154, IoU: 0.9426432590053737 |:  19%|█▉        | 5/26 [00:13<00:56,  2.70s/it]\u001b[A\n","Training loss: 0.43993574, IoU: 0.9385812882649137 |:  19%|█▉        | 5/26 [00:14<00:56,  2.70s/it]\u001b[A\n","Training loss: 0.43993574, IoU: 0.9385812882649137 |:  23%|██▎       | 6/26 [00:14<00:41,  2.09s/it]\u001b[A\n","Training loss: 0.48424298, IoU: 0.9253802615472252 |:  23%|██▎       | 6/26 [00:17<00:41,  2.09s/it]\u001b[A\n","Training loss: 0.48424298, IoU: 0.9253802615472252 |:  27%|██▋       | 7/26 [00:17<00:43,  2.30s/it]\u001b[A\n","Training loss: 0.44709274, IoU: 0.9271539348647394 |:  27%|██▋       | 7/26 [00:19<00:43,  2.30s/it]\u001b[A\n","Training loss: 0.44709274, IoU: 0.9271539348647394 |:  31%|███       | 8/26 [00:19<00:43,  2.43s/it]\u001b[A\n","Training loss: 0.4604242, IoU: 0.9317951027197412 |:  31%|███       | 8/26 [00:22<00:43,  2.43s/it] \u001b[A\n","Training loss: 0.4604242, IoU: 0.9317951027197412 |:  35%|███▍      | 9/26 [00:22<00:42,  2.51s/it]\u001b[A\n","Training loss: 0.4935338, IoU: 0.9236326085496841 |:  35%|███▍      | 9/26 [00:25<00:42,  2.51s/it]\u001b[A\n","Training loss: 0.4935338, IoU: 0.9236326085496841 |:  38%|███▊      | 10/26 [00:25<00:41,  2.57s/it]\u001b[A\n","Training loss: 0.46861744, IoU: 0.9279745854854986 |:  38%|███▊      | 10/26 [00:27<00:41,  2.57s/it]\u001b[A\n","Training loss: 0.46861744, IoU: 0.9279745854854986 |:  42%|████▏     | 11/26 [00:27<00:39,  2.61s/it]\u001b[A\n","Training loss: 0.4598923, IoU: 0.9230047840667819 |:  42%|████▏     | 11/26 [00:30<00:39,  2.61s/it] \u001b[A\n","Training loss: 0.4598923, IoU: 0.9230047840667819 |:  46%|████▌     | 12/26 [00:30<00:36,  2.63s/it]\u001b[A\n","Training loss: 0.48556554, IoU: 0.9366410349547597 |:  46%|████▌     | 12/26 [00:33<00:36,  2.63s/it]\u001b[A\n","Training loss: 0.48556554, IoU: 0.9366410349547597 |:  50%|█████     | 13/26 [00:33<00:34,  2.66s/it]\u001b[A\n","Training loss: 0.44771135, IoU: 0.93763542404449 |:  50%|█████     | 13/26 [00:36<00:34,  2.66s/it]  \u001b[A\n","Training loss: 0.44771135, IoU: 0.93763542404449 |:  54%|█████▍    | 14/26 [00:36<00:32,  2.67s/it]\u001b[A\n","Training loss: 0.5051621, IoU: 0.9207696147388483 |:  54%|█████▍    | 14/26 [00:38<00:32,  2.67s/it]\u001b[A\n","Training loss: 0.5051621, IoU: 0.9207696147388483 |:  58%|█████▊    | 15/26 [00:38<00:29,  2.69s/it]\u001b[A\n","Training loss: 0.57234985, IoU: 0.9374689546751058 |:  58%|█████▊    | 15/26 [00:41<00:29,  2.69s/it]\u001b[A\n","Training loss: 0.57234985, IoU: 0.9374689546751058 |:  62%|██████▏   | 16/26 [00:41<00:26,  2.70s/it]\u001b[A\n","Training loss: 0.46567997, IoU: 0.9287661488383191 |:  62%|██████▏   | 16/26 [00:44<00:26,  2.70s/it]\u001b[A\n","Training loss: 0.46567997, IoU: 0.9287661488383191 |:  65%|██████▌   | 17/26 [00:44<00:24,  2.70s/it]\u001b[A\n","Training loss: 0.4721607, IoU: 0.9322963211660091 |:  65%|██████▌   | 17/26 [00:46<00:24,  2.70s/it] \u001b[A\n","Training loss: 0.4721607, IoU: 0.9322963211660091 |:  69%|██████▉   | 18/26 [00:46<00:21,  2.71s/it]\u001b[A\n","Training loss: 0.49788275, IoU: 0.9351121212254426 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.71s/it]\u001b[A\n","Training loss: 0.49788275, IoU: 0.9351121212254426 |:  73%|███████▎  | 19/26 [00:49<00:19,  2.72s/it]\u001b[A\n","Training loss: 0.48295653, IoU: 0.9402109892981176 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.72s/it]\u001b[A\n","Training loss: 0.48295653, IoU: 0.9402109892981176 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.73s/it]\u001b[A\n","Training loss: 0.48811758, IoU: 0.9487832789481758 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.73s/it]\u001b[A\n","Training loss: 0.48811758, IoU: 0.9487832789481758 |:  81%|████████  | 21/26 [00:55<00:13,  2.73s/it]\u001b[A\n","Training loss: 0.5157751, IoU: 0.9277194725079398 |:  81%|████████  | 21/26 [00:57<00:13,  2.73s/it] \u001b[A\n","Training loss: 0.5157751, IoU: 0.9277194725079398 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.74s/it]\u001b[A\n","Training loss: 0.5066378, IoU: 0.9354100006273919 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.74s/it]\u001b[A\n","Training loss: 0.5066378, IoU: 0.9354100006273919 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.4765141, IoU: 0.9434016042031357 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.4765141, IoU: 0.9434016042031357 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.5563776, IoU: 0.9287488619375723 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.5563776, IoU: 0.9287488619375723 |:  96%|█████████▌| 25/26 [01:06<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.53662735, IoU: 0.9070196863635646 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.53662735, IoU: 0.9070196863635646 |: 100%|██████████| 26/26 [01:08<00:00,  2.64s/it]\n","Epoch Loop:   5%|▍         | 7/150 [21:48<4:13:48, 106.49s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4432233, IoU: 0.929037062295345 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4432233, IoU: 0.929037062295345 |:   4%|▍         | 1/26 [00:02<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.49698853, IoU: 0.9305727764286396 |:   4%|▍         | 1/26 [00:05<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.49698853, IoU: 0.9305727764286396 |:   8%|▊         | 2/26 [00:05<01:05,  2.75s/it]\u001b[A\n","Training loss: 0.4968222, IoU: 0.9231443300095495 |:   8%|▊         | 2/26 [00:08<01:05,  2.75s/it] \u001b[A\n","Training loss: 0.4968222, IoU: 0.9231443300095495 |:  12%|█▏        | 3/26 [00:08<01:02,  2.74s/it]\u001b[A\n","Training loss: 0.5509495, IoU: 0.9305769924036206 |:  12%|█▏        | 3/26 [00:10<01:02,  2.74s/it]\u001b[A\n","Training loss: 0.5509495, IoU: 0.9305769924036206 |:  15%|█▌        | 4/26 [00:10<01:00,  2.73s/it]\u001b[A\n","Training loss: 0.53407544, IoU: 0.9346561902463475 |:  15%|█▌        | 4/26 [00:13<01:00,  2.73s/it]\u001b[A\n","Training loss: 0.53407544, IoU: 0.9346561902463475 |:  19%|█▉        | 5/26 [00:13<00:57,  2.73s/it]\u001b[A\n","Training loss: 0.47909898, IoU: 0.9295309236529814 |:  19%|█▉        | 5/26 [00:16<00:57,  2.73s/it]\u001b[A\n","Training loss: 0.47909898, IoU: 0.9295309236529814 |:  23%|██▎       | 6/26 [00:16<00:54,  2.73s/it]\u001b[A\n","Training loss: 0.53306973, IoU: 0.9073673116357929 |:  23%|██▎       | 6/26 [00:17<00:54,  2.73s/it]\u001b[A\n","Training loss: 0.53306973, IoU: 0.9073673116357929 |:  27%|██▋       | 7/26 [00:17<00:40,  2.14s/it]\u001b[A\n","Training loss: 0.50413305, IoU: 0.9181127764300885 |:  27%|██▋       | 7/26 [00:20<00:40,  2.14s/it]\u001b[A\n","Training loss: 0.50413305, IoU: 0.9181127764300885 |:  31%|███       | 8/26 [00:20<00:41,  2.33s/it]\u001b[A\n","Training loss: 0.49705717, IoU: 0.9326861035321878 |:  31%|███       | 8/26 [00:22<00:41,  2.33s/it]\u001b[A\n","Training loss: 0.49705717, IoU: 0.9326861035321878 |:  35%|███▍      | 9/26 [00:22<00:41,  2.45s/it]\u001b[A\n","Training loss: 0.47138333, IoU: 0.9315598971215984 |:  35%|███▍      | 9/26 [00:25<00:41,  2.45s/it]\u001b[A\n","Training loss: 0.47138333, IoU: 0.9315598971215984 |:  38%|███▊      | 10/26 [00:25<00:40,  2.55s/it]\u001b[A\n","Training loss: 0.4597607, IoU: 0.9296492384095009 |:  38%|███▊      | 10/26 [00:28<00:40,  2.55s/it] \u001b[A\n","Training loss: 0.4597607, IoU: 0.9296492384095009 |:  42%|████▏     | 11/26 [00:28<00:39,  2.60s/it]\u001b[A\n","Training loss: 0.46537134, IoU: 0.9287559351221375 |:  42%|████▏     | 11/26 [00:31<00:39,  2.60s/it]\u001b[A\n","Training loss: 0.46537134, IoU: 0.9287559351221375 |:  46%|████▌     | 12/26 [00:31<00:37,  2.65s/it]\u001b[A\n","Training loss: 0.46128005, IoU: 0.9396532649726997 |:  46%|████▌     | 12/26 [00:33<00:37,  2.65s/it]\u001b[A\n","Training loss: 0.46128005, IoU: 0.9396532649726997 |:  50%|█████     | 13/26 [00:33<00:34,  2.68s/it]\u001b[A\n","Training loss: 0.52555543, IoU: 0.9372356930609045 |:  50%|█████     | 13/26 [00:36<00:34,  2.68s/it]\u001b[A\n","Training loss: 0.52555543, IoU: 0.9372356930609045 |:  54%|█████▍    | 14/26 [00:36<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.54722714, IoU: 0.9283386483591272 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.54722714, IoU: 0.9283386483591272 |:  58%|█████▊    | 15/26 [00:39<00:29,  2.71s/it]\u001b[A\n","Training loss: 0.47519922, IoU: 0.9210087561912155 |:  58%|█████▊    | 15/26 [00:41<00:29,  2.71s/it]\u001b[A\n","Training loss: 0.47519922, IoU: 0.9210087561912155 |:  62%|██████▏   | 16/26 [00:41<00:27,  2.71s/it]\u001b[A\n","Training loss: 0.52937275, IoU: 0.9296069381633864 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.71s/it]\u001b[A\n","Training loss: 0.52937275, IoU: 0.9296069381633864 |:  65%|██████▌   | 17/26 [00:44<00:24,  2.70s/it]\u001b[A\n","Training loss: 0.44467327, IoU: 0.9428861255223369 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.70s/it]\u001b[A\n","Training loss: 0.44467327, IoU: 0.9428861255223369 |:  69%|██████▉   | 18/26 [00:47<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.50921905, IoU: 0.9409500148154901 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.50921905, IoU: 0.9409500148154901 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.69s/it]\u001b[A\n","Training loss: 0.5398293, IoU: 0.9336476145313212 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.69s/it] \u001b[A\n","Training loss: 0.5398293, IoU: 0.9336476145313212 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.4903651, IoU: 0.927201738816648 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.70s/it] \u001b[A\n","Training loss: 0.4903651, IoU: 0.927201738816648 |:  81%|████████  | 21/26 [00:55<00:13,  2.70s/it]\u001b[A\n","Training loss: 0.49806502, IoU: 0.933452550435779 |:  81%|████████  | 21/26 [00:58<00:13,  2.70s/it]\u001b[A\n","Training loss: 0.49806502, IoU: 0.933452550435779 |:  85%|████████▍ | 22/26 [00:58<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.50446165, IoU: 0.9330912166697994 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.50446165, IoU: 0.9330912166697994 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.70s/it]\u001b[A\n","Training loss: 0.4528311, IoU: 0.9182910666686522 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.70s/it] \u001b[A\n","Training loss: 0.4528311, IoU: 0.9182910666686522 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.46801567, IoU: 0.9411011607896439 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.46801567, IoU: 0.9411011607896439 |:  96%|█████████▌| 25/26 [01:06<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.49463916, IoU: 0.9374954082563698 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.49463916, IoU: 0.9374954082563698 |: 100%|██████████| 26/26 [01:08<00:00,  2.65s/it]\n","Epoch Loop:   5%|▌         | 8/150 [23:05<3:49:34, 97.00s/it] "]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47514433, IoU: 0.931424631237014 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47514433, IoU: 0.931424631237014 |:   4%|▍         | 1/26 [00:02<01:07,  2.71s/it]\u001b[A\n","Training loss: 0.48132223, IoU: 0.9241799643817538 |:   4%|▍         | 1/26 [00:05<01:07,  2.71s/it]\u001b[A\n","Training loss: 0.48132223, IoU: 0.9241799643817538 |:   8%|▊         | 2/26 [00:05<01:05,  2.72s/it]\u001b[A\n","Training loss: 0.4868701, IoU: 0.925211484736319 |:   8%|▊         | 2/26 [00:08<01:05,  2.72s/it]  \u001b[A\n","Training loss: 0.4868701, IoU: 0.925211484736319 |:  12%|█▏        | 3/26 [00:08<01:02,  2.72s/it]\u001b[A\n","Training loss: 0.49165604, IoU: 0.933951638569065 |:  12%|█▏        | 3/26 [00:10<01:02,  2.72s/it]\u001b[A\n","Training loss: 0.49165604, IoU: 0.933951638569065 |:  15%|█▌        | 4/26 [00:10<00:59,  2.71s/it]\u001b[A\n","Training loss: 0.4364384, IoU: 0.9406662865295249 |:  15%|█▌        | 4/26 [00:13<00:59,  2.71s/it]\u001b[A\n","Training loss: 0.4364384, IoU: 0.9406662865295249 |:  19%|█▉        | 5/26 [00:13<00:57,  2.72s/it]\u001b[A\n","Training loss: 0.48793387, IoU: 0.939756155273547 |:  19%|█▉        | 5/26 [00:16<00:57,  2.72s/it]\u001b[A\n","Training loss: 0.48793387, IoU: 0.939756155273547 |:  23%|██▎       | 6/26 [00:16<00:54,  2.72s/it]\u001b[A\n","Training loss: 0.49856567, IoU: 0.9403039342880517 |:  23%|██▎       | 6/26 [00:19<00:54,  2.72s/it]\u001b[A\n","Training loss: 0.49856567, IoU: 0.9403039342880517 |:  27%|██▋       | 7/26 [00:19<00:51,  2.71s/it]\u001b[A\n","Training loss: 0.5590379, IoU: 0.9373950587670904 |:  27%|██▋       | 7/26 [00:19<00:51,  2.71s/it] \u001b[A\n","Training loss: 0.5590379, IoU: 0.9373950587670904 |:  31%|███       | 8/26 [00:19<00:38,  2.14s/it]\u001b[A\n","Training loss: 0.4920139, IoU: 0.9206306292556682 |:  31%|███       | 8/26 [00:22<00:38,  2.14s/it]\u001b[A\n","Training loss: 0.4920139, IoU: 0.9206306292556682 |:  35%|███▍      | 9/26 [00:22<00:39,  2.31s/it]\u001b[A\n","Training loss: 0.4655797, IoU: 0.9294714857704248 |:  35%|███▍      | 9/26 [00:25<00:39,  2.31s/it]\u001b[A\n","Training loss: 0.4655797, IoU: 0.9294714857704248 |:  38%|███▊      | 10/26 [00:25<00:38,  2.43s/it]\u001b[A\n","Training loss: 0.48338223, IoU: 0.9352857560650475 |:  38%|███▊      | 10/26 [00:27<00:38,  2.43s/it]\u001b[A\n","Training loss: 0.48338223, IoU: 0.9352857560650475 |:  42%|████▏     | 11/26 [00:27<00:37,  2.51s/it]\u001b[A\n","Training loss: 0.44857234, IoU: 0.9427488762027417 |:  42%|████▏     | 11/26 [00:30<00:37,  2.51s/it]\u001b[A\n","Training loss: 0.44857234, IoU: 0.9427488762027417 |:  46%|████▌     | 12/26 [00:30<00:35,  2.56s/it]\u001b[A\n","Training loss: 0.49002755, IoU: 0.9347057302727558 |:  46%|████▌     | 12/26 [00:33<00:35,  2.56s/it]\u001b[A\n","Training loss: 0.49002755, IoU: 0.9347057302727558 |:  50%|█████     | 13/26 [00:33<00:33,  2.60s/it]\u001b[A\n","Training loss: 0.48322567, IoU: 0.9261902971748651 |:  50%|█████     | 13/26 [00:36<00:33,  2.60s/it]\u001b[A\n","Training loss: 0.48322567, IoU: 0.9261902971748651 |:  54%|█████▍    | 14/26 [00:36<00:31,  2.63s/it]\u001b[A\n","Training loss: 0.5067748, IoU: 0.9381608145891962 |:  54%|█████▍    | 14/26 [00:38<00:31,  2.63s/it] \u001b[A\n","Training loss: 0.5067748, IoU: 0.9381608145891962 |:  58%|█████▊    | 15/26 [00:38<00:29,  2.64s/it]\u001b[A\n","Training loss: 0.4505111, IoU: 0.9310009741262563 |:  58%|█████▊    | 15/26 [00:41<00:29,  2.64s/it]\u001b[A\n","Training loss: 0.4505111, IoU: 0.9310009741262563 |:  62%|██████▏   | 16/26 [00:41<00:26,  2.65s/it]\u001b[A\n","Training loss: 0.43755737, IoU: 0.9418254815788393 |:  62%|██████▏   | 16/26 [00:44<00:26,  2.65s/it]\u001b[A\n","Training loss: 0.43755737, IoU: 0.9418254815788393 |:  65%|██████▌   | 17/26 [00:44<00:24,  2.67s/it]\u001b[A\n","Training loss: 0.49049318, IoU: 0.9272196744418333 |:  65%|██████▌   | 17/26 [00:46<00:24,  2.67s/it]\u001b[A\n","Training loss: 0.49049318, IoU: 0.9272196744418333 |:  69%|██████▉   | 18/26 [00:46<00:21,  2.68s/it]\u001b[A\n","Training loss: 0.49776453, IoU: 0.9404859229929604 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.68s/it]\u001b[A\n","Training loss: 0.49776453, IoU: 0.9404859229929604 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.41698596, IoU: 0.9324347744937275 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.41698596, IoU: 0.9324347744937275 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.68s/it]\u001b[A\n","Training loss: 0.5071292, IoU: 0.9200266386644751 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.68s/it] \u001b[A\n","Training loss: 0.5071292, IoU: 0.9200266386644751 |:  81%|████████  | 21/26 [00:54<00:13,  2.68s/it]\u001b[A\n","Training loss: 0.42713314, IoU: 0.9215075358020984 |:  81%|████████  | 21/26 [00:57<00:13,  2.68s/it]\u001b[A\n","Training loss: 0.42713314, IoU: 0.9215075358020984 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.68s/it]\u001b[A\n","Training loss: 0.45415574, IoU: 0.9359052182793318 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.68s/it]\u001b[A\n","Training loss: 0.45415574, IoU: 0.9359052182793318 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.68s/it]\u001b[A\n","Training loss: 0.49027723, IoU: 0.9439638071459284 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.68s/it]\u001b[A\n","Training loss: 0.49027723, IoU: 0.9439638071459284 |:  92%|█████████▏| 24/26 [01:02<00:05,  2.67s/it]\u001b[A\n","Training loss: 0.50440484, IoU: 0.9411813098464092 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.67s/it]\u001b[A\n","Training loss: 0.50440484, IoU: 0.9411813098464092 |:  96%|█████████▌| 25/26 [01:05<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.5248171, IoU: 0.9386308891586375 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.68s/it] \u001b[A\n","Training loss: 0.5248171, IoU: 0.9386308891586375 |: 100%|██████████| 26/26 [01:08<00:00,  2.62s/it]\n","Epoch Loop:   6%|▌         | 9/150 [24:21<3:32:28, 90.42s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44817907, IoU: 0.9364292066967035 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44817907, IoU: 0.9364292066967035 |:   4%|▍         | 1/26 [00:02<01:08,  2.72s/it]\u001b[A\n","Training loss: 0.44341746, IoU: 0.9331001386894461 |:   4%|▍         | 1/26 [00:05<01:08,  2.72s/it]\u001b[A\n","Training loss: 0.44341746, IoU: 0.9331001386894461 |:   8%|▊         | 2/26 [00:05<01:04,  2.71s/it]\u001b[A\n","Training loss: 0.43928915, IoU: 0.9256246108905976 |:   8%|▊         | 2/26 [00:08<01:04,  2.71s/it]\u001b[A\n","Training loss: 0.43928915, IoU: 0.9256246108905976 |:  12%|█▏        | 3/26 [00:08<01:02,  2.73s/it]\u001b[A\n","Training loss: 0.42731285, IoU: 0.9267538545105085 |:  12%|█▏        | 3/26 [00:10<01:02,  2.73s/it]\u001b[A\n","Training loss: 0.42731285, IoU: 0.9267538545105085 |:  15%|█▌        | 4/26 [00:10<01:00,  2.73s/it]\u001b[A\n","Training loss: 0.48794615, IoU: 0.935200029281505 |:  15%|█▌        | 4/26 [00:13<01:00,  2.73s/it] \u001b[A\n","Training loss: 0.48794615, IoU: 0.935200029281505 |:  19%|█▉        | 5/26 [00:13<00:57,  2.72s/it]\u001b[A\n","Training loss: 0.53951514, IoU: 0.9407377841766272 |:  19%|█▉        | 5/26 [00:16<00:57,  2.72s/it]\u001b[A\n","Training loss: 0.53951514, IoU: 0.9407377841766272 |:  23%|██▎       | 6/26 [00:16<00:54,  2.73s/it]\u001b[A\n","Training loss: 0.4946784, IoU: 0.9394062547911135 |:  23%|██▎       | 6/26 [00:19<00:54,  2.73s/it] \u001b[A\n","Training loss: 0.4946784, IoU: 0.9394062547911135 |:  27%|██▋       | 7/26 [00:19<00:51,  2.74s/it]\u001b[A\n","Training loss: 0.5170437, IoU: 0.9373805206150665 |:  27%|██▋       | 7/26 [00:21<00:51,  2.74s/it]\u001b[A\n","Training loss: 0.5170437, IoU: 0.9373805206150665 |:  31%|███       | 8/26 [00:21<00:48,  2.72s/it]\u001b[A\n","Training loss: 0.60515696, IoU: 0.9120181669966227 |:  31%|███       | 8/26 [00:22<00:48,  2.72s/it]\u001b[A\n","Training loss: 0.60515696, IoU: 0.9120181669966227 |:  35%|███▍      | 9/26 [00:22<00:36,  2.16s/it]\u001b[A\n","Training loss: 0.49120277, IoU: 0.9351886157776196 |:  35%|███▍      | 9/26 [00:25<00:36,  2.16s/it]\u001b[A\n","Training loss: 0.49120277, IoU: 0.9351886157776196 |:  38%|███▊      | 10/26 [00:25<00:37,  2.33s/it]\u001b[A\n","Training loss: 0.513224, IoU: 0.9311416959131039 |:  38%|███▊      | 10/26 [00:28<00:37,  2.33s/it]  \u001b[A\n","Training loss: 0.513224, IoU: 0.9311416959131039 |:  42%|████▏     | 11/26 [00:28<00:36,  2.46s/it]\u001b[A\n","Training loss: 0.46599895, IoU: 0.9370815562731424 |:  42%|████▏     | 11/26 [00:30<00:36,  2.46s/it]\u001b[A\n","Training loss: 0.46599895, IoU: 0.9370815562731424 |:  46%|████▌     | 12/26 [00:30<00:35,  2.54s/it]\u001b[A\n","Training loss: 0.5139024, IoU: 0.9325678204241099 |:  46%|████▌     | 12/26 [00:33<00:35,  2.54s/it] \u001b[A\n","Training loss: 0.5139024, IoU: 0.9325678204241099 |:  50%|█████     | 13/26 [00:33<00:33,  2.60s/it]\u001b[A\n","Training loss: 0.5115506, IoU: 0.9309169223605325 |:  50%|█████     | 13/26 [00:36<00:33,  2.60s/it]\u001b[A\n","Training loss: 0.5115506, IoU: 0.9309169223605325 |:  54%|█████▍    | 14/26 [00:36<00:31,  2.64s/it]\u001b[A\n","Training loss: 0.47455508, IoU: 0.9420659424521695 |:  54%|█████▍    | 14/26 [00:39<00:31,  2.64s/it]\u001b[A\n","Training loss: 0.47455508, IoU: 0.9420659424521695 |:  58%|█████▊    | 15/26 [00:39<00:29,  2.66s/it]\u001b[A\n","Training loss: 0.47283646, IoU: 0.929184400156932 |:  58%|█████▊    | 15/26 [00:41<00:29,  2.66s/it] \u001b[A\n","Training loss: 0.47283646, IoU: 0.929184400156932 |:  62%|██████▏   | 16/26 [00:41<00:26,  2.68s/it]\u001b[A\n","Training loss: 0.52176046, IoU: 0.9361654431689412 |:  62%|██████▏   | 16/26 [00:44<00:26,  2.68s/it]\u001b[A\n","Training loss: 0.52176046, IoU: 0.9361654431689412 |:  65%|██████▌   | 17/26 [00:44<00:24,  2.69s/it]\u001b[A\n","Training loss: 0.48472637, IoU: 0.9236321458839555 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.69s/it]\u001b[A\n","Training loss: 0.48472637, IoU: 0.9236321458839555 |:  69%|██████▉   | 18/26 [00:47<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.5305385, IoU: 0.911019383829717 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.70s/it]  \u001b[A\n","Training loss: 0.5305385, IoU: 0.911019383829717 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.70s/it]\u001b[A\n","Training loss: 0.521284, IoU: 0.9289480264178924 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.70s/it]\u001b[A\n","Training loss: 0.521284, IoU: 0.9289480264178924 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.69s/it]\u001b[A\n","Training loss: 0.5148696, IoU: 0.9299103756472412 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.69s/it]\u001b[A\n","Training loss: 0.5148696, IoU: 0.9299103756472412 |:  81%|████████  | 21/26 [00:55<00:13,  2.69s/it]\u001b[A\n","Training loss: 0.43926823, IoU: 0.9300724210443566 |:  81%|████████  | 21/26 [00:57<00:13,  2.69s/it]\u001b[A\n","Training loss: 0.43926823, IoU: 0.9300724210443566 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.69s/it]\u001b[A\n","Training loss: 0.4442718, IoU: 0.9259742696546717 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.69s/it] \u001b[A\n","Training loss: 0.4442718, IoU: 0.9259742696546717 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4774825, IoU: 0.9403737145483445 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4774825, IoU: 0.9403737145483445 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.68s/it]\u001b[A\n","Training loss: 0.5317469, IoU: 0.9264579354017174 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.68s/it]\u001b[A\n","Training loss: 0.5317469, IoU: 0.9264579354017174 |:  96%|█████████▌| 25/26 [01:06<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.45282352, IoU: 0.924387916090454 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.45282352, IoU: 0.924387916090454 |: 100%|██████████| 26/26 [01:08<00:00,  2.64s/it]\n","Epoch Loop:   7%|▋         | 10/150 [25:37<3:20:50, 86.08s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.06311667868406572\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48398322, IoU: 0.9306392845313017 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48398322, IoU: 0.9306392845313017 |:   4%|▍         | 1/26 [00:02<01:07,  2.69s/it]\u001b[A\n","Training loss: 0.44849765, IoU: 0.9335149480879457 |:   4%|▍         | 1/26 [00:05<01:07,  2.69s/it]\u001b[A\n","Training loss: 0.44849765, IoU: 0.9335149480879457 |:   8%|▊         | 2/26 [00:05<01:04,  2.68s/it]\u001b[A\n","Training loss: 0.4617886, IoU: 0.9378955110754313 |:   8%|▊         | 2/26 [00:08<01:04,  2.68s/it] \u001b[A\n","Training loss: 0.4617886, IoU: 0.9378955110754313 |:  12%|█▏        | 3/26 [00:08<01:01,  2.68s/it]\u001b[A\n","Training loss: 0.5505757, IoU: 0.9415288528648332 |:  12%|█▏        | 3/26 [00:10<01:01,  2.68s/it]\u001b[A\n","Training loss: 0.5505757, IoU: 0.9415288528648332 |:  15%|█▌        | 4/26 [00:10<00:59,  2.68s/it]\u001b[A\n","Training loss: 0.44338167, IoU: 0.9402582632831271 |:  15%|█▌        | 4/26 [00:13<00:59,  2.68s/it]\u001b[A\n","Training loss: 0.44338167, IoU: 0.9402582632831271 |:  19%|█▉        | 5/26 [00:13<00:56,  2.69s/it]\u001b[A\n","Training loss: 0.47340834, IoU: 0.9414180070347117 |:  19%|█▉        | 5/26 [00:16<00:56,  2.69s/it]\u001b[A\n","Training loss: 0.47340834, IoU: 0.9414180070347117 |:  23%|██▎       | 6/26 [00:16<00:54,  2.70s/it]\u001b[A\n","Training loss: 0.5263807, IoU: 0.9437510776935052 |:  23%|██▎       | 6/26 [00:18<00:54,  2.70s/it] \u001b[A\n","Training loss: 0.5263807, IoU: 0.9437510776935052 |:  27%|██▋       | 7/26 [00:18<00:51,  2.70s/it]\u001b[A\n","Training loss: 0.45698744, IoU: 0.9302495730104204 |:  27%|██▋       | 7/26 [00:21<00:51,  2.70s/it]\u001b[A\n","Training loss: 0.45698744, IoU: 0.9302495730104204 |:  31%|███       | 8/26 [00:21<00:48,  2.71s/it]\u001b[A\n","Training loss: 0.49744844, IoU: 0.952534304116494 |:  31%|███       | 8/26 [00:24<00:48,  2.71s/it] \u001b[A\n","Training loss: 0.49744844, IoU: 0.952534304116494 |:  35%|███▍      | 9/26 [00:24<00:46,  2.71s/it]\u001b[A\n","Training loss: 0.5285583, IoU: 0.9367069945727792 |:  35%|███▍      | 9/26 [00:25<00:46,  2.71s/it]\u001b[A\n","Training loss: 0.5285583, IoU: 0.9367069945727792 |:  38%|███▊      | 10/26 [00:25<00:34,  2.16s/it]\u001b[A\n","Training loss: 0.4577999, IoU: 0.9275590038956457 |:  38%|███▊      | 10/26 [00:27<00:34,  2.16s/it]\u001b[A\n","Training loss: 0.4577999, IoU: 0.9275590038956457 |:  42%|████▏     | 11/26 [00:27<00:34,  2.32s/it]\u001b[A\n","Training loss: 0.5278603, IoU: 0.9322201897899682 |:  42%|████▏     | 11/26 [00:30<00:34,  2.32s/it]\u001b[A\n","Training loss: 0.5278603, IoU: 0.9322201897899682 |:  46%|████▌     | 12/26 [00:30<00:34,  2.43s/it]\u001b[A\n","Training loss: 0.39531985, IoU: 0.9319336814407699 |:  46%|████▌     | 12/26 [00:33<00:34,  2.43s/it]\u001b[A\n","Training loss: 0.39531985, IoU: 0.9319336814407699 |:  50%|█████     | 13/26 [00:33<00:32,  2.52s/it]\u001b[A\n","Training loss: 0.49790198, IoU: 0.9319254365266635 |:  50%|█████     | 13/26 [00:35<00:32,  2.52s/it]\u001b[A\n","Training loss: 0.49790198, IoU: 0.9319254365266635 |:  54%|█████▍    | 14/26 [00:35<00:30,  2.56s/it]\u001b[A\n","Training loss: 0.46073303, IoU: 0.9381209530068862 |:  54%|█████▍    | 14/26 [00:38<00:30,  2.56s/it]\u001b[A\n","Training loss: 0.46073303, IoU: 0.9381209530068862 |:  58%|█████▊    | 15/26 [00:38<00:28,  2.60s/it]\u001b[A\n","Training loss: 0.46014982, IoU: 0.9294436515836562 |:  58%|█████▊    | 15/26 [00:41<00:28,  2.60s/it]\u001b[A\n","Training loss: 0.46014982, IoU: 0.9294436515836562 |:  62%|██████▏   | 16/26 [00:41<00:26,  2.63s/it]\u001b[A\n","Training loss: 0.502295, IoU: 0.945272978122331 |:  62%|██████▏   | 16/26 [00:44<00:26,  2.63s/it]   \u001b[A\n","Training loss: 0.502295, IoU: 0.945272978122331 |:  65%|██████▌   | 17/26 [00:44<00:23,  2.65s/it]\u001b[A\n","Training loss: 0.4504587, IoU: 0.9353363934366061 |:  65%|██████▌   | 17/26 [00:46<00:23,  2.65s/it]\u001b[A\n","Training loss: 0.4504587, IoU: 0.9353363934366061 |:  69%|██████▉   | 18/26 [00:46<00:21,  2.66s/it]\u001b[A\n","Training loss: 0.48743987, IoU: 0.9357542418123158 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.66s/it]\u001b[A\n","Training loss: 0.48743987, IoU: 0.9357542418123158 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.69s/it]\u001b[A\n","Training loss: 0.48480374, IoU: 0.9479207309337502 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.69s/it]\u001b[A\n","Training loss: 0.48480374, IoU: 0.9479207309337502 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.68s/it]\u001b[A\n","Training loss: 0.47307372, IoU: 0.9468423422578285 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.68s/it]\u001b[A\n","Training loss: 0.47307372, IoU: 0.9468423422578285 |:  81%|████████  | 21/26 [00:54<00:13,  2.68s/it]\u001b[A\n","Training loss: 0.4449061, IoU: 0.9410753436115978 |:  81%|████████  | 21/26 [00:57<00:13,  2.68s/it] \u001b[A\n","Training loss: 0.4449061, IoU: 0.9410753436115978 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.68s/it]\u001b[A\n","Training loss: 0.50366795, IoU: 0.925164395904165 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.68s/it]\u001b[A\n","Training loss: 0.50366795, IoU: 0.925164395904165 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.68s/it]\u001b[A\n","Training loss: 0.45779026, IoU: 0.9402870817961333 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.68s/it]\u001b[A\n","Training loss: 0.45779026, IoU: 0.9402870817961333 |:  92%|█████████▏| 24/26 [01:02<00:05,  2.67s/it]\u001b[A\n","Training loss: 0.46899927, IoU: 0.9282370348242915 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.67s/it]\u001b[A\n","Training loss: 0.46899927, IoU: 0.9282370348242915 |:  96%|█████████▌| 25/26 [01:05<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.44394588, IoU: 0.9394633359950583 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.44394588, IoU: 0.9394633359950583 |: 100%|██████████| 26/26 [01:08<00:00,  2.63s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.06311667868406572 to 0.10912693706465451\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:   7%|▋         | 11/150 [26:55<3:13:42, 83.61s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4785595, IoU: 0.9342187300814704 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4785595, IoU: 0.9342187300814704 |:   4%|▍         | 1/26 [00:02<01:10,  2.83s/it]\u001b[A\n","Training loss: 0.5049089, IoU: 0.930093852987534 |:   4%|▍         | 1/26 [00:05<01:10,  2.83s/it] \u001b[A\n","Training loss: 0.5049089, IoU: 0.930093852987534 |:   8%|▊         | 2/26 [00:05<01:05,  2.75s/it]\u001b[A\n","Training loss: 0.41823998, IoU: 0.9379980636031876 |:   8%|▊         | 2/26 [00:08<01:05,  2.75s/it]\u001b[A\n","Training loss: 0.41823998, IoU: 0.9379980636031876 |:  12%|█▏        | 3/26 [00:08<01:02,  2.73s/it]\u001b[A\n","Training loss: 0.480407, IoU: 0.9311825354567017 |:  12%|█▏        | 3/26 [00:11<01:02,  2.73s/it]  \u001b[A\n","Training loss: 0.480407, IoU: 0.9311825354567017 |:  15%|█▌        | 4/26 [00:11<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.54880834, IoU: 0.9308153761149262 |:  15%|█▌        | 4/26 [00:13<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.54880834, IoU: 0.9308153761149262 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.4523312, IoU: 0.9366260551611844 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it] \u001b[A\n","Training loss: 0.4523312, IoU: 0.9366260551611844 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.5117573, IoU: 0.9414571502085975 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.5117573, IoU: 0.9414571502085975 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.47609884, IoU: 0.9356164213710927 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.47609884, IoU: 0.9356164213710927 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.47292304, IoU: 0.9276387592534977 |:  31%|███       | 8/26 [00:24<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.47292304, IoU: 0.9276387592534977 |:  35%|███▍      | 9/26 [00:24<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.49064934, IoU: 0.9329548300910078 |:  35%|███▍      | 9/26 [00:27<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.49064934, IoU: 0.9329548300910078 |:  38%|███▊      | 10/26 [00:27<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.43466592, IoU: 0.9339505963675793 |:  38%|███▊      | 10/26 [00:28<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.43466592, IoU: 0.9339505963675793 |:  42%|████▏     | 11/26 [00:28<00:32,  2.18s/it]\u001b[A\n","Training loss: 0.48743027, IoU: 0.9278049026023053 |:  42%|████▏     | 11/26 [00:31<00:32,  2.18s/it]\u001b[A\n","Training loss: 0.48743027, IoU: 0.9278049026023053 |:  46%|████▌     | 12/26 [00:31<00:32,  2.33s/it]\u001b[A\n","Training loss: 0.45614085, IoU: 0.9459537503281388 |:  46%|████▌     | 12/26 [00:33<00:32,  2.33s/it]\u001b[A\n","Training loss: 0.45614085, IoU: 0.9459537503281388 |:  50%|█████     | 13/26 [00:33<00:31,  2.44s/it]\u001b[A\n","Training loss: 0.48892468, IoU: 0.9325624783546156 |:  50%|█████     | 13/26 [00:36<00:31,  2.44s/it]\u001b[A\n","Training loss: 0.48892468, IoU: 0.9325624783546156 |:  54%|█████▍    | 14/26 [00:36<00:30,  2.51s/it]\u001b[A\n","Training loss: 0.5237719, IoU: 0.934776514880252 |:  54%|█████▍    | 14/26 [00:39<00:30,  2.51s/it]  \u001b[A\n","Training loss: 0.5237719, IoU: 0.934776514880252 |:  58%|█████▊    | 15/26 [00:39<00:28,  2.56s/it]\u001b[A\n","Training loss: 0.50567436, IoU: 0.9361347584658634 |:  58%|█████▊    | 15/26 [00:41<00:28,  2.56s/it]\u001b[A\n","Training loss: 0.50567436, IoU: 0.9361347584658634 |:  62%|██████▏   | 16/26 [00:41<00:26,  2.60s/it]\u001b[A\n","Training loss: 0.4254918, IoU: 0.9354255155826211 |:  62%|██████▏   | 16/26 [00:44<00:26,  2.60s/it] \u001b[A\n","Training loss: 0.4254918, IoU: 0.9354255155826211 |:  65%|██████▌   | 17/26 [00:44<00:23,  2.64s/it]\u001b[A\n","Training loss: 0.48248103, IoU: 0.9328396262679355 |:  65%|██████▌   | 17/26 [00:47<00:23,  2.64s/it]\u001b[A\n","Training loss: 0.48248103, IoU: 0.9328396262679355 |:  69%|██████▉   | 18/26 [00:47<00:21,  2.66s/it]\u001b[A\n","Training loss: 0.49092945, IoU: 0.9413297337281591 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.66s/it]\u001b[A\n","Training loss: 0.49092945, IoU: 0.9413297337281591 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.50825655, IoU: 0.9449226552701259 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.50825655, IoU: 0.9449226552701259 |:  77%|███████▋  | 20/26 [00:52<00:16,  2.68s/it]\u001b[A\n","Training loss: 0.51404524, IoU: 0.9301603420756318 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.68s/it]\u001b[A\n","Training loss: 0.51404524, IoU: 0.9301603420756318 |:  81%|████████  | 21/26 [00:55<00:13,  2.69s/it]\u001b[A\n","Training loss: 0.49334955, IoU: 0.9426410778965355 |:  81%|████████  | 21/26 [00:58<00:13,  2.69s/it]\u001b[A\n","Training loss: 0.49334955, IoU: 0.9426410778965355 |:  85%|████████▍ | 22/26 [00:58<00:10,  2.69s/it]\u001b[A\n","Training loss: 0.419187, IoU: 0.9414853938022518 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.69s/it]  \u001b[A\n","Training loss: 0.419187, IoU: 0.9414853938022518 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.70s/it]\u001b[A\n","Training loss: 0.48132688, IoU: 0.930238753369651 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.70s/it]\u001b[A\n","Training loss: 0.48132688, IoU: 0.930238753369651 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.43307048, IoU: 0.9392303911310534 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.43307048, IoU: 0.9392303911310534 |:  96%|█████████▌| 25/26 [01:06<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.45231062, IoU: 0.9388430156458341 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.45231062, IoU: 0.9388430156458341 |: 100%|██████████| 26/26 [01:08<00:00,  2.65s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.10912693706465451 to 0.45829636958696257\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:   8%|▊         | 12/150 [28:14<3:08:47, 82.08s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.49842212, IoU: 0.9302607337163835 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.49842212, IoU: 0.9302607337163835 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.55859095, IoU: 0.9169593151789124 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.55859095, IoU: 0.9169593151789124 |:   8%|▊         | 2/26 [00:05<01:05,  2.74s/it]\u001b[A\n","Training loss: 0.4228149, IoU: 0.937450545972464 |:   8%|▊         | 2/26 [00:08<01:05,  2.74s/it]  \u001b[A\n","Training loss: 0.4228149, IoU: 0.937450545972464 |:  12%|█▏        | 3/26 [00:08<01:02,  2.72s/it]\u001b[A\n","Training loss: 0.47669834, IoU: 0.9373388269308481 |:  12%|█▏        | 3/26 [00:10<01:02,  2.72s/it]\u001b[A\n","Training loss: 0.47669834, IoU: 0.9373388269308481 |:  15%|█▌        | 4/26 [00:10<01:00,  2.74s/it]\u001b[A\n","Training loss: 0.4758364, IoU: 0.9429651352556739 |:  15%|█▌        | 4/26 [00:13<01:00,  2.74s/it] \u001b[A\n","Training loss: 0.4758364, IoU: 0.9429651352556739 |:  19%|█▉        | 5/26 [00:13<00:57,  2.75s/it]\u001b[A\n","Training loss: 0.44433406, IoU: 0.9436879852243926 |:  19%|█▉        | 5/26 [00:16<00:57,  2.75s/it]\u001b[A\n","Training loss: 0.44433406, IoU: 0.9436879852243926 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.53772986, IoU: 0.9308071351138267 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.53772986, IoU: 0.9308071351138267 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.5505413, IoU: 0.9324132997878744 |:  27%|██▋       | 7/26 [00:22<00:52,  2.76s/it] \u001b[A\n","Training loss: 0.5505413, IoU: 0.9324132997878744 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.45453745, IoU: 0.9317784632056262 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.45453745, IoU: 0.9317784632056262 |:  35%|███▍      | 9/26 [00:24<00:46,  2.74s/it]\u001b[A\n","Training loss: 0.4808424, IoU: 0.9493705622062909 |:  35%|███▍      | 9/26 [00:27<00:46,  2.74s/it] \u001b[A\n","Training loss: 0.4808424, IoU: 0.9493705622062909 |:  38%|███▊      | 10/26 [00:27<00:43,  2.73s/it]\u001b[A\n","Training loss: 0.47034723, IoU: 0.9407897199760408 |:  38%|███▊      | 10/26 [00:30<00:43,  2.73s/it]\u001b[A\n","Training loss: 0.47034723, IoU: 0.9407897199760408 |:  42%|████▏     | 11/26 [00:30<00:40,  2.72s/it]\u001b[A\n","Training loss: 0.40334505, IoU: 0.9307903152124257 |:  42%|████▏     | 11/26 [00:31<00:40,  2.72s/it]\u001b[A\n","Training loss: 0.40334505, IoU: 0.9307903152124257 |:  46%|████▌     | 12/26 [00:31<00:30,  2.17s/it]\u001b[A\n","Training loss: 0.4971487, IoU: 0.9294501913608421 |:  46%|████▌     | 12/26 [00:33<00:30,  2.17s/it] \u001b[A\n","Training loss: 0.4971487, IoU: 0.9294501913608421 |:  50%|█████     | 13/26 [00:33<00:30,  2.33s/it]\u001b[A\n","Training loss: 0.5061372, IoU: 0.9447543874600917 |:  50%|█████     | 13/26 [00:36<00:30,  2.33s/it]\u001b[A\n","Training loss: 0.5061372, IoU: 0.9447543874600917 |:  54%|█████▍    | 14/26 [00:36<00:29,  2.43s/it]\u001b[A\n","Training loss: 0.46319288, IoU: 0.9348076077085546 |:  54%|█████▍    | 14/26 [00:39<00:29,  2.43s/it]\u001b[A\n","Training loss: 0.46319288, IoU: 0.9348076077085546 |:  58%|█████▊    | 15/26 [00:39<00:27,  2.51s/it]\u001b[A\n","Training loss: 0.4591247, IoU: 0.9419740445291106 |:  58%|█████▊    | 15/26 [00:41<00:27,  2.51s/it] \u001b[A\n","Training loss: 0.4591247, IoU: 0.9419740445291106 |:  62%|██████▏   | 16/26 [00:41<00:25,  2.56s/it]\u001b[A\n","Training loss: 0.4789167, IoU: 0.930672034523931 |:  62%|██████▏   | 16/26 [00:44<00:25,  2.56s/it] \u001b[A\n","Training loss: 0.4789167, IoU: 0.930672034523931 |:  65%|██████▌   | 17/26 [00:44<00:23,  2.60s/it]\u001b[A\n","Training loss: 0.4397623, IoU: 0.9404249632500334 |:  65%|██████▌   | 17/26 [00:47<00:23,  2.60s/it]\u001b[A\n","Training loss: 0.4397623, IoU: 0.9404249632500334 |:  69%|██████▉   | 18/26 [00:47<00:20,  2.62s/it]\u001b[A\n","Training loss: 0.45259613, IoU: 0.9300930601253108 |:  69%|██████▉   | 18/26 [00:49<00:20,  2.62s/it]\u001b[A\n","Training loss: 0.45259613, IoU: 0.9300930601253108 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.64s/it]\u001b[A\n","Training loss: 0.4198625, IoU: 0.9241837383891081 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.64s/it] \u001b[A\n","Training loss: 0.4198625, IoU: 0.9241837383891081 |:  77%|███████▋  | 20/26 [00:52<00:15,  2.65s/it]\u001b[A\n","Training loss: 0.4421935, IoU: 0.9387718532830565 |:  77%|███████▋  | 20/26 [00:55<00:15,  2.65s/it]\u001b[A\n","Training loss: 0.4421935, IoU: 0.9387718532830565 |:  81%|████████  | 21/26 [00:55<00:13,  2.66s/it]\u001b[A\n","Training loss: 0.46331286, IoU: 0.9380029026429848 |:  81%|████████  | 21/26 [00:57<00:13,  2.66s/it]\u001b[A\n","Training loss: 0.46331286, IoU: 0.9380029026429848 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.67s/it]\u001b[A\n","Training loss: 0.44759977, IoU: 0.9439329492632674 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.67s/it]\u001b[A\n","Training loss: 0.44759977, IoU: 0.9439329492632674 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.68s/it]\u001b[A\n","Training loss: 0.49533695, IoU: 0.9197808052363193 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.68s/it]\u001b[A\n","Training loss: 0.49533695, IoU: 0.9197808052363193 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.68s/it]\u001b[A\n","Training loss: 0.509709, IoU: 0.9513731883195697 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.68s/it]  \u001b[A\n","Training loss: 0.509709, IoU: 0.9513731883195697 |:  96%|█████████▌| 25/26 [01:05<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.5191358, IoU: 0.9260518414536664 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.5191358, IoU: 0.9260518414536664 |: 100%|██████████| 26/26 [01:08<00:00,  2.64s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.45829636958696257 to 0.6550260574337963\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:   9%|▊         | 13/150 [29:32<3:04:46, 80.92s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46311545, IoU: 0.9476612758903258 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46311545, IoU: 0.9476612758903258 |:   4%|▍         | 1/26 [00:02<01:10,  2.84s/it]\u001b[A\n","Training loss: 0.5089549, IoU: 0.9347639992493632 |:   4%|▍         | 1/26 [00:05<01:10,  2.84s/it] \u001b[A\n","Training loss: 0.5089549, IoU: 0.9347639992493632 |:   8%|▊         | 2/26 [00:05<01:05,  2.74s/it]\u001b[A\n","Training loss: 0.469574, IoU: 0.9334561431160848 |:   8%|▊         | 2/26 [00:08<01:05,  2.74s/it] \u001b[A\n","Training loss: 0.469574, IoU: 0.9334561431160848 |:  12%|█▏        | 3/26 [00:08<01:02,  2.72s/it]\u001b[A\n","Training loss: 0.47505498, IoU: 0.9415740176667682 |:  12%|█▏        | 3/26 [00:10<01:02,  2.72s/it]\u001b[A\n","Training loss: 0.47505498, IoU: 0.9415740176667682 |:  15%|█▌        | 4/26 [00:10<01:00,  2.74s/it]\u001b[A\n","Training loss: 0.4617046, IoU: 0.9437287533488916 |:  15%|█▌        | 4/26 [00:13<01:00,  2.74s/it] \u001b[A\n","Training loss: 0.4617046, IoU: 0.9437287533488916 |:  19%|█▉        | 5/26 [00:13<00:57,  2.74s/it]\u001b[A\n","Training loss: 0.5044783, IoU: 0.9217420175972553 |:  19%|█▉        | 5/26 [00:16<00:57,  2.74s/it]\u001b[A\n","Training loss: 0.5044783, IoU: 0.9217420175972553 |:  23%|██▎       | 6/26 [00:16<00:54,  2.75s/it]\u001b[A\n","Training loss: 0.5201024, IoU: 0.9370892018779343 |:  23%|██▎       | 6/26 [00:19<00:54,  2.75s/it]\u001b[A\n","Training loss: 0.5201024, IoU: 0.9370892018779343 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.4574245, IoU: 0.9393500685090872 |:  27%|██▋       | 7/26 [00:21<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.4574245, IoU: 0.9393500685090872 |:  31%|███       | 8/26 [00:21<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.48501235, IoU: 0.9382103721283815 |:  31%|███       | 8/26 [00:24<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.48501235, IoU: 0.9382103721283815 |:  35%|███▍      | 9/26 [00:24<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.5410088, IoU: 0.9162496541179892 |:  35%|███▍      | 9/26 [00:27<00:46,  2.73s/it] \u001b[A\n","Training loss: 0.5410088, IoU: 0.9162496541179892 |:  38%|███▊      | 10/26 [00:27<00:43,  2.71s/it]\u001b[A\n","Training loss: 0.4970736, IoU: 0.9438158700788878 |:  38%|███▊      | 10/26 [00:29<00:43,  2.71s/it]\u001b[A\n","Training loss: 0.4970736, IoU: 0.9438158700788878 |:  42%|████▏     | 11/26 [00:29<00:40,  2.69s/it]\u001b[A\n","Training loss: 0.48083928, IoU: 0.9458552791507981 |:  42%|████▏     | 11/26 [00:32<00:40,  2.69s/it]\u001b[A\n","Training loss: 0.48083928, IoU: 0.9458552791507981 |:  46%|████▌     | 12/26 [00:32<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.47745103, IoU: 0.9274368165359632 |:  46%|████▌     | 12/26 [00:33<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.47745103, IoU: 0.9274368165359632 |:  50%|█████     | 13/26 [00:33<00:27,  2.15s/it]\u001b[A\n","Training loss: 0.47631964, IoU: 0.9352279687951459 |:  50%|█████     | 13/26 [00:36<00:27,  2.15s/it]\u001b[A\n","Training loss: 0.47631964, IoU: 0.9352279687951459 |:  54%|█████▍    | 14/26 [00:36<00:27,  2.31s/it]\u001b[A\n","Training loss: 0.47919247, IoU: 0.9410131564810564 |:  54%|█████▍    | 14/26 [00:38<00:27,  2.31s/it]\u001b[A\n","Training loss: 0.47919247, IoU: 0.9410131564810564 |:  58%|█████▊    | 15/26 [00:38<00:26,  2.43s/it]\u001b[A\n","Training loss: 0.44508976, IoU: 0.9371756437979163 |:  58%|█████▊    | 15/26 [00:41<00:26,  2.43s/it]\u001b[A\n","Training loss: 0.44508976, IoU: 0.9371756437979163 |:  62%|██████▏   | 16/26 [00:41<00:25,  2.50s/it]\u001b[A\n","Training loss: 0.46753514, IoU: 0.952252219994271 |:  62%|██████▏   | 16/26 [00:44<00:25,  2.50s/it] \u001b[A\n","Training loss: 0.46753514, IoU: 0.952252219994271 |:  65%|██████▌   | 17/26 [00:44<00:22,  2.55s/it]\u001b[A\n","Training loss: 0.5099176, IoU: 0.953073100998934 |:  65%|██████▌   | 17/26 [00:46<00:22,  2.55s/it] \u001b[A\n","Training loss: 0.5099176, IoU: 0.953073100998934 |:  69%|██████▉   | 18/26 [00:46<00:20,  2.59s/it]\u001b[A\n","Training loss: 0.48412865, IoU: 0.9442688685805743 |:  69%|██████▉   | 18/26 [00:49<00:20,  2.59s/it]\u001b[A\n","Training loss: 0.48412865, IoU: 0.9442688685805743 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.62s/it]\u001b[A\n","Training loss: 0.43965974, IoU: 0.9413184087938604 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.62s/it]\u001b[A\n","Training loss: 0.43965974, IoU: 0.9413184087938604 |:  77%|███████▋  | 20/26 [00:52<00:15,  2.64s/it]\u001b[A\n","Training loss: 0.5053069, IoU: 0.9486391637350143 |:  77%|███████▋  | 20/26 [00:55<00:15,  2.64s/it] \u001b[A\n","Training loss: 0.5053069, IoU: 0.9486391637350143 |:  81%|████████  | 21/26 [00:55<00:13,  2.65s/it]\u001b[A\n","Training loss: 0.4428019, IoU: 0.9416876733773035 |:  81%|████████  | 21/26 [00:57<00:13,  2.65s/it]\u001b[A\n","Training loss: 0.4428019, IoU: 0.9416876733773035 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.66s/it]\u001b[A\n","Training loss: 0.43390208, IoU: 0.940529855547108 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.66s/it]\u001b[A\n","Training loss: 0.43390208, IoU: 0.940529855547108 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.67s/it]\u001b[A\n","Training loss: 0.43742484, IoU: 0.9299841781977055 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.67s/it]\u001b[A\n","Training loss: 0.43742484, IoU: 0.9299841781977055 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.67s/it]\u001b[A\n","Training loss: 0.5343234, IoU: 0.9184734391611981 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.67s/it] \u001b[A\n","Training loss: 0.5343234, IoU: 0.9184734391611981 |:  96%|█████████▌| 25/26 [01:05<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.42808646, IoU: 0.9272875637887147 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.42808646, IoU: 0.9272875637887147 |: 100%|██████████| 26/26 [01:08<00:00,  2.63s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.6550260574337963 to 0.7218593346239364\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:   9%|▉         | 14/150 [30:50<3:01:33, 80.10s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47733724, IoU: 0.929192649450365 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47733724, IoU: 0.929192649450365 |:   4%|▍         | 1/26 [00:02<01:11,  2.87s/it]\u001b[A\n","Training loss: 0.4782632, IoU: 0.9394578051694153 |:   4%|▍         | 1/26 [00:05<01:11,  2.87s/it]\u001b[A\n","Training loss: 0.4782632, IoU: 0.9394578051694153 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.48322845, IoU: 0.9335394779325932 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.48322845, IoU: 0.9335394779325932 |:  12%|█▏        | 3/26 [00:08<01:02,  2.73s/it]\u001b[A\n","Training loss: 0.46099883, IoU: 0.9500112758305539 |:  12%|█▏        | 3/26 [00:11<01:02,  2.73s/it]\u001b[A\n","Training loss: 0.46099883, IoU: 0.9500112758305539 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.46684557, IoU: 0.9348125163182102 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.46684557, IoU: 0.9348125163182102 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.4913685, IoU: 0.9463653469246938 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it] \u001b[A\n","Training loss: 0.4913685, IoU: 0.9463653469246938 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.46743345, IoU: 0.9331817162625324 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.46743345, IoU: 0.9331817162625324 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.5139425, IoU: 0.9372854067709168 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it] \u001b[A\n","Training loss: 0.5139425, IoU: 0.9372854067709168 |:  31%|███       | 8/26 [00:22<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.48247117, IoU: 0.9288629352241533 |:  31%|███       | 8/26 [00:24<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.48247117, IoU: 0.9288629352241533 |:  35%|███▍      | 9/26 [00:24<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.51097906, IoU: 0.9327777972242155 |:  35%|███▍      | 9/26 [00:27<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.51097906, IoU: 0.9327777972242155 |:  38%|███▊      | 10/26 [00:27<00:43,  2.71s/it]\u001b[A\n","Training loss: 0.4435174, IoU: 0.9459669895693773 |:  38%|███▊      | 10/26 [00:30<00:43,  2.71s/it] \u001b[A\n","Training loss: 0.4435174, IoU: 0.9459669895693773 |:  42%|████▏     | 11/26 [00:30<00:40,  2.71s/it]\u001b[A\n","Training loss: 0.5080818, IoU: 0.9424395318357209 |:  42%|████▏     | 11/26 [00:32<00:40,  2.71s/it]\u001b[A\n","Training loss: 0.5080818, IoU: 0.9424395318357209 |:  46%|████▌     | 12/26 [00:32<00:37,  2.70s/it]\u001b[A\n","Training loss: 0.46435687, IoU: 0.9275924148156833 |:  46%|████▌     | 12/26 [00:35<00:37,  2.70s/it]\u001b[A\n","Training loss: 0.46435687, IoU: 0.9275924148156833 |:  50%|█████     | 13/26 [00:35<00:35,  2.70s/it]\u001b[A\n","Training loss: 0.4821025, IoU: 0.9459044775500471 |:  50%|█████     | 13/26 [00:36<00:35,  2.70s/it] \u001b[A\n","Training loss: 0.4821025, IoU: 0.9459044775500471 |:  54%|█████▍    | 14/26 [00:36<00:25,  2.16s/it]\u001b[A\n","Training loss: 0.5002945, IoU: 0.9332464211169431 |:  54%|█████▍    | 14/26 [00:39<00:25,  2.16s/it]\u001b[A\n","Training loss: 0.5002945, IoU: 0.9332464211169431 |:  58%|█████▊    | 15/26 [00:39<00:25,  2.32s/it]\u001b[A\n","Training loss: 0.5093874, IoU: 0.923222577881971 |:  58%|█████▊    | 15/26 [00:41<00:25,  2.32s/it] \u001b[A\n","Training loss: 0.5093874, IoU: 0.923222577881971 |:  62%|██████▏   | 16/26 [00:41<00:24,  2.43s/it]\u001b[A\n","Training loss: 0.47613806, IoU: 0.9387594199533719 |:  62%|██████▏   | 16/26 [00:44<00:24,  2.43s/it]\u001b[A\n","Training loss: 0.47613806, IoU: 0.9387594199533719 |:  65%|██████▌   | 17/26 [00:44<00:22,  2.51s/it]\u001b[A\n","Training loss: 0.46557716, IoU: 0.9390411701230345 |:  65%|██████▌   | 17/26 [00:47<00:22,  2.51s/it]\u001b[A\n","Training loss: 0.46557716, IoU: 0.9390411701230345 |:  69%|██████▉   | 18/26 [00:47<00:20,  2.56s/it]\u001b[A\n","Training loss: 0.49146882, IoU: 0.9514980115290687 |:  69%|██████▉   | 18/26 [00:49<00:20,  2.56s/it]\u001b[A\n","Training loss: 0.49146882, IoU: 0.9514980115290687 |:  73%|███████▎  | 19/26 [00:49<00:18,  2.59s/it]\u001b[A\n","Training loss: 0.4593041, IoU: 0.9282691841947733 |:  73%|███████▎  | 19/26 [00:52<00:18,  2.59s/it] \u001b[A\n","Training loss: 0.4593041, IoU: 0.9282691841947733 |:  77%|███████▋  | 20/26 [00:52<00:15,  2.62s/it]\u001b[A\n","Training loss: 0.5063867, IoU: 0.9140532398900627 |:  77%|███████▋  | 20/26 [00:55<00:15,  2.62s/it]\u001b[A\n","Training loss: 0.5063867, IoU: 0.9140532398900627 |:  81%|████████  | 21/26 [00:55<00:13,  2.66s/it]\u001b[A\n","Training loss: 0.49302968, IoU: 0.9303745664462393 |:  81%|████████  | 21/26 [00:58<00:13,  2.66s/it]\u001b[A\n","Training loss: 0.49302968, IoU: 0.9303745664462393 |:  85%|████████▍ | 22/26 [00:58<00:10,  2.68s/it]\u001b[A\n","Training loss: 0.5055849, IoU: 0.9373539593502198 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.68s/it] \u001b[A\n","Training loss: 0.5055849, IoU: 0.9373539593502198 |:  88%|████████▊ | 23/26 [01:00<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4777131, IoU: 0.9392632052821128 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4777131, IoU: 0.9392632052821128 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.69s/it]\u001b[A\n","Training loss: 0.4408634, IoU: 0.9396789965986394 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.69s/it]\u001b[A\n","Training loss: 0.4408634, IoU: 0.9396789965986394 |:  96%|█████████▌| 25/26 [01:06<00:02,  2.69s/it]\u001b[A\n","Training loss: 0.49490392, IoU: 0.9468105965458948 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.69s/it]\u001b[A\n","Training loss: 0.49490392, IoU: 0.9468105965458948 |: 100%|██████████| 26/26 [01:08<00:00,  2.65s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.7218593346239364 to 0.7492760404046749\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  10%|█         | 15/150 [32:10<3:00:23, 80.17s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.42522606, IoU: 0.941982701891848 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.42522606, IoU: 0.941982701891848 |:   4%|▍         | 1/26 [00:02<01:08,  2.73s/it]\u001b[A\n","Training loss: 0.5120615, IoU: 0.9449964860454313 |:   4%|▍         | 1/26 [00:05<01:08,  2.73s/it]\u001b[A\n","Training loss: 0.5120615, IoU: 0.9449964860454313 |:   8%|▊         | 2/26 [00:05<01:05,  2.71s/it]\u001b[A\n","Training loss: 0.44728723, IoU: 0.936548126155877 |:   8%|▊         | 2/26 [00:08<01:05,  2.71s/it]\u001b[A\n","Training loss: 0.44728723, IoU: 0.936548126155877 |:  12%|█▏        | 3/26 [00:08<01:02,  2.74s/it]\u001b[A\n","Training loss: 0.46908182, IoU: 0.9388782077040536 |:  12%|█▏        | 3/26 [00:10<01:02,  2.74s/it]\u001b[A\n","Training loss: 0.46908182, IoU: 0.9388782077040536 |:  15%|█▌        | 4/26 [00:10<01:00,  2.75s/it]\u001b[A\n","Training loss: 0.4507392, IoU: 0.94276990644647 |:  15%|█▌        | 4/26 [00:13<01:00,  2.75s/it]   \u001b[A\n","Training loss: 0.4507392, IoU: 0.94276990644647 |:  19%|█▉        | 5/26 [00:13<00:57,  2.75s/it]\u001b[A\n","Training loss: 0.47670394, IoU: 0.9324220311135452 |:  19%|█▉        | 5/26 [00:16<00:57,  2.75s/it]\u001b[A\n","Training loss: 0.47670394, IoU: 0.9324220311135452 |:  23%|██▎       | 6/26 [00:16<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.4666928, IoU: 0.9503848646101283 |:  23%|██▎       | 6/26 [00:19<00:55,  2.76s/it] \u001b[A\n","Training loss: 0.4666928, IoU: 0.9503848646101283 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.4618765, IoU: 0.9331839922814796 |:  27%|██▋       | 7/26 [00:21<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.4618765, IoU: 0.9331839922814796 |:  31%|███       | 8/26 [00:21<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.5143765, IoU: 0.9438354697040026 |:  31%|███       | 8/26 [00:24<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.5143765, IoU: 0.9438354697040026 |:  35%|███▍      | 9/26 [00:24<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.4740166, IoU: 0.9413464519355444 |:  35%|███▍      | 9/26 [00:27<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.4740166, IoU: 0.9413464519355444 |:  38%|███▊      | 10/26 [00:27<00:43,  2.72s/it]\u001b[A\n","Training loss: 0.5272, IoU: 0.9444660334367482 |:  38%|███▊      | 10/26 [00:30<00:43,  2.72s/it]   \u001b[A\n","Training loss: 0.5272, IoU: 0.9444660334367482 |:  42%|████▏     | 11/26 [00:30<00:40,  2.71s/it]\u001b[A\n","Training loss: 0.46568102, IoU: 0.9408389532285484 |:  42%|████▏     | 11/26 [00:32<00:40,  2.71s/it]\u001b[A\n","Training loss: 0.46568102, IoU: 0.9408389532285484 |:  46%|████▌     | 12/26 [00:32<00:37,  2.71s/it]\u001b[A\n","Training loss: 0.48128673, IoU: 0.9383630860522307 |:  46%|████▌     | 12/26 [00:35<00:37,  2.71s/it]\u001b[A\n","Training loss: 0.48128673, IoU: 0.9383630860522307 |:  50%|█████     | 13/26 [00:35<00:35,  2.70s/it]\u001b[A\n","Training loss: 0.49189207, IoU: 0.9354387748617907 |:  50%|█████     | 13/26 [00:38<00:35,  2.70s/it]\u001b[A\n","Training loss: 0.49189207, IoU: 0.9354387748617907 |:  54%|█████▍    | 14/26 [00:38<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.5035642, IoU: 0.9551967340714501 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.70s/it] \u001b[A\n","Training loss: 0.5035642, IoU: 0.9551967340714501 |:  58%|█████▊    | 15/26 [00:39<00:23,  2.17s/it]\u001b[A\n","Training loss: 0.5244546, IoU: 0.9495191210104893 |:  58%|█████▊    | 15/26 [00:41<00:23,  2.17s/it]\u001b[A\n","Training loss: 0.5244546, IoU: 0.9495191210104893 |:  62%|██████▏   | 16/26 [00:41<00:23,  2.32s/it]\u001b[A\n","Training loss: 0.44209847, IoU: 0.9375597958966727 |:  62%|██████▏   | 16/26 [00:44<00:23,  2.32s/it]\u001b[A\n","Training loss: 0.44209847, IoU: 0.9375597958966727 |:  65%|██████▌   | 17/26 [00:44<00:21,  2.43s/it]\u001b[A\n","Training loss: 0.5300524, IoU: 0.9420430342417127 |:  65%|██████▌   | 17/26 [00:47<00:21,  2.43s/it] \u001b[A\n","Training loss: 0.5300524, IoU: 0.9420430342417127 |:  69%|██████▉   | 18/26 [00:47<00:20,  2.51s/it]\u001b[A\n","Training loss: 0.44518137, IoU: 0.941094560047987 |:  69%|██████▉   | 18/26 [00:49<00:20,  2.51s/it]\u001b[A\n","Training loss: 0.44518137, IoU: 0.941094560047987 |:  73%|███████▎  | 19/26 [00:49<00:17,  2.56s/it]\u001b[A\n","Training loss: 0.47676015, IoU: 0.9295306502048059 |:  73%|███████▎  | 19/26 [00:52<00:17,  2.56s/it]\u001b[A\n","Training loss: 0.47676015, IoU: 0.9295306502048059 |:  77%|███████▋  | 20/26 [00:52<00:15,  2.60s/it]\u001b[A\n","Training loss: 0.5188155, IoU: 0.9248437491744991 |:  77%|███████▋  | 20/26 [00:55<00:15,  2.60s/it] \u001b[A\n","Training loss: 0.5188155, IoU: 0.9248437491744991 |:  81%|████████  | 21/26 [00:55<00:13,  2.63s/it]\u001b[A\n","Training loss: 0.4900298, IoU: 0.9472239730192956 |:  81%|████████  | 21/26 [00:57<00:13,  2.63s/it]\u001b[A\n","Training loss: 0.4900298, IoU: 0.9472239730192956 |:  85%|████████▍ | 22/26 [00:57<00:10,  2.64s/it]\u001b[A\n","Training loss: 0.42345962, IoU: 0.9324828588178319 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.64s/it]\u001b[A\n","Training loss: 0.42345962, IoU: 0.9324828588178319 |:  88%|████████▊ | 23/26 [01:00<00:07,  2.65s/it]\u001b[A\n","Training loss: 0.44946903, IoU: 0.9268837444190664 |:  88%|████████▊ | 23/26 [01:03<00:07,  2.65s/it]\u001b[A\n","Training loss: 0.44946903, IoU: 0.9268837444190664 |:  92%|█████████▏| 24/26 [01:03<00:05,  2.67s/it]\u001b[A\n","Training loss: 0.50537205, IoU: 0.9378750033936959 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.67s/it]\u001b[A\n","Training loss: 0.50537205, IoU: 0.9378750033936959 |:  96%|█████████▌| 25/26 [01:05<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.45414227, IoU: 0.9440665085745155 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.45414227, IoU: 0.9440665085745155 |: 100%|██████████| 26/26 [01:08<00:00,  2.64s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.7492760404046749 to 0.7830667623660349\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  11%|█         | 16/150 [33:29<2:57:44, 79.59s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46111065, IoU: 0.9275516472061713 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46111065, IoU: 0.9275516472061713 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.46833605, IoU: 0.9426437517277103 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.46833605, IoU: 0.9426437517277103 |:   8%|▊         | 2/26 [00:05<01:05,  2.74s/it]\u001b[A\n","Training loss: 0.4365574, IoU: 0.9300027427089653 |:   8%|▊         | 2/26 [00:08<01:05,  2.74s/it] \u001b[A\n","Training loss: 0.4365574, IoU: 0.9300027427089653 |:  12%|█▏        | 3/26 [00:08<01:02,  2.73s/it]\u001b[A\n","Training loss: 0.49401784, IoU: 0.9307515988301375 |:  12%|█▏        | 3/26 [00:10<01:02,  2.73s/it]\u001b[A\n","Training loss: 0.49401784, IoU: 0.9307515988301375 |:  15%|█▌        | 4/26 [00:10<01:00,  2.75s/it]\u001b[A\n","Training loss: 0.5277317, IoU: 0.938686075064566 |:  15%|█▌        | 4/26 [00:13<01:00,  2.75s/it]  \u001b[A\n","Training loss: 0.5277317, IoU: 0.938686075064566 |:  19%|█▉        | 5/26 [00:13<00:57,  2.76s/it]\u001b[A\n","Training loss: 0.50024384, IoU: 0.9390300831251227 |:  19%|█▉        | 5/26 [00:16<00:57,  2.76s/it]\u001b[A\n","Training loss: 0.50024384, IoU: 0.9390300831251227 |:  23%|██▎       | 6/26 [00:16<00:55,  2.75s/it]\u001b[A\n","Training loss: 0.46325207, IoU: 0.9316661082881977 |:  23%|██▎       | 6/26 [00:19<00:55,  2.75s/it]\u001b[A\n","Training loss: 0.46325207, IoU: 0.9316661082881977 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.5083258, IoU: 0.9376331543091367 |:  27%|██▋       | 7/26 [00:22<00:52,  2.76s/it] \u001b[A\n","Training loss: 0.5083258, IoU: 0.9376331543091367 |:  31%|███       | 8/26 [00:22<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.47911668, IoU: 0.9495536275619263 |:  31%|███       | 8/26 [00:24<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.47911668, IoU: 0.9495536275619263 |:  35%|███▍      | 9/26 [00:24<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.46494484, IoU: 0.9366157518700582 |:  35%|███▍      | 9/26 [00:27<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.46494484, IoU: 0.9366157518700582 |:  38%|███▊      | 10/26 [00:27<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.47479582, IoU: 0.9432302688815019 |:  38%|███▊      | 10/26 [00:30<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.47479582, IoU: 0.9432302688815019 |:  42%|████▏     | 11/26 [00:30<00:41,  2.74s/it]\u001b[A\n","Training loss: 0.50326383, IoU: 0.9242568504346622 |:  42%|████▏     | 11/26 [00:32<00:41,  2.74s/it]\u001b[A\n","Training loss: 0.50326383, IoU: 0.9242568504346622 |:  46%|████▌     | 12/26 [00:32<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.4684127, IoU: 0.9404068757056323 |:  46%|████▌     | 12/26 [00:35<00:38,  2.74s/it] \u001b[A\n","Training loss: 0.4684127, IoU: 0.9404068757056323 |:  50%|█████     | 13/26 [00:35<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.44666153, IoU: 0.9342054017243913 |:  50%|█████     | 13/26 [00:38<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.44666153, IoU: 0.9342054017243913 |:  54%|█████▍    | 14/26 [00:38<00:32,  2.73s/it]\u001b[A\n","Training loss: 0.44082472, IoU: 0.9379603946067199 |:  54%|█████▍    | 14/26 [00:41<00:32,  2.73s/it]\u001b[A\n","Training loss: 0.44082472, IoU: 0.9379603946067199 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.74s/it]\u001b[A\n","Training loss: 0.419527, IoU: 0.9393176128812931 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.74s/it]  \u001b[A\n","Training loss: 0.419527, IoU: 0.9393176128812931 |:  62%|██████▏   | 16/26 [00:42<00:21,  2.20s/it]\u001b[A\n","Training loss: 0.44036502, IoU: 0.929456803435295 |:  62%|██████▏   | 16/26 [00:44<00:21,  2.20s/it]\u001b[A\n","Training loss: 0.44036502, IoU: 0.929456803435295 |:  65%|██████▌   | 17/26 [00:44<00:21,  2.37s/it]\u001b[A\n","Training loss: 0.41856372, IoU: 0.9471749161374058 |:  65%|██████▌   | 17/26 [00:47<00:21,  2.37s/it]\u001b[A\n","Training loss: 0.41856372, IoU: 0.9471749161374058 |:  69%|██████▉   | 18/26 [00:47<00:19,  2.49s/it]\u001b[A\n","Training loss: 0.49410993, IoU: 0.9395861930063072 |:  69%|██████▉   | 18/26 [00:50<00:19,  2.49s/it]\u001b[A\n","Training loss: 0.49410993, IoU: 0.9395861930063072 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.58s/it]\u001b[A\n","Training loss: 0.46290708, IoU: 0.9358670226981923 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.58s/it]\u001b[A\n","Training loss: 0.46290708, IoU: 0.9358670226981923 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.64s/it]\u001b[A\n","Training loss: 0.46008188, IoU: 0.9455089241776342 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.64s/it]\u001b[A\n","Training loss: 0.46008188, IoU: 0.9455089241776342 |:  81%|████████  | 21/26 [00:56<00:13,  2.70s/it]\u001b[A\n","Training loss: 0.5290134, IoU: 0.9260295163707433 |:  81%|████████  | 21/26 [00:58<00:13,  2.70s/it] \u001b[A\n","Training loss: 0.5290134, IoU: 0.9260295163707433 |:  85%|████████▍ | 22/26 [00:58<00:10,  2.73s/it]\u001b[A\n","Training loss: 0.41853338, IoU: 0.9397796982259606 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.73s/it]\u001b[A\n","Training loss: 0.41853338, IoU: 0.9397796982259606 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.49920887, IoU: 0.94122749318742 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.76s/it]  \u001b[A\n","Training loss: 0.49920887, IoU: 0.94122749318742 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.43644083, IoU: 0.9529157820554303 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.43644083, IoU: 0.9529157820554303 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.4819954, IoU: 0.940217088038284 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it]  \u001b[A\n","Training loss: 0.4819954, IoU: 0.940217088038284 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.7830667623660349 to 0.7985407932244943\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  11%|█▏        | 17/150 [34:49<2:56:49, 79.77s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48715353, IoU: 0.9445154143490148 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48715353, IoU: 0.9445154143490148 |:   4%|▍         | 1/26 [00:02<01:12,  2.89s/it]\u001b[A\n","Training loss: 0.5172963, IoU: 0.9283864417454379 |:   4%|▍         | 1/26 [00:05<01:12,  2.89s/it] \u001b[A\n","Training loss: 0.5172963, IoU: 0.9283864417454379 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.45932335, IoU: 0.9323084360647812 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.45932335, IoU: 0.9323084360647812 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.39323086, IoU: 0.935586901907318 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it] \u001b[A\n","Training loss: 0.39323086, IoU: 0.935586901907318 |:  15%|█▌        | 4/26 [00:11<01:02,  2.83s/it]\u001b[A\n","Training loss: 0.49553353, IoU: 0.936932876273619 |:  15%|█▌        | 4/26 [00:14<01:02,  2.83s/it]\u001b[A\n","Training loss: 0.49553353, IoU: 0.936932876273619 |:  19%|█▉        | 5/26 [00:14<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.46018603, IoU: 0.9405031615342717 |:  19%|█▉        | 5/26 [00:16<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.46018603, IoU: 0.9405031615342717 |:  23%|██▎       | 6/26 [00:17<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.4986235, IoU: 0.9461412194657924 |:  23%|██▎       | 6/26 [00:19<00:56,  2.84s/it] \u001b[A\n","Training loss: 0.4986235, IoU: 0.9461412194657924 |:  27%|██▋       | 7/26 [00:19<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.5169016, IoU: 0.9460700509032068 |:  27%|██▋       | 7/26 [00:22<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.5169016, IoU: 0.9460700509032068 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.49729916, IoU: 0.9402642186998347 |:  31%|███       | 8/26 [00:25<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.49729916, IoU: 0.9402642186998347 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.5529313, IoU: 0.9405857779256548 |:  35%|███▍      | 9/26 [00:28<00:47,  2.79s/it] \u001b[A\n","Training loss: 0.5529313, IoU: 0.9405857779256548 |:  38%|███▊      | 10/26 [00:28<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.51566124, IoU: 0.9422749337485624 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.51566124, IoU: 0.9422749337485624 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.46187335, IoU: 0.9397232518024783 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.46187335, IoU: 0.9397232518024783 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.42489868, IoU: 0.9380404860724616 |:  46%|████▌     | 12/26 [00:36<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.42489868, IoU: 0.9380404860724616 |:  50%|█████     | 13/26 [00:36<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.49528742, IoU: 0.936953205972473 |:  50%|█████     | 13/26 [00:39<00:35,  2.77s/it] \u001b[A\n","Training loss: 0.49528742, IoU: 0.936953205972473 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.5077831, IoU: 0.9478048939307259 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.5077831, IoU: 0.9478048939307259 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.47175366, IoU: 0.9438372409633945 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.47175366, IoU: 0.9438372409633945 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44461393, IoU: 0.9284068367162923 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44461393, IoU: 0.9284068367162923 |:  65%|██████▌   | 17/26 [00:45<00:20,  2.23s/it]\u001b[A\n","Training loss: 0.48242944, IoU: 0.9516861265197838 |:  65%|██████▌   | 17/26 [00:48<00:20,  2.23s/it]\u001b[A\n","Training loss: 0.48242944, IoU: 0.9516861265197838 |:  69%|██████▉   | 18/26 [00:48<00:19,  2.39s/it]\u001b[A\n","Training loss: 0.46753758, IoU: 0.9429536557646168 |:  69%|██████▉   | 18/26 [00:51<00:19,  2.39s/it]\u001b[A\n","Training loss: 0.46753758, IoU: 0.9429536557646168 |:  73%|███████▎  | 19/26 [00:51<00:17,  2.51s/it]\u001b[A\n","Training loss: 0.49951044, IoU: 0.9461053979537168 |:  73%|███████▎  | 19/26 [00:53<00:17,  2.51s/it]\u001b[A\n","Training loss: 0.49951044, IoU: 0.9461053979537168 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.59s/it]\u001b[A\n","Training loss: 0.46329594, IoU: 0.9429324283681448 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.59s/it]\u001b[A\n","Training loss: 0.46329594, IoU: 0.9429324283681448 |:  81%|████████  | 21/26 [00:56<00:13,  2.65s/it]\u001b[A\n","Training loss: 0.4258906, IoU: 0.9353489729832477 |:  81%|████████  | 21/26 [00:59<00:13,  2.65s/it] \u001b[A\n","Training loss: 0.4258906, IoU: 0.9353489729832477 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.69s/it]\u001b[A\n","Training loss: 0.46951765, IoU: 0.9435350837803984 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.69s/it]\u001b[A\n","Training loss: 0.46951765, IoU: 0.9435350837803984 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.46894807, IoU: 0.9407947362260028 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.46894807, IoU: 0.9407947362260028 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.75s/it]\u001b[A\n","Training loss: 0.4569881, IoU: 0.9469604633369513 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.75s/it] \u001b[A\n","Training loss: 0.4569881, IoU: 0.9469604633369513 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.47703224, IoU: 0.9366674900716362 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.47703224, IoU: 0.9366674900716362 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  12%|█▏        | 18/150 [36:08<2:54:50, 79.48s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.7985407932244943\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.49893272, IoU: 0.949779934797153 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.49893272, IoU: 0.949779934797153 |:   4%|▍         | 1/26 [00:02<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.52119607, IoU: 0.9504575614557826 |:   4%|▍         | 1/26 [00:05<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.52119607, IoU: 0.9504575614557826 |:   8%|▊         | 2/26 [00:05<01:05,  2.75s/it]\u001b[A\n","Training loss: 0.48144004, IoU: 0.9421590213463399 |:   8%|▊         | 2/26 [00:08<01:05,  2.75s/it]\u001b[A\n","Training loss: 0.48144004, IoU: 0.9421590213463399 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.46711138, IoU: 0.9410373812963572 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.46711138, IoU: 0.9410373812963572 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.51142097, IoU: 0.9444261704081659 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.51142097, IoU: 0.9444261704081659 |:  19%|█▉        | 5/26 [00:13<00:58,  2.76s/it]\u001b[A\n","Training loss: 0.5337956, IoU: 0.9394146789476938 |:  19%|█▉        | 5/26 [00:16<00:58,  2.76s/it] \u001b[A\n","Training loss: 0.5337956, IoU: 0.9394146789476938 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.4724837, IoU: 0.9437488677565121 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.4724837, IoU: 0.9437488677565121 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.4971931, IoU: 0.9372600612933238 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.4971931, IoU: 0.9372600612933238 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.49319243, IoU: 0.9190325039029841 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.49319243, IoU: 0.9190325039029841 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.49975368, IoU: 0.9457063526578129 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.49975368, IoU: 0.9457063526578129 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.48483253, IoU: 0.9137817639665491 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.48483253, IoU: 0.9137817639665491 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.4494107, IoU: 0.9443342672430127 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it] \u001b[A\n","Training loss: 0.4494107, IoU: 0.9443342672430127 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.49708527, IoU: 0.9362775924609468 |:  46%|████▌     | 12/26 [00:35<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.49708527, IoU: 0.9362775924609468 |:  50%|█████     | 13/26 [00:35<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.4429567, IoU: 0.9471918636640174 |:  50%|█████     | 13/26 [00:38<00:36,  2.77s/it] \u001b[A\n","Training loss: 0.4429567, IoU: 0.9471918636640174 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.48971164, IoU: 0.9374604210710911 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.48971164, IoU: 0.9374604210710911 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.42484018, IoU: 0.9435539588227166 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.42484018, IoU: 0.9435539588227166 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.5031593, IoU: 0.9148151702332911 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it] \u001b[A\n","Training loss: 0.5031593, IoU: 0.9148151702332911 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.37769842, IoU: 0.937847796661152 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.37769842, IoU: 0.937847796661152 |:  69%|██████▉   | 18/26 [00:47<00:17,  2.22s/it]\u001b[A\n","Training loss: 0.46217844, IoU: 0.9429587574742495 |:  69%|██████▉   | 18/26 [00:50<00:17,  2.22s/it]\u001b[A\n","Training loss: 0.46217844, IoU: 0.9429587574742495 |:  73%|███████▎  | 19/26 [00:50<00:16,  2.39s/it]\u001b[A\n","Training loss: 0.51590294, IoU: 0.9424971416770106 |:  73%|███████▎  | 19/26 [00:53<00:16,  2.39s/it]\u001b[A\n","Training loss: 0.51590294, IoU: 0.9424971416770106 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.50s/it]\u001b[A\n","Training loss: 0.45715094, IoU: 0.9496058771213801 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.50s/it]\u001b[A\n","Training loss: 0.45715094, IoU: 0.9496058771213801 |:  81%|████████  | 21/26 [00:56<00:12,  2.59s/it]\u001b[A\n","Training loss: 0.44671094, IoU: 0.9444654186502638 |:  81%|████████  | 21/26 [00:59<00:12,  2.59s/it]\u001b[A\n","Training loss: 0.44671094, IoU: 0.9444654186502638 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.65s/it]\u001b[A\n","Training loss: 0.4721985, IoU: 0.9388444592316781 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.65s/it] \u001b[A\n","Training loss: 0.4721985, IoU: 0.9388444592316781 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4689843, IoU: 0.9344285216562145 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4689843, IoU: 0.9344285216562145 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.72s/it]\u001b[A\n","Training loss: 0.4751528, IoU: 0.9515042798893291 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.72s/it]\u001b[A\n","Training loss: 0.4751528, IoU: 0.9515042798893291 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.74s/it]\u001b[A\n","Training loss: 0.4075383, IoU: 0.9445450982986672 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.74s/it]\u001b[A\n","Training loss: 0.4075383, IoU: 0.9445450982986672 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  13%|█▎        | 19/150 [37:26<2:52:40, 79.09s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.7985407932244943\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.50471514, IoU: 0.9366504160945175 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.50471514, IoU: 0.9366504160945175 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.4165863, IoU: 0.925980566587101 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]  \u001b[A\n","Training loss: 0.4165863, IoU: 0.925980566587101 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.46742004, IoU: 0.9444859199749825 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.46742004, IoU: 0.9444859199749825 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.4869114, IoU: 0.94133307243123 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]   \u001b[A\n","Training loss: 0.4869114, IoU: 0.94133307243123 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.44637984, IoU: 0.9398605709186173 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.44637984, IoU: 0.9398605709186173 |:  19%|█▉        | 5/26 [00:13<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.5347887, IoU: 0.9266272605727958 |:  19%|█▉        | 5/26 [00:16<00:58,  2.81s/it] \u001b[A\n","Training loss: 0.5347887, IoU: 0.9266272605727958 |:  23%|██▎       | 6/26 [00:16<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.49858856, IoU: 0.9452574809540016 |:  23%|██▎       | 6/26 [00:19<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.49858856, IoU: 0.9452574809540016 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.5089103, IoU: 0.9442015525045924 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it] \u001b[A\n","Training loss: 0.5089103, IoU: 0.9442015525045924 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.4482361, IoU: 0.9467916387564522 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.4482361, IoU: 0.9467916387564522 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.48251635, IoU: 0.9268102550933844 |:  35%|███▍      | 9/26 [00:27<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.48251635, IoU: 0.9268102550933844 |:  38%|███▊      | 10/26 [00:27<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.53853565, IoU: 0.9467390974477254 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.53853565, IoU: 0.9467390974477254 |:  42%|████▏     | 11/26 [00:30<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.5073908, IoU: 0.9442797675207579 |:  42%|████▏     | 11/26 [00:33<00:41,  2.80s/it] \u001b[A\n","Training loss: 0.5073908, IoU: 0.9442797675207579 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.4846321, IoU: 0.94474023999322 |:  46%|████▌     | 12/26 [00:36<00:39,  2.81s/it]  \u001b[A\n","Training loss: 0.4846321, IoU: 0.94474023999322 |:  50%|█████     | 13/26 [00:36<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.5169456, IoU: 0.9283543306900951 |:  50%|█████     | 13/26 [00:39<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.5169456, IoU: 0.9283543306900951 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.40928686, IoU: 0.9463500834689264 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.40928686, IoU: 0.9463500834689264 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.80s/it]\u001b[A\n","Training loss: 0.46609002, IoU: 0.950373975526495 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.80s/it] \u001b[A\n","Training loss: 0.46609002, IoU: 0.950373975526495 |:  62%|██████▏   | 16/26 [00:44<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.5090296, IoU: 0.9349430765157533 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.5090296, IoU: 0.9349430765157533 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.4052155, IoU: 0.9425111134763497 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.4052155, IoU: 0.9425111134763497 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.51876473, IoU: 0.9552228602679792 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.51876473, IoU: 0.9552228602679792 |:  73%|███████▎  | 19/26 [00:51<00:15,  2.24s/it]\u001b[A\n","Training loss: 0.4586659, IoU: 0.9358362081824876 |:  73%|███████▎  | 19/26 [00:54<00:15,  2.24s/it] \u001b[A\n","Training loss: 0.4586659, IoU: 0.9358362081824876 |:  77%|███████▋  | 20/26 [00:54<00:14,  2.40s/it]\u001b[A\n","Training loss: 0.38330382, IoU: 0.9421192840316154 |:  77%|███████▋  | 20/26 [00:56<00:14,  2.40s/it]\u001b[A\n","Training loss: 0.38330382, IoU: 0.9421192840316154 |:  81%|████████  | 21/26 [00:56<00:12,  2.52s/it]\u001b[A\n","Training loss: 0.47573906, IoU: 0.943071253722638 |:  81%|████████  | 21/26 [00:59<00:12,  2.52s/it] \u001b[A\n","Training loss: 0.47573906, IoU: 0.943071253722638 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.61s/it]\u001b[A\n","Training loss: 0.4844516, IoU: 0.9358731001227977 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.61s/it]\u001b[A\n","Training loss: 0.4844516, IoU: 0.9358731001227977 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.66s/it]\u001b[A\n","Training loss: 0.43469602, IoU: 0.9492121504671931 |:  88%|████████▊ | 23/26 [01:05<00:07,  2.66s/it]\u001b[A\n","Training loss: 0.43469602, IoU: 0.9492121504671931 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.69s/it]\u001b[A\n","Training loss: 0.43859446, IoU: 0.9419913177947944 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.69s/it]\u001b[A\n","Training loss: 0.43859446, IoU: 0.9419913177947944 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.71s/it]\u001b[A\n","Training loss: 0.43208328, IoU: 0.9373933495733983 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.71s/it]\u001b[A\n","Training loss: 0.43208328, IoU: 0.9373933495733983 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.7985407932244943 to 0.805179008577203\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  13%|█▎        | 20/150 [38:46<2:52:21, 79.55s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5411081, IoU: 0.9369738508530134 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5411081, IoU: 0.9369738508530134 |:   4%|▍         | 1/26 [00:02<01:13,  2.94s/it]\u001b[A\n","Training loss: 0.49610496, IoU: 0.9485033759504758 |:   4%|▍         | 1/26 [00:05<01:13,  2.94s/it]\u001b[A\n","Training loss: 0.49610496, IoU: 0.9485033759504758 |:   8%|▊         | 2/26 [00:05<01:08,  2.84s/it]\u001b[A\n","Training loss: 0.5078521, IoU: 0.9484061627594584 |:   8%|▊         | 2/26 [00:08<01:08,  2.84s/it] \u001b[A\n","Training loss: 0.5078521, IoU: 0.9484061627594584 |:  12%|█▏        | 3/26 [00:08<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.49556792, IoU: 0.9470319135648264 |:  12%|█▏        | 3/26 [00:11<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.49556792, IoU: 0.9470319135648264 |:  15%|█▌        | 4/26 [00:11<01:02,  2.83s/it]\u001b[A\n","Training loss: 0.49180442, IoU: 0.9333805585337214 |:  15%|█▌        | 4/26 [00:14<01:02,  2.83s/it]\u001b[A\n","Training loss: 0.49180442, IoU: 0.9333805585337214 |:  19%|█▉        | 5/26 [00:14<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.46877497, IoU: 0.945271925653996 |:  19%|█▉        | 5/26 [00:17<00:59,  2.84s/it] \u001b[A\n","Training loss: 0.46877497, IoU: 0.945271925653996 |:  23%|██▎       | 6/26 [00:17<00:57,  2.86s/it]\u001b[A\n","Training loss: 0.46888125, IoU: 0.9463631092765026 |:  23%|██▎       | 6/26 [00:19<00:57,  2.86s/it]\u001b[A\n","Training loss: 0.46888125, IoU: 0.9463631092765026 |:  27%|██▋       | 7/26 [00:19<00:54,  2.86s/it]\u001b[A\n","Training loss: 0.46685484, IoU: 0.9451351390758732 |:  27%|██▋       | 7/26 [00:22<00:54,  2.86s/it]\u001b[A\n","Training loss: 0.46685484, IoU: 0.9451351390758732 |:  31%|███       | 8/26 [00:22<00:51,  2.87s/it]\u001b[A\n","Training loss: 0.46415952, IoU: 0.9488924149303992 |:  31%|███       | 8/26 [00:25<00:51,  2.87s/it]\u001b[A\n","Training loss: 0.46415952, IoU: 0.9488924149303992 |:  35%|███▍      | 9/26 [00:25<00:48,  2.84s/it]\u001b[A\n","Training loss: 0.40133262, IoU: 0.9376864314296107 |:  35%|███▍      | 9/26 [00:28<00:48,  2.84s/it]\u001b[A\n","Training loss: 0.40133262, IoU: 0.9376864314296107 |:  38%|███▊      | 10/26 [00:28<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.46551403, IoU: 0.9396165672658233 |:  38%|███▊      | 10/26 [00:31<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.46551403, IoU: 0.9396165672658233 |:  42%|████▏     | 11/26 [00:31<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.4337425, IoU: 0.925492579648483 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it]  \u001b[A\n","Training loss: 0.4337425, IoU: 0.925492579648483 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.52875876, IoU: 0.9305473275005264 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.52875876, IoU: 0.9305473275005264 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.47083947, IoU: 0.9459769772499662 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.47083947, IoU: 0.9459769772499662 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.4483898, IoU: 0.932425864234613 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.78s/it]  \u001b[A\n","Training loss: 0.4483898, IoU: 0.932425864234613 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.55696213, IoU: 0.9445368261613399 |:  58%|█████▊    | 15/26 [00:45<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.55696213, IoU: 0.9445368261613399 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.49351174, IoU: 0.9358855149083889 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.49351174, IoU: 0.9358855149083889 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.48723924, IoU: 0.9366416653407003 |:  65%|██████▌   | 17/26 [00:50<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.48723924, IoU: 0.9366416653407003 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.44922203, IoU: 0.9466988018247124 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.44922203, IoU: 0.9466988018247124 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.5285664, IoU: 0.9501297766042038 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.78s/it] \u001b[A\n","Training loss: 0.5285664, IoU: 0.9501297766042038 |:  77%|███████▋  | 20/26 [00:54<00:13,  2.23s/it]\u001b[A\n","Training loss: 0.45038173, IoU: 0.9546731928831981 |:  77%|███████▋  | 20/26 [00:57<00:13,  2.23s/it]\u001b[A\n","Training loss: 0.45038173, IoU: 0.9546731928831981 |:  81%|████████  | 21/26 [00:57<00:11,  2.39s/it]\u001b[A\n","Training loss: 0.4606475, IoU: 0.9414879733247425 |:  81%|████████  | 21/26 [00:59<00:11,  2.39s/it] \u001b[A\n","Training loss: 0.4606475, IoU: 0.9414879733247425 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.51s/it]\u001b[A\n","Training loss: 0.45813623, IoU: 0.9385591389309982 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.51s/it]\u001b[A\n","Training loss: 0.45813623, IoU: 0.9385591389309982 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.61s/it]\u001b[A\n","Training loss: 0.40817052, IoU: 0.9376836796164099 |:  88%|████████▊ | 23/26 [01:05<00:07,  2.61s/it]\u001b[A\n","Training loss: 0.40817052, IoU: 0.9376836796164099 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.68s/it]\u001b[A\n","Training loss: 0.45152497, IoU: 0.9445848721761235 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.68s/it]\u001b[A\n","Training loss: 0.45152497, IoU: 0.9445848721761235 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.48552364, IoU: 0.9324097618620552 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.48552364, IoU: 0.9324097618620552 |: 100%|██████████| 26/26 [01:11<00:00,  2.74s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.805179008577203 to 0.8071534194588204\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  14%|█▍        | 21/150 [40:09<2:53:15, 80.58s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4897318, IoU: 0.9458323075951104 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4897318, IoU: 0.9458323075951104 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.5239879, IoU: 0.9438872189545265 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.5239879, IoU: 0.9438872189545265 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.4797454, IoU: 0.9438177704228329 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.4797454, IoU: 0.9438177704228329 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.48378867, IoU: 0.9473406968085488 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.48378867, IoU: 0.9473406968085488 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.43481934, IoU: 0.914671259179231 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it] \u001b[A\n","Training loss: 0.43481934, IoU: 0.914671259179231 |:  19%|█▉        | 5/26 [00:14<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.53113556, IoU: 0.9334895648690832 |:  19%|█▉        | 5/26 [00:16<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.53113556, IoU: 0.9334895648690832 |:  23%|██▎       | 6/26 [00:16<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.49404982, IoU: 0.9423033954685245 |:  23%|██▎       | 6/26 [00:19<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.49404982, IoU: 0.9423033954685245 |:  27%|██▋       | 7/26 [00:19<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.53056866, IoU: 0.9473243208403158 |:  27%|██▋       | 7/26 [00:22<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.53056866, IoU: 0.9473243208403158 |:  31%|███       | 8/26 [00:22<00:51,  2.84s/it]\u001b[A\n","Training loss: 0.4446194, IoU: 0.9490525602926303 |:  31%|███       | 8/26 [00:25<00:51,  2.84s/it] \u001b[A\n","Training loss: 0.4446194, IoU: 0.9490525602926303 |:  35%|███▍      | 9/26 [00:25<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.43499643, IoU: 0.9467290977222396 |:  35%|███▍      | 9/26 [00:28<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.43499643, IoU: 0.9467290977222396 |:  38%|███▊      | 10/26 [00:28<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.5521885, IoU: 0.9356608128214441 |:  38%|███▊      | 10/26 [00:30<00:45,  2.82s/it] \u001b[A\n","Training loss: 0.5521885, IoU: 0.9356608128214441 |:  42%|████▏     | 11/26 [00:31<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.45603967, IoU: 0.9375233803213612 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.45603967, IoU: 0.9375233803213612 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.48622602, IoU: 0.943302639244163 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it] \u001b[A\n","Training loss: 0.48622602, IoU: 0.943302639244163 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.42604727, IoU: 0.9432354983752113 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.42604727, IoU: 0.9432354983752113 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.47040245, IoU: 0.9462984870865716 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.47040245, IoU: 0.9462984870865716 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.48305386, IoU: 0.9287438579212743 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.48305386, IoU: 0.9287438579212743 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.48535687, IoU: 0.9343686490352191 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.48535687, IoU: 0.9343686490352191 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.4915019, IoU: 0.9487814992101977 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.78s/it] \u001b[A\n","Training loss: 0.4915019, IoU: 0.9487814992101977 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.5059287, IoU: 0.9544993828213594 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.5059287, IoU: 0.9544993828213594 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.44823056, IoU: 0.9478960200875799 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.44823056, IoU: 0.9478960200875799 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.51449144, IoU: 0.940655938228661 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.76s/it] \u001b[A\n","Training loss: 0.51449144, IoU: 0.940655938228661 |:  81%|████████  | 21/26 [00:56<00:11,  2.22s/it]\u001b[A\n","Training loss: 0.46537817, IoU: 0.9445800670556371 |:  81%|████████  | 21/26 [00:59<00:11,  2.22s/it]\u001b[A\n","Training loss: 0.46537817, IoU: 0.9445800670556371 |:  85%|████████▍ | 22/26 [00:59<00:09,  2.37s/it]\u001b[A\n","Training loss: 0.5199145, IoU: 0.9349345397033597 |:  85%|████████▍ | 22/26 [01:02<00:09,  2.37s/it] \u001b[A\n","Training loss: 0.5199145, IoU: 0.9349345397033597 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.49s/it]\u001b[A\n","Training loss: 0.4362769, IoU: 0.9408963153762044 |:  88%|████████▊ | 23/26 [01:05<00:07,  2.49s/it]\u001b[A\n","Training loss: 0.4362769, IoU: 0.9408963153762044 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.58s/it]\u001b[A\n","Training loss: 0.4883878, IoU: 0.9231858645805233 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.58s/it]\u001b[A\n","Training loss: 0.4883878, IoU: 0.9231858645805233 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.63s/it]\u001b[A\n","Training loss: 0.5559896, IoU: 0.9453793669522392 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.63s/it]\u001b[A\n","Training loss: 0.5559896, IoU: 0.9453793669522392 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  15%|█▍        | 22/150 [41:28<2:50:35, 79.97s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8071534194588204\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46563572, IoU: 0.9555223927208322 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46563572, IoU: 0.9555223927208322 |:   4%|▍         | 1/26 [00:02<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.50032914, IoU: 0.9343034268985707 |:   4%|▍         | 1/26 [00:05<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.50032914, IoU: 0.9343034268985707 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.42709094, IoU: 0.9388956842976636 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.42709094, IoU: 0.9388956842976636 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4319022, IoU: 0.942044925963253 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]  \u001b[A\n","Training loss: 0.4319022, IoU: 0.942044925963253 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.50600034, IoU: 0.9267451160105843 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.50600034, IoU: 0.9267451160105843 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.41967684, IoU: 0.946758119556544 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it] \u001b[A\n","Training loss: 0.41967684, IoU: 0.946758119556544 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.42694882, IoU: 0.9397962869320234 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.42694882, IoU: 0.9397962869320234 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.4781199, IoU: 0.9395323975426342 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it] \u001b[A\n","Training loss: 0.4781199, IoU: 0.9395323975426342 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.49282616, IoU: 0.9413116526518588 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.49282616, IoU: 0.9413116526518588 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.47221792, IoU: 0.9420591684843967 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.47221792, IoU: 0.9420591684843967 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.4765304, IoU: 0.9312897245762712 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it] \u001b[A\n","Training loss: 0.4765304, IoU: 0.9312897245762712 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.454018, IoU: 0.9438309932598158 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it] \u001b[A\n","Training loss: 0.454018, IoU: 0.9438309932598158 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.44082, IoU: 0.9416935773232867 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it] \u001b[A\n","Training loss: 0.44082, IoU: 0.9416935773232867 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.51126623, IoU: 0.9476655674176876 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.51126623, IoU: 0.9476655674176876 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.45082623, IoU: 0.9400150532040998 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.45082623, IoU: 0.9400150532040998 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.5010708, IoU: 0.9496462671879571 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it] \u001b[A\n","Training loss: 0.5010708, IoU: 0.9496462671879571 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.41141158, IoU: 0.9409394563468888 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.41141158, IoU: 0.9409394563468888 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.49127072, IoU: 0.9446509502698297 |:  65%|██████▌   | 17/26 [00:49<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.49127072, IoU: 0.9446509502698297 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45729825, IoU: 0.943168849585027 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it] \u001b[A\n","Training loss: 0.45729825, IoU: 0.943168849585027 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.46689686, IoU: 0.943264224014694 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.46689686, IoU: 0.943264224014694 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.43841955, IoU: 0.9425981637849806 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.43841955, IoU: 0.9425981637849806 |:  81%|████████  | 21/26 [00:58<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.41054666, IoU: 0.9446453569762016 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.41054666, IoU: 0.9446453569762016 |:  85%|████████▍ | 22/26 [00:59<00:08,  2.23s/it]\u001b[A\n","Training loss: 0.5134984, IoU: 0.9361861120585965 |:  85%|████████▍ | 22/26 [01:02<00:08,  2.23s/it] \u001b[A\n","Training loss: 0.5134984, IoU: 0.9361861120585965 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.39s/it]\u001b[A\n","Training loss: 0.5285816, IoU: 0.9470255528649689 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.39s/it]\u001b[A\n","Training loss: 0.5285816, IoU: 0.9470255528649689 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.50s/it]\u001b[A\n","Training loss: 0.46080917, IoU: 0.9350829160137926 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.50s/it]\u001b[A\n","Training loss: 0.46080917, IoU: 0.9350829160137926 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.58s/it]\u001b[A\n","Training loss: 0.49191916, IoU: 0.9346118083468216 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.58s/it]\u001b[A\n","Training loss: 0.49191916, IoU: 0.9346118083468216 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  15%|█▌        | 23/150 [42:46<2:48:08, 79.44s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8071534194588204\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5137733, IoU: 0.9350880637840256 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5137733, IoU: 0.9350880637840256 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.46438405, IoU: 0.956142205704888 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.46438405, IoU: 0.956142205704888 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.37746096, IoU: 0.929436414011781 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.37746096, IoU: 0.929436414011781 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.46111193, IoU: 0.9417093975552261 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.46111193, IoU: 0.9417093975552261 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.47862363, IoU: 0.9498452941524571 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.47862363, IoU: 0.9498452941524571 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.5491534, IoU: 0.9373965380637177 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it] \u001b[A\n","Training loss: 0.5491534, IoU: 0.9373965380637177 |:  23%|██▎       | 6/26 [00:16<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.470249, IoU: 0.916958947503603 |:  23%|██▎       | 6/26 [00:19<00:55,  2.76s/it]  \u001b[A\n","Training loss: 0.470249, IoU: 0.916958947503603 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.40654683, IoU: 0.9547187991277448 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.40654683, IoU: 0.9547187991277448 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.39739498, IoU: 0.9301876401504072 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.39739498, IoU: 0.9301876401504072 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.50435555, IoU: 0.9291440189948698 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.50435555, IoU: 0.9291440189948698 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.49804813, IoU: 0.9397725913177923 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.49804813, IoU: 0.9397725913177923 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.48133612, IoU: 0.9448461548094624 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.48133612, IoU: 0.9448461548094624 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.4502452, IoU: 0.9491759614893338 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it] \u001b[A\n","Training loss: 0.4502452, IoU: 0.9491759614893338 |:  50%|█████     | 13/26 [00:36<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.5072882, IoU: 0.9484334105066468 |:  50%|█████     | 13/26 [00:38<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.5072882, IoU: 0.9484334105066468 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.49121743, IoU: 0.9395661298133638 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.49121743, IoU: 0.9395661298133638 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.80s/it]\u001b[A\n","Training loss: 0.4386164, IoU: 0.9473811271431741 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.80s/it] \u001b[A\n","Training loss: 0.4386164, IoU: 0.9473811271431741 |:  62%|██████▏   | 16/26 [00:44<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.48919535, IoU: 0.9452134970374121 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.48919535, IoU: 0.9452134970374121 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.4483212, IoU: 0.945732521173587 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.80s/it]  \u001b[A\n","Training loss: 0.4483212, IoU: 0.945732521173587 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.42732656, IoU: 0.9373445551118045 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.42732656, IoU: 0.9373445551118045 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.47276384, IoU: 0.9537947028295883 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.47276384, IoU: 0.9537947028295883 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.4704223, IoU: 0.9434338422678785 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.79s/it] \u001b[A\n","Training loss: 0.4704223, IoU: 0.9434338422678785 |:  81%|████████  | 21/26 [00:58<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.43426412, IoU: 0.9386730399324937 |:  81%|████████  | 21/26 [01:01<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.43426412, IoU: 0.9386730399324937 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.4181251, IoU: 0.952824845643192 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.80s/it]  \u001b[A\n","Training loss: 0.4181251, IoU: 0.952824845643192 |:  88%|████████▊ | 23/26 [01:02<00:06,  2.25s/it]\u001b[A\n","Training loss: 0.47878549, IoU: 0.9407394821076515 |:  88%|████████▊ | 23/26 [01:05<00:06,  2.25s/it]\u001b[A\n","Training loss: 0.47878549, IoU: 0.9407394821076515 |:  92%|█████████▏| 24/26 [01:05<00:04,  2.42s/it]\u001b[A\n","Training loss: 0.40750545, IoU: 0.947178087696094 |:  92%|█████████▏| 24/26 [01:07<00:04,  2.42s/it] \u001b[A\n","Training loss: 0.40750545, IoU: 0.947178087696094 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.54s/it]\u001b[A\n","Training loss: 0.4640528, IoU: 0.9360821880513435 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.54s/it]\u001b[A\n","Training loss: 0.4640528, IoU: 0.9360821880513435 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  16%|█▌        | 24/150 [44:05<2:46:13, 79.16s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8071534194588204\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48361462, IoU: 0.9492065941997735 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48361462, IoU: 0.9492065941997735 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.46311086, IoU: 0.9350522697285681 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.46311086, IoU: 0.9350522697285681 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.52364886, IoU: 0.9463023442312386 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.52364886, IoU: 0.9463023442312386 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.4918002, IoU: 0.9470346926867363 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it] \u001b[A\n","Training loss: 0.4918002, IoU: 0.9470346926867363 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.49806207, IoU: 0.9098851165565034 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.49806207, IoU: 0.9098851165565034 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.4625067, IoU: 0.9393822657852747 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it] \u001b[A\n","Training loss: 0.4625067, IoU: 0.9393822657852747 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.4457634, IoU: 0.949836494440811 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it] \u001b[A\n","Training loss: 0.4457634, IoU: 0.949836494440811 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.4252761, IoU: 0.9355372529625473 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.4252761, IoU: 0.9355372529625473 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.48474678, IoU: 0.9431178591691058 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.48474678, IoU: 0.9431178591691058 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.43588033, IoU: 0.948087910376578 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it] \u001b[A\n","Training loss: 0.43588033, IoU: 0.948087910376578 |:  38%|███▊      | 10/26 [00:27<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.49832302, IoU: 0.937745165368042 |:  38%|███▊      | 10/26 [00:30<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.49832302, IoU: 0.937745165368042 |:  42%|████▏     | 11/26 [00:30<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.53008246, IoU: 0.9297680034699835 |:  42%|████▏     | 11/26 [00:33<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.53008246, IoU: 0.9297680034699835 |:  46%|████▌     | 12/26 [00:33<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.47305185, IoU: 0.9348497156783103 |:  46%|████▌     | 12/26 [00:36<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.47305185, IoU: 0.9348497156783103 |:  50%|█████     | 13/26 [00:36<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.52883786, IoU: 0.9190077149478336 |:  50%|█████     | 13/26 [00:38<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.52883786, IoU: 0.9190077149478336 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.50765145, IoU: 0.9350498570452359 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.50765145, IoU: 0.9350498570452359 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.46980938, IoU: 0.9374426350952019 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.46980938, IoU: 0.9374426350952019 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.43448424, IoU: 0.9465040657522736 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.43448424, IoU: 0.9465040657522736 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.78s/it]\u001b[A\n","Training loss: 0.39843267, IoU: 0.9375204248366014 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.78s/it]\u001b[A\n","Training loss: 0.39843267, IoU: 0.9375204248366014 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.42319137, IoU: 0.9412323527334611 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.42319137, IoU: 0.9412323527334611 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.42536706, IoU: 0.9455229863842733 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.42536706, IoU: 0.9455229863842733 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.47246838, IoU: 0.9438589764073068 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.47246838, IoU: 0.9438589764073068 |:  81%|████████  | 21/26 [00:58<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.48765028, IoU: 0.9377728590696123 |:  81%|████████  | 21/26 [01:01<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.48765028, IoU: 0.9377728590696123 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.50812936, IoU: 0.9453513662763943 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.50812936, IoU: 0.9453513662763943 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4566253, IoU: 0.9480045792178057 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.78s/it] \u001b[A\n","Training loss: 0.4566253, IoU: 0.9480045792178057 |:  92%|█████████▏| 24/26 [01:04<00:04,  2.23s/it]\u001b[A\n","Training loss: 0.4777457, IoU: 0.9462483265219842 |:  92%|█████████▏| 24/26 [01:07<00:04,  2.23s/it]\u001b[A\n","Training loss: 0.4777457, IoU: 0.9462483265219842 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.41s/it]\u001b[A\n","Training loss: 0.45903847, IoU: 0.9497756768585219 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.41s/it]\u001b[A\n","Training loss: 0.45903847, IoU: 0.9497756768585219 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  17%|█▋        | 25/150 [45:23<2:44:23, 78.91s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8071534194588204\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46038306, IoU: 0.9438155634698057 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46038306, IoU: 0.9438155634698057 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.4282865, IoU: 0.9420799914680938 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it] \u001b[A\n","Training loss: 0.4282865, IoU: 0.9420799914680938 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.52791274, IoU: 0.9353089872034668 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.52791274, IoU: 0.9353089872034668 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.48965597, IoU: 0.9467452419219551 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.48965597, IoU: 0.9467452419219551 |:  15%|█▌        | 4/26 [00:11<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.47571826, IoU: 0.9410288911458047 |:  15%|█▌        | 4/26 [00:13<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.47571826, IoU: 0.9410288911458047 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.4583553, IoU: 0.9372218927010939 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it] \u001b[A\n","Training loss: 0.4583553, IoU: 0.9372218927010939 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.50616145, IoU: 0.9324043905045136 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.50616145, IoU: 0.9324043905045136 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.49531206, IoU: 0.9519033925538665 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.49531206, IoU: 0.9519033925538665 |:  31%|███       | 8/26 [00:22<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.43311065, IoU: 0.9403844083770886 |:  31%|███       | 8/26 [00:24<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.43311065, IoU: 0.9403844083770886 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.41641212, IoU: 0.9445568184503415 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.41641212, IoU: 0.9445568184503415 |:  38%|███▊      | 10/26 [00:27<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.53389984, IoU: 0.9237283538629445 |:  38%|███▊      | 10/26 [00:30<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.53389984, IoU: 0.9237283538629445 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.4446873, IoU: 0.9437030469321 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it]    \u001b[A\n","Training loss: 0.4446873, IoU: 0.9437030469321 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.4652897, IoU: 0.9485771825041036 |:  46%|████▌     | 12/26 [00:35<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.4652897, IoU: 0.9485771825041036 |:  50%|█████     | 13/26 [00:35<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.4639343, IoU: 0.9496694344198965 |:  50%|█████     | 13/26 [00:38<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.4639343, IoU: 0.9496694344198965 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.5020965, IoU: 0.9246419841779878 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.5020965, IoU: 0.9246419841779878 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.48714054, IoU: 0.9543624008027 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.76s/it]  \u001b[A\n","Training loss: 0.48714054, IoU: 0.9543624008027 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.3919771, IoU: 0.9411015764141362 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.3919771, IoU: 0.9411015764141362 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.44259357, IoU: 0.9310532750417775 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.44259357, IoU: 0.9310532750417775 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.49434376, IoU: 0.9430874869166637 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.49434376, IoU: 0.9430874869166637 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.49823084, IoU: 0.9512273951860518 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.49823084, IoU: 0.9512273951860518 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.4919449, IoU: 0.9433927819468346 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.75s/it] \u001b[A\n","Training loss: 0.4919449, IoU: 0.9433927819468346 |:  81%|████████  | 21/26 [00:58<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.51464796, IoU: 0.9409136967346182 |:  81%|████████  | 21/26 [01:00<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.51464796, IoU: 0.9409136967346182 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.42411366, IoU: 0.9406265707841102 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.42411366, IoU: 0.9406265707841102 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4929976, IoU: 0.9483774502697218 |:  88%|████████▊ | 23/26 [01:06<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.4929976, IoU: 0.9483774502697218 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.48721495, IoU: 0.9614567584636289 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.48721495, IoU: 0.9614567584636289 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.22s/it]\u001b[A\n","Training loss: 0.4624859, IoU: 0.9389307221589859 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.22s/it] \u001b[A\n","Training loss: 0.4624859, IoU: 0.9389307221589859 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  17%|█▋        | 26/150 [46:41<2:42:30, 78.63s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8071534194588204\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4678054, IoU: 0.9373093164329044 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4678054, IoU: 0.9373093164329044 |:   4%|▍         | 1/26 [00:02<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.44803256, IoU: 0.9366028182839725 |:   4%|▍         | 1/26 [00:05<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.44803256, IoU: 0.9366028182839725 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.47473365, IoU: 0.9530220109455518 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.47473365, IoU: 0.9530220109455518 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.44138843, IoU: 0.9381684333954289 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.44138843, IoU: 0.9381684333954289 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.4203822, IoU: 0.924749576421084 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]  \u001b[A\n","Training loss: 0.4203822, IoU: 0.924749576421084 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.41493815, IoU: 0.9482624394990908 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.41493815, IoU: 0.9482624394990908 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.4764302, IoU: 0.9355947811418834 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it] \u001b[A\n","Training loss: 0.4764302, IoU: 0.9355947811418834 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.45185983, IoU: 0.9312511635379715 |:  27%|██▋       | 7/26 [00:22<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.45185983, IoU: 0.9312511635379715 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.5072898, IoU: 0.9389966754546869 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it] \u001b[A\n","Training loss: 0.5072898, IoU: 0.9389966754546869 |:  35%|███▍      | 9/26 [00:24<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.46137735, IoU: 0.9352095236316185 |:  35%|███▍      | 9/26 [00:27<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.46137735, IoU: 0.9352095236316185 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.5157688, IoU: 0.9387057904719402 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it] \u001b[A\n","Training loss: 0.5157688, IoU: 0.9387057904719402 |:  42%|████▏     | 11/26 [00:30<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.48462513, IoU: 0.9495193801201771 |:  42%|████▏     | 11/26 [00:33<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.48462513, IoU: 0.9495193801201771 |:  46%|████▌     | 12/26 [00:33<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.4225494, IoU: 0.943321067089198 |:  46%|████▌     | 12/26 [00:35<00:38,  2.76s/it]  \u001b[A\n","Training loss: 0.4225494, IoU: 0.943321067089198 |:  50%|█████     | 13/26 [00:35<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.4333812, IoU: 0.9558923353183869 |:  50%|█████     | 13/26 [00:38<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.4333812, IoU: 0.9558923353183869 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.46640998, IoU: 0.9446256241129214 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.46640998, IoU: 0.9446256241129214 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.42720106, IoU: 0.9510004850977507 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.42720106, IoU: 0.9510004850977507 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.5379743, IoU: 0.9352207127045444 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it] \u001b[A\n","Training loss: 0.5379743, IoU: 0.9352207127045444 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.44918337, IoU: 0.9402661492821546 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.44918337, IoU: 0.9402661492821546 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.47221678, IoU: 0.943303322030375 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it] \u001b[A\n","Training loss: 0.47221678, IoU: 0.943303322030375 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.42002025, IoU: 0.9476653605228526 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.42002025, IoU: 0.9476653605228526 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.4552087, IoU: 0.9511570050459381 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.78s/it] \u001b[A\n","Training loss: 0.4552087, IoU: 0.9511570050459381 |:  81%|████████  | 21/26 [00:58<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.44829965, IoU: 0.9403153242507677 |:  81%|████████  | 21/26 [01:00<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.44829965, IoU: 0.9403153242507677 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.48943985, IoU: 0.9466253797273301 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.48943985, IoU: 0.9466253797273301 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.49634105, IoU: 0.945203464655959 |:  88%|████████▊ | 23/26 [01:06<00:08,  2.78s/it] \u001b[A\n","Training loss: 0.49634105, IoU: 0.945203464655959 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.508056, IoU: 0.945146497540968 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.78s/it]  \u001b[A\n","Training loss: 0.508056, IoU: 0.945146497540968 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.5322064, IoU: 0.9277219195447903 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.5322064, IoU: 0.9277219195447903 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.8071534194588204 to 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  18%|█▊        | 27/150 [48:01<2:42:22, 79.21s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.42633575, IoU: 0.9407972031979827 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.42633575, IoU: 0.9407972031979827 |:   4%|▍         | 1/26 [00:02<01:12,  2.89s/it]\u001b[A\n","Training loss: 0.46367097, IoU: 0.9572121654317571 |:   4%|▍         | 1/26 [00:05<01:12,  2.89s/it]\u001b[A\n","Training loss: 0.46367097, IoU: 0.9572121654317571 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.45708692, IoU: 0.933945409670871 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it] \u001b[A\n","Training loss: 0.45708692, IoU: 0.933945409670871 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.5159453, IoU: 0.9337477976340297 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.5159453, IoU: 0.9337477976340297 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.50123286, IoU: 0.9441968703295504 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.50123286, IoU: 0.9441968703295504 |:  19%|█▉        | 5/26 [00:14<00:59,  2.83s/it]\u001b[A\n","Training loss: 0.46632558, IoU: 0.9467800331005214 |:  19%|█▉        | 5/26 [00:16<00:59,  2.83s/it]\u001b[A\n","Training loss: 0.46632558, IoU: 0.9467800331005214 |:  23%|██▎       | 6/26 [00:16<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.45291275, IoU: 0.951518085780107 |:  23%|██▎       | 6/26 [00:19<00:56,  2.83s/it] \u001b[A\n","Training loss: 0.45291275, IoU: 0.951518085780107 |:  27%|██▋       | 7/26 [00:19<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.5032044, IoU: 0.9395822495398887 |:  27%|██▋       | 7/26 [00:22<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.5032044, IoU: 0.9395822495398887 |:  31%|███       | 8/26 [00:22<00:51,  2.85s/it]\u001b[A\n","Training loss: 0.43669063, IoU: 0.9517336758342001 |:  31%|███       | 8/26 [00:25<00:51,  2.85s/it]\u001b[A\n","Training loss: 0.43669063, IoU: 0.9517336758342001 |:  35%|███▍      | 9/26 [00:25<00:48,  2.85s/it]\u001b[A\n","Training loss: 0.5028697, IoU: 0.9529383765106173 |:  35%|███▍      | 9/26 [00:28<00:48,  2.85s/it] \u001b[A\n","Training loss: 0.5028697, IoU: 0.9529383765106173 |:  38%|███▊      | 10/26 [00:28<00:45,  2.84s/it]\u001b[A\n","Training loss: 0.45178783, IoU: 0.9392779234030575 |:  38%|███▊      | 10/26 [00:31<00:45,  2.84s/it]\u001b[A\n","Training loss: 0.45178783, IoU: 0.9392779234030575 |:  42%|████▏     | 11/26 [00:31<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.48578086, IoU: 0.9397938441707118 |:  42%|████▏     | 11/26 [00:33<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.48578086, IoU: 0.9397938441707118 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.47935903, IoU: 0.9353155935749717 |:  46%|████▌     | 12/26 [00:36<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.47935903, IoU: 0.9353155935749717 |:  50%|█████     | 13/26 [00:36<00:36,  2.81s/it]\u001b[A\n","Training loss: 0.43460363, IoU: 0.941994541275391 |:  50%|█████     | 13/26 [00:39<00:36,  2.81s/it] \u001b[A\n","Training loss: 0.43460363, IoU: 0.941994541275391 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.81s/it]\u001b[A\n","Training loss: 0.4969526, IoU: 0.9511133642900527 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.81s/it]\u001b[A\n","Training loss: 0.4969526, IoU: 0.9511133642900527 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.80s/it]\u001b[A\n","Training loss: 0.4325215, IoU: 0.950448866699482 |:  58%|█████▊    | 15/26 [00:45<00:30,  2.80s/it] \u001b[A\n","Training loss: 0.4325215, IoU: 0.950448866699482 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.4882148, IoU: 0.9431950526117714 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.4882148, IoU: 0.9431950526117714 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.47663122, IoU: 0.9496434748469382 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.47663122, IoU: 0.9496434748469382 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.83s/it]\u001b[A\n","Training loss: 0.47792187, IoU: 0.9383392622504246 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.83s/it]\u001b[A\n","Training loss: 0.47792187, IoU: 0.9383392622504246 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.83s/it]\u001b[A\n","Training loss: 0.5269992, IoU: 0.942116653072386 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.83s/it]  \u001b[A\n","Training loss: 0.5269992, IoU: 0.942116653072386 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.83s/it]\u001b[A\n","Training loss: 0.4885053, IoU: 0.9452816711455659 |:  77%|███████▋  | 20/26 [00:59<00:16,  2.83s/it]\u001b[A\n","Training loss: 0.4885053, IoU: 0.9452816711455659 |:  81%|████████  | 21/26 [00:59<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.45965317, IoU: 0.9367067408337819 |:  81%|████████  | 21/26 [01:02<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.45965317, IoU: 0.9367067408337819 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.84s/it]\u001b[A\n","Training loss: 0.45675993, IoU: 0.9395467657556349 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.84s/it]\u001b[A\n","Training loss: 0.45675993, IoU: 0.9395467657556349 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.84s/it]\u001b[A\n","Training loss: 0.4988124, IoU: 0.9434570310377873 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.84s/it] \u001b[A\n","Training loss: 0.4988124, IoU: 0.9434570310377873 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.84s/it]\u001b[A\n","Training loss: 0.49903935, IoU: 0.9483799370457183 |:  92%|█████████▏| 24/26 [01:10<00:05,  2.84s/it]\u001b[A\n","Training loss: 0.49903935, IoU: 0.9483799370457183 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.83s/it]\u001b[A\n","Training loss: 0.49247497, IoU: 0.9372953464209548 |:  96%|█████████▌| 25/26 [01:13<00:02,  2.83s/it]\u001b[A\n","Training loss: 0.49247497, IoU: 0.9372953464209548 |: 100%|██████████| 26/26 [01:13<00:00,  2.82s/it]\n","Epoch Loop:  19%|█▊        | 28/150 [49:23<2:42:21, 79.85s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.50076926, IoU: 0.9172169541871359 |:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.50076926, IoU: 0.9172169541871359 |:   4%|▍         | 1/26 [00:00<00:23,  1.06it/s]\u001b[A\n","Training loss: 0.46705073, IoU: 0.9522251964846663 |:   4%|▍         | 1/26 [00:03<00:23,  1.06it/s]\u001b[A\n","Training loss: 0.46705073, IoU: 0.9522251964846663 |:   8%|▊         | 2/26 [00:03<00:48,  2.02s/it]\u001b[A\n","Training loss: 0.48894006, IoU: 0.9504774885159537 |:   8%|▊         | 2/26 [00:06<00:48,  2.02s/it]\u001b[A\n","Training loss: 0.48894006, IoU: 0.9504774885159537 |:  12%|█▏        | 3/26 [00:06<00:54,  2.37s/it]\u001b[A\n","Training loss: 0.45890263, IoU: 0.9438095381874726 |:  12%|█▏        | 3/26 [00:09<00:54,  2.37s/it]\u001b[A\n","Training loss: 0.45890263, IoU: 0.9438095381874726 |:  15%|█▌        | 4/26 [00:09<00:55,  2.53s/it]\u001b[A\n","Training loss: 0.46630108, IoU: 0.9483832812994265 |:  15%|█▌        | 4/26 [00:12<00:55,  2.53s/it]\u001b[A\n","Training loss: 0.46630108, IoU: 0.9483832812994265 |:  19%|█▉        | 5/26 [00:12<00:54,  2.62s/it]\u001b[A\n","Training loss: 0.45413315, IoU: 0.9405675652021704 |:  19%|█▉        | 5/26 [00:14<00:54,  2.62s/it]\u001b[A\n","Training loss: 0.45413315, IoU: 0.9405675652021704 |:  23%|██▎       | 6/26 [00:14<00:53,  2.67s/it]\u001b[A\n","Training loss: 0.5311541, IoU: 0.9382917115008346 |:  23%|██▎       | 6/26 [00:17<00:53,  2.67s/it] \u001b[A\n","Training loss: 0.5311541, IoU: 0.9382917115008346 |:  27%|██▋       | 7/26 [00:17<00:51,  2.71s/it]\u001b[A\n","Training loss: 0.46986502, IoU: 0.9456401752703048 |:  27%|██▋       | 7/26 [00:20<00:51,  2.71s/it]\u001b[A\n","Training loss: 0.46986502, IoU: 0.9456401752703048 |:  31%|███       | 8/26 [00:20<00:49,  2.73s/it]\u001b[A\n","Training loss: 0.46169126, IoU: 0.9431887700661561 |:  31%|███       | 8/26 [00:23<00:49,  2.73s/it]\u001b[A\n","Training loss: 0.46169126, IoU: 0.9431887700661561 |:  35%|███▍      | 9/26 [00:23<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.4413911, IoU: 0.9391419508545145 |:  35%|███▍      | 9/26 [00:25<00:46,  2.73s/it] \u001b[A\n","Training loss: 0.4413911, IoU: 0.9391419508545145 |:  38%|███▊      | 10/26 [00:25<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.50602686, IoU: 0.9402848085472941 |:  38%|███▊      | 10/26 [00:28<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.50602686, IoU: 0.9402848085472941 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.50105935, IoU: 0.9474776762170641 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.50105935, IoU: 0.9474776762170641 |:  46%|████▌     | 12/26 [00:31<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.45595887, IoU: 0.9549690773287078 |:  46%|████▌     | 12/26 [00:34<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.45595887, IoU: 0.9549690773287078 |:  50%|█████     | 13/26 [00:34<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.52234304, IoU: 0.9439852211558079 |:  50%|█████     | 13/26 [00:37<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.52234304, IoU: 0.9439852211558079 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.4839635, IoU: 0.9445937844935866 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.78s/it] \u001b[A\n","Training loss: 0.4839635, IoU: 0.9445937844935866 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.42292035, IoU: 0.9439608220264437 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.42292035, IoU: 0.9439608220264437 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.48043254, IoU: 0.9272931152727509 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.48043254, IoU: 0.9272931152727509 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.43079144, IoU: 0.9447906155101887 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.43079144, IoU: 0.9447906155101887 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.51400626, IoU: 0.9429303603630715 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.51400626, IoU: 0.9429303603630715 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.5053189, IoU: 0.9439786568793296 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it] \u001b[A\n","Training loss: 0.5053189, IoU: 0.9439786568793296 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.45701265, IoU: 0.9515684607596451 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.45701265, IoU: 0.9515684607596451 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.52934116, IoU: 0.9349230017051273 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.52934116, IoU: 0.9349230017051273 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.47367895, IoU: 0.9458954996279172 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.47367895, IoU: 0.9458954996279172 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.43597835, IoU: 0.9431191969887076 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.43597835, IoU: 0.9431191969887076 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.48708114, IoU: 0.9533706511654133 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.48708114, IoU: 0.9533706511654133 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.5203488, IoU: 0.9354247101624503 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it] \u001b[A\n","Training loss: 0.5203488, IoU: 0.9354247101624503 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  19%|█▉        | 29/150 [50:41<2:40:04, 79.38s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.477165, IoU: 0.952139998643424 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.477165, IoU: 0.952139998643424 |:   4%|▍         | 1/26 [00:02<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.45221156, IoU: 0.9618943091779067 |:   4%|▍         | 1/26 [00:03<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.45221156, IoU: 0.9618943091779067 |:   8%|▊         | 2/26 [00:03<00:40,  1.69s/it]\u001b[A\n","Training loss: 0.48283887, IoU: 0.9384276448221874 |:   8%|▊         | 2/26 [00:06<00:40,  1.69s/it]\u001b[A\n","Training loss: 0.48283887, IoU: 0.9384276448221874 |:  12%|█▏        | 3/26 [00:06<00:50,  2.21s/it]\u001b[A\n","Training loss: 0.4379375, IoU: 0.9434488784280162 |:  12%|█▏        | 3/26 [00:09<00:50,  2.21s/it] \u001b[A\n","Training loss: 0.4379375, IoU: 0.9434488784280162 |:  15%|█▌        | 4/26 [00:09<00:53,  2.43s/it]\u001b[A\n","Training loss: 0.4421196, IoU: 0.9437249168472303 |:  15%|█▌        | 4/26 [00:12<00:53,  2.43s/it]\u001b[A\n","Training loss: 0.4421196, IoU: 0.9437249168472303 |:  19%|█▉        | 5/26 [00:12<00:53,  2.56s/it]\u001b[A\n","Training loss: 0.4674121, IoU: 0.9543489885618145 |:  19%|█▉        | 5/26 [00:14<00:53,  2.56s/it]\u001b[A\n","Training loss: 0.4674121, IoU: 0.9543489885618145 |:  23%|██▎       | 6/26 [00:14<00:52,  2.64s/it]\u001b[A\n","Training loss: 0.44078326, IoU: 0.9351930227841255 |:  23%|██▎       | 6/26 [00:17<00:52,  2.64s/it]\u001b[A\n","Training loss: 0.44078326, IoU: 0.9351930227841255 |:  27%|██▋       | 7/26 [00:17<00:51,  2.70s/it]\u001b[A\n","Training loss: 0.48726028, IoU: 0.9343736865520131 |:  27%|██▋       | 7/26 [00:20<00:51,  2.70s/it]\u001b[A\n","Training loss: 0.48726028, IoU: 0.9343736865520131 |:  31%|███       | 8/26 [00:20<00:49,  2.73s/it]\u001b[A\n","Training loss: 0.4848112, IoU: 0.9407940095427254 |:  31%|███       | 8/26 [00:23<00:49,  2.73s/it] \u001b[A\n","Training loss: 0.4848112, IoU: 0.9407940095427254 |:  35%|███▍      | 9/26 [00:23<00:46,  2.74s/it]\u001b[A\n","Training loss: 0.48627102, IoU: 0.9478999868603027 |:  35%|███▍      | 9/26 [00:26<00:46,  2.74s/it]\u001b[A\n","Training loss: 0.48627102, IoU: 0.9478999868603027 |:  38%|███▊      | 10/26 [00:26<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.47324696, IoU: 0.9439917971179452 |:  38%|███▊      | 10/26 [00:28<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.47324696, IoU: 0.9439917971179452 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.4374079, IoU: 0.9465108436424158 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it] \u001b[A\n","Training loss: 0.4374079, IoU: 0.9465108436424158 |:  46%|████▌     | 12/26 [00:31<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.4542343, IoU: 0.9550112615195483 |:  46%|████▌     | 12/26 [00:34<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.4542343, IoU: 0.9550112615195483 |:  50%|█████     | 13/26 [00:34<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.442347, IoU: 0.9401340375282533 |:  50%|█████     | 13/26 [00:37<00:35,  2.76s/it] \u001b[A\n","Training loss: 0.442347, IoU: 0.9401340375282533 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.53884643, IoU: 0.9345912648296746 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.53884643, IoU: 0.9345912648296746 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.4686338, IoU: 0.9388732556450928 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.76s/it] \u001b[A\n","Training loss: 0.4686338, IoU: 0.9388732556450928 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.48315912, IoU: 0.9413238151750003 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.48315912, IoU: 0.9413238151750003 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.4326305, IoU: 0.9294124235254588 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.76s/it] \u001b[A\n","Training loss: 0.4326305, IoU: 0.9294124235254588 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.4446863, IoU: 0.9395921517791098 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.4446863, IoU: 0.9395921517791098 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.5105288, IoU: 0.940291765032936 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it] \u001b[A\n","Training loss: 0.5105288, IoU: 0.940291765032936 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.46176413, IoU: 0.9438402143163752 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.46176413, IoU: 0.9438402143163752 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45489326, IoU: 0.9506459400637928 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45489326, IoU: 0.9506459400637928 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.53294253, IoU: 0.9366362608166079 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.53294253, IoU: 0.9366362608166079 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.4898486, IoU: 0.9417700616073197 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.79s/it] \u001b[A\n","Training loss: 0.4898486, IoU: 0.9417700616073197 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.4791658, IoU: 0.9566291097587694 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.4791658, IoU: 0.9566291097587694 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.48275602, IoU: 0.9393875242297743 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.48275602, IoU: 0.9393875242297743 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  20%|██        | 30/150 [51:59<2:38:09, 79.08s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4785294, IoU: 0.9348353354463436 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4785294, IoU: 0.9348353354463436 |:   4%|▍         | 1/26 [00:02<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.4440018, IoU: 0.9397627376638248 |:   4%|▍         | 1/26 [00:05<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.4440018, IoU: 0.9397627376638248 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.45113745, IoU: 0.9517431434331972 |:   8%|▊         | 2/26 [00:06<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.45113745, IoU: 0.9517431434331972 |:  12%|█▏        | 3/26 [00:06<00:45,  1.96s/it]\u001b[A\n","Training loss: 0.41733462, IoU: 0.9437107222275936 |:  12%|█▏        | 3/26 [00:09<00:45,  1.96s/it]\u001b[A\n","Training loss: 0.41733462, IoU: 0.9437107222275936 |:  15%|█▌        | 4/26 [00:09<00:50,  2.27s/it]\u001b[A\n","Training loss: 0.47238976, IoU: 0.9393539469973975 |:  15%|█▌        | 4/26 [00:12<00:50,  2.27s/it]\u001b[A\n","Training loss: 0.47238976, IoU: 0.9393539469973975 |:  19%|█▉        | 5/26 [00:12<00:51,  2.47s/it]\u001b[A\n","Training loss: 0.45266688, IoU: 0.9392599039215153 |:  19%|█▉        | 5/26 [00:14<00:51,  2.47s/it]\u001b[A\n","Training loss: 0.45266688, IoU: 0.9392599039215153 |:  23%|██▎       | 6/26 [00:14<00:51,  2.57s/it]\u001b[A\n","Training loss: 0.4636832, IoU: 0.9483000457386797 |:  23%|██▎       | 6/26 [00:17<00:51,  2.57s/it] \u001b[A\n","Training loss: 0.4636832, IoU: 0.9483000457386797 |:  27%|██▋       | 7/26 [00:17<00:50,  2.64s/it]\u001b[A\n","Training loss: 0.48514253, IoU: 0.945659526979572 |:  27%|██▋       | 7/26 [00:20<00:50,  2.64s/it]\u001b[A\n","Training loss: 0.48514253, IoU: 0.945659526979572 |:  31%|███       | 8/26 [00:20<00:48,  2.69s/it]\u001b[A\n","Training loss: 0.48115897, IoU: 0.9544739012607517 |:  31%|███       | 8/26 [00:23<00:48,  2.69s/it]\u001b[A\n","Training loss: 0.48115897, IoU: 0.9544739012607517 |:  35%|███▍      | 9/26 [00:23<00:46,  2.72s/it]\u001b[A\n","Training loss: 0.4747561, IoU: 0.9476748415491357 |:  35%|███▍      | 9/26 [00:26<00:46,  2.72s/it] \u001b[A\n","Training loss: 0.4747561, IoU: 0.9476748415491357 |:  38%|███▊      | 10/26 [00:26<00:43,  2.73s/it]\u001b[A\n","Training loss: 0.4642824, IoU: 0.9379572775608088 |:  38%|███▊      | 10/26 [00:28<00:43,  2.73s/it]\u001b[A\n","Training loss: 0.4642824, IoU: 0.9379572775608088 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.45711505, IoU: 0.9400552205120616 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.45711505, IoU: 0.9400552205120616 |:  46%|████▌     | 12/26 [00:31<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.49881217, IoU: 0.9440846475447504 |:  46%|████▌     | 12/26 [00:34<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.49881217, IoU: 0.9440846475447504 |:  50%|█████     | 13/26 [00:34<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.5134861, IoU: 0.9473892658626595 |:  50%|█████     | 13/26 [00:37<00:36,  2.78s/it] \u001b[A\n","Training loss: 0.5134861, IoU: 0.9473892658626595 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.46653923, IoU: 0.9374196810118145 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.46653923, IoU: 0.9374196810118145 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.4144338, IoU: 0.95145195452456 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it]   \u001b[A\n","Training loss: 0.4144338, IoU: 0.95145195452456 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.4826225, IoU: 0.9223879274485142 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.4826225, IoU: 0.9223879274485142 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.4174026, IoU: 0.9362139231948504 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.4174026, IoU: 0.9362139231948504 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.48011255, IoU: 0.9419275275630091 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.48011255, IoU: 0.9419275275630091 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.43145525, IoU: 0.934693672805101 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it] \u001b[A\n","Training loss: 0.43145525, IoU: 0.934693672805101 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4335774, IoU: 0.9419019007535617 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4335774, IoU: 0.9419019007535617 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47962403, IoU: 0.9539279850662349 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47962403, IoU: 0.9539279850662349 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.4331241, IoU: 0.9495935183462318 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it] \u001b[A\n","Training loss: 0.4331241, IoU: 0.9495935183462318 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.48718107, IoU: 0.9502484077827144 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.48718107, IoU: 0.9502484077827144 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.48744178, IoU: 0.9362229965156794 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.48744178, IoU: 0.9362229965156794 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.47160774, IoU: 0.9504535822281482 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.47160774, IoU: 0.9504535822281482 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  21%|██        | 31/150 [53:18<2:36:34, 78.94s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.51947844, IoU: 0.9278971512298106 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.51947844, IoU: 0.9278971512298106 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.45508957, IoU: 0.9316655922262929 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.45508957, IoU: 0.9316655922262929 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.43154687, IoU: 0.9366104904999697 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.43154687, IoU: 0.9366104904999697 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.56753826, IoU: 0.9576095798025144 |:  12%|█▏        | 3/26 [00:09<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.56753826, IoU: 0.9576095798025144 |:  15%|█▌        | 4/26 [00:09<00:45,  2.06s/it]\u001b[A\n","Training loss: 0.49611494, IoU: 0.9435936986033445 |:  15%|█▌        | 4/26 [00:12<00:45,  2.06s/it]\u001b[A\n","Training loss: 0.49611494, IoU: 0.9435936986033445 |:  19%|█▉        | 5/26 [00:12<00:48,  2.31s/it]\u001b[A\n","Training loss: 0.47160935, IoU: 0.9578693813384 |:  19%|█▉        | 5/26 [00:14<00:48,  2.31s/it]   \u001b[A\n","Training loss: 0.47160935, IoU: 0.9578693813384 |:  23%|██▎       | 6/26 [00:14<00:49,  2.47s/it]\u001b[A\n","Training loss: 0.42154604, IoU: 0.9444756945074486 |:  23%|██▎       | 6/26 [00:17<00:49,  2.47s/it]\u001b[A\n","Training loss: 0.42154604, IoU: 0.9444756945074486 |:  27%|██▋       | 7/26 [00:17<00:48,  2.57s/it]\u001b[A\n","Training loss: 0.48817372, IoU: 0.9440180661171008 |:  27%|██▋       | 7/26 [00:20<00:48,  2.57s/it]\u001b[A\n","Training loss: 0.48817372, IoU: 0.9440180661171008 |:  31%|███       | 8/26 [00:20<00:47,  2.63s/it]\u001b[A\n","Training loss: 0.4770236, IoU: 0.9297268787121333 |:  31%|███       | 8/26 [00:23<00:47,  2.63s/it] \u001b[A\n","Training loss: 0.4770236, IoU: 0.9297268787121333 |:  35%|███▍      | 9/26 [00:23<00:45,  2.68s/it]\u001b[A\n","Training loss: 0.46672088, IoU: 0.9377768147345612 |:  35%|███▍      | 9/26 [00:25<00:45,  2.68s/it]\u001b[A\n","Training loss: 0.46672088, IoU: 0.9377768147345612 |:  38%|███▊      | 10/26 [00:25<00:43,  2.71s/it]\u001b[A\n","Training loss: 0.4782858, IoU: 0.9414961386795571 |:  38%|███▊      | 10/26 [00:28<00:43,  2.71s/it] \u001b[A\n","Training loss: 0.4782858, IoU: 0.9414961386795571 |:  42%|████▏     | 11/26 [00:28<00:41,  2.73s/it]\u001b[A\n","Training loss: 0.47942168, IoU: 0.9426971375526556 |:  42%|████▏     | 11/26 [00:31<00:41,  2.73s/it]\u001b[A\n","Training loss: 0.47942168, IoU: 0.9426971375526556 |:  46%|████▌     | 12/26 [00:31<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.45518813, IoU: 0.9452015206852052 |:  46%|████▌     | 12/26 [00:34<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.45518813, IoU: 0.9452015206852052 |:  50%|█████     | 13/26 [00:34<00:35,  2.75s/it]\u001b[A\n","Training loss: 0.51719224, IoU: 0.937283215443674 |:  50%|█████     | 13/26 [00:37<00:35,  2.75s/it] \u001b[A\n","Training loss: 0.51719224, IoU: 0.937283215443674 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.49165416, IoU: 0.9454960015861477 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.49165416, IoU: 0.9454960015861477 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.43091422, IoU: 0.935849889624724 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.76s/it] \u001b[A\n","Training loss: 0.43091422, IoU: 0.935849889624724 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.44270903, IoU: 0.934786934323404 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.44270903, IoU: 0.934786934323404 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.49409798, IoU: 0.939700519823105 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.49409798, IoU: 0.939700519823105 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.5369532, IoU: 0.9387717019720244 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.5369532, IoU: 0.9387717019720244 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.49544993, IoU: 0.9366773540330746 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.49544993, IoU: 0.9366773540330746 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.4864753, IoU: 0.955320662956348 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]  \u001b[A\n","Training loss: 0.4864753, IoU: 0.955320662956348 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45373592, IoU: 0.947877328507437 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45373592, IoU: 0.947877328507437 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.47193706, IoU: 0.953082892518101 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.47193706, IoU: 0.953082892518101 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4580859, IoU: 0.9345784035251291 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4580859, IoU: 0.9345784035251291 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.46548447, IoU: 0.9577076239395164 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.46548447, IoU: 0.9577076239395164 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.48587018, IoU: 0.9514505508833692 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.48587018, IoU: 0.9514505508833692 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  21%|██▏       | 32/150 [54:36<2:34:51, 78.75s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.42586383, IoU: 0.9518784038113596 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.42586383, IoU: 0.9518784038113596 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.4510835, IoU: 0.9367566363713904 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it] \u001b[A\n","Training loss: 0.4510835, IoU: 0.9367566363713904 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.4655044, IoU: 0.9504784513909853 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.4655044, IoU: 0.9504784513909853 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.49836305, IoU: 0.9518362335368994 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.49836305, IoU: 0.9518362335368994 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.3935681, IoU: 0.9426174833928783 |:  15%|█▌        | 4/26 [00:12<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.3935681, IoU: 0.9426174833928783 |:  19%|█▉        | 5/26 [00:12<00:44,  2.13s/it]\u001b[A\n","Training loss: 0.4757048, IoU: 0.9474285051337085 |:  19%|█▉        | 5/26 [00:14<00:44,  2.13s/it]\u001b[A\n","Training loss: 0.4757048, IoU: 0.9474285051337085 |:  23%|██▎       | 6/26 [00:14<00:46,  2.35s/it]\u001b[A\n","Training loss: 0.48962778, IoU: 0.9380075396530712 |:  23%|██▎       | 6/26 [00:17<00:46,  2.35s/it]\u001b[A\n","Training loss: 0.48962778, IoU: 0.9380075396530712 |:  27%|██▋       | 7/26 [00:17<00:47,  2.49s/it]\u001b[A\n","Training loss: 0.49731484, IoU: 0.9468208229574292 |:  27%|██▋       | 7/26 [00:20<00:47,  2.49s/it]\u001b[A\n","Training loss: 0.49731484, IoU: 0.9468208229574292 |:  31%|███       | 8/26 [00:20<00:46,  2.58s/it]\u001b[A\n","Training loss: 0.42940477, IoU: 0.9434384205463066 |:  31%|███       | 8/26 [00:23<00:46,  2.58s/it]\u001b[A\n","Training loss: 0.42940477, IoU: 0.9434384205463066 |:  35%|███▍      | 9/26 [00:23<00:44,  2.64s/it]\u001b[A\n","Training loss: 0.46696815, IoU: 0.9530810779346458 |:  35%|███▍      | 9/26 [00:26<00:44,  2.64s/it]\u001b[A\n","Training loss: 0.46696815, IoU: 0.9530810779346458 |:  38%|███▊      | 10/26 [00:26<00:42,  2.68s/it]\u001b[A\n","Training loss: 0.45755708, IoU: 0.9339204346087123 |:  38%|███▊      | 10/26 [00:28<00:42,  2.68s/it]\u001b[A\n","Training loss: 0.45755708, IoU: 0.9339204346087123 |:  42%|████▏     | 11/26 [00:28<00:40,  2.71s/it]\u001b[A\n","Training loss: 0.46311176, IoU: 0.9486832025708178 |:  42%|████▏     | 11/26 [00:31<00:40,  2.71s/it]\u001b[A\n","Training loss: 0.46311176, IoU: 0.9486832025708178 |:  46%|████▌     | 12/26 [00:31<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.49394917, IoU: 0.9442908190671929 |:  46%|████▌     | 12/26 [00:34<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.49394917, IoU: 0.9442908190671929 |:  50%|█████     | 13/26 [00:34<00:35,  2.75s/it]\u001b[A\n","Training loss: 0.4637047, IoU: 0.9336385239027117 |:  50%|█████     | 13/26 [00:37<00:35,  2.75s/it] \u001b[A\n","Training loss: 0.4637047, IoU: 0.9336385239027117 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.48502505, IoU: 0.9420191358860748 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.48502505, IoU: 0.9420191358860748 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.4779413, IoU: 0.9377636967776833 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it] \u001b[A\n","Training loss: 0.4779413, IoU: 0.9377636967776833 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.45162153, IoU: 0.936243157060439 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.45162153, IoU: 0.936243157060439 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.48547444, IoU: 0.9417599266924029 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.48547444, IoU: 0.9417599266924029 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.43753716, IoU: 0.9382890587598025 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.43753716, IoU: 0.9382890587598025 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.487398, IoU: 0.9367481375722707 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]  \u001b[A\n","Training loss: 0.487398, IoU: 0.9367481375722707 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.47849065, IoU: 0.9444574485096955 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.47849065, IoU: 0.9444574485096955 |:  81%|████████  | 21/26 [00:56<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.44190356, IoU: 0.9497119989406858 |:  81%|████████  | 21/26 [00:59<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.44190356, IoU: 0.9497119989406858 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.4527371, IoU: 0.9512952868184302 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.80s/it] \u001b[A\n","Training loss: 0.4527371, IoU: 0.9512952868184302 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.49630898, IoU: 0.9489976797122746 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.49630898, IoU: 0.9489976797122746 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.44275576, IoU: 0.948824242814519 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it] \u001b[A\n","Training loss: 0.44275576, IoU: 0.948824242814519 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.43732, IoU: 0.9442407662005212 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]  \u001b[A\n","Training loss: 0.43732, IoU: 0.9442407662005212 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  22%|██▏       | 33/150 [55:55<2:33:25, 78.68s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.51924336, IoU: 0.9445651753771888 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.51924336, IoU: 0.9445651753771888 |:   4%|▍         | 1/26 [00:02<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.43556222, IoU: 0.9467047363742559 |:   4%|▍         | 1/26 [00:05<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.43556222, IoU: 0.9467047363742559 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.43921316, IoU: 0.9456942069327076 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.43921316, IoU: 0.9456942069327076 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.42851183, IoU: 0.9502046128070576 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.42851183, IoU: 0.9502046128070576 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.46621376, IoU: 0.9439288568025621 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.46621376, IoU: 0.9439288568025621 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.5090735, IoU: 0.9547214801800025 |:  19%|█▉        | 5/26 [00:14<00:58,  2.77s/it] \u001b[A\n","Training loss: 0.5090735, IoU: 0.9547214801800025 |:  23%|██▎       | 6/26 [00:14<00:42,  2.15s/it]\u001b[A\n","Training loss: 0.56864935, IoU: 0.9141651837550757 |:  23%|██▎       | 6/26 [00:17<00:42,  2.15s/it]\u001b[A\n","Training loss: 0.56864935, IoU: 0.9141651837550757 |:  27%|██▋       | 7/26 [00:17<00:44,  2.35s/it]\u001b[A\n","Training loss: 0.4444518, IoU: 0.9343612494123037 |:  27%|██▋       | 7/26 [00:20<00:44,  2.35s/it] \u001b[A\n","Training loss: 0.4444518, IoU: 0.9343612494123037 |:  31%|███       | 8/26 [00:20<00:44,  2.49s/it]\u001b[A\n","Training loss: 0.46687222, IoU: 0.9468731699945218 |:  31%|███       | 8/26 [00:23<00:44,  2.49s/it]\u001b[A\n","Training loss: 0.46687222, IoU: 0.9468731699945218 |:  35%|███▍      | 9/26 [00:23<00:43,  2.59s/it]\u001b[A\n","Training loss: 0.49748898, IoU: 0.9482464754551714 |:  35%|███▍      | 9/26 [00:25<00:43,  2.59s/it]\u001b[A\n","Training loss: 0.49748898, IoU: 0.9482464754551714 |:  38%|███▊      | 10/26 [00:25<00:42,  2.65s/it]\u001b[A\n","Training loss: 0.48891425, IoU: 0.9554482127192241 |:  38%|███▊      | 10/26 [00:28<00:42,  2.65s/it]\u001b[A\n","Training loss: 0.48891425, IoU: 0.9554482127192241 |:  42%|████▏     | 11/26 [00:28<00:40,  2.69s/it]\u001b[A\n","Training loss: 0.4738568, IoU: 0.9486684640301026 |:  42%|████▏     | 11/26 [00:31<00:40,  2.69s/it] \u001b[A\n","Training loss: 0.4738568, IoU: 0.9486684640301026 |:  46%|████▌     | 12/26 [00:31<00:38,  2.72s/it]\u001b[A\n","Training loss: 0.43700024, IoU: 0.9405318444213117 |:  46%|████▌     | 12/26 [00:34<00:38,  2.72s/it]\u001b[A\n","Training loss: 0.43700024, IoU: 0.9405318444213117 |:  50%|█████     | 13/26 [00:34<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.4245663, IoU: 0.9394892033432871 |:  50%|█████     | 13/26 [00:37<00:35,  2.73s/it] \u001b[A\n","Training loss: 0.4245663, IoU: 0.9394892033432871 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.49658403, IoU: 0.9500372872579371 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.49658403, IoU: 0.9500372872579371 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.46695188, IoU: 0.9413325094343786 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.46695188, IoU: 0.9413325094343786 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.44049424, IoU: 0.940999624201428 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it] \u001b[A\n","Training loss: 0.44049424, IoU: 0.940999624201428 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.43006593, IoU: 0.9491034086838528 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.43006593, IoU: 0.9491034086838528 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45836723, IoU: 0.9478008982692955 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45836723, IoU: 0.9478008982692955 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.4512842, IoU: 0.9489358937572073 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it] \u001b[A\n","Training loss: 0.4512842, IoU: 0.9489358937572073 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.50017166, IoU: 0.9416312235853126 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.50017166, IoU: 0.9416312235853126 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.48303974, IoU: 0.9466609767223819 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.48303974, IoU: 0.9466609767223819 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.45808747, IoU: 0.9417703735301755 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.45808747, IoU: 0.9417703735301755 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4884424, IoU: 0.9439591327369636 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.78s/it] \u001b[A\n","Training loss: 0.4884424, IoU: 0.9439591327369636 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.5246768, IoU: 0.9274335910739295 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.5246768, IoU: 0.9274335910739295 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4417498, IoU: 0.9532593032870481 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4417498, IoU: 0.9532593032870481 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  23%|██▎       | 34/150 [57:13<2:31:54, 78.57s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44959724, IoU: 0.9465943868472871 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44959724, IoU: 0.9465943868472871 |:   4%|▍         | 1/26 [00:02<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.51711464, IoU: 0.9465237775665045 |:   4%|▍         | 1/26 [00:05<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.51711464, IoU: 0.9465237775665045 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.5035308, IoU: 0.9453189238655488 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it] \u001b[A\n","Training loss: 0.5035308, IoU: 0.9453189238655488 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.46933055, IoU: 0.9495818453569432 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.46933055, IoU: 0.9495818453569432 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.4673099, IoU: 0.9548945341926843 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it] \u001b[A\n","Training loss: 0.4673099, IoU: 0.9548945341926843 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4065224, IoU: 0.9526816294982949 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4065224, IoU: 0.9526816294982949 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.49970537, IoU: 0.9535686521304557 |:  23%|██▎       | 6/26 [00:17<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.49970537, IoU: 0.9535686521304557 |:  27%|██▋       | 7/26 [00:17<00:41,  2.18s/it]\u001b[A\n","Training loss: 0.4405449, IoU: 0.9359820006460164 |:  27%|██▋       | 7/26 [00:20<00:41,  2.18s/it] \u001b[A\n","Training loss: 0.4405449, IoU: 0.9359820006460164 |:  31%|███       | 8/26 [00:20<00:42,  2.37s/it]\u001b[A\n","Training loss: 0.5336237, IoU: 0.9486096232815568 |:  31%|███       | 8/26 [00:23<00:42,  2.37s/it]\u001b[A\n","Training loss: 0.5336237, IoU: 0.9486096232815568 |:  35%|███▍      | 9/26 [00:23<00:42,  2.49s/it]\u001b[A\n","Training loss: 0.47594994, IoU: 0.9475709273381402 |:  35%|███▍      | 9/26 [00:25<00:42,  2.49s/it]\u001b[A\n","Training loss: 0.47594994, IoU: 0.9475709273381402 |:  38%|███▊      | 10/26 [00:25<00:41,  2.58s/it]\u001b[A\n","Training loss: 0.5034017, IoU: 0.9321426608781668 |:  38%|███▊      | 10/26 [00:28<00:41,  2.58s/it] \u001b[A\n","Training loss: 0.5034017, IoU: 0.9321426608781668 |:  42%|████▏     | 11/26 [00:28<00:39,  2.64s/it]\u001b[A\n","Training loss: 0.45081547, IoU: 0.956225409195718 |:  42%|████▏     | 11/26 [00:31<00:39,  2.64s/it]\u001b[A\n","Training loss: 0.45081547, IoU: 0.956225409195718 |:  46%|████▌     | 12/26 [00:31<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.478985, IoU: 0.9537633002115404 |:  46%|████▌     | 12/26 [00:34<00:37,  2.68s/it] \u001b[A\n","Training loss: 0.478985, IoU: 0.9537633002115404 |:  50%|█████     | 13/26 [00:34<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.431574, IoU: 0.9469535556022367 |:  50%|█████     | 13/26 [00:37<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.431574, IoU: 0.9469535556022367 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.5114498, IoU: 0.9523765220324002 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.5114498, IoU: 0.9523765220324002 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.48140067, IoU: 0.9469933499976418 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.48140067, IoU: 0.9469933499976418 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.49878523, IoU: 0.9508134178102885 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.49878523, IoU: 0.9508134178102885 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.473184, IoU: 0.9417701916869045 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.79s/it]  \u001b[A\n","Training loss: 0.473184, IoU: 0.9417701916869045 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.46607584, IoU: 0.937019043150736 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.46607584, IoU: 0.937019043150736 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.49624485, IoU: 0.9530545360812088 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.49624485, IoU: 0.9530545360812088 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.5450491, IoU: 0.937999672467954 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]  \u001b[A\n","Training loss: 0.5450491, IoU: 0.937999672467954 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47155738, IoU: 0.9449631848830311 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47155738, IoU: 0.9449631848830311 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.4499355, IoU: 0.9480699940574417 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it] \u001b[A\n","Training loss: 0.4499355, IoU: 0.9480699940574417 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.4529082, IoU: 0.9326785394116679 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.4529082, IoU: 0.9326785394116679 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.43707025, IoU: 0.9408064292021318 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.43707025, IoU: 0.9408064292021318 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.46243867, IoU: 0.9414890096653528 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.46243867, IoU: 0.9414890096653528 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  23%|██▎       | 35/150 [58:32<2:30:37, 78.59s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45003158, IoU: 0.9434001789338163 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45003158, IoU: 0.9434001789338163 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.47470087, IoU: 0.9332957370026088 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.47470087, IoU: 0.9332957370026088 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.4487075, IoU: 0.9551678398731113 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it] \u001b[A\n","Training loss: 0.4487075, IoU: 0.9551678398731113 |:  12%|█▏        | 3/26 [00:08<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.47432026, IoU: 0.9529687272401314 |:  12%|█▏        | 3/26 [00:11<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.47432026, IoU: 0.9529687272401314 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.4795335, IoU: 0.9391512325055185 |:  15%|█▌        | 4/26 [00:14<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.4795335, IoU: 0.9391512325055185 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.41069582, IoU: 0.9322723087528502 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.41069582, IoU: 0.9322723087528502 |:  23%|██▎       | 6/26 [00:16<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.41301686, IoU: 0.9434264032804178 |:  23%|██▎       | 6/26 [00:19<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.41301686, IoU: 0.9434264032804178 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.3505266, IoU: 0.9310384497392371 |:  27%|██▋       | 7/26 [00:20<00:53,  2.80s/it] \u001b[A\n","Training loss: 0.3505266, IoU: 0.9310384497392371 |:  31%|███       | 8/26 [00:20<00:39,  2.21s/it]\u001b[A\n","Training loss: 0.4477244, IoU: 0.9473090341167408 |:  31%|███       | 8/26 [00:23<00:39,  2.21s/it]\u001b[A\n","Training loss: 0.4477244, IoU: 0.9473090341167408 |:  35%|███▍      | 9/26 [00:23<00:40,  2.39s/it]\u001b[A\n","Training loss: 0.43949053, IoU: 0.9474311743550561 |:  35%|███▍      | 9/26 [00:26<00:40,  2.39s/it]\u001b[A\n","Training loss: 0.43949053, IoU: 0.9474311743550561 |:  38%|███▊      | 10/26 [00:26<00:40,  2.51s/it]\u001b[A\n","Training loss: 0.38750488, IoU: 0.9355154243402716 |:  38%|███▊      | 10/26 [00:28<00:40,  2.51s/it]\u001b[A\n","Training loss: 0.38750488, IoU: 0.9355154243402716 |:  42%|████▏     | 11/26 [00:28<00:39,  2.61s/it]\u001b[A\n","Training loss: 0.4734515, IoU: 0.9512478360191337 |:  42%|████▏     | 11/26 [00:31<00:39,  2.61s/it] \u001b[A\n","Training loss: 0.4734515, IoU: 0.9512478360191337 |:  46%|████▌     | 12/26 [00:31<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.49135262, IoU: 0.9495824369459976 |:  46%|████▌     | 12/26 [00:34<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.49135262, IoU: 0.9495824369459976 |:  50%|█████     | 13/26 [00:34<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.4376924, IoU: 0.9268118292251445 |:  50%|█████     | 13/26 [00:37<00:35,  2.72s/it] \u001b[A\n","Training loss: 0.4376924, IoU: 0.9268118292251445 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.45616305, IoU: 0.9273502696879589 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.45616305, IoU: 0.9273502696879589 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.44400907, IoU: 0.943509784952738 |:  58%|█████▊    | 15/26 [00:43<00:30,  2.77s/it] \u001b[A\n","Training loss: 0.44400907, IoU: 0.943509784952738 |:  62%|██████▏   | 16/26 [00:43<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.4428149, IoU: 0.9403252248882149 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.4428149, IoU: 0.9403252248882149 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.48345244, IoU: 0.9493939945404913 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.48345244, IoU: 0.9493939945404913 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.4770668, IoU: 0.9380589277228151 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.80s/it] \u001b[A\n","Training loss: 0.4770668, IoU: 0.9380589277228151 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.82s/it]\u001b[A\n","Training loss: 0.38613218, IoU: 0.9516345865285378 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.82s/it]\u001b[A\n","Training loss: 0.38613218, IoU: 0.9516345865285378 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.82s/it]\u001b[A\n","Training loss: 0.47372615, IoU: 0.9597714712102721 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.82s/it]\u001b[A\n","Training loss: 0.47372615, IoU: 0.9597714712102721 |:  81%|████████  | 21/26 [00:57<00:14,  2.82s/it]\u001b[A\n","Training loss: 0.45025194, IoU: 0.9476513382078235 |:  81%|████████  | 21/26 [01:00<00:14,  2.82s/it]\u001b[A\n","Training loss: 0.45025194, IoU: 0.9476513382078235 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.82s/it]\u001b[A\n","Training loss: 0.4268487, IoU: 0.9415196948979028 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.82s/it] \u001b[A\n","Training loss: 0.4268487, IoU: 0.9415196948979028 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.82s/it]\u001b[A\n","Training loss: 0.42151693, IoU: 0.9348610055082958 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.82s/it]\u001b[A\n","Training loss: 0.42151693, IoU: 0.9348610055082958 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.82s/it]\u001b[A\n","Training loss: 0.4506169, IoU: 0.9409382018173553 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.82s/it] \u001b[A\n","Training loss: 0.4506169, IoU: 0.9409382018173553 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.82s/it]\u001b[A\n","Training loss: 0.4814695, IoU: 0.9397859859174478 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.82s/it]\u001b[A\n","Training loss: 0.4814695, IoU: 0.9397859859174478 |: 100%|██████████| 26/26 [01:11<00:00,  2.74s/it]\n","Epoch Loop:  24%|██▍       | 36/150 [59:51<2:29:43, 78.80s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46142048, IoU: 0.9383399564670407 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46142048, IoU: 0.9383399564670407 |:   4%|▍         | 1/26 [00:02<01:10,  2.80s/it]\u001b[A\n","Training loss: 0.467291, IoU: 0.9403680625858488 |:   4%|▍         | 1/26 [00:05<01:10,  2.80s/it]  \u001b[A\n","Training loss: 0.467291, IoU: 0.9403680625858488 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.48684183, IoU: 0.9491342136126681 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.48684183, IoU: 0.9491342136126681 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.461438, IoU: 0.9487267768722337 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]  \u001b[A\n","Training loss: 0.461438, IoU: 0.9487267768722337 |:  15%|█▌        | 4/26 [00:11<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.48951107, IoU: 0.9300705240463765 |:  15%|█▌        | 4/26 [00:14<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.48951107, IoU: 0.9300705240463765 |:  19%|█▉        | 5/26 [00:14<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.48672408, IoU: 0.9347608387002017 |:  19%|█▉        | 5/26 [00:16<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.48672408, IoU: 0.9347608387002017 |:  23%|██▎       | 6/26 [00:16<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.44932497, IoU: 0.9295723656727943 |:  23%|██▎       | 6/26 [00:19<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.44932497, IoU: 0.9295723656727943 |:  27%|██▋       | 7/26 [00:19<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.46051794, IoU: 0.9496930815417652 |:  27%|██▋       | 7/26 [00:22<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.46051794, IoU: 0.9496930815417652 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.48599857, IoU: 0.9051257732847627 |:  31%|███       | 8/26 [00:23<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.48599857, IoU: 0.9051257732847627 |:  35%|███▍      | 9/26 [00:23<00:37,  2.23s/it]\u001b[A\n","Training loss: 0.48459387, IoU: 0.9416567362658239 |:  35%|███▍      | 9/26 [00:26<00:37,  2.23s/it]\u001b[A\n","Training loss: 0.48459387, IoU: 0.9416567362658239 |:  38%|███▊      | 10/26 [00:26<00:38,  2.40s/it]\u001b[A\n","Training loss: 0.4746567, IoU: 0.9477664925472912 |:  38%|███▊      | 10/26 [00:29<00:38,  2.40s/it] \u001b[A\n","Training loss: 0.4746567, IoU: 0.9477664925472912 |:  42%|████▏     | 11/26 [00:29<00:37,  2.52s/it]\u001b[A\n","Training loss: 0.45914918, IoU: 0.9473607352397372 |:  42%|████▏     | 11/26 [00:31<00:37,  2.52s/it]\u001b[A\n","Training loss: 0.45914918, IoU: 0.9473607352397372 |:  46%|████▌     | 12/26 [00:31<00:36,  2.62s/it]\u001b[A\n","Training loss: 0.39908507, IoU: 0.9448371901526985 |:  46%|████▌     | 12/26 [00:34<00:36,  2.62s/it]\u001b[A\n","Training loss: 0.39908507, IoU: 0.9448371901526985 |:  50%|█████     | 13/26 [00:34<00:34,  2.68s/it]\u001b[A\n","Training loss: 0.44181305, IoU: 0.9420634861593626 |:  50%|█████     | 13/26 [00:37<00:34,  2.68s/it]\u001b[A\n","Training loss: 0.44181305, IoU: 0.9420634861593626 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.71s/it]\u001b[A\n","Training loss: 0.48924467, IoU: 0.9471430311066611 |:  54%|█████▍    | 14/26 [00:40<00:32,  2.71s/it]\u001b[A\n","Training loss: 0.48924467, IoU: 0.9471430311066611 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.45080894, IoU: 0.9350163386648976 |:  58%|█████▊    | 15/26 [00:43<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.45080894, IoU: 0.9350163386648976 |:  62%|██████▏   | 16/26 [00:43<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.42551142, IoU: 0.9392047736235675 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.42551142, IoU: 0.9392047736235675 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.45831662, IoU: 0.9297548687142718 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.45831662, IoU: 0.9297548687142718 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.43600717, IoU: 0.9447765402509516 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.43600717, IoU: 0.9447765402509516 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.46952572, IoU: 0.9408470766286083 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.46952572, IoU: 0.9408470766286083 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.46607786, IoU: 0.9571666376234718 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.46607786, IoU: 0.9571666376234718 |:  81%|████████  | 21/26 [00:57<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.45036685, IoU: 0.9532392251611348 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.45036685, IoU: 0.9532392251611348 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.4866981, IoU: 0.9587890687788557 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it] \u001b[A\n","Training loss: 0.4866981, IoU: 0.9587890687788557 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4764639, IoU: 0.9445562563890108 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4764639, IoU: 0.9445562563890108 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.44859385, IoU: 0.9239842407538383 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.44859385, IoU: 0.9239842407538383 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.49930853, IoU: 0.9367052937570448 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.49930853, IoU: 0.9367052937570448 |: 100%|██████████| 26/26 [01:11<00:00,  2.73s/it]\n","Epoch Loop:  25%|██▍       | 37/150 [1:01:10<2:28:28, 78.84s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4796389, IoU: 0.9424831217284048 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4796389, IoU: 0.9424831217284048 |:   4%|▍         | 1/26 [00:02<01:10,  2.80s/it]\u001b[A\n","Training loss: 0.47482935, IoU: 0.9298495323302155 |:   4%|▍         | 1/26 [00:05<01:10,  2.80s/it]\u001b[A\n","Training loss: 0.47482935, IoU: 0.9298495323302155 |:   8%|▊         | 2/26 [00:05<01:07,  2.79s/it]\u001b[A\n","Training loss: 0.49555898, IoU: 0.9471248532144871 |:   8%|▊         | 2/26 [00:08<01:07,  2.79s/it]\u001b[A\n","Training loss: 0.49555898, IoU: 0.9471248532144871 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.51144177, IoU: 0.9271992944502202 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.51144177, IoU: 0.9271992944502202 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.4844135, IoU: 0.945305899873794 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]  \u001b[A\n","Training loss: 0.4844135, IoU: 0.945305899873794 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4731197, IoU: 0.9483384455831041 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4731197, IoU: 0.9483384455831041 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.3587684, IoU: 0.9378725009430403 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.3587684, IoU: 0.9378725009430403 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.44958192, IoU: 0.9415864332865521 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.44958192, IoU: 0.9415864332865521 |:  31%|███       | 8/26 [00:22<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.47860557, IoU: 0.9411772613014665 |:  31%|███       | 8/26 [00:25<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.47860557, IoU: 0.9411772613014665 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.4300207, IoU: 0.9540743407052945 |:  35%|███▍      | 9/26 [00:26<00:47,  2.81s/it] \u001b[A\n","Training loss: 0.4300207, IoU: 0.9540743407052945 |:  38%|███▊      | 10/26 [00:26<00:35,  2.23s/it]\u001b[A\n","Training loss: 0.4932677, IoU: 0.9441010836694783 |:  38%|███▊      | 10/26 [00:28<00:35,  2.23s/it]\u001b[A\n","Training loss: 0.4932677, IoU: 0.9441010836694783 |:  42%|████▏     | 11/26 [00:28<00:36,  2.40s/it]\u001b[A\n","Training loss: 0.4443742, IoU: 0.9534149526914657 |:  42%|████▏     | 11/26 [00:31<00:36,  2.40s/it]\u001b[A\n","Training loss: 0.4443742, IoU: 0.9534149526914657 |:  46%|████▌     | 12/26 [00:31<00:35,  2.51s/it]\u001b[A\n","Training loss: 0.46123332, IoU: 0.9500834010256156 |:  46%|████▌     | 12/26 [00:34<00:35,  2.51s/it]\u001b[A\n","Training loss: 0.46123332, IoU: 0.9500834010256156 |:  50%|█████     | 13/26 [00:34<00:33,  2.59s/it]\u001b[A\n","Training loss: 0.47528556, IoU: 0.9567740255661036 |:  50%|█████     | 13/26 [00:37<00:33,  2.59s/it]\u001b[A\n","Training loss: 0.47528556, IoU: 0.9567740255661036 |:  54%|█████▍    | 14/26 [00:37<00:31,  2.64s/it]\u001b[A\n","Training loss: 0.43078125, IoU: 0.9505595581171951 |:  54%|█████▍    | 14/26 [00:39<00:31,  2.64s/it]\u001b[A\n","Training loss: 0.43078125, IoU: 0.9505595581171951 |:  58%|█████▊    | 15/26 [00:39<00:29,  2.68s/it]\u001b[A\n","Training loss: 0.486466, IoU: 0.9550467981059281 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.68s/it]  \u001b[A\n","Training loss: 0.486466, IoU: 0.9550467981059281 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.70s/it]\u001b[A\n","Training loss: 0.4806786, IoU: 0.9436989249244122 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.70s/it]\u001b[A\n","Training loss: 0.4806786, IoU: 0.9436989249244122 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.72s/it]\u001b[A\n","Training loss: 0.44657987, IoU: 0.9368828051411382 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.72s/it]\u001b[A\n","Training loss: 0.44657987, IoU: 0.9368828051411382 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.74s/it]\u001b[A\n","Training loss: 0.48732242, IoU: 0.9496467081499198 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.74s/it]\u001b[A\n","Training loss: 0.48732242, IoU: 0.9496467081499198 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.74s/it]\u001b[A\n","Training loss: 0.4120245, IoU: 0.9431408321854068 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.74s/it] \u001b[A\n","Training loss: 0.4120245, IoU: 0.9431408321854068 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.4179324, IoU: 0.94716854915481 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.76s/it]  \u001b[A\n","Training loss: 0.4179324, IoU: 0.94716854915481 |:  81%|████████  | 21/26 [00:56<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.46573007, IoU: 0.9508753134157705 |:  81%|████████  | 21/26 [00:59<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.46573007, IoU: 0.9508753134157705 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.56369615, IoU: 0.9289655545646849 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.56369615, IoU: 0.9289655545646849 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.46190938, IoU: 0.9463813122809643 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.46190938, IoU: 0.9463813122809643 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.43922383, IoU: 0.9325622997878271 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.43922383, IoU: 0.9325622997878271 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.47489613, IoU: 0.9437918602724813 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.47489613, IoU: 0.9437918602724813 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  25%|██▌       | 38/150 [1:02:28<2:26:55, 78.71s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44314653, IoU: 0.9412614357843668 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44314653, IoU: 0.9412614357843668 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.4770555, IoU: 0.9399354894952489 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it] \u001b[A\n","Training loss: 0.4770555, IoU: 0.9399354894952489 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.5044751, IoU: 0.9419414200276032 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.5044751, IoU: 0.9419414200276032 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.5072257, IoU: 0.9525604539458699 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.5072257, IoU: 0.9525604539458699 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.4893247, IoU: 0.939753787203253 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it] \u001b[A\n","Training loss: 0.4893247, IoU: 0.939753787203253 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.44170463, IoU: 0.9367293470280971 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.44170463, IoU: 0.9367293470280971 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.4401539, IoU: 0.94511885755247 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]   \u001b[A\n","Training loss: 0.4401539, IoU: 0.94511885755247 |:  27%|██▋       | 7/26 [00:19<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.47500157, IoU: 0.9512508229822897 |:  27%|██▋       | 7/26 [00:22<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.47500157, IoU: 0.9512508229822897 |:  31%|███       | 8/26 [00:22<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.44843137, IoU: 0.9539265667399505 |:  31%|███       | 8/26 [00:25<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.44843137, IoU: 0.9539265667399505 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.4951126, IoU: 0.9436854144395784 |:  35%|███▍      | 9/26 [00:28<00:47,  2.81s/it] \u001b[A\n","Training loss: 0.4951126, IoU: 0.9436854144395784 |:  38%|███▊      | 10/26 [00:28<00:45,  2.81s/it]\u001b[A\n","Training loss: 0.5055506, IoU: 0.9665456043133144 |:  38%|███▊      | 10/26 [00:28<00:45,  2.81s/it]\u001b[A\n","Training loss: 0.5055506, IoU: 0.9665456043133144 |:  42%|████▏     | 11/26 [00:28<00:33,  2.24s/it]\u001b[A\n","Training loss: 0.49054772, IoU: 0.9498132974003975 |:  42%|████▏     | 11/26 [00:31<00:33,  2.24s/it]\u001b[A\n","Training loss: 0.49054772, IoU: 0.9498132974003975 |:  46%|████▌     | 12/26 [00:31<00:33,  2.41s/it]\u001b[A\n","Training loss: 0.48626566, IoU: 0.9367009820155628 |:  46%|████▌     | 12/26 [00:34<00:33,  2.41s/it]\u001b[A\n","Training loss: 0.48626566, IoU: 0.9367009820155628 |:  50%|█████     | 13/26 [00:34<00:32,  2.53s/it]\u001b[A\n","Training loss: 0.5109158, IoU: 0.9561791282314386 |:  50%|█████     | 13/26 [00:37<00:32,  2.53s/it] \u001b[A\n","Training loss: 0.5109158, IoU: 0.9561791282314386 |:  54%|█████▍    | 14/26 [00:37<00:31,  2.60s/it]\u001b[A\n","Training loss: 0.4698186, IoU: 0.9460491055564614 |:  54%|█████▍    | 14/26 [00:40<00:31,  2.60s/it]\u001b[A\n","Training loss: 0.4698186, IoU: 0.9460491055564614 |:  58%|█████▊    | 15/26 [00:40<00:29,  2.65s/it]\u001b[A\n","Training loss: 0.42908463, IoU: 0.9389215461483611 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.65s/it]\u001b[A\n","Training loss: 0.42908463, IoU: 0.9389215461483611 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.68s/it]\u001b[A\n","Training loss: 0.43729556, IoU: 0.9443618358140955 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.68s/it]\u001b[A\n","Training loss: 0.43729556, IoU: 0.9443618358140955 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.71s/it]\u001b[A\n","Training loss: 0.46367508, IoU: 0.9492416843351139 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.71s/it]\u001b[A\n","Training loss: 0.46367508, IoU: 0.9492416843351139 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.73s/it]\u001b[A\n","Training loss: 0.41537404, IoU: 0.9302801773171088 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.73s/it]\u001b[A\n","Training loss: 0.41537404, IoU: 0.9302801773171088 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.74s/it]\u001b[A\n","Training loss: 0.4965934, IoU: 0.941858721675413 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.74s/it]  \u001b[A\n","Training loss: 0.4965934, IoU: 0.941858721675413 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.430564, IoU: 0.9480480354607328 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.430564, IoU: 0.9480480354607328 |:  81%|████████  | 21/26 [00:56<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.46072167, IoU: 0.9466022537913438 |:  81%|████████  | 21/26 [00:59<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.46072167, IoU: 0.9466022537913438 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.4487224, IoU: 0.9519607502000765 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.76s/it] \u001b[A\n","Training loss: 0.4487224, IoU: 0.9519607502000765 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.49928012, IoU: 0.9408324868661053 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.49928012, IoU: 0.9408324868661053 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.46610957, IoU: 0.9409777276203622 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.46610957, IoU: 0.9409777276203622 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.46386126, IoU: 0.9404177851831281 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.46386126, IoU: 0.9404177851831281 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  26%|██▌       | 39/150 [1:03:47<2:25:27, 78.63s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47478354, IoU: 0.931189957128999 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47478354, IoU: 0.931189957128999 |:   4%|▍         | 1/26 [00:02<01:11,  2.85s/it]\u001b[A\n","Training loss: 0.44978774, IoU: 0.9529098730556891 |:   4%|▍         | 1/26 [00:05<01:11,  2.85s/it]\u001b[A\n","Training loss: 0.44978774, IoU: 0.9529098730556891 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.45535606, IoU: 0.9326143474311434 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.45535606, IoU: 0.9326143474311434 |:  12%|█▏        | 3/26 [00:08<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.4604441, IoU: 0.9365541209512841 |:  12%|█▏        | 3/26 [00:11<01:05,  2.83s/it] \u001b[A\n","Training loss: 0.4604441, IoU: 0.9365541209512841 |:  15%|█▌        | 4/26 [00:11<01:02,  2.84s/it]\u001b[A\n","Training loss: 0.51608944, IoU: 0.9492489158084906 |:  15%|█▌        | 4/26 [00:14<01:02,  2.84s/it]\u001b[A\n","Training loss: 0.51608944, IoU: 0.9492489158084906 |:  19%|█▉        | 5/26 [00:14<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.48335516, IoU: 0.9570990575136789 |:  19%|█▉        | 5/26 [00:17<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.48335516, IoU: 0.9570990575136789 |:  23%|██▎       | 6/26 [00:17<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.4685288, IoU: 0.9529465132582787 |:  23%|██▎       | 6/26 [00:19<00:56,  2.83s/it] \u001b[A\n","Training loss: 0.4685288, IoU: 0.9529465132582787 |:  27%|██▋       | 7/26 [00:19<00:53,  2.83s/it]\u001b[A\n","Training loss: 0.44906408, IoU: 0.934339810814799 |:  27%|██▋       | 7/26 [00:22<00:53,  2.83s/it]\u001b[A\n","Training loss: 0.44906408, IoU: 0.934339810814799 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.45033655, IoU: 0.9514151518196337 |:  31%|███       | 8/26 [00:25<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.45033655, IoU: 0.9514151518196337 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.4439534, IoU: 0.9216278666420495 |:  35%|███▍      | 9/26 [00:28<00:47,  2.80s/it] \u001b[A\n","Training loss: 0.4439534, IoU: 0.9216278666420495 |:  38%|███▊      | 10/26 [00:28<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.39992762, IoU: 0.9468137296777485 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.39992762, IoU: 0.9468137296777485 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.51650405, IoU: 0.9353634291810115 |:  42%|████▏     | 11/26 [00:31<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.51650405, IoU: 0.9353634291810115 |:  46%|████▌     | 12/26 [00:31<00:31,  2.23s/it]\u001b[A\n","Training loss: 0.50014806, IoU: 0.9499070456088791 |:  46%|████▌     | 12/26 [00:34<00:31,  2.23s/it]\u001b[A\n","Training loss: 0.50014806, IoU: 0.9499070456088791 |:  50%|█████     | 13/26 [00:34<00:31,  2.39s/it]\u001b[A\n","Training loss: 0.4381346, IoU: 0.9507583361348196 |:  50%|█████     | 13/26 [00:37<00:31,  2.39s/it] \u001b[A\n","Training loss: 0.4381346, IoU: 0.9507583361348196 |:  54%|█████▍    | 14/26 [00:37<00:30,  2.51s/it]\u001b[A\n","Training loss: 0.49850368, IoU: 0.9457795999864304 |:  54%|█████▍    | 14/26 [00:40<00:30,  2.51s/it]\u001b[A\n","Training loss: 0.49850368, IoU: 0.9457795999864304 |:  58%|█████▊    | 15/26 [00:40<00:28,  2.59s/it]\u001b[A\n","Training loss: 0.4947744, IoU: 0.9485677719604421 |:  58%|█████▊    | 15/26 [00:42<00:28,  2.59s/it] \u001b[A\n","Training loss: 0.4947744, IoU: 0.9485677719604421 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.64s/it]\u001b[A\n","Training loss: 0.45220172, IoU: 0.9550575736106938 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.64s/it]\u001b[A\n","Training loss: 0.45220172, IoU: 0.9550575736106938 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.68s/it]\u001b[A\n","Training loss: 0.4580189, IoU: 0.9581806626576513 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.68s/it] \u001b[A\n","Training loss: 0.4580189, IoU: 0.9581806626576513 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.48416856, IoU: 0.9424397520027068 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.48416856, IoU: 0.9424397520027068 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.72s/it]\u001b[A\n","Training loss: 0.47757298, IoU: 0.9540216563107005 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.72s/it]\u001b[A\n","Training loss: 0.47757298, IoU: 0.9540216563107005 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.73s/it]\u001b[A\n","Training loss: 0.49644375, IoU: 0.9468914000656271 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.73s/it]\u001b[A\n","Training loss: 0.49644375, IoU: 0.9468914000656271 |:  81%|████████  | 21/26 [00:56<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.4790463, IoU: 0.9508436712552362 |:  81%|████████  | 21/26 [00:59<00:13,  2.75s/it] \u001b[A\n","Training loss: 0.4790463, IoU: 0.9508436712552362 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.75s/it]\u001b[A\n","Training loss: 0.46315664, IoU: 0.9470092126463449 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.75s/it]\u001b[A\n","Training loss: 0.46315664, IoU: 0.9470092126463449 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.45382124, IoU: 0.9329706868117252 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.45382124, IoU: 0.9329706868117252 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.43312567, IoU: 0.9412890916853452 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.43312567, IoU: 0.9412890916853452 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.5092323, IoU: 0.9443931529825569 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it] \u001b[A\n","Training loss: 0.5092323, IoU: 0.9443931529825569 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  27%|██▋       | 40/150 [1:05:05<2:24:05, 78.59s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.41956565, IoU: 0.9433873250511087 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.41956565, IoU: 0.9433873250511087 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.498412, IoU: 0.9479959138686523 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]  \u001b[A\n","Training loss: 0.498412, IoU: 0.9479959138686523 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.4636889, IoU: 0.9480200557204591 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.4636889, IoU: 0.9480200557204591 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.47783008, IoU: 0.9517613128408788 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.47783008, IoU: 0.9517613128408788 |:  15%|█▌        | 4/26 [00:11<01:01,  2.77s/it]\u001b[A\n","Training loss: 0.47171807, IoU: 0.9479688414565023 |:  15%|█▌        | 4/26 [00:13<01:01,  2.77s/it]\u001b[A\n","Training loss: 0.47171807, IoU: 0.9479688414565023 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.47310856, IoU: 0.9510264007078929 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.47310856, IoU: 0.9510264007078929 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.44460523, IoU: 0.945503501016648 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it] \u001b[A\n","Training loss: 0.44460523, IoU: 0.945503501016648 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.483248, IoU: 0.9447791065913964 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it] \u001b[A\n","Training loss: 0.483248, IoU: 0.9447791065913964 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.4618668, IoU: 0.9463739619237086 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.4618668, IoU: 0.9463739619237086 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.45700392, IoU: 0.9492873973417518 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.45700392, IoU: 0.9492873973417518 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.44786322, IoU: 0.9368857610848698 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.44786322, IoU: 0.9368857610848698 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.41923204, IoU: 0.951558968563797 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it] \u001b[A\n","Training loss: 0.41923204, IoU: 0.951558968563797 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.52027744, IoU: 0.9520431073192636 |:  46%|████▌     | 12/26 [00:34<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.52027744, IoU: 0.9520431073192636 |:  50%|█████     | 13/26 [00:34<00:29,  2.24s/it]\u001b[A\n","Training loss: 0.42518663, IoU: 0.9501911205592576 |:  50%|█████     | 13/26 [00:37<00:29,  2.24s/it]\u001b[A\n","Training loss: 0.42518663, IoU: 0.9501911205592576 |:  54%|█████▍    | 14/26 [00:37<00:29,  2.43s/it]\u001b[A\n","Training loss: 0.4698165, IoU: 0.9543770061948081 |:  54%|█████▍    | 14/26 [00:40<00:29,  2.43s/it] \u001b[A\n","Training loss: 0.4698165, IoU: 0.9543770061948081 |:  58%|█████▊    | 15/26 [00:40<00:28,  2.55s/it]\u001b[A\n","Training loss: 0.5284791, IoU: 0.9384098620684946 |:  58%|█████▊    | 15/26 [00:42<00:28,  2.55s/it]\u001b[A\n","Training loss: 0.5284791, IoU: 0.9384098620684946 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.63s/it]\u001b[A\n","Training loss: 0.44291115, IoU: 0.9521643119493454 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.63s/it]\u001b[A\n","Training loss: 0.44291115, IoU: 0.9521643119493454 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.68s/it]\u001b[A\n","Training loss: 0.4190016, IoU: 0.9492259979560937 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.68s/it] \u001b[A\n","Training loss: 0.4190016, IoU: 0.9492259979560937 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.45701584, IoU: 0.9425502049706213 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.45701584, IoU: 0.9425502049706213 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.73s/it]\u001b[A\n","Training loss: 0.5064323, IoU: 0.9233533804328385 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.73s/it] \u001b[A\n","Training loss: 0.5064323, IoU: 0.9233533804328385 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.4830125, IoU: 0.9479288798157165 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.4830125, IoU: 0.9479288798157165 |:  81%|████████  | 21/26 [00:56<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.48137742, IoU: 0.9455200259481708 |:  81%|████████  | 21/26 [00:59<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.48137742, IoU: 0.9455200259481708 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.50244254, IoU: 0.9436683712972965 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.50244254, IoU: 0.9436683712972965 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.51276225, IoU: 0.9493758354559773 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.51276225, IoU: 0.9493758354559773 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.75s/it]\u001b[A\n","Training loss: 0.4423713, IoU: 0.9369399977506185 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.75s/it] \u001b[A\n","Training loss: 0.4423713, IoU: 0.9369399977506185 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.75s/it]\u001b[A\n","Training loss: 0.47977513, IoU: 0.950799821013142 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.75s/it]\u001b[A\n","Training loss: 0.47977513, IoU: 0.950799821013142 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  27%|██▋       | 41/150 [1:06:24<2:22:44, 78.57s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5150637, IoU: 0.9519117526520364 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5150637, IoU: 0.9519117526520364 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.50678724, IoU: 0.9505487093437971 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.50678724, IoU: 0.9505487093437971 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.44500524, IoU: 0.952986914620614 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it] \u001b[A\n","Training loss: 0.44500524, IoU: 0.952986914620614 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.50691086, IoU: 0.9433618970676108 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.50691086, IoU: 0.9433618970676108 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.4141811, IoU: 0.9447992123033666 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it] \u001b[A\n","Training loss: 0.4141811, IoU: 0.9447992123033666 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4580105, IoU: 0.9446788652297541 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4580105, IoU: 0.9446788652297541 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.50775594, IoU: 0.9502461584365209 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.50775594, IoU: 0.9502461584365209 |:  27%|██▋       | 7/26 [00:19<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.49764627, IoU: 0.9456348193781212 |:  27%|██▋       | 7/26 [00:22<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.49764627, IoU: 0.9456348193781212 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.47290355, IoU: 0.9448644449926843 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.47290355, IoU: 0.9448644449926843 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.41804966, IoU: 0.9513037355018248 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.41804966, IoU: 0.9513037355018248 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.45413214, IoU: 0.9526540627632999 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.45413214, IoU: 0.9526540627632999 |:  42%|████▏     | 11/26 [00:30<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.42732114, IoU: 0.9433406333746363 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.42732114, IoU: 0.9433406333746363 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.43731195, IoU: 0.9483226396944141 |:  46%|████▌     | 12/26 [00:36<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.43731195, IoU: 0.9483226396944141 |:  50%|█████     | 13/26 [00:36<00:36,  2.81s/it]\u001b[A\n","Training loss: 0.4341006, IoU: 0.939539295685074 |:  50%|█████     | 13/26 [00:37<00:36,  2.81s/it]  \u001b[A\n","Training loss: 0.4341006, IoU: 0.939539295685074 |:  54%|█████▍    | 14/26 [00:37<00:27,  2.25s/it]\u001b[A\n","Training loss: 0.4256995, IoU: 0.9445842270252434 |:  54%|█████▍    | 14/26 [00:40<00:27,  2.25s/it]\u001b[A\n","Training loss: 0.4256995, IoU: 0.9445842270252434 |:  58%|█████▊    | 15/26 [00:40<00:26,  2.42s/it]\u001b[A\n","Training loss: 0.46814615, IoU: 0.9581232347386114 |:  58%|█████▊    | 15/26 [00:42<00:26,  2.42s/it]\u001b[A\n","Training loss: 0.46814615, IoU: 0.9581232347386114 |:  62%|██████▏   | 16/26 [00:42<00:25,  2.54s/it]\u001b[A\n","Training loss: 0.45710468, IoU: 0.9548138460118543 |:  62%|██████▏   | 16/26 [00:45<00:25,  2.54s/it]\u001b[A\n","Training loss: 0.45710468, IoU: 0.9548138460118543 |:  65%|██████▌   | 17/26 [00:45<00:23,  2.61s/it]\u001b[A\n","Training loss: 0.47481877, IoU: 0.9395386196387862 |:  65%|██████▌   | 17/26 [00:48<00:23,  2.61s/it]\u001b[A\n","Training loss: 0.47481877, IoU: 0.9395386196387862 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.66s/it]\u001b[A\n","Training loss: 0.47026837, IoU: 0.9463993493935277 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.66s/it]\u001b[A\n","Training loss: 0.47026837, IoU: 0.9463993493935277 |:  73%|███████▎  | 19/26 [00:51<00:18,  2.70s/it]\u001b[A\n","Training loss: 0.4752458, IoU: 0.9457732339381066 |:  73%|███████▎  | 19/26 [00:54<00:18,  2.70s/it] \u001b[A\n","Training loss: 0.4752458, IoU: 0.9457732339381066 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.72s/it]\u001b[A\n","Training loss: 0.45875233, IoU: 0.9532813117693123 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.72s/it]\u001b[A\n","Training loss: 0.45875233, IoU: 0.9532813117693123 |:  81%|████████  | 21/26 [00:56<00:13,  2.74s/it]\u001b[A\n","Training loss: 0.4639447, IoU: 0.9515569666905501 |:  81%|████████  | 21/26 [00:59<00:13,  2.74s/it] \u001b[A\n","Training loss: 0.4639447, IoU: 0.9515569666905501 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.43197292, IoU: 0.9441977629929611 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.43197292, IoU: 0.9441977629929611 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.49934244, IoU: 0.9380863495289323 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.49934244, IoU: 0.9380863495289323 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.5027312, IoU: 0.9477621497022602 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it] \u001b[A\n","Training loss: 0.5027312, IoU: 0.9477621497022602 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.40413862, IoU: 0.9395989509013807 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.40413862, IoU: 0.9395989509013807 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  28%|██▊       | 42/150 [1:07:43<2:21:28, 78.59s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8095836808488212\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46189559, IoU: 0.9512451548564332 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46189559, IoU: 0.9512451548564332 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.44802666, IoU: 0.9429062759978086 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.44802666, IoU: 0.9429062759978086 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.46565452, IoU: 0.9472671726252607 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.46565452, IoU: 0.9472671726252607 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.4491613, IoU: 0.9405069039819888 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it] \u001b[A\n","Training loss: 0.4491613, IoU: 0.9405069039819888 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46151096, IoU: 0.9536053674115529 |:  15%|█▌        | 4/26 [00:14<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46151096, IoU: 0.9536053674115529 |:  19%|█▉        | 5/26 [00:14<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.41898948, IoU: 0.9474485343699179 |:  19%|█▉        | 5/26 [00:16<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.41898948, IoU: 0.9474485343699179 |:  23%|██▎       | 6/26 [00:16<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.51038, IoU: 0.9440979235300457 |:  23%|██▎       | 6/26 [00:19<00:56,  2.80s/it]   \u001b[A\n","Training loss: 0.51038, IoU: 0.9440979235300457 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.43607327, IoU: 0.9463073247537637 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.43607327, IoU: 0.9463073247537637 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.44634056, IoU: 0.9483456243003382 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.44634056, IoU: 0.9483456243003382 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.48558617, IoU: 0.9474123253565593 |:  35%|███▍      | 9/26 [00:27<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.48558617, IoU: 0.9474123253565593 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.5312095, IoU: 0.950074637309325 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]  \u001b[A\n","Training loss: 0.5312095, IoU: 0.950074637309325 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.5089751, IoU: 0.9275939740360395 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.5089751, IoU: 0.9275939740360395 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.4155814, IoU: 0.9439500507766954 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.4155814, IoU: 0.9439500507766954 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.5091786, IoU: 0.942855224882524 |:  50%|█████     | 13/26 [00:39<00:36,  2.78s/it] \u001b[A\n","Training loss: 0.5091786, IoU: 0.942855224882524 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.3158459, IoU: 0.9489740527630007 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.3158459, IoU: 0.9489740527630007 |:  58%|█████▊    | 15/26 [00:39<00:24,  2.23s/it]\u001b[A\n","Training loss: 0.49642542, IoU: 0.9500627329207004 |:  58%|█████▊    | 15/26 [00:42<00:24,  2.23s/it]\u001b[A\n","Training loss: 0.49642542, IoU: 0.9500627329207004 |:  62%|██████▏   | 16/26 [00:42<00:23,  2.38s/it]\u001b[A\n","Training loss: 0.4245572, IoU: 0.9393393915529259 |:  62%|██████▏   | 16/26 [00:45<00:23,  2.38s/it] \u001b[A\n","Training loss: 0.4245572, IoU: 0.9393393915529259 |:  65%|██████▌   | 17/26 [00:45<00:22,  2.51s/it]\u001b[A\n","Training loss: 0.47906855, IoU: 0.922405383742058 |:  65%|██████▌   | 17/26 [00:48<00:22,  2.51s/it]\u001b[A\n","Training loss: 0.47906855, IoU: 0.922405383742058 |:  69%|██████▉   | 18/26 [00:48<00:20,  2.58s/it]\u001b[A\n","Training loss: 0.42390433, IoU: 0.9445722471663548 |:  69%|██████▉   | 18/26 [00:51<00:20,  2.58s/it]\u001b[A\n","Training loss: 0.42390433, IoU: 0.9445722471663548 |:  73%|███████▎  | 19/26 [00:51<00:18,  2.65s/it]\u001b[A\n","Training loss: 0.46417862, IoU: 0.9501148656664905 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.65s/it]\u001b[A\n","Training loss: 0.46417862, IoU: 0.9501148656664905 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.43573746, IoU: 0.9474498149575765 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.43573746, IoU: 0.9474498149575765 |:  81%|████████  | 21/26 [00:56<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.48695046, IoU: 0.9369234468327219 |:  81%|████████  | 21/26 [00:59<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.48695046, IoU: 0.9369234468327219 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.51340216, IoU: 0.9458899849120443 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.51340216, IoU: 0.9458899849120443 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4924815, IoU: 0.9413136701693308 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it] \u001b[A\n","Training loss: 0.4924815, IoU: 0.9413136701693308 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.43750915, IoU: 0.9448551574539997 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.43750915, IoU: 0.9448551574539997 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4663274, IoU: 0.9503459585748304 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it] \u001b[A\n","Training loss: 0.4663274, IoU: 0.9503459585748304 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.8095836808488212 to 0.8146942287181347\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  29%|██▊       | 43/150 [1:09:05<2:22:14, 79.76s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46979958, IoU: 0.9543061396518607 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46979958, IoU: 0.9543061396518607 |:   4%|▍         | 1/26 [00:02<01:11,  2.86s/it]\u001b[A\n","Training loss: 0.5133306, IoU: 0.9439777373920945 |:   4%|▍         | 1/26 [00:05<01:11,  2.86s/it] \u001b[A\n","Training loss: 0.5133306, IoU: 0.9439777373920945 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.48878902, IoU: 0.923947105129028 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.48878902, IoU: 0.923947105129028 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.49002528, IoU: 0.9526532912747355 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.49002528, IoU: 0.9526532912747355 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.5022652, IoU: 0.9549986976905713 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it] \u001b[A\n","Training loss: 0.5022652, IoU: 0.9549986976905713 |:  19%|█▉        | 5/26 [00:14<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.4342649, IoU: 0.9539527322498876 |:  19%|█▉        | 5/26 [00:16<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.4342649, IoU: 0.9539527322498876 |:  23%|██▎       | 6/26 [00:16<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.4289019, IoU: 0.9567187406176818 |:  23%|██▎       | 6/26 [00:19<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.4289019, IoU: 0.9567187406176818 |:  27%|██▋       | 7/26 [00:19<00:54,  2.86s/it]\u001b[A\n","Training loss: 0.46645206, IoU: 0.9496680324119768 |:  27%|██▋       | 7/26 [00:22<00:54,  2.86s/it]\u001b[A\n","Training loss: 0.46645206, IoU: 0.9496680324119768 |:  31%|███       | 8/26 [00:22<00:50,  2.83s/it]\u001b[A\n","Training loss: 0.45439252, IoU: 0.9571378070390727 |:  31%|███       | 8/26 [00:25<00:50,  2.83s/it]\u001b[A\n","Training loss: 0.45439252, IoU: 0.9571378070390727 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.46624285, IoU: 0.9520456499945361 |:  35%|███▍      | 9/26 [00:28<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.46624285, IoU: 0.9520456499945361 |:  38%|███▊      | 10/26 [00:28<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.47039288, IoU: 0.9531078065944389 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.47039288, IoU: 0.9531078065944389 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.46098173, IoU: 0.954625558271927 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it] \u001b[A\n","Training loss: 0.46098173, IoU: 0.954625558271927 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.47661677, IoU: 0.9449751737100319 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.47661677, IoU: 0.9449751737100319 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.478843, IoU: 0.9403761659708653 |:  50%|█████     | 13/26 [00:39<00:36,  2.78s/it]  \u001b[A\n","Training loss: 0.478843, IoU: 0.9403761659708653 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.45598537, IoU: 0.947173729479224 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.45598537, IoU: 0.947173729479224 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.56273305, IoU: 0.9140386974241285 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.56273305, IoU: 0.9140386974241285 |:  62%|██████▏   | 16/26 [00:42<00:22,  2.22s/it]\u001b[A\n","Training loss: 0.453623, IoU: 0.9543457689723113 |:  62%|██████▏   | 16/26 [00:45<00:22,  2.22s/it]  \u001b[A\n","Training loss: 0.453623, IoU: 0.9543457689723113 |:  65%|██████▌   | 17/26 [00:45<00:21,  2.38s/it]\u001b[A\n","Training loss: 0.41809994, IoU: 0.9385619977701806 |:  65%|██████▌   | 17/26 [00:48<00:21,  2.38s/it]\u001b[A\n","Training loss: 0.41809994, IoU: 0.9385619977701806 |:  69%|██████▉   | 18/26 [00:48<00:19,  2.49s/it]\u001b[A\n","Training loss: 0.46264797, IoU: 0.8962765734763424 |:  69%|██████▉   | 18/26 [00:51<00:19,  2.49s/it]\u001b[A\n","Training loss: 0.46264797, IoU: 0.8962765734763424 |:  73%|███████▎  | 19/26 [00:51<00:18,  2.58s/it]\u001b[A\n","Training loss: 0.5135111, IoU: 0.9512925281017026 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.58s/it] \u001b[A\n","Training loss: 0.5135111, IoU: 0.9512925281017026 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.63s/it]\u001b[A\n","Training loss: 0.47381243, IoU: 0.9436180405805585 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.63s/it]\u001b[A\n","Training loss: 0.47381243, IoU: 0.9436180405805585 |:  81%|████████  | 21/26 [00:56<00:13,  2.67s/it]\u001b[A\n","Training loss: 0.48810554, IoU: 0.9386852691026333 |:  81%|████████  | 21/26 [00:59<00:13,  2.67s/it]\u001b[A\n","Training loss: 0.48810554, IoU: 0.9386852691026333 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.69s/it]\u001b[A\n","Training loss: 0.45910865, IoU: 0.9467002493258027 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.69s/it]\u001b[A\n","Training loss: 0.45910865, IoU: 0.9467002493258027 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.72s/it]\u001b[A\n","Training loss: 0.4036023, IoU: 0.9412910295362853 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.72s/it] \u001b[A\n","Training loss: 0.4036023, IoU: 0.9412910295362853 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.4728779, IoU: 0.9386828481710939 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.4728779, IoU: 0.9386828481710939 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.74s/it]\u001b[A\n","Training loss: 0.5339569, IoU: 0.9333595286721316 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.74s/it]\u001b[A\n","Training loss: 0.5339569, IoU: 0.9333595286721316 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  29%|██▉       | 44/150 [1:10:24<2:20:12, 79.36s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8146942287181347\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.41293195, IoU: 0.9500433368392349 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.41293195, IoU: 0.9500433368392349 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.48222494, IoU: 0.9438299008357698 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.48222494, IoU: 0.9438299008357698 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.51805264, IoU: 0.950020246811957 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it] \u001b[A\n","Training loss: 0.51805264, IoU: 0.950020246811957 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.50288194, IoU: 0.945532061126086 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.50288194, IoU: 0.945532061126086 |:  15%|█▌        | 4/26 [00:11<01:00,  2.75s/it]\u001b[A\n","Training loss: 0.49161923, IoU: 0.9481740694401001 |:  15%|█▌        | 4/26 [00:13<01:00,  2.75s/it]\u001b[A\n","Training loss: 0.49161923, IoU: 0.9481740694401001 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.48760265, IoU: 0.9495631577898546 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.48760265, IoU: 0.9495631577898546 |:  23%|██▎       | 6/26 [00:16<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.45225146, IoU: 0.9445292063874265 |:  23%|██▎       | 6/26 [00:19<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.45225146, IoU: 0.9445292063874265 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.4831867, IoU: 0.9580445282129815 |:  27%|██▋       | 7/26 [00:22<00:52,  2.76s/it] \u001b[A\n","Training loss: 0.4831867, IoU: 0.9580445282129815 |:  31%|███       | 8/26 [00:22<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.43958217, IoU: 0.9392111502677304 |:  31%|███       | 8/26 [00:24<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.43958217, IoU: 0.9392111502677304 |:  35%|███▍      | 9/26 [00:24<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.5072118, IoU: 0.9532728132297392 |:  35%|███▍      | 9/26 [00:27<00:46,  2.76s/it] \u001b[A\n","Training loss: 0.5072118, IoU: 0.9532728132297392 |:  38%|███▊      | 10/26 [00:27<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.47948834, IoU: 0.9390162052368968 |:  38%|███▊      | 10/26 [00:30<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.47948834, IoU: 0.9390162052368968 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.4288507, IoU: 0.9298552932216299 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it] \u001b[A\n","Training loss: 0.4288507, IoU: 0.9298552932216299 |:  46%|████▌     | 12/26 [00:33<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.46274632, IoU: 0.9466570680292744 |:  46%|████▌     | 12/26 [00:35<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.46274632, IoU: 0.9466570680292744 |:  50%|█████     | 13/26 [00:35<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.544468, IoU: 0.9407835587183677 |:  50%|█████     | 13/26 [00:38<00:35,  2.76s/it]  \u001b[A\n","Training loss: 0.544468, IoU: 0.9407835587183677 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.46712846, IoU: 0.9489381679600122 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.46712846, IoU: 0.9489381679600122 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.4380868, IoU: 0.9523956113727207 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.76s/it] \u001b[A\n","Training loss: 0.4380868, IoU: 0.9523956113727207 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.52965915, IoU: 0.9567927754892298 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.52965915, IoU: 0.9567927754892298 |:  65%|██████▌   | 17/26 [00:45<00:19,  2.21s/it]\u001b[A\n","Training loss: 0.38301823, IoU: 0.9417018416315346 |:  65%|██████▌   | 17/26 [00:47<00:19,  2.21s/it]\u001b[A\n","Training loss: 0.38301823, IoU: 0.9417018416315346 |:  69%|██████▉   | 18/26 [00:47<00:18,  2.37s/it]\u001b[A\n","Training loss: 0.46762103, IoU: 0.9443313567572351 |:  69%|██████▉   | 18/26 [00:50<00:18,  2.37s/it]\u001b[A\n","Training loss: 0.46762103, IoU: 0.9443313567572351 |:  73%|███████▎  | 19/26 [00:50<00:17,  2.48s/it]\u001b[A\n","Training loss: 0.4178887, IoU: 0.9426532929507153 |:  73%|███████▎  | 19/26 [00:53<00:17,  2.48s/it] \u001b[A\n","Training loss: 0.4178887, IoU: 0.9426532929507153 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.55s/it]\u001b[A\n","Training loss: 0.4739077, IoU: 0.9450783124123678 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.55s/it]\u001b[A\n","Training loss: 0.4739077, IoU: 0.9450783124123678 |:  81%|████████  | 21/26 [00:56<00:13,  2.61s/it]\u001b[A\n","Training loss: 0.48560637, IoU: 0.9471969660135168 |:  81%|████████  | 21/26 [00:58<00:13,  2.61s/it]\u001b[A\n","Training loss: 0.48560637, IoU: 0.9471969660135168 |:  85%|████████▍ | 22/26 [00:58<00:10,  2.65s/it]\u001b[A\n","Training loss: 0.51377285, IoU: 0.9470034367496822 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.65s/it]\u001b[A\n","Training loss: 0.51377285, IoU: 0.9470034367496822 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.68s/it]\u001b[A\n","Training loss: 0.5151375, IoU: 0.9493861829497372 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.68s/it] \u001b[A\n","Training loss: 0.5151375, IoU: 0.9493861829497372 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.3898301, IoU: 0.9488371272811552 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.3898301, IoU: 0.9488371272811552 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.44669175, IoU: 0.9444612159506172 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.44669175, IoU: 0.9444612159506172 |: 100%|██████████| 26/26 [01:09<00:00,  2.69s/it]\n","Epoch Loop:  30%|███       | 45/150 [1:11:41<2:18:01, 78.87s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8146942287181347\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46086514, IoU: 0.9401667342852282 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46086514, IoU: 0.9401667342852282 |:   4%|▍         | 1/26 [00:02<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.48146358, IoU: 0.9558498125493722 |:   4%|▍         | 1/26 [00:05<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.48146358, IoU: 0.9558498125493722 |:   8%|▊         | 2/26 [00:05<01:06,  2.75s/it]\u001b[A\n","Training loss: 0.50290203, IoU: 0.9435280936024834 |:   8%|▊         | 2/26 [00:08<01:06,  2.75s/it]\u001b[A\n","Training loss: 0.50290203, IoU: 0.9435280936024834 |:  12%|█▏        | 3/26 [00:08<01:03,  2.76s/it]\u001b[A\n","Training loss: 0.44325975, IoU: 0.946815746504198 |:  12%|█▏        | 3/26 [00:11<01:03,  2.76s/it] \u001b[A\n","Training loss: 0.44325975, IoU: 0.946815746504198 |:  15%|█▌        | 4/26 [00:11<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.48608163, IoU: 0.9566279548820275 |:  15%|█▌        | 4/26 [00:13<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.48608163, IoU: 0.9566279548820275 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.48193413, IoU: 0.945330572300112 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it] \u001b[A\n","Training loss: 0.48193413, IoU: 0.945330572300112 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.46445167, IoU: 0.9423632402377831 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.46445167, IoU: 0.9423632402377831 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.4613207, IoU: 0.9446900920989096 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it] \u001b[A\n","Training loss: 0.4613207, IoU: 0.9446900920989096 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.49148834, IoU: 0.9456470687637143 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.49148834, IoU: 0.9456470687637143 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.4696926, IoU: 0.9553893288464779 |:  35%|███▍      | 9/26 [00:27<00:47,  2.81s/it] \u001b[A\n","Training loss: 0.4696926, IoU: 0.9553893288464779 |:  38%|███▊      | 10/26 [00:27<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.506383, IoU: 0.9373337115580249 |:  38%|███▊      | 10/26 [00:30<00:45,  2.82s/it] \u001b[A\n","Training loss: 0.506383, IoU: 0.9373337115580249 |:  42%|████▏     | 11/26 [00:30<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.45036525, IoU: 0.9530833025171883 |:  42%|████▏     | 11/26 [00:33<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.45036525, IoU: 0.9530833025171883 |:  46%|████▌     | 12/26 [00:33<00:39,  2.82s/it]\u001b[A\n","Training loss: 0.42470977, IoU: 0.9518026341364998 |:  46%|████▌     | 12/26 [00:36<00:39,  2.82s/it]\u001b[A\n","Training loss: 0.42470977, IoU: 0.9518026341364998 |:  50%|█████     | 13/26 [00:36<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.48306137, IoU: 0.9601507429410704 |:  50%|█████     | 13/26 [00:39<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.48306137, IoU: 0.9601507429410704 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.44104663, IoU: 0.9584601985386078 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.44104663, IoU: 0.9584601985386078 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.82s/it]\u001b[A\n","Training loss: 0.4687519, IoU: 0.9446910024066768 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.82s/it] \u001b[A\n","Training loss: 0.4687519, IoU: 0.9446910024066768 |:  62%|██████▏   | 16/26 [00:44<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.44583172, IoU: 0.9405476775320408 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.44583172, IoU: 0.9405476775320408 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.49295434, IoU: 0.9521527384874807 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.49295434, IoU: 0.9521527384874807 |:  69%|██████▉   | 18/26 [00:48<00:17,  2.24s/it]\u001b[A\n","Training loss: 0.48407355, IoU: 0.928828992304328 |:  69%|██████▉   | 18/26 [00:51<00:17,  2.24s/it] \u001b[A\n","Training loss: 0.48407355, IoU: 0.928828992304328 |:  73%|███████▎  | 19/26 [00:51<00:16,  2.41s/it]\u001b[A\n","Training loss: 0.48554868, IoU: 0.9460993707382864 |:  73%|███████▎  | 19/26 [00:54<00:16,  2.41s/it]\u001b[A\n","Training loss: 0.48554868, IoU: 0.9460993707382864 |:  77%|███████▋  | 20/26 [00:54<00:15,  2.51s/it]\u001b[A\n","Training loss: 0.42192876, IoU: 0.9387666641465688 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.51s/it]\u001b[A\n","Training loss: 0.42192876, IoU: 0.9387666641465688 |:  81%|████████  | 21/26 [00:56<00:12,  2.60s/it]\u001b[A\n","Training loss: 0.4861029, IoU: 0.942393420262232 |:  81%|████████  | 21/26 [00:59<00:12,  2.60s/it]  \u001b[A\n","Training loss: 0.4861029, IoU: 0.942393420262232 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.66s/it]\u001b[A\n","Training loss: 0.44463658, IoU: 0.9598988223509789 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.66s/it]\u001b[A\n","Training loss: 0.44463658, IoU: 0.9598988223509789 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.50365293, IoU: 0.9504323780346615 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.50365293, IoU: 0.9504323780346615 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.70s/it]\u001b[A\n","Training loss: 0.4845326, IoU: 0.9513147526750758 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.70s/it] \u001b[A\n","Training loss: 0.4845326, IoU: 0.9513147526750758 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.48406076, IoU: 0.945919241156709 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.48406076, IoU: 0.945919241156709 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  31%|███       | 46/150 [1:13:00<2:16:34, 78.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8146942287181347\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44555718, IoU: 0.94389338731444 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44555718, IoU: 0.94389338731444 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.49402386, IoU: 0.9473019254294391 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.49402386, IoU: 0.9473019254294391 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.42084518, IoU: 0.9518389231905192 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.42084518, IoU: 0.9518389231905192 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.5151236, IoU: 0.9512977598166243 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it] \u001b[A\n","Training loss: 0.5151236, IoU: 0.9512977598166243 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.4616818, IoU: 0.9498279670530841 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.4616818, IoU: 0.9498279670530841 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.48901585, IoU: 0.9557975960058303 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.48901585, IoU: 0.9557975960058303 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.5014972, IoU: 0.9518929430250628 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it] \u001b[A\n","Training loss: 0.5014972, IoU: 0.9518929430250628 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.4512691, IoU: 0.9559376542251612 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.4512691, IoU: 0.9559376542251612 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.39106432, IoU: 0.9483572357465084 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.39106432, IoU: 0.9483572357465084 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.45697272, IoU: 0.9415470371563424 |:  35%|███▍      | 9/26 [00:27<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.45697272, IoU: 0.9415470371563424 |:  38%|███▊      | 10/26 [00:27<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.500302, IoU: 0.9435870893747099 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]  \u001b[A\n","Training loss: 0.500302, IoU: 0.9435870893747099 |:  42%|████▏     | 11/26 [00:30<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.4917724, IoU: 0.9511352522373776 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.4917724, IoU: 0.9511352522373776 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.4544068, IoU: 0.9480323480174881 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.4544068, IoU: 0.9480323480174881 |:  50%|█████     | 13/26 [00:36<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.5145755, IoU: 0.937407073390694 |:  50%|█████     | 13/26 [00:39<00:36,  2.80s/it] \u001b[A\n","Training loss: 0.5145755, IoU: 0.937407073390694 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.43698776, IoU: 0.9496902845691555 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.43698776, IoU: 0.9496902845691555 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.490455, IoU: 0.9399752176501827 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]  \u001b[A\n","Training loss: 0.490455, IoU: 0.9399752176501827 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.470066, IoU: 0.9344005519215045 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.470066, IoU: 0.9344005519215045 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.45431745, IoU: 0.9452161597665303 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.45431745, IoU: 0.9452161597665303 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.38851517, IoU: 0.9460405508798776 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.38851517, IoU: 0.9460405508798776 |:  73%|███████▎  | 19/26 [00:51<00:15,  2.25s/it]\u001b[A\n","Training loss: 0.4919657, IoU: 0.9543794688741045 |:  73%|███████▎  | 19/26 [00:54<00:15,  2.25s/it] \u001b[A\n","Training loss: 0.4919657, IoU: 0.9543794688741045 |:  77%|███████▋  | 20/26 [00:54<00:14,  2.40s/it]\u001b[A\n","Training loss: 0.491175, IoU: 0.9256524531178973 |:  77%|███████▋  | 20/26 [00:56<00:14,  2.40s/it] \u001b[A\n","Training loss: 0.491175, IoU: 0.9256524531178973 |:  81%|████████  | 21/26 [00:56<00:12,  2.52s/it]\u001b[A\n","Training loss: 0.46086252, IoU: 0.9427412802145488 |:  81%|████████  | 21/26 [00:59<00:12,  2.52s/it]\u001b[A\n","Training loss: 0.46086252, IoU: 0.9427412802145488 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.61s/it]\u001b[A\n","Training loss: 0.497429, IoU: 0.9118269753960333 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.61s/it]  \u001b[A\n","Training loss: 0.497429, IoU: 0.9118269753960333 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.67s/it]\u001b[A\n","Training loss: 0.47731128, IoU: 0.9412612980374583 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.67s/it]\u001b[A\n","Training loss: 0.47731128, IoU: 0.9412612980374583 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.71s/it]\u001b[A\n","Training loss: 0.47744507, IoU: 0.9502969517517587 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.71s/it]\u001b[A\n","Training loss: 0.47744507, IoU: 0.9502969517517587 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.73s/it]\u001b[A\n","Training loss: 0.45960456, IoU: 0.9468398440960227 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.73s/it]\u001b[A\n","Training loss: 0.45960456, IoU: 0.9468398440960227 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.8146942287181347 to 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  31%|███▏      | 47/150 [1:14:21<2:16:26, 79.48s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4907907, IoU: 0.9564000907195631 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4907907, IoU: 0.9564000907195631 |:   4%|▍         | 1/26 [00:02<01:12,  2.89s/it]\u001b[A\n","Training loss: 0.47706848, IoU: 0.9482046034307048 |:   4%|▍         | 1/26 [00:05<01:12,  2.89s/it]\u001b[A\n","Training loss: 0.47706848, IoU: 0.9482046034307048 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.446629, IoU: 0.9447525602164281 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]  \u001b[A\n","Training loss: 0.446629, IoU: 0.9447525602164281 |:  12%|█▏        | 3/26 [00:08<01:05,  2.84s/it]\u001b[A\n","Training loss: 0.44826344, IoU: 0.9549207920792079 |:  12%|█▏        | 3/26 [00:11<01:05,  2.84s/it]\u001b[A\n","Training loss: 0.44826344, IoU: 0.9549207920792079 |:  15%|█▌        | 4/26 [00:11<01:04,  2.93s/it]\u001b[A\n","Training loss: 0.4453618, IoU: 0.9482065323502887 |:  15%|█▌        | 4/26 [00:14<01:04,  2.93s/it] \u001b[A\n","Training loss: 0.4453618, IoU: 0.9482065323502887 |:  19%|█▉        | 5/26 [00:14<01:01,  2.93s/it]\u001b[A\n","Training loss: 0.4337176, IoU: 0.9537013184212455 |:  19%|█▉        | 5/26 [00:17<01:01,  2.93s/it]\u001b[A\n","Training loss: 0.4337176, IoU: 0.9537013184212455 |:  23%|██▎       | 6/26 [00:17<00:59,  2.99s/it]\u001b[A\n","Training loss: 0.51099086, IoU: 0.9552233700485736 |:  23%|██▎       | 6/26 [00:20<00:59,  2.99s/it]\u001b[A\n","Training loss: 0.51099086, IoU: 0.9552233700485736 |:  27%|██▋       | 7/26 [00:20<00:56,  2.97s/it]\u001b[A\n","Training loss: 0.5023967, IoU: 0.9442128661342257 |:  27%|██▋       | 7/26 [00:23<00:56,  2.97s/it] \u001b[A\n","Training loss: 0.5023967, IoU: 0.9442128661342257 |:  31%|███       | 8/26 [00:23<00:53,  2.99s/it]\u001b[A\n","Training loss: 0.39380592, IoU: 0.932206656563363 |:  31%|███       | 8/26 [00:26<00:53,  2.99s/it]\u001b[A\n","Training loss: 0.39380592, IoU: 0.932206656563363 |:  35%|███▍      | 9/26 [00:26<00:50,  2.95s/it]\u001b[A\n","Training loss: 0.512429, IoU: 0.9549586597982771 |:  35%|███▍      | 9/26 [00:29<00:50,  2.95s/it] \u001b[A\n","Training loss: 0.512429, IoU: 0.9549586597982771 |:  38%|███▊      | 10/26 [00:29<00:46,  2.93s/it]\u001b[A\n","Training loss: 0.43354225, IoU: 0.9536101575406976 |:  38%|███▊      | 10/26 [00:32<00:46,  2.93s/it]\u001b[A\n","Training loss: 0.43354225, IoU: 0.9536101575406976 |:  42%|████▏     | 11/26 [00:32<00:43,  2.89s/it]\u001b[A\n","Training loss: 0.41384348, IoU: 0.9457718001163423 |:  42%|████▏     | 11/26 [00:35<00:43,  2.89s/it]\u001b[A\n","Training loss: 0.41384348, IoU: 0.9457718001163423 |:  46%|████▌     | 12/26 [00:35<00:41,  2.93s/it]\u001b[A\n","Training loss: 0.4724301, IoU: 0.9426165281905394 |:  46%|████▌     | 12/26 [00:38<00:41,  2.93s/it] \u001b[A\n","Training loss: 0.4724301, IoU: 0.9426165281905394 |:  50%|█████     | 13/26 [00:38<00:37,  2.92s/it]\u001b[A\n","Training loss: 0.45317888, IoU: 0.9456603789909005 |:  50%|█████     | 13/26 [00:41<00:37,  2.92s/it]\u001b[A\n","Training loss: 0.45317888, IoU: 0.9456603789909005 |:  54%|█████▍    | 14/26 [00:41<00:35,  2.93s/it]\u001b[A\n","Training loss: 0.4570536, IoU: 0.9472580183801148 |:  54%|█████▍    | 14/26 [00:43<00:35,  2.93s/it] \u001b[A\n","Training loss: 0.4570536, IoU: 0.9472580183801148 |:  58%|█████▊    | 15/26 [00:43<00:31,  2.91s/it]\u001b[A\n","Training loss: 0.46977007, IoU: 0.9481941179641378 |:  58%|█████▊    | 15/26 [00:46<00:31,  2.91s/it]\u001b[A\n","Training loss: 0.46977007, IoU: 0.9481941179641378 |:  62%|██████▏   | 16/26 [00:46<00:29,  2.91s/it]\u001b[A\n","Training loss: 0.5076552, IoU: 0.9504133480435867 |:  62%|██████▏   | 16/26 [00:49<00:29,  2.91s/it] \u001b[A\n","Training loss: 0.5076552, IoU: 0.9504133480435867 |:  65%|██████▌   | 17/26 [00:49<00:25,  2.87s/it]\u001b[A\n","Training loss: 0.46143407, IoU: 0.9501712234695185 |:  65%|██████▌   | 17/26 [00:52<00:25,  2.87s/it]\u001b[A\n","Training loss: 0.46143407, IoU: 0.9501712234695185 |:  69%|██████▉   | 18/26 [00:52<00:23,  2.89s/it]\u001b[A\n","Training loss: 0.46909648, IoU: 0.9505622953303267 |:  69%|██████▉   | 18/26 [00:55<00:23,  2.89s/it]\u001b[A\n","Training loss: 0.46909648, IoU: 0.9505622953303267 |:  73%|███████▎  | 19/26 [00:55<00:20,  2.86s/it]\u001b[A\n","Training loss: 0.38745615, IoU: 0.9501703246949248 |:  73%|███████▎  | 19/26 [00:56<00:20,  2.86s/it]\u001b[A\n","Training loss: 0.38745615, IoU: 0.9501703246949248 |:  77%|███████▋  | 20/26 [00:56<00:13,  2.29s/it]\u001b[A\n","Training loss: 0.45992738, IoU: 0.9465065450760021 |:  77%|███████▋  | 20/26 [00:58<00:13,  2.29s/it]\u001b[A\n","Training loss: 0.45992738, IoU: 0.9465065450760021 |:  81%|████████  | 21/26 [00:58<00:12,  2.43s/it]\u001b[A\n","Training loss: 0.44204742, IoU: 0.9414913873376296 |:  81%|████████  | 21/26 [01:01<00:12,  2.43s/it]\u001b[A\n","Training loss: 0.44204742, IoU: 0.9414913873376296 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.54s/it]\u001b[A\n","Training loss: 0.44599992, IoU: 0.9606706332301902 |:  85%|████████▍ | 22/26 [01:04<00:10,  2.54s/it]\u001b[A\n","Training loss: 0.44599992, IoU: 0.9606706332301902 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.61s/it]\u001b[A\n","Training loss: 0.4778757, IoU: 0.9581197780584345 |:  88%|████████▊ | 23/26 [01:07<00:07,  2.61s/it] \u001b[A\n","Training loss: 0.4778757, IoU: 0.9581197780584345 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.65s/it]\u001b[A\n","Training loss: 0.4911772, IoU: 0.9483979184511979 |:  92%|█████████▏| 24/26 [01:10<00:05,  2.65s/it]\u001b[A\n","Training loss: 0.4911772, IoU: 0.9483979184511979 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.46067265, IoU: 0.9523883199489181 |:  96%|█████████▌| 25/26 [01:12<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.46067265, IoU: 0.9523883199489181 |: 100%|██████████| 26/26 [01:12<00:00,  2.80s/it]\n","Epoch Loop:  32%|███▏      | 48/150 [1:15:42<2:15:50, 79.91s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46240908, IoU: 0.9468734613490891 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46240908, IoU: 0.9468734613490891 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.5212606, IoU: 0.9320201624512103 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it] \u001b[A\n","Training loss: 0.5212606, IoU: 0.9320201624512103 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.46452898, IoU: 0.94837222984899 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it] \u001b[A\n","Training loss: 0.46452898, IoU: 0.94837222984899 |:  12%|█▏        | 3/26 [00:08<01:05,  2.84s/it]\u001b[A\n","Training loss: 0.47600985, IoU: 0.9446580076288401 |:  12%|█▏        | 3/26 [00:11<01:05,  2.84s/it]\u001b[A\n","Training loss: 0.47600985, IoU: 0.9446580076288401 |:  15%|█▌        | 4/26 [00:11<01:02,  2.84s/it]\u001b[A\n","Training loss: 0.47236228, IoU: 0.9531751707455208 |:  15%|█▌        | 4/26 [00:14<01:02,  2.84s/it]\u001b[A\n","Training loss: 0.47236228, IoU: 0.9531751707455208 |:  19%|█▉        | 5/26 [00:14<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.4274221, IoU: 0.9424992439003833 |:  19%|█▉        | 5/26 [00:17<00:59,  2.84s/it] \u001b[A\n","Training loss: 0.4274221, IoU: 0.9424992439003833 |:  23%|██▎       | 6/26 [00:17<00:57,  2.87s/it]\u001b[A\n","Training loss: 0.43793648, IoU: 0.9393849718234336 |:  23%|██▎       | 6/26 [00:19<00:57,  2.87s/it]\u001b[A\n","Training loss: 0.43793648, IoU: 0.9393849718234336 |:  27%|██▋       | 7/26 [00:19<00:54,  2.87s/it]\u001b[A\n","Training loss: 0.41982332, IoU: 0.9421855968052569 |:  27%|██▋       | 7/26 [00:22<00:54,  2.87s/it]\u001b[A\n","Training loss: 0.41982332, IoU: 0.9421855968052569 |:  31%|███       | 8/26 [00:22<00:52,  2.90s/it]\u001b[A\n","Training loss: 0.49167866, IoU: 0.9427192779504402 |:  31%|███       | 8/26 [00:25<00:52,  2.90s/it]\u001b[A\n","Training loss: 0.49167866, IoU: 0.9427192779504402 |:  35%|███▍      | 9/26 [00:25<00:49,  2.90s/it]\u001b[A\n","Training loss: 0.43856573, IoU: 0.9565056851343207 |:  35%|███▍      | 9/26 [00:28<00:49,  2.90s/it]\u001b[A\n","Training loss: 0.43856573, IoU: 0.9565056851343207 |:  38%|███▊      | 10/26 [00:28<00:46,  2.92s/it]\u001b[A\n","Training loss: 0.43111563, IoU: 0.9492277838929678 |:  38%|███▊      | 10/26 [00:31<00:46,  2.92s/it]\u001b[A\n","Training loss: 0.43111563, IoU: 0.9492277838929678 |:  42%|████▏     | 11/26 [00:31<00:43,  2.91s/it]\u001b[A\n","Training loss: 0.4418632, IoU: 0.9497280733892571 |:  42%|████▏     | 11/26 [00:34<00:43,  2.91s/it] \u001b[A\n","Training loss: 0.4418632, IoU: 0.9497280733892571 |:  46%|████▌     | 12/26 [00:34<00:40,  2.93s/it]\u001b[A\n","Training loss: 0.47594267, IoU: 0.9539912610138434 |:  46%|████▌     | 12/26 [00:37<00:40,  2.93s/it]\u001b[A\n","Training loss: 0.47594267, IoU: 0.9539912610138434 |:  50%|█████     | 13/26 [00:37<00:37,  2.90s/it]\u001b[A\n","Training loss: 0.47593114, IoU: 0.9527933344862295 |:  50%|█████     | 13/26 [00:40<00:37,  2.90s/it]\u001b[A\n","Training loss: 0.47593114, IoU: 0.9527933344862295 |:  54%|█████▍    | 14/26 [00:40<00:35,  2.92s/it]\u001b[A\n","Training loss: 0.4479308, IoU: 0.9509714760207789 |:  54%|█████▍    | 14/26 [00:43<00:35,  2.92s/it] \u001b[A\n","Training loss: 0.4479308, IoU: 0.9509714760207789 |:  58%|█████▊    | 15/26 [00:43<00:31,  2.90s/it]\u001b[A\n","Training loss: 0.41983408, IoU: 0.951699539088105 |:  58%|█████▊    | 15/26 [00:46<00:31,  2.90s/it]\u001b[A\n","Training loss: 0.41983408, IoU: 0.951699539088105 |:  62%|██████▏   | 16/26 [00:46<00:29,  2.92s/it]\u001b[A\n","Training loss: 0.5172376, IoU: 0.9501350675337669 |:  62%|██████▏   | 16/26 [00:49<00:29,  2.92s/it]\u001b[A\n","Training loss: 0.5172376, IoU: 0.9501350675337669 |:  65%|██████▌   | 17/26 [00:49<00:26,  2.91s/it]\u001b[A\n","Training loss: 0.37683862, IoU: 0.9399471665339799 |:  65%|██████▌   | 17/26 [00:52<00:26,  2.91s/it]\u001b[A\n","Training loss: 0.37683862, IoU: 0.9399471665339799 |:  69%|██████▉   | 18/26 [00:52<00:23,  2.94s/it]\u001b[A\n","Training loss: 0.457754, IoU: 0.9370865229076181 |:  69%|██████▉   | 18/26 [00:55<00:23,  2.94s/it]  \u001b[A\n","Training loss: 0.457754, IoU: 0.9370865229076181 |:  73%|███████▎  | 19/26 [00:55<00:20,  2.91s/it]\u001b[A\n","Training loss: 0.4414793, IoU: 0.9411907517257565 |:  73%|███████▎  | 19/26 [00:58<00:20,  2.91s/it]\u001b[A\n","Training loss: 0.4414793, IoU: 0.9411907517257565 |:  77%|███████▋  | 20/26 [00:58<00:17,  2.94s/it]\u001b[A\n","Training loss: 0.3811112, IoU: 0.9134191323871381 |:  77%|███████▋  | 20/26 [00:59<00:17,  2.94s/it]\u001b[A\n","Training loss: 0.3811112, IoU: 0.9134191323871381 |:  81%|████████  | 21/26 [00:59<00:11,  2.35s/it]\u001b[A\n","Training loss: 0.5025448, IoU: 0.9527583032692379 |:  81%|████████  | 21/26 [01:01<00:11,  2.35s/it]\u001b[A\n","Training loss: 0.5025448, IoU: 0.9527583032692379 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.51s/it]\u001b[A\n","Training loss: 0.48532754, IoU: 0.9483278590982267 |:  85%|████████▍ | 22/26 [01:04<00:10,  2.51s/it]\u001b[A\n","Training loss: 0.48532754, IoU: 0.9483278590982267 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.60s/it]\u001b[A\n","Training loss: 0.46059722, IoU: 0.9534292569207033 |:  88%|████████▊ | 23/26 [01:07<00:07,  2.60s/it]\u001b[A\n","Training loss: 0.46059722, IoU: 0.9534292569207033 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.69s/it]\u001b[A\n","Training loss: 0.42327267, IoU: 0.9459772453403027 |:  92%|█████████▏| 24/26 [01:10<00:05,  2.69s/it]\u001b[A\n","Training loss: 0.42327267, IoU: 0.9459772453403027 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.46776968, IoU: 0.9429814689774176 |:  96%|█████████▌| 25/26 [01:13<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.46776968, IoU: 0.9429814689774176 |: 100%|██████████| 26/26 [01:13<00:00,  2.82s/it]\n","Epoch Loop:  33%|███▎      | 49/150 [1:17:03<2:15:16, 80.36s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44698796, IoU: 0.9520825918290141 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44698796, IoU: 0.9520825918290141 |:   4%|▍         | 1/26 [00:02<01:12,  2.89s/it]\u001b[A\n","Training loss: 0.477459, IoU: 0.945010232334176 |:   4%|▍         | 1/26 [00:05<01:12,  2.89s/it]   \u001b[A\n","Training loss: 0.477459, IoU: 0.945010232334176 |:   8%|▊         | 2/26 [00:05<01:08,  2.87s/it]\u001b[A\n","Training loss: 0.49532974, IoU: 0.9599468979124546 |:   8%|▊         | 2/26 [00:08<01:08,  2.87s/it]\u001b[A\n","Training loss: 0.49532974, IoU: 0.9599468979124546 |:  12%|█▏        | 3/26 [00:08<01:05,  2.87s/it]\u001b[A\n","Training loss: 0.4601586, IoU: 0.9408453339600813 |:  12%|█▏        | 3/26 [00:11<01:05,  2.87s/it] \u001b[A\n","Training loss: 0.4601586, IoU: 0.9408453339600813 |:  15%|█▌        | 4/26 [00:11<01:02,  2.85s/it]\u001b[A\n","Training loss: 0.44396055, IoU: 0.9436300835127398 |:  15%|█▌        | 4/26 [00:14<01:02,  2.85s/it]\u001b[A\n","Training loss: 0.44396055, IoU: 0.9436300835127398 |:  19%|█▉        | 5/26 [00:14<00:59,  2.85s/it]\u001b[A\n","Training loss: 0.46994182, IoU: 0.944713357898124 |:  19%|█▉        | 5/26 [00:17<00:59,  2.85s/it] \u001b[A\n","Training loss: 0.46994182, IoU: 0.944713357898124 |:  23%|██▎       | 6/26 [00:17<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.47420996, IoU: 0.9509841904059523 |:  23%|██▎       | 6/26 [00:19<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.47420996, IoU: 0.9509841904059523 |:  27%|██▋       | 7/26 [00:19<00:53,  2.83s/it]\u001b[A\n","Training loss: 0.45022702, IoU: 0.9458555609688025 |:  27%|██▋       | 7/26 [00:22<00:53,  2.83s/it]\u001b[A\n","Training loss: 0.45022702, IoU: 0.9458555609688025 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.49488467, IoU: 0.9466769009532221 |:  31%|███       | 8/26 [00:25<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.49488467, IoU: 0.9466769009532221 |:  35%|███▍      | 9/26 [00:25<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.4257947, IoU: 0.9418092676773687 |:  35%|███▍      | 9/26 [00:28<00:48,  2.83s/it] \u001b[A\n","Training loss: 0.4257947, IoU: 0.9418092676773687 |:  38%|███▊      | 10/26 [00:28<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.4546692, IoU: 0.9535188601483691 |:  38%|███▊      | 10/26 [00:31<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.4546692, IoU: 0.9535188601483691 |:  42%|████▏     | 11/26 [00:31<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.5033246, IoU: 0.9484277080687258 |:  42%|████▏     | 11/26 [00:33<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.5033246, IoU: 0.9484277080687258 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.38266942, IoU: 0.9463053715641204 |:  46%|████▌     | 12/26 [00:36<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.38266942, IoU: 0.9463053715641204 |:  50%|█████     | 13/26 [00:36<00:36,  2.82s/it]\u001b[A\n","Training loss: 0.47487777, IoU: 0.9501538583413996 |:  50%|█████     | 13/26 [00:39<00:36,  2.82s/it]\u001b[A\n","Training loss: 0.47487777, IoU: 0.9501538583413996 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.468176, IoU: 0.9483508286790256 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.82s/it]  \u001b[A\n","Training loss: 0.468176, IoU: 0.9483508286790256 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.82s/it]\u001b[A\n","Training loss: 0.4905674, IoU: 0.951417004048583 |:  58%|█████▊    | 15/26 [00:45<00:30,  2.82s/it]\u001b[A\n","Training loss: 0.4905674, IoU: 0.951417004048583 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.46045345, IoU: 0.944796962796936 |:  62%|██████▏   | 16/26 [00:48<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.46045345, IoU: 0.944796962796936 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.46508628, IoU: 0.9406716330772285 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.46508628, IoU: 0.9406716330772285 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.48551208, IoU: 0.9514970436250499 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.48551208, IoU: 0.9514970436250499 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.5121601, IoU: 0.9482337850360412 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.80s/it] \u001b[A\n","Training loss: 0.5121601, IoU: 0.9482337850360412 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.4453816, IoU: 0.9519173654106702 |:  77%|███████▋  | 20/26 [00:59<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.4453816, IoU: 0.9519173654106702 |:  81%|████████  | 21/26 [00:59<00:14,  2.82s/it]\u001b[A\n","Training loss: 0.59915805, IoU: 0.978950655266469 |:  81%|████████  | 21/26 [01:00<00:14,  2.82s/it]\u001b[A\n","Training loss: 0.59915805, IoU: 0.978950655266469 |:  85%|████████▍ | 22/26 [01:00<00:09,  2.26s/it]\u001b[A\n","Training loss: 0.49089167, IoU: 0.9498393021120294 |:  85%|████████▍ | 22/26 [01:03<00:09,  2.26s/it]\u001b[A\n","Training loss: 0.49089167, IoU: 0.9498393021120294 |:  88%|████████▊ | 23/26 [01:03<00:07,  2.41s/it]\u001b[A\n","Training loss: 0.50574285, IoU: 0.9540257692238768 |:  88%|████████▊ | 23/26 [01:05<00:07,  2.41s/it]\u001b[A\n","Training loss: 0.50574285, IoU: 0.9540257692238768 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.52s/it]\u001b[A\n","Training loss: 0.49062094, IoU: 0.9494301182504631 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.52s/it]\u001b[A\n","Training loss: 0.49062094, IoU: 0.9494301182504631 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.60s/it]\u001b[A\n","Training loss: 0.45948476, IoU: 0.9511307947859327 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.60s/it]\u001b[A\n","Training loss: 0.45948476, IoU: 0.9511307947859327 |: 100%|██████████| 26/26 [01:11<00:00,  2.74s/it]\n","Epoch Loop:  33%|███▎      | 50/150 [1:18:23<2:13:32, 80.13s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47731614, IoU: 0.9492186951248636 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47731614, IoU: 0.9492186951248636 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.54936713, IoU: 0.9503660575315617 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.54936713, IoU: 0.9503660575315617 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.5165734, IoU: 0.9361219566649785 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it] \u001b[A\n","Training loss: 0.5165734, IoU: 0.9361219566649785 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.48780137, IoU: 0.9521826593361123 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.48780137, IoU: 0.9521826593361123 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.43458873, IoU: 0.9474068470918292 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.43458873, IoU: 0.9474068470918292 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.42607182, IoU: 0.9489063579398169 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.42607182, IoU: 0.9489063579398169 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.43990734, IoU: 0.9550983518657704 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.43990734, IoU: 0.9550983518657704 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.49210703, IoU: 0.9461482136793793 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.49210703, IoU: 0.9461482136793793 |:  31%|███       | 8/26 [00:22<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.46544355, IoU: 0.9393115001651644 |:  31%|███       | 8/26 [00:25<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.46544355, IoU: 0.9393115001651644 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.46266347, IoU: 0.9508711386987261 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.46266347, IoU: 0.9508711386987261 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.423839, IoU: 0.9519331678247643 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]  \u001b[A\n","Training loss: 0.423839, IoU: 0.9519331678247643 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.41345206, IoU: 0.9510762648317234 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.41345206, IoU: 0.9510762648317234 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.43401963, IoU: 0.9462279557378434 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.43401963, IoU: 0.9462279557378434 |:  50%|█████     | 13/26 [00:36<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.50452584, IoU: 0.9357608963309529 |:  50%|█████     | 13/26 [00:39<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.50452584, IoU: 0.9357608963309529 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.43835038, IoU: 0.938714817859789 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.80s/it] \u001b[A\n","Training loss: 0.43835038, IoU: 0.938714817859789 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.81s/it]\u001b[A\n","Training loss: 0.4737696, IoU: 0.9482620774108015 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.81s/it]\u001b[A\n","Training loss: 0.4737696, IoU: 0.9482620774108015 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.4807112, IoU: 0.9458459924768519 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.4807112, IoU: 0.9458459924768519 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.44425026, IoU: 0.9417684147993466 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.44425026, IoU: 0.9417684147993466 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.83s/it]\u001b[A\n","Training loss: 0.4273866, IoU: 0.9541656847572841 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.83s/it] \u001b[A\n","Training loss: 0.4273866, IoU: 0.9541656847572841 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.82s/it]\u001b[A\n","Training loss: 0.45967555, IoU: 0.9475724843136983 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.82s/it]\u001b[A\n","Training loss: 0.45967555, IoU: 0.9475724843136983 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.46675736, IoU: 0.9536466707515399 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.46675736, IoU: 0.9536466707515399 |:  81%|████████  | 21/26 [00:58<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.44768178, IoU: 0.9533064466091704 |:  81%|████████  | 21/26 [01:01<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.44768178, IoU: 0.9533064466091704 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.82s/it]\u001b[A\n","Training loss: 0.42038977, IoU: 0.9513055266311715 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.82s/it]\u001b[A\n","Training loss: 0.42038977, IoU: 0.9513055266311715 |:  88%|████████▊ | 23/26 [01:02<00:06,  2.26s/it]\u001b[A\n","Training loss: 0.49159154, IoU: 0.9557770943714442 |:  88%|████████▊ | 23/26 [01:05<00:06,  2.26s/it]\u001b[A\n","Training loss: 0.49159154, IoU: 0.9557770943714442 |:  92%|█████████▏| 24/26 [01:05<00:04,  2.42s/it]\u001b[A\n","Training loss: 0.528641, IoU: 0.9441434617221335 |:  92%|█████████▏| 24/26 [01:08<00:04,  2.42s/it]  \u001b[A\n","Training loss: 0.528641, IoU: 0.9441434617221335 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.53s/it]\u001b[A\n","Training loss: 0.5263229, IoU: 0.9553749874268022 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.53s/it]\u001b[A\n","Training loss: 0.5263229, IoU: 0.9553749874268022 |: 100%|██████████| 26/26 [01:11<00:00,  2.73s/it]\n","Epoch Loop:  34%|███▍      | 51/150 [1:19:42<2:11:43, 79.83s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47146678, IoU: 0.9535915038702544 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47146678, IoU: 0.9535915038702544 |:   4%|▍         | 1/26 [00:02<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.42252162, IoU: 0.9476593770212127 |:   4%|▍         | 1/26 [00:05<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.42252162, IoU: 0.9476593770212127 |:   8%|▊         | 2/26 [00:05<01:08,  2.84s/it]\u001b[A\n","Training loss: 0.43083817, IoU: 0.9366026158821038 |:   8%|▊         | 2/26 [00:08<01:08,  2.84s/it]\u001b[A\n","Training loss: 0.43083817, IoU: 0.9366026158821038 |:  12%|█▏        | 3/26 [00:08<01:05,  2.86s/it]\u001b[A\n","Training loss: 0.4117151, IoU: 0.9586976966642216 |:  12%|█▏        | 3/26 [00:11<01:05,  2.86s/it] \u001b[A\n","Training loss: 0.4117151, IoU: 0.9586976966642216 |:  15%|█▌        | 4/26 [00:11<01:02,  2.85s/it]\u001b[A\n","Training loss: 0.46169186, IoU: 0.9585153941049583 |:  15%|█▌        | 4/26 [00:14<01:02,  2.85s/it]\u001b[A\n","Training loss: 0.46169186, IoU: 0.9585153941049583 |:  19%|█▉        | 5/26 [00:14<00:59,  2.85s/it]\u001b[A\n","Training loss: 0.530012, IoU: 0.9360328199548952 |:  19%|█▉        | 5/26 [00:17<00:59,  2.85s/it]  \u001b[A\n","Training loss: 0.530012, IoU: 0.9360328199548952 |:  23%|██▎       | 6/26 [00:17<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.46215636, IoU: 0.9525090460040951 |:  23%|██▎       | 6/26 [00:19<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.46215636, IoU: 0.9525090460040951 |:  27%|██▋       | 7/26 [00:19<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.4825197, IoU: 0.9542687152039377 |:  27%|██▋       | 7/26 [00:22<00:53,  2.82s/it] \u001b[A\n","Training loss: 0.4825197, IoU: 0.9542687152039377 |:  31%|███       | 8/26 [00:22<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.4862742, IoU: 0.9464840606059027 |:  31%|███       | 8/26 [00:25<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.4862742, IoU: 0.9464840606059027 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.43115348, IoU: 0.9500536338450237 |:  35%|███▍      | 9/26 [00:28<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.43115348, IoU: 0.9500536338450237 |:  38%|███▊      | 10/26 [00:28<00:44,  2.81s/it]\u001b[A\n","Training loss: 0.4508835, IoU: 0.9561919279907085 |:  38%|███▊      | 10/26 [00:31<00:44,  2.81s/it] \u001b[A\n","Training loss: 0.4508835, IoU: 0.9561919279907085 |:  42%|████▏     | 11/26 [00:31<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.49772483, IoU: 0.9552371499767707 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.49772483, IoU: 0.9552371499767707 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.4362568, IoU: 0.9498436041026191 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it] \u001b[A\n","Training loss: 0.4362568, IoU: 0.9498436041026191 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.5124334, IoU: 0.9407162861357118 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.5124334, IoU: 0.9407162861357118 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.48512083, IoU: 0.9308369950087454 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.48512083, IoU: 0.9308369950087454 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.45664665, IoU: 0.9489820927588832 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.45664665, IoU: 0.9489820927588832 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.4846636, IoU: 0.9334271410607449 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.79s/it] \u001b[A\n","Training loss: 0.4846636, IoU: 0.9334271410607449 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.444979, IoU: 0.9543152696533265 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.79s/it] \u001b[A\n","Training loss: 0.444979, IoU: 0.9543152696533265 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.42939517, IoU: 0.9534036986327062 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.42939517, IoU: 0.9534036986327062 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.4776451, IoU: 0.9348661809394794 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.79s/it] \u001b[A\n","Training loss: 0.4776451, IoU: 0.9348661809394794 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.40586364, IoU: 0.9553826495909206 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.40586364, IoU: 0.9553826495909206 |:  81%|████████  | 21/26 [00:58<00:14,  2.80s/it]\u001b[A\n","Training loss: 0.4642541, IoU: 0.9518259033653724 |:  81%|████████  | 21/26 [01:01<00:14,  2.80s/it] \u001b[A\n","Training loss: 0.4642541, IoU: 0.9518259033653724 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.49825525, IoU: 0.9376816339896034 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.49825525, IoU: 0.9376816339896034 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.51163226, IoU: 0.9468409423566374 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.51163226, IoU: 0.9468409423566374 |:  92%|█████████▏| 24/26 [01:05<00:04,  2.25s/it]\u001b[A\n","Training loss: 0.44867012, IoU: 0.9371899720186474 |:  92%|█████████▏| 24/26 [01:08<00:04,  2.25s/it]\u001b[A\n","Training loss: 0.44867012, IoU: 0.9371899720186474 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.41s/it]\u001b[A\n","Training loss: 0.5018995, IoU: 0.9388632857967504 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.41s/it] \u001b[A\n","Training loss: 0.5018995, IoU: 0.9388632857967504 |: 100%|██████████| 26/26 [01:11<00:00,  2.74s/it]\n","Epoch Loop:  35%|███▍      | 52/150 [1:21:01<2:10:07, 79.67s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5101686, IoU: 0.9502336083199749 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5101686, IoU: 0.9502336083199749 |:   4%|▍         | 1/26 [00:02<01:10,  2.81s/it]\u001b[A\n","Training loss: 0.46422964, IoU: 0.9451866142881622 |:   4%|▍         | 1/26 [00:05<01:10,  2.81s/it]\u001b[A\n","Training loss: 0.46422964, IoU: 0.9451866142881622 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.43799075, IoU: 0.9378785815920916 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.43799075, IoU: 0.9378785815920916 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.4376995, IoU: 0.9541355477794606 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it] \u001b[A\n","Training loss: 0.4376995, IoU: 0.9541355477794606 |:  15%|█▌        | 4/26 [00:11<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.4950465, IoU: 0.9589360199751039 |:  15%|█▌        | 4/26 [00:14<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.4950465, IoU: 0.9589360199751039 |:  19%|█▉        | 5/26 [00:14<00:59,  2.83s/it]\u001b[A\n","Training loss: 0.42990527, IoU: 0.93961493278997 |:  19%|█▉        | 5/26 [00:16<00:59,  2.83s/it] \u001b[A\n","Training loss: 0.42990527, IoU: 0.93961493278997 |:  23%|██▎       | 6/26 [00:16<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.43046683, IoU: 0.9521882607793417 |:  23%|██▎       | 6/26 [00:19<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.43046683, IoU: 0.9521882607793417 |:  27%|██▋       | 7/26 [00:19<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.5169679, IoU: 0.9364805549446521 |:  27%|██▋       | 7/26 [00:22<00:53,  2.84s/it] \u001b[A\n","Training loss: 0.5169679, IoU: 0.9364805549446521 |:  31%|███       | 8/26 [00:22<00:51,  2.84s/it]\u001b[A\n","Training loss: 0.43180776, IoU: 0.9432101446896207 |:  31%|███       | 8/26 [00:25<00:51,  2.84s/it]\u001b[A\n","Training loss: 0.43180776, IoU: 0.9432101446896207 |:  35%|███▍      | 9/26 [00:25<00:48,  2.85s/it]\u001b[A\n","Training loss: 0.4970766, IoU: 0.9461432537980541 |:  35%|███▍      | 9/26 [00:28<00:48,  2.85s/it] \u001b[A\n","Training loss: 0.4970766, IoU: 0.9461432537980541 |:  38%|███▊      | 10/26 [00:28<00:45,  2.84s/it]\u001b[A\n","Training loss: 0.43743607, IoU: 0.9462100146830515 |:  38%|███▊      | 10/26 [00:31<00:45,  2.84s/it]\u001b[A\n","Training loss: 0.43743607, IoU: 0.9462100146830515 |:  42%|████▏     | 11/26 [00:31<00:42,  2.84s/it]\u001b[A\n","Training loss: 0.4664514, IoU: 0.9519399554929961 |:  42%|████▏     | 11/26 [00:33<00:42,  2.84s/it] \u001b[A\n","Training loss: 0.4664514, IoU: 0.9519399554929961 |:  46%|████▌     | 12/26 [00:33<00:39,  2.83s/it]\u001b[A\n","Training loss: 0.43460056, IoU: 0.9520776003409099 |:  46%|████▌     | 12/26 [00:36<00:39,  2.83s/it]\u001b[A\n","Training loss: 0.43460056, IoU: 0.9520776003409099 |:  50%|█████     | 13/26 [00:36<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.48012033, IoU: 0.9563016934429314 |:  50%|█████     | 13/26 [00:39<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.48012033, IoU: 0.9563016934429314 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.4561195, IoU: 0.9507031207987524 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.82s/it] \u001b[A\n","Training loss: 0.4561195, IoU: 0.9507031207987524 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.81s/it]\u001b[A\n","Training loss: 0.42765713, IoU: 0.9435641263359914 |:  58%|█████▊    | 15/26 [00:45<00:30,  2.81s/it]\u001b[A\n","Training loss: 0.42765713, IoU: 0.9435641263359914 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.4267698, IoU: 0.9500369522411664 |:  62%|██████▏   | 16/26 [00:48<00:28,  2.81s/it] \u001b[A\n","Training loss: 0.4267698, IoU: 0.9500369522411664 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.46551192, IoU: 0.9512856966942427 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.46551192, IoU: 0.9512856966942427 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.47957307, IoU: 0.9464800808270555 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.47957307, IoU: 0.9464800808270555 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.48190552, IoU: 0.9317484720464387 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.48190552, IoU: 0.9317484720464387 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.45640188, IoU: 0.9489565963622156 |:  77%|███████▋  | 20/26 [00:59<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.45640188, IoU: 0.9489565963622156 |:  81%|████████  | 21/26 [00:59<00:14,  2.80s/it]\u001b[A\n","Training loss: 0.48798084, IoU: 0.9499159663865546 |:  81%|████████  | 21/26 [01:02<00:14,  2.80s/it]\u001b[A\n","Training loss: 0.48798084, IoU: 0.9499159663865546 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.48834217, IoU: 0.954949578058622 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.80s/it] \u001b[A\n","Training loss: 0.48834217, IoU: 0.954949578058622 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.43190882, IoU: 0.9504506782005966 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.43190882, IoU: 0.9504506782005966 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.49252176, IoU: 0.9417921959358423 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.49252176, IoU: 0.9417921959358423 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.24s/it]\u001b[A\n","Training loss: 0.42094332, IoU: 0.9437678815612937 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.24s/it]\u001b[A\n","Training loss: 0.42094332, IoU: 0.9437678815612937 |: 100%|██████████| 26/26 [01:11<00:00,  2.74s/it]\n","Epoch Loop:  35%|███▌      | 53/150 [1:22:21<2:08:38, 79.57s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48804396, IoU: 0.9566711122457013 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48804396, IoU: 0.9566711122457013 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.47318625, IoU: 0.9544769435767492 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.47318625, IoU: 0.9544769435767492 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.40488324, IoU: 0.9445594081103534 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.40488324, IoU: 0.9445594081103534 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.44899088, IoU: 0.9517970565276858 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.44899088, IoU: 0.9517970565276858 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.45223966, IoU: 0.9497387212201934 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.45223966, IoU: 0.9497387212201934 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.4008626, IoU: 0.9521361483258453 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it] \u001b[A\n","Training loss: 0.4008626, IoU: 0.9521361483258453 |:  23%|██▎       | 6/26 [00:16<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.4901343, IoU: 0.9338351718422743 |:  23%|██▎       | 6/26 [00:19<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.4901343, IoU: 0.9338351718422743 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.444054, IoU: 0.9506548054809918 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it] \u001b[A\n","Training loss: 0.444054, IoU: 0.9506548054809918 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.4787137, IoU: 0.9547371959360293 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.4787137, IoU: 0.9547371959360293 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.41389978, IoU: 0.9361098810410419 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.41389978, IoU: 0.9361098810410419 |:  38%|███▊      | 10/26 [00:27<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.47887862, IoU: 0.9571586810574234 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.47887862, IoU: 0.9571586810574234 |:  42%|████▏     | 11/26 [00:30<00:42,  2.80s/it]\u001b[A\n","Training loss: 0.4115509, IoU: 0.9524455286523834 |:  42%|████▏     | 11/26 [00:33<00:42,  2.80s/it] \u001b[A\n","Training loss: 0.4115509, IoU: 0.9524455286523834 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.4704215, IoU: 0.9518695706167247 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.4704215, IoU: 0.9518695706167247 |:  50%|█████     | 13/26 [00:36<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.43467468, IoU: 0.946226762925344 |:  50%|█████     | 13/26 [00:39<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.43467468, IoU: 0.946226762925344 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.43016252, IoU: 0.9516261446163562 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.43016252, IoU: 0.9516261446163562 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.40963992, IoU: 0.9456148324072853 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.40963992, IoU: 0.9456148324072853 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.48238885, IoU: 0.93402759355965 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.79s/it]  \u001b[A\n","Training loss: 0.48238885, IoU: 0.93402759355965 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.45623806, IoU: 0.9478279355491371 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.45623806, IoU: 0.9478279355491371 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.49147242, IoU: 0.9465067081107714 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.49147242, IoU: 0.9465067081107714 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.45060936, IoU: 0.9403185401736134 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.45060936, IoU: 0.9403185401736134 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.47765857, IoU: 0.9551299500487415 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.47765857, IoU: 0.9551299500487415 |:  81%|████████  | 21/26 [00:58<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.4444272, IoU: 0.9428090536840255 |:  81%|████████  | 21/26 [01:01<00:13,  2.79s/it] \u001b[A\n","Training loss: 0.4444272, IoU: 0.9428090536840255 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.38528565, IoU: 0.9454115163990094 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.38528565, IoU: 0.9454115163990094 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.55007166, IoU: 0.959970529910156 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.80s/it] \u001b[A\n","Training loss: 0.55007166, IoU: 0.959970529910156 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.4817952, IoU: 0.9551453104809314 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.4817952, IoU: 0.9551453104809314 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.81s/it]\u001b[A\n","Training loss: 0.4281738, IoU: 0.9203945281152605 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.81s/it]\u001b[A\n","Training loss: 0.4281738, IoU: 0.9203945281152605 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  36%|███▌      | 54/150 [1:23:39<2:06:56, 79.34s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4571019, IoU: 0.9444941330068601 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4571019, IoU: 0.9444941330068601 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.43553394, IoU: 0.9444171851851851 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.43553394, IoU: 0.9444171851851851 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.50090206, IoU: 0.9457155918336569 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.50090206, IoU: 0.9457155918336569 |:  12%|█▏        | 3/26 [00:08<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.44493684, IoU: 0.9515945663425565 |:  12%|█▏        | 3/26 [00:11<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.44493684, IoU: 0.9515945663425565 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.4582184, IoU: 0.9571519800381189 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.4582184, IoU: 0.9571519800381189 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.45210218, IoU: 0.9544853232989873 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.45210218, IoU: 0.9544853232989873 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.44115493, IoU: 0.9489978368781025 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.44115493, IoU: 0.9489978368781025 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.41072756, IoU: 0.9483333776348316 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.41072756, IoU: 0.9483333776348316 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.3817618, IoU: 0.9516215731947679 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it] \u001b[A\n","Training loss: 0.3817618, IoU: 0.9516215731947679 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.45093232, IoU: 0.9428564558209996 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.45093232, IoU: 0.9428564558209996 |:  38%|███▊      | 10/26 [00:28<00:44,  2.81s/it]\u001b[A\n","Training loss: 0.37554336, IoU: 0.9461533721750204 |:  38%|███▊      | 10/26 [00:30<00:44,  2.81s/it]\u001b[A\n","Training loss: 0.37554336, IoU: 0.9461533721750204 |:  42%|████▏     | 11/26 [00:30<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.45613992, IoU: 0.9382458892381939 |:  42%|████▏     | 11/26 [00:33<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.45613992, IoU: 0.9382458892381939 |:  46%|████▌     | 12/26 [00:33<00:39,  2.82s/it]\u001b[A\n","Training loss: 0.428664, IoU: 0.9462439101252665 |:  46%|████▌     | 12/26 [00:36<00:39,  2.82s/it]  \u001b[A\n","Training loss: 0.428664, IoU: 0.9462439101252665 |:  50%|█████     | 13/26 [00:36<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.45598632, IoU: 0.955836850121542 |:  50%|█████     | 13/26 [00:39<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.45598632, IoU: 0.955836850121542 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.81s/it]\u001b[A\n","Training loss: 0.45197216, IoU: 0.9393031118319753 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.81s/it]\u001b[A\n","Training loss: 0.45197216, IoU: 0.9393031118319753 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.80s/it]\u001b[A\n","Training loss: 0.3909688, IoU: 0.9453409953496275 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.80s/it] \u001b[A\n","Training loss: 0.3909688, IoU: 0.9453409953496275 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.46906698, IoU: 0.9484088413701244 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.46906698, IoU: 0.9484088413701244 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.44816265, IoU: 0.9523250703871656 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.44816265, IoU: 0.9523250703871656 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.44474113, IoU: 0.9549269558214728 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.44474113, IoU: 0.9549269558214728 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.4493362, IoU: 0.9514356637768866 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.78s/it] \u001b[A\n","Training loss: 0.4493362, IoU: 0.9514356637768866 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4622795, IoU: 0.9420814033009722 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4622795, IoU: 0.9420814033009722 |:  81%|████████  | 21/26 [00:58<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.44679338, IoU: 0.9527451735757233 |:  81%|████████  | 21/26 [01:01<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.44679338, IoU: 0.9527451735757233 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.44078273, IoU: 0.9441811777305961 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.44078273, IoU: 0.9441811777305961 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4605826, IoU: 0.9502330256315341 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.78s/it] \u001b[A\n","Training loss: 0.4605826, IoU: 0.9502330256315341 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.53895557, IoU: 0.9338961546379192 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.53895557, IoU: 0.9338961546379192 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.46605647, IoU: 0.9465148758659978 |:  96%|█████████▌| 25/26 [01:12<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.46605647, IoU: 0.9465148758659978 |: 100%|██████████| 26/26 [01:12<00:00,  2.80s/it]\n","Epoch Loop:  37%|███▋      | 55/150 [1:25:00<2:06:13, 79.73s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.41215205, IoU: 0.9407339707536558 |:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.41215205, IoU: 0.9407339707536558 |:   4%|▍         | 1/26 [00:00<00:23,  1.05it/s]\u001b[A\n","Training loss: 0.43617684, IoU: 0.9441781050065509 |:   4%|▍         | 1/26 [00:03<00:23,  1.05it/s]\u001b[A\n","Training loss: 0.43617684, IoU: 0.9441781050065509 |:   8%|▊         | 2/26 [00:03<00:49,  2.07s/it]\u001b[A\n","Training loss: 0.46761933, IoU: 0.9367182953856059 |:   8%|▊         | 2/26 [00:06<00:49,  2.07s/it]\u001b[A\n","Training loss: 0.46761933, IoU: 0.9367182953856059 |:  12%|█▏        | 3/26 [00:06<00:55,  2.43s/it]\u001b[A\n","Training loss: 0.48764297, IoU: 0.9555450620615219 |:  12%|█▏        | 3/26 [00:09<00:55,  2.43s/it]\u001b[A\n","Training loss: 0.48764297, IoU: 0.9555450620615219 |:  15%|█▌        | 4/26 [00:09<00:57,  2.59s/it]\u001b[A\n","Training loss: 0.4035053, IoU: 0.9528874836365198 |:  15%|█▌        | 4/26 [00:12<00:57,  2.59s/it] \u001b[A\n","Training loss: 0.4035053, IoU: 0.9528874836365198 |:  19%|█▉        | 5/26 [00:12<00:56,  2.69s/it]\u001b[A\n","Training loss: 0.45262018, IoU: 0.944698085736006 |:  19%|█▉        | 5/26 [00:15<00:56,  2.69s/it]\u001b[A\n","Training loss: 0.45262018, IoU: 0.944698085736006 |:  23%|██▎       | 6/26 [00:15<00:54,  2.74s/it]\u001b[A\n","Training loss: 0.44207656, IoU: 0.9597397688064471 |:  23%|██▎       | 6/26 [00:18<00:54,  2.74s/it]\u001b[A\n","Training loss: 0.44207656, IoU: 0.9597397688064471 |:  27%|██▋       | 7/26 [00:18<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.46019587, IoU: 0.9387706608138873 |:  27%|██▋       | 7/26 [00:20<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.46019587, IoU: 0.9387706608138873 |:  31%|███       | 8/26 [00:20<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.4694764, IoU: 0.940992221744236 |:  31%|███       | 8/26 [00:23<00:50,  2.79s/it]  \u001b[A\n","Training loss: 0.4694764, IoU: 0.940992221744236 |:  35%|███▍      | 9/26 [00:23<00:47,  2.82s/it]\u001b[A\n","Training loss: 0.42697728, IoU: 0.9517243059531496 |:  35%|███▍      | 9/26 [00:26<00:47,  2.82s/it]\u001b[A\n","Training loss: 0.42697728, IoU: 0.9517243059531496 |:  38%|███▊      | 10/26 [00:26<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.479546, IoU: 0.9528860523114504 |:  38%|███▊      | 10/26 [00:29<00:45,  2.82s/it]  \u001b[A\n","Training loss: 0.479546, IoU: 0.9528860523114504 |:  42%|████▏     | 11/26 [00:29<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.48485672, IoU: 0.9507615576768101 |:  42%|████▏     | 11/26 [00:32<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.48485672, IoU: 0.9507615576768101 |:  46%|████▌     | 12/26 [00:32<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.46067005, IoU: 0.963031158858493 |:  46%|████▌     | 12/26 [00:34<00:39,  2.80s/it] \u001b[A\n","Training loss: 0.46067005, IoU: 0.963031158858493 |:  50%|█████     | 13/26 [00:34<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.5548005, IoU: 0.923844670174887 |:  50%|█████     | 13/26 [00:37<00:36,  2.80s/it] \u001b[A\n","Training loss: 0.5548005, IoU: 0.923844670174887 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.4029431, IoU: 0.9490859104353172 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.4029431, IoU: 0.9490859104353172 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.81s/it]\u001b[A\n","Training loss: 0.40643165, IoU: 0.951973068312077 |:  58%|█████▊    | 15/26 [00:43<00:30,  2.81s/it]\u001b[A\n","Training loss: 0.40643165, IoU: 0.951973068312077 |:  62%|██████▏   | 16/26 [00:43<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.41257578, IoU: 0.9420679097133133 |:  62%|██████▏   | 16/26 [00:46<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.41257578, IoU: 0.9420679097133133 |:  65%|██████▌   | 17/26 [00:46<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.50621164, IoU: 0.9451983373091263 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.50621164, IoU: 0.9451983373091263 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.4662516, IoU: 0.9462042034584925 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.80s/it] \u001b[A\n","Training loss: 0.4662516, IoU: 0.9462042034584925 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.43075323, IoU: 0.9508333062301663 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.43075323, IoU: 0.9508333062301663 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.44330323, IoU: 0.9470386768022722 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.44330323, IoU: 0.9470386768022722 |:  81%|████████  | 21/26 [00:57<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.47294787, IoU: 0.9546143007729405 |:  81%|████████  | 21/26 [01:00<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.47294787, IoU: 0.9546143007729405 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.45011675, IoU: 0.9487471552142446 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.45011675, IoU: 0.9487471552142446 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.4792239, IoU: 0.9427307127826994 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it] \u001b[A\n","Training loss: 0.4792239, IoU: 0.9427307127826994 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.4986022, IoU: 0.9533692312508665 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.4986022, IoU: 0.9533692312508665 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.42856777, IoU: 0.957165146655331 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.42856777, IoU: 0.957165146655331 |: 100%|██████████| 26/26 [01:11<00:00,  2.75s/it]\n","Epoch Loop:  37%|███▋      | 56/150 [1:26:19<2:04:42, 79.60s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5002765, IoU: 0.9524337691988858 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5002765, IoU: 0.9524337691988858 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.47548681, IoU: 0.9396303901437372 |:   4%|▍         | 1/26 [00:03<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.47548681, IoU: 0.9396303901437372 |:   8%|▊         | 2/26 [00:03<00:40,  1.70s/it]\u001b[A\n","Training loss: 0.41424066, IoU: 0.9571130136634741 |:   8%|▊         | 2/26 [00:06<00:40,  1.70s/it]\u001b[A\n","Training loss: 0.41424066, IoU: 0.9571130136634741 |:  12%|█▏        | 3/26 [00:06<00:50,  2.20s/it]\u001b[A\n","Training loss: 0.4873823, IoU: 0.9540741025116025 |:  12%|█▏        | 3/26 [00:09<00:50,  2.20s/it] \u001b[A\n","Training loss: 0.4873823, IoU: 0.9540741025116025 |:  15%|█▌        | 4/26 [00:09<00:53,  2.44s/it]\u001b[A\n","Training loss: 0.4680298, IoU: 0.9446230247752039 |:  15%|█▌        | 4/26 [00:12<00:53,  2.44s/it]\u001b[A\n","Training loss: 0.4680298, IoU: 0.9446230247752039 |:  19%|█▉        | 5/26 [00:12<00:53,  2.56s/it]\u001b[A\n","Training loss: 0.48380834, IoU: 0.9503387219056469 |:  19%|█▉        | 5/26 [00:14<00:53,  2.56s/it]\u001b[A\n","Training loss: 0.48380834, IoU: 0.9503387219056469 |:  23%|██▎       | 6/26 [00:14<00:52,  2.63s/it]\u001b[A\n","Training loss: 0.4985432, IoU: 0.9512678885262366 |:  23%|██▎       | 6/26 [00:17<00:52,  2.63s/it] \u001b[A\n","Training loss: 0.4985432, IoU: 0.9512678885262366 |:  27%|██▋       | 7/26 [00:17<00:50,  2.68s/it]\u001b[A\n","Training loss: 0.44267786, IoU: 0.9433776180605398 |:  27%|██▋       | 7/26 [00:20<00:50,  2.68s/it]\u001b[A\n","Training loss: 0.44267786, IoU: 0.9433776180605398 |:  31%|███       | 8/26 [00:20<00:48,  2.71s/it]\u001b[A\n","Training loss: 0.43527898, IoU: 0.9533071230342276 |:  31%|███       | 8/26 [00:23<00:48,  2.71s/it]\u001b[A\n","Training loss: 0.43527898, IoU: 0.9533071230342276 |:  35%|███▍      | 9/26 [00:23<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.50291705, IoU: 0.9565453045317698 |:  35%|███▍      | 9/26 [00:25<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.50291705, IoU: 0.9565453045317698 |:  38%|███▊      | 10/26 [00:25<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.39751023, IoU: 0.9545165687563367 |:  38%|███▊      | 10/26 [00:28<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.39751023, IoU: 0.9545165687563367 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.5058955, IoU: 0.9399628493272216 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it] \u001b[A\n","Training loss: 0.5058955, IoU: 0.9399628493272216 |:  46%|████▌     | 12/26 [00:31<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.4431789, IoU: 0.9486879083266565 |:  46%|████▌     | 12/26 [00:34<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.4431789, IoU: 0.9486879083266565 |:  50%|█████     | 13/26 [00:34<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.5054215, IoU: 0.9548333215809329 |:  50%|█████     | 13/26 [00:37<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.5054215, IoU: 0.9548333215809329 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.4445606, IoU: 0.9508799399333406 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.4445606, IoU: 0.9508799399333406 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.80s/it]\u001b[A\n","Training loss: 0.44028276, IoU: 0.9491095401716142 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.80s/it]\u001b[A\n","Training loss: 0.44028276, IoU: 0.9491095401716142 |:  62%|██████▏   | 16/26 [00:42<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.50325483, IoU: 0.9348207666616565 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.50325483, IoU: 0.9348207666616565 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.50776565, IoU: 0.940453189324995 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.80s/it] \u001b[A\n","Training loss: 0.50776565, IoU: 0.940453189324995 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.49605983, IoU: 0.9563237947442718 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.49605983, IoU: 0.9563237947442718 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.4366163, IoU: 0.9505512847527209 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it] \u001b[A\n","Training loss: 0.4366163, IoU: 0.9505512847527209 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.468365, IoU: 0.94528138191486 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]   \u001b[A\n","Training loss: 0.468365, IoU: 0.94528138191486 |:  81%|████████  | 21/26 [00:56<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.44645643, IoU: 0.9381922861707936 |:  81%|████████  | 21/26 [00:59<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.44645643, IoU: 0.9381922861707936 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.4101066, IoU: 0.9497747764479807 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it] \u001b[A\n","Training loss: 0.4101066, IoU: 0.9497747764479807 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.5011337, IoU: 0.9566466577689531 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.5011337, IoU: 0.9566466577689531 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.41723174, IoU: 0.9538226292065883 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.41723174, IoU: 0.9538226292065883 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.46791095, IoU: 0.9491231523399788 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.46791095, IoU: 0.9491231523399788 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  38%|███▊      | 57/150 [1:27:38<2:02:56, 79.31s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8166429834245238\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5505961, IoU: 0.9386130982590548 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5505961, IoU: 0.9386130982590548 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.47975355, IoU: 0.9454503987371615 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.47975355, IoU: 0.9454503987371615 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.51085544, IoU: 0.9238413107790336 |:   8%|▊         | 2/26 [00:06<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.51085544, IoU: 0.9238413107790336 |:  12%|█▏        | 3/26 [00:06<00:44,  1.96s/it]\u001b[A\n","Training loss: 0.460499, IoU: 0.9594388893262997 |:  12%|█▏        | 3/26 [00:09<00:44,  1.96s/it]  \u001b[A\n","Training loss: 0.460499, IoU: 0.9594388893262997 |:  15%|█▌        | 4/26 [00:09<00:50,  2.28s/it]\u001b[A\n","Training loss: 0.45763665, IoU: 0.9502388504310112 |:  15%|█▌        | 4/26 [00:12<00:50,  2.28s/it]\u001b[A\n","Training loss: 0.45763665, IoU: 0.9502388504310112 |:  19%|█▉        | 5/26 [00:12<00:51,  2.46s/it]\u001b[A\n","Training loss: 0.4565996, IoU: 0.9488367487864817 |:  19%|█▉        | 5/26 [00:14<00:51,  2.46s/it] \u001b[A\n","Training loss: 0.4565996, IoU: 0.9488367487864817 |:  23%|██▎       | 6/26 [00:14<00:51,  2.57s/it]\u001b[A\n","Training loss: 0.45802802, IoU: 0.9566143469903575 |:  23%|██▎       | 6/26 [00:17<00:51,  2.57s/it]\u001b[A\n","Training loss: 0.45802802, IoU: 0.9566143469903575 |:  27%|██▋       | 7/26 [00:17<00:50,  2.63s/it]\u001b[A\n","Training loss: 0.46114194, IoU: 0.943935482179169 |:  27%|██▋       | 7/26 [00:20<00:50,  2.63s/it] \u001b[A\n","Training loss: 0.46114194, IoU: 0.943935482179169 |:  31%|███       | 8/26 [00:20<00:48,  2.69s/it]\u001b[A\n","Training loss: 0.42416993, IoU: 0.9508988630898026 |:  31%|███       | 8/26 [00:23<00:48,  2.69s/it]\u001b[A\n","Training loss: 0.42416993, IoU: 0.9508988630898026 |:  35%|███▍      | 9/26 [00:23<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.45265493, IoU: 0.9415402745645268 |:  35%|███▍      | 9/26 [00:26<00:46,  2.73s/it]\u001b[A\n","Training loss: 0.45265493, IoU: 0.9415402745645268 |:  38%|███▊      | 10/26 [00:26<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.47369123, IoU: 0.9480742770284386 |:  38%|███▊      | 10/26 [00:28<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.47369123, IoU: 0.9480742770284386 |:  42%|████▏     | 11/26 [00:28<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.4427119, IoU: 0.9426831370878591 |:  42%|████▏     | 11/26 [00:31<00:41,  2.77s/it] \u001b[A\n","Training loss: 0.4427119, IoU: 0.9426831370878591 |:  46%|████▌     | 12/26 [00:31<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.44094056, IoU: 0.944099456176811 |:  46%|████▌     | 12/26 [00:34<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.44094056, IoU: 0.944099456176811 |:  50%|█████     | 13/26 [00:34<00:36,  2.81s/it]\u001b[A\n","Training loss: 0.45077372, IoU: 0.9545442736523057 |:  50%|█████     | 13/26 [00:37<00:36,  2.81s/it]\u001b[A\n","Training loss: 0.45077372, IoU: 0.9545442736523057 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.83s/it]\u001b[A\n","Training loss: 0.45000857, IoU: 0.9399695039472713 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.83s/it]\u001b[A\n","Training loss: 0.45000857, IoU: 0.9399695039472713 |:  58%|█████▊    | 15/26 [00:40<00:31,  2.84s/it]\u001b[A\n","Training loss: 0.42923248, IoU: 0.940427929086625 |:  58%|█████▊    | 15/26 [00:43<00:31,  2.84s/it] \u001b[A\n","Training loss: 0.42923248, IoU: 0.940427929086625 |:  62%|██████▏   | 16/26 [00:43<00:28,  2.84s/it]\u001b[A\n","Training loss: 0.53433263, IoU: 0.9347643594762419 |:  62%|██████▏   | 16/26 [00:46<00:28,  2.84s/it]\u001b[A\n","Training loss: 0.53433263, IoU: 0.9347643594762419 |:  65%|██████▌   | 17/26 [00:46<00:25,  2.85s/it]\u001b[A\n","Training loss: 0.4332011, IoU: 0.9570503241035989 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.85s/it] \u001b[A\n","Training loss: 0.4332011, IoU: 0.9570503241035989 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.85s/it]\u001b[A\n","Training loss: 0.47010666, IoU: 0.9538142428169284 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.85s/it]\u001b[A\n","Training loss: 0.47010666, IoU: 0.9538142428169284 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.85s/it]\u001b[A\n","Training loss: 0.5258541, IoU: 0.9436062341904419 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.85s/it] \u001b[A\n","Training loss: 0.5258541, IoU: 0.9436062341904419 |:  77%|███████▋  | 20/26 [00:54<00:17,  2.84s/it]\u001b[A\n","Training loss: 0.4532311, IoU: 0.956885522429217 |:  77%|███████▋  | 20/26 [00:57<00:17,  2.84s/it] \u001b[A\n","Training loss: 0.4532311, IoU: 0.956885522429217 |:  81%|████████  | 21/26 [00:57<00:14,  2.83s/it]\u001b[A\n","Training loss: 0.47040075, IoU: 0.9565577123090767 |:  81%|████████  | 21/26 [01:00<00:14,  2.83s/it]\u001b[A\n","Training loss: 0.47040075, IoU: 0.9565577123090767 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.83s/it]\u001b[A\n","Training loss: 0.4522852, IoU: 0.9498291534126841 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.83s/it] \u001b[A\n","Training loss: 0.4522852, IoU: 0.9498291534126841 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.84s/it]\u001b[A\n","Training loss: 0.42591274, IoU: 0.9511720768995916 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.84s/it]\u001b[A\n","Training loss: 0.42591274, IoU: 0.9511720768995916 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.84s/it]\u001b[A\n","Training loss: 0.4359645, IoU: 0.9495747487982031 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.84s/it] \u001b[A\n","Training loss: 0.4359645, IoU: 0.9495747487982031 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.85s/it]\u001b[A\n","Training loss: 0.40434065, IoU: 0.9563138731952291 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.85s/it]\u001b[A\n","Training loss: 0.40434065, IoU: 0.9563138731952291 |: 100%|██████████| 26/26 [01:11<00:00,  2.75s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.8166429834245238 to 0.8256325013881294\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  39%|███▊      | 58/150 [1:29:00<2:02:45, 80.06s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46544623, IoU: 0.9526591257715318 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46544623, IoU: 0.9526591257715318 |:   4%|▍         | 1/26 [00:02<01:11,  2.87s/it]\u001b[A\n","Training loss: 0.4445235, IoU: 0.9396217227504549 |:   4%|▍         | 1/26 [00:05<01:11,  2.87s/it] \u001b[A\n","Training loss: 0.4445235, IoU: 0.9396217227504549 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.4857924, IoU: 0.933898970177252 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it] \u001b[A\n","Training loss: 0.4857924, IoU: 0.933898970177252 |:  12%|█▏        | 3/26 [00:08<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.5128828, IoU: 0.9473809297461736 |:  12%|█▏        | 3/26 [00:09<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.5128828, IoU: 0.9473809297461736 |:  15%|█▌        | 4/26 [00:09<00:45,  2.08s/it]\u001b[A\n","Training loss: 0.4560839, IoU: 0.9374942236879867 |:  15%|█▌        | 4/26 [00:12<00:45,  2.08s/it]\u001b[A\n","Training loss: 0.4560839, IoU: 0.9374942236879867 |:  19%|█▉        | 5/26 [00:12<00:49,  2.37s/it]\u001b[A\n","Training loss: 0.5047903, IoU: 0.9409455629881043 |:  19%|█▉        | 5/26 [00:15<00:49,  2.37s/it]\u001b[A\n","Training loss: 0.5047903, IoU: 0.9409455629881043 |:  23%|██▎       | 6/26 [00:15<00:50,  2.53s/it]\u001b[A\n","Training loss: 0.51451486, IoU: 0.937084117508335 |:  23%|██▎       | 6/26 [00:18<00:50,  2.53s/it]\u001b[A\n","Training loss: 0.51451486, IoU: 0.937084117508335 |:  27%|██▋       | 7/26 [00:18<00:50,  2.64s/it]\u001b[A\n","Training loss: 0.45243815, IoU: 0.9605697291386047 |:  27%|██▋       | 7/26 [00:20<00:50,  2.64s/it]\u001b[A\n","Training loss: 0.45243815, IoU: 0.9605697291386047 |:  31%|███       | 8/26 [00:20<00:48,  2.72s/it]\u001b[A\n","Training loss: 0.40264714, IoU: 0.944928020174785 |:  31%|███       | 8/26 [00:23<00:48,  2.72s/it] \u001b[A\n","Training loss: 0.40264714, IoU: 0.944928020174785 |:  35%|███▍      | 9/26 [00:23<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.43101126, IoU: 0.9516149811786587 |:  35%|███▍      | 9/26 [00:26<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.43101126, IoU: 0.9516149811786587 |:  38%|███▊      | 10/26 [00:26<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.47695512, IoU: 0.9463434983568654 |:  38%|███▊      | 10/26 [00:29<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.47695512, IoU: 0.9463434983568654 |:  42%|████▏     | 11/26 [00:29<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.44402108, IoU: 0.9554995040956165 |:  42%|████▏     | 11/26 [00:32<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.44402108, IoU: 0.9554995040956165 |:  46%|████▌     | 12/26 [00:32<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.44170696, IoU: 0.9562375263934284 |:  46%|████▌     | 12/26 [00:34<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.44170696, IoU: 0.9562375263934284 |:  50%|█████     | 13/26 [00:34<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.45518106, IoU: 0.9527078888255135 |:  50%|█████     | 13/26 [00:37<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.45518106, IoU: 0.9527078888255135 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.4190025, IoU: 0.949310488238708 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.78s/it]  \u001b[A\n","Training loss: 0.4190025, IoU: 0.949310488238708 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.46723872, IoU: 0.9490208874425694 |:  58%|█████▊    | 15/26 [00:43<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.46723872, IoU: 0.9490208874425694 |:  62%|██████▏   | 16/26 [00:43<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.4408877, IoU: 0.9556548058137403 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it] \u001b[A\n","Training loss: 0.4408877, IoU: 0.9556548058137403 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.39172548, IoU: 0.9507671628558764 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.39172548, IoU: 0.9507671628558764 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.48112476, IoU: 0.9552909743542988 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.48112476, IoU: 0.9552909743542988 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.45673934, IoU: 0.9484861893949835 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.45673934, IoU: 0.9484861893949835 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.5149989, IoU: 0.9585763425044568 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.78s/it] \u001b[A\n","Training loss: 0.5149989, IoU: 0.9585763425044568 |:  81%|████████  | 21/26 [00:57<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.48382646, IoU: 0.957543660694035 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.48382646, IoU: 0.957543660694035 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.38830942, IoU: 0.9449212691209435 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.38830942, IoU: 0.9449212691209435 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.4806646, IoU: 0.9382570881417764 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it] \u001b[A\n","Training loss: 0.4806646, IoU: 0.9382570881417764 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.5176203, IoU: 0.9343066901533332 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.5176203, IoU: 0.9343066901533332 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4371728, IoU: 0.9498115068404558 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4371728, IoU: 0.9498115068404558 |: 100%|██████████| 26/26 [01:11<00:00,  2.73s/it]\n","Epoch Loop:  39%|███▉      | 59/150 [1:30:19<2:00:56, 79.74s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8256325013881294\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5119069, IoU: 0.9610735360977919 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5119069, IoU: 0.9610735360977919 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.5020804, IoU: 0.9535726708529374 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.5020804, IoU: 0.9535726708529374 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.47338343, IoU: 0.9453544524348276 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.47338343, IoU: 0.9453544524348276 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.445082, IoU: 0.9400039552187056 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]  \u001b[A\n","Training loss: 0.445082, IoU: 0.9400039552187056 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46066016, IoU: 0.9533378947990844 |:  15%|█▌        | 4/26 [00:12<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46066016, IoU: 0.9533378947990844 |:  19%|█▉        | 5/26 [00:12<00:44,  2.13s/it]\u001b[A\n","Training loss: 0.43150935, IoU: 0.9588483238054248 |:  19%|█▉        | 5/26 [00:14<00:44,  2.13s/it]\u001b[A\n","Training loss: 0.43150935, IoU: 0.9588483238054248 |:  23%|██▎       | 6/26 [00:14<00:47,  2.35s/it]\u001b[A\n","Training loss: 0.43866804, IoU: 0.9422997268217636 |:  23%|██▎       | 6/26 [00:17<00:47,  2.35s/it]\u001b[A\n","Training loss: 0.43866804, IoU: 0.9422997268217636 |:  27%|██▋       | 7/26 [00:17<00:47,  2.49s/it]\u001b[A\n","Training loss: 0.4636472, IoU: 0.938843771048945 |:  27%|██▋       | 7/26 [00:20<00:47,  2.49s/it]  \u001b[A\n","Training loss: 0.4636472, IoU: 0.938843771048945 |:  31%|███       | 8/26 [00:20<00:46,  2.59s/it]\u001b[A\n","Training loss: 0.44302547, IoU: 0.9198278181329029 |:  31%|███       | 8/26 [00:23<00:46,  2.59s/it]\u001b[A\n","Training loss: 0.44302547, IoU: 0.9198278181329029 |:  35%|███▍      | 9/26 [00:23<00:45,  2.65s/it]\u001b[A\n","Training loss: 0.40135252, IoU: 0.9417674767993239 |:  35%|███▍      | 9/26 [00:26<00:45,  2.65s/it]\u001b[A\n","Training loss: 0.40135252, IoU: 0.9417674767993239 |:  38%|███▊      | 10/26 [00:26<00:43,  2.69s/it]\u001b[A\n","Training loss: 0.4594664, IoU: 0.9527794667194983 |:  38%|███▊      | 10/26 [00:28<00:43,  2.69s/it] \u001b[A\n","Training loss: 0.4594664, IoU: 0.9527794667194983 |:  42%|████▏     | 11/26 [00:28<00:40,  2.72s/it]\u001b[A\n","Training loss: 0.4802994, IoU: 0.9366946837350973 |:  42%|████▏     | 11/26 [00:31<00:40,  2.72s/it]\u001b[A\n","Training loss: 0.4802994, IoU: 0.9366946837350973 |:  46%|████▌     | 12/26 [00:31<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.45472515, IoU: 0.9495868676658024 |:  46%|████▌     | 12/26 [00:34<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.45472515, IoU: 0.9495868676658024 |:  50%|█████     | 13/26 [00:34<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.44241464, IoU: 0.9421738336844079 |:  50%|█████     | 13/26 [00:37<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.44241464, IoU: 0.9421738336844079 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.50998545, IoU: 0.9550834967147704 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.50998545, IoU: 0.9550834967147704 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.43163723, IoU: 0.95388824510874 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it]  \u001b[A\n","Training loss: 0.43163723, IoU: 0.95388824510874 |:  62%|██████▏   | 16/26 [00:42<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.45853403, IoU: 0.957505776929424 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.45853403, IoU: 0.957505776929424 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.4579192, IoU: 0.94611085738419 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.81s/it]  \u001b[A\n","Training loss: 0.4579192, IoU: 0.94611085738419 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.44181064, IoU: 0.9349644378679708 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.44181064, IoU: 0.9349644378679708 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.44892004, IoU: 0.9460098011569328 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.44892004, IoU: 0.9460098011569328 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.47913063, IoU: 0.946424863609294 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.81s/it] \u001b[A\n","Training loss: 0.47913063, IoU: 0.946424863609294 |:  81%|████████  | 21/26 [00:56<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.42978898, IoU: 0.9451180409868355 |:  81%|████████  | 21/26 [00:59<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.42978898, IoU: 0.9451180409868355 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.4569353, IoU: 0.9577958010538661 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.80s/it] \u001b[A\n","Training loss: 0.4569353, IoU: 0.9577958010538661 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.48520875, IoU: 0.9569277898135755 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.48520875, IoU: 0.9569277898135755 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.4842338, IoU: 0.9509858688190878 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.79s/it] \u001b[A\n","Training loss: 0.4842338, IoU: 0.9509858688190878 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4858207, IoU: 0.9427934766638915 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4858207, IoU: 0.9427934766638915 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  40%|████      | 60/150 [1:31:38<1:59:11, 79.46s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8256325013881294\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44749564, IoU: 0.9533327411733866 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44749564, IoU: 0.9533327411733866 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.50837797, IoU: 0.9486808834489544 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.50837797, IoU: 0.9486808834489544 |:   8%|▊         | 2/26 [00:05<01:07,  2.79s/it]\u001b[A\n","Training loss: 0.47112146, IoU: 0.9450192040942027 |:   8%|▊         | 2/26 [00:08<01:07,  2.79s/it]\u001b[A\n","Training loss: 0.47112146, IoU: 0.9450192040942027 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.43100157, IoU: 0.9461549965309529 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.43100157, IoU: 0.9461549965309529 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.44718796, IoU: 0.9571092528932811 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.44718796, IoU: 0.9571092528932811 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.36752716, IoU: 0.9473852102464959 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.36752716, IoU: 0.9473852102464959 |:  23%|██▎       | 6/26 [00:14<00:43,  2.17s/it]\u001b[A\n","Training loss: 0.46479565, IoU: 0.9452068505811749 |:  23%|██▎       | 6/26 [00:17<00:43,  2.17s/it]\u001b[A\n","Training loss: 0.46479565, IoU: 0.9452068505811749 |:  27%|██▋       | 7/26 [00:17<00:44,  2.36s/it]\u001b[A\n","Training loss: 0.4318586, IoU: 0.9489085664260394 |:  27%|██▋       | 7/26 [00:20<00:44,  2.36s/it] \u001b[A\n","Training loss: 0.4318586, IoU: 0.9489085664260394 |:  31%|███       | 8/26 [00:20<00:44,  2.50s/it]\u001b[A\n","Training loss: 0.48080844, IoU: 0.9423678751010935 |:  31%|███       | 8/26 [00:23<00:44,  2.50s/it]\u001b[A\n","Training loss: 0.48080844, IoU: 0.9423678751010935 |:  35%|███▍      | 9/26 [00:23<00:43,  2.58s/it]\u001b[A\n","Training loss: 0.51233184, IoU: 0.9565043628854992 |:  35%|███▍      | 9/26 [00:26<00:43,  2.58s/it]\u001b[A\n","Training loss: 0.51233184, IoU: 0.9565043628854992 |:  38%|███▊      | 10/26 [00:26<00:42,  2.65s/it]\u001b[A\n","Training loss: 0.40590912, IoU: 0.9509996824933312 |:  38%|███▊      | 10/26 [00:28<00:42,  2.65s/it]\u001b[A\n","Training loss: 0.40590912, IoU: 0.9509996824933312 |:  42%|████▏     | 11/26 [00:28<00:40,  2.69s/it]\u001b[A\n","Training loss: 0.44932473, IoU: 0.943535148085963 |:  42%|████▏     | 11/26 [00:31<00:40,  2.69s/it] \u001b[A\n","Training loss: 0.44932473, IoU: 0.943535148085963 |:  46%|████▌     | 12/26 [00:31<00:38,  2.71s/it]\u001b[A\n","Training loss: 0.460498, IoU: 0.9581664000757792 |:  46%|████▌     | 12/26 [00:34<00:38,  2.71s/it] \u001b[A\n","Training loss: 0.460498, IoU: 0.9581664000757792 |:  50%|█████     | 13/26 [00:34<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.39912468, IoU: 0.9485331776981074 |:  50%|█████     | 13/26 [00:37<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.39912468, IoU: 0.9485331776981074 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.46893367, IoU: 0.9573798194512385 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.46893367, IoU: 0.9573798194512385 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.41898957, IoU: 0.9449002667962489 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.41898957, IoU: 0.9449002667962489 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.4610655, IoU: 0.9588668014375562 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it] \u001b[A\n","Training loss: 0.4610655, IoU: 0.9588668014375562 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.37930375, IoU: 0.9480085348506401 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.37930375, IoU: 0.9480085348506401 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.45508265, IoU: 0.9437982445621633 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.45508265, IoU: 0.9437982445621633 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.46609682, IoU: 0.9560419615066702 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.46609682, IoU: 0.9560419615066702 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.50993013, IoU: 0.9519003272654278 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.50993013, IoU: 0.9519003272654278 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.45339668, IoU: 0.956794366236831 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it] \u001b[A\n","Training loss: 0.45339668, IoU: 0.956794366236831 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.5025618, IoU: 0.9480672982806065 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.5025618, IoU: 0.9480672982806065 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.44470122, IoU: 0.9489869184616898 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.44470122, IoU: 0.9489869184616898 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.47481394, IoU: 0.9523959106745102 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.47481394, IoU: 0.9523959106745102 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4501925, IoU: 0.95306917868161 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]   \u001b[A\n","Training loss: 0.4501925, IoU: 0.95306917868161 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  41%|████      | 61/150 [1:32:56<1:57:25, 79.17s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8256325013881294\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48139653, IoU: 0.9549009243112128 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48139653, IoU: 0.9549009243112128 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.4467473, IoU: 0.9537045051776057 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it] \u001b[A\n","Training loss: 0.4467473, IoU: 0.9537045051776057 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.50889957, IoU: 0.9349517716301532 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.50889957, IoU: 0.9349517716301532 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.5191828, IoU: 0.9376391488796092 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it] \u001b[A\n","Training loss: 0.5191828, IoU: 0.9376391488796092 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.49182057, IoU: 0.9503896575208497 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.49182057, IoU: 0.9503896575208497 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.4096309, IoU: 0.9442930531585269 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it] \u001b[A\n","Training loss: 0.4096309, IoU: 0.9442930531585269 |:  23%|██▎       | 6/26 [00:16<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.49227384, IoU: 0.9298124162572577 |:  23%|██▎       | 6/26 [00:17<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.49227384, IoU: 0.9298124162572577 |:  27%|██▋       | 7/26 [00:17<00:41,  2.20s/it]\u001b[A\n","Training loss: 0.437051, IoU: 0.9517773186196022 |:  27%|██▋       | 7/26 [00:20<00:41,  2.20s/it]  \u001b[A\n","Training loss: 0.437051, IoU: 0.9517773186196022 |:  31%|███       | 8/26 [00:20<00:42,  2.38s/it]\u001b[A\n","Training loss: 0.5003375, IoU: 0.9345970463522688 |:  31%|███       | 8/26 [00:23<00:42,  2.38s/it]\u001b[A\n","Training loss: 0.5003375, IoU: 0.9345970463522688 |:  35%|███▍      | 9/26 [00:23<00:42,  2.52s/it]\u001b[A\n","Training loss: 0.5007771, IoU: 0.9495242777947369 |:  35%|███▍      | 9/26 [00:26<00:42,  2.52s/it]\u001b[A\n","Training loss: 0.5007771, IoU: 0.9495242777947369 |:  38%|███▊      | 10/26 [00:26<00:41,  2.60s/it]\u001b[A\n","Training loss: 0.44686913, IoU: 0.9546511086267934 |:  38%|███▊      | 10/26 [00:28<00:41,  2.60s/it]\u001b[A\n","Training loss: 0.44686913, IoU: 0.9546511086267934 |:  42%|████▏     | 11/26 [00:28<00:39,  2.66s/it]\u001b[A\n","Training loss: 0.48426157, IoU: 0.95542735565497 |:  42%|████▏     | 11/26 [00:31<00:39,  2.66s/it]  \u001b[A\n","Training loss: 0.48426157, IoU: 0.95542735565497 |:  46%|████▌     | 12/26 [00:31<00:37,  2.70s/it]\u001b[A\n","Training loss: 0.44775844, IoU: 0.9455735679809836 |:  46%|████▌     | 12/26 [00:34<00:37,  2.70s/it]\u001b[A\n","Training loss: 0.44775844, IoU: 0.9455735679809836 |:  50%|█████     | 13/26 [00:34<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.47025678, IoU: 0.9548131626969455 |:  50%|█████     | 13/26 [00:37<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.47025678, IoU: 0.9548131626969455 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.75s/it]\u001b[A\n","Training loss: 0.49266714, IoU: 0.9404592867675168 |:  54%|█████▍    | 14/26 [00:40<00:32,  2.75s/it]\u001b[A\n","Training loss: 0.49266714, IoU: 0.9404592867675168 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.4753093, IoU: 0.9528566349249349 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it] \u001b[A\n","Training loss: 0.4753093, IoU: 0.9528566349249349 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.49333197, IoU: 0.9394059365477501 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.49333197, IoU: 0.9394059365477501 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.42102537, IoU: 0.952667158428046 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.42102537, IoU: 0.952667158428046 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45817345, IoU: 0.9498264773908611 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45817345, IoU: 0.9498264773908611 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.41274852, IoU: 0.9601354878540049 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.41274852, IoU: 0.9601354878540049 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.5184773, IoU: 0.9471644673033884 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it] \u001b[A\n","Training loss: 0.5184773, IoU: 0.9471644673033884 |:  81%|████████  | 21/26 [00:56<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.40202883, IoU: 0.9480351303643256 |:  81%|████████  | 21/26 [00:59<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.40202883, IoU: 0.9480351303643256 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.4915725, IoU: 0.9542211924576967 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it] \u001b[A\n","Training loss: 0.4915725, IoU: 0.9542211924576967 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.47527015, IoU: 0.9522474576346013 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.47527015, IoU: 0.9522474576346013 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.45470852, IoU: 0.9534470553624947 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.45470852, IoU: 0.9534470553624947 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.40388033, IoU: 0.9496942950070948 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.40388033, IoU: 0.9496942950070948 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  41%|████▏     | 62/150 [1:34:15<1:55:52, 79.00s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8256325013881294\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44889975, IoU: 0.9584378342385567 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44889975, IoU: 0.9584378342385567 |:   4%|▍         | 1/26 [00:02<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.46151283, IoU: 0.9439741698610237 |:   4%|▍         | 1/26 [00:05<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.46151283, IoU: 0.9439741698610237 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4972986, IoU: 0.9450552669169036 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it] \u001b[A\n","Training loss: 0.4972986, IoU: 0.9450552669169036 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.48372757, IoU: 0.9578763283330026 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.48372757, IoU: 0.9578763283330026 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.48555112, IoU: 0.9439464134597455 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.48555112, IoU: 0.9439464134597455 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.50333834, IoU: 0.9558675369048141 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.50333834, IoU: 0.9558675369048141 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.4802603, IoU: 0.9445439942080137 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it] \u001b[A\n","Training loss: 0.4802603, IoU: 0.9445439942080137 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.51276016, IoU: 0.943673198272999 |:  27%|██▋       | 7/26 [00:20<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.51276016, IoU: 0.943673198272999 |:  31%|███       | 8/26 [00:20<00:39,  2.19s/it]\u001b[A\n","Training loss: 0.49819893, IoU: 0.9493863280443835 |:  31%|███       | 8/26 [00:23<00:39,  2.19s/it]\u001b[A\n","Training loss: 0.49819893, IoU: 0.9493863280443835 |:  35%|███▍      | 9/26 [00:23<00:40,  2.38s/it]\u001b[A\n","Training loss: 0.49623245, IoU: 0.9452931466533528 |:  35%|███▍      | 9/26 [00:25<00:40,  2.38s/it]\u001b[A\n","Training loss: 0.49623245, IoU: 0.9452931466533528 |:  38%|███▊      | 10/26 [00:25<00:40,  2.50s/it]\u001b[A\n","Training loss: 0.46084377, IoU: 0.9564364347224303 |:  38%|███▊      | 10/26 [00:28<00:40,  2.50s/it]\u001b[A\n","Training loss: 0.46084377, IoU: 0.9564364347224303 |:  42%|████▏     | 11/26 [00:28<00:38,  2.59s/it]\u001b[A\n","Training loss: 0.4348676, IoU: 0.9517439694514296 |:  42%|████▏     | 11/26 [00:31<00:38,  2.59s/it] \u001b[A\n","Training loss: 0.4348676, IoU: 0.9517439694514296 |:  46%|████▌     | 12/26 [00:31<00:37,  2.64s/it]\u001b[A\n","Training loss: 0.43342793, IoU: 0.9570767570288413 |:  46%|████▌     | 12/26 [00:34<00:37,  2.64s/it]\u001b[A\n","Training loss: 0.43342793, IoU: 0.9570767570288413 |:  50%|█████     | 13/26 [00:34<00:35,  2.70s/it]\u001b[A\n","Training loss: 0.42161587, IoU: 0.9418795190863588 |:  50%|█████     | 13/26 [00:37<00:35,  2.70s/it]\u001b[A\n","Training loss: 0.42161587, IoU: 0.9418795190863588 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.72s/it]\u001b[A\n","Training loss: 0.4699648, IoU: 0.9586223484957506 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.72s/it] \u001b[A\n","Training loss: 0.4699648, IoU: 0.9586223484957506 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.74s/it]\u001b[A\n","Training loss: 0.5148929, IoU: 0.9378084695329463 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.74s/it]\u001b[A\n","Training loss: 0.5148929, IoU: 0.9378084695329463 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.4026046, IoU: 0.950360556056622 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.75s/it] \u001b[A\n","Training loss: 0.4026046, IoU: 0.950360556056622 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.450558, IoU: 0.9486636423913718 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.450558, IoU: 0.9486636423913718 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.4303861, IoU: 0.9521204754186926 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.4303861, IoU: 0.9521204754186926 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.41588947, IoU: 0.9458367690072224 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.41588947, IoU: 0.9458367690072224 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.457977, IoU: 0.9471800751450538 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]  \u001b[A\n","Training loss: 0.457977, IoU: 0.9471800751450538 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.4719683, IoU: 0.9533181155500355 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.4719683, IoU: 0.9533181155500355 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.51488525, IoU: 0.9407160357861836 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.51488525, IoU: 0.9407160357861836 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.54335916, IoU: 0.9290616359599748 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.54335916, IoU: 0.9290616359599748 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.49941993, IoU: 0.9548453943079854 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.49941993, IoU: 0.9548453943079854 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4358848, IoU: 0.9477455299300337 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it] \u001b[A\n","Training loss: 0.4358848, IoU: 0.9477455299300337 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  42%|████▏     | 63/150 [1:35:33<1:54:18, 78.83s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8256325013881294\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48542348, IoU: 0.9592376693096178 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48542348, IoU: 0.9592376693096178 |:   4%|▍         | 1/26 [00:02<01:10,  2.83s/it]\u001b[A\n","Training loss: 0.521355, IoU: 0.960859375 |:   4%|▍         | 1/26 [00:05<01:10,  2.83s/it]         \u001b[A\n","Training loss: 0.521355, IoU: 0.960859375 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.44858682, IoU: 0.9535444392044997 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.44858682, IoU: 0.9535444392044997 |:  12%|█▏        | 3/26 [00:08<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.42751548, IoU: 0.9424549111197612 |:  12%|█▏        | 3/26 [00:11<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.42751548, IoU: 0.9424549111197612 |:  15%|█▌        | 4/26 [00:11<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.44176966, IoU: 0.9519241301252328 |:  15%|█▌        | 4/26 [00:14<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.44176966, IoU: 0.9519241301252328 |:  19%|█▉        | 5/26 [00:14<00:59,  2.82s/it]\u001b[A\n","Training loss: 0.44799322, IoU: 0.941370943712133 |:  19%|█▉        | 5/26 [00:16<00:59,  2.82s/it] \u001b[A\n","Training loss: 0.44799322, IoU: 0.941370943712133 |:  23%|██▎       | 6/26 [00:16<00:56,  2.82s/it]\u001b[A\n","Training loss: 0.45822608, IoU: 0.9612569640702993 |:  23%|██▎       | 6/26 [00:19<00:56,  2.82s/it]\u001b[A\n","Training loss: 0.45822608, IoU: 0.9612569640702993 |:  27%|██▋       | 7/26 [00:19<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.43652332, IoU: 0.946701788699959 |:  27%|██▋       | 7/26 [00:22<00:53,  2.84s/it] \u001b[A\n","Training loss: 0.43652332, IoU: 0.946701788699959 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.47170025, IoU: 0.9306298373267832 |:  31%|███       | 8/26 [00:23<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.47170025, IoU: 0.9306298373267832 |:  35%|███▍      | 9/26 [00:23<00:37,  2.23s/it]\u001b[A\n","Training loss: 0.4368053, IoU: 0.9564003777854665 |:  35%|███▍      | 9/26 [00:26<00:37,  2.23s/it] \u001b[A\n","Training loss: 0.4368053, IoU: 0.9564003777854665 |:  38%|███▊      | 10/26 [00:26<00:38,  2.40s/it]\u001b[A\n","Training loss: 0.39653334, IoU: 0.9490112969872225 |:  38%|███▊      | 10/26 [00:29<00:38,  2.40s/it]\u001b[A\n","Training loss: 0.39653334, IoU: 0.9490112969872225 |:  42%|████▏     | 11/26 [00:29<00:37,  2.52s/it]\u001b[A\n","Training loss: 0.47650972, IoU: 0.9486943093553368 |:  42%|████▏     | 11/26 [00:31<00:37,  2.52s/it]\u001b[A\n","Training loss: 0.47650972, IoU: 0.9486943093553368 |:  46%|████▌     | 12/26 [00:31<00:36,  2.60s/it]\u001b[A\n","Training loss: 0.44224313, IoU: 0.9533443332100198 |:  46%|████▌     | 12/26 [00:34<00:36,  2.60s/it]\u001b[A\n","Training loss: 0.44224313, IoU: 0.9533443332100198 |:  50%|█████     | 13/26 [00:34<00:34,  2.65s/it]\u001b[A\n","Training loss: 0.43888107, IoU: 0.9515402834636136 |:  50%|█████     | 13/26 [00:37<00:34,  2.65s/it]\u001b[A\n","Training loss: 0.43888107, IoU: 0.9515402834636136 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.48924083, IoU: 0.9444219992924071 |:  54%|█████▍    | 14/26 [00:40<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.48924083, IoU: 0.9444219992924071 |:  58%|█████▊    | 15/26 [00:40<00:29,  2.72s/it]\u001b[A\n","Training loss: 0.45430973, IoU: 0.9534653741508673 |:  58%|█████▊    | 15/26 [00:43<00:29,  2.72s/it]\u001b[A\n","Training loss: 0.45430973, IoU: 0.9534653741508673 |:  62%|██████▏   | 16/26 [00:43<00:27,  2.74s/it]\u001b[A\n","Training loss: 0.4403147, IoU: 0.9542499742751176 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.74s/it] \u001b[A\n","Training loss: 0.4403147, IoU: 0.9542499742751176 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.48380166, IoU: 0.9418813873303729 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.48380166, IoU: 0.9418813873303729 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.44866538, IoU: 0.9405017886469895 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.44866538, IoU: 0.9405017886469895 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.4086896, IoU: 0.9549947095036553 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.78s/it] \u001b[A\n","Training loss: 0.4086896, IoU: 0.9549947095036553 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.44477618, IoU: 0.9502904313473718 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.44477618, IoU: 0.9502904313473718 |:  81%|████████  | 21/26 [00:57<00:14,  2.80s/it]\u001b[A\n","Training loss: 0.48765516, IoU: 0.9471828704972519 |:  81%|████████  | 21/26 [00:59<00:14,  2.80s/it]\u001b[A\n","Training loss: 0.48765516, IoU: 0.9471828704972519 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.4271201, IoU: 0.9532384470307721 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.81s/it] \u001b[A\n","Training loss: 0.4271201, IoU: 0.9532384470307721 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.4816885, IoU: 0.9389326989264193 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.4816885, IoU: 0.9389326989264193 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.45803568, IoU: 0.945152670475509 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.45803568, IoU: 0.945152670475509 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.82s/it]\u001b[A\n","Training loss: 0.47621685, IoU: 0.9444532167494004 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.82s/it]\u001b[A\n","Training loss: 0.47621685, IoU: 0.9444532167494004 |: 100%|██████████| 26/26 [01:11<00:00,  2.74s/it]\n","Epoch Loop:  43%|████▎     | 64/150 [1:36:53<1:53:14, 79.00s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8256325013881294\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45182702, IoU: 0.9526213955180148 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45182702, IoU: 0.9526213955180148 |:   4%|▍         | 1/26 [00:02<01:11,  2.85s/it]\u001b[A\n","Training loss: 0.44171798, IoU: 0.9407991881552767 |:   4%|▍         | 1/26 [00:05<01:11,  2.85s/it]\u001b[A\n","Training loss: 0.44171798, IoU: 0.9407991881552767 |:   8%|▊         | 2/26 [00:05<01:08,  2.85s/it]\u001b[A\n","Training loss: 0.40559226, IoU: 0.950631353222881 |:   8%|▊         | 2/26 [00:08<01:08,  2.85s/it] \u001b[A\n","Training loss: 0.40559226, IoU: 0.950631353222881 |:  12%|█▏        | 3/26 [00:08<01:05,  2.84s/it]\u001b[A\n","Training loss: 0.40684503, IoU: 0.9425703882369312 |:  12%|█▏        | 3/26 [00:11<01:05,  2.84s/it]\u001b[A\n","Training loss: 0.40684503, IoU: 0.9425703882369312 |:  15%|█▌        | 4/26 [00:11<01:02,  2.84s/it]\u001b[A\n","Training loss: 0.434744, IoU: 0.9435550476336816 |:  15%|█▌        | 4/26 [00:14<01:02,  2.84s/it]  \u001b[A\n","Training loss: 0.434744, IoU: 0.9435550476336816 |:  19%|█▉        | 5/26 [00:14<00:59,  2.85s/it]\u001b[A\n","Training loss: 0.44164336, IoU: 0.9451697637856787 |:  19%|█▉        | 5/26 [00:17<00:59,  2.85s/it]\u001b[A\n","Training loss: 0.44164336, IoU: 0.9451697637856787 |:  23%|██▎       | 6/26 [00:17<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.47109365, IoU: 0.9477824844519563 |:  23%|██▎       | 6/26 [00:19<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.47109365, IoU: 0.9477824844519563 |:  27%|██▋       | 7/26 [00:19<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.43909848, IoU: 0.9519484725270771 |:  27%|██▋       | 7/26 [00:22<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.43909848, IoU: 0.9519484725270771 |:  31%|███       | 8/26 [00:22<00:51,  2.85s/it]\u001b[A\n","Training loss: 0.41989008, IoU: 0.9478716531476563 |:  31%|███       | 8/26 [00:25<00:51,  2.85s/it]\u001b[A\n","Training loss: 0.41989008, IoU: 0.9478716531476563 |:  35%|███▍      | 9/26 [00:25<00:48,  2.86s/it]\u001b[A\n","Training loss: 0.5179704, IoU: 0.9293505412156536 |:  35%|███▍      | 9/26 [00:26<00:48,  2.86s/it] \u001b[A\n","Training loss: 0.5179704, IoU: 0.9293505412156536 |:  38%|███▊      | 10/26 [00:26<00:36,  2.27s/it]\u001b[A\n","Training loss: 0.47884035, IoU: 0.9528834000171065 |:  38%|███▊      | 10/26 [00:29<00:36,  2.27s/it]\u001b[A\n","Training loss: 0.47884035, IoU: 0.9528834000171065 |:  42%|████▏     | 11/26 [00:29<00:36,  2.44s/it]\u001b[A\n","Training loss: 0.50784683, IoU: 0.9556568559730324 |:  42%|████▏     | 11/26 [00:32<00:36,  2.44s/it]\u001b[A\n","Training loss: 0.50784683, IoU: 0.9556568559730324 |:  46%|████▌     | 12/26 [00:32<00:35,  2.56s/it]\u001b[A\n","Training loss: 0.40045723, IoU: 0.9599418102085134 |:  46%|████▌     | 12/26 [00:35<00:35,  2.56s/it]\u001b[A\n","Training loss: 0.40045723, IoU: 0.9599418102085134 |:  50%|█████     | 13/26 [00:35<00:34,  2.64s/it]\u001b[A\n","Training loss: 0.5192716, IoU: 0.9586801251401924 |:  50%|█████     | 13/26 [00:37<00:34,  2.64s/it] \u001b[A\n","Training loss: 0.5192716, IoU: 0.9586801251401924 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.69s/it]\u001b[A\n","Training loss: 0.4741937, IoU: 0.9454490618614945 |:  54%|█████▍    | 14/26 [00:40<00:32,  2.69s/it]\u001b[A\n","Training loss: 0.4741937, IoU: 0.9454490618614945 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.73s/it]\u001b[A\n","Training loss: 0.43080223, IoU: 0.9588921851737346 |:  58%|█████▊    | 15/26 [00:43<00:30,  2.73s/it]\u001b[A\n","Training loss: 0.43080223, IoU: 0.9588921851737346 |:  62%|██████▏   | 16/26 [00:43<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.48914838, IoU: 0.9533417214973934 |:  62%|██████▏   | 16/26 [00:46<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.48914838, IoU: 0.9533417214973934 |:  65%|██████▌   | 17/26 [00:46<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.44736046, IoU: 0.9547119421980379 |:  65%|██████▌   | 17/26 [00:49<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.44736046, IoU: 0.9547119421980379 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.83s/it]\u001b[A\n","Training loss: 0.4762051, IoU: 0.9468339416476235 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.83s/it] \u001b[A\n","Training loss: 0.4762051, IoU: 0.9468339416476235 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.84s/it]\u001b[A\n","Training loss: 0.47975427, IoU: 0.9448794800753162 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.84s/it]\u001b[A\n","Training loss: 0.47975427, IoU: 0.9448794800753162 |:  77%|███████▋  | 20/26 [00:55<00:17,  2.86s/it]\u001b[A\n","Training loss: 0.43041426, IoU: 0.9569605157058543 |:  77%|███████▋  | 20/26 [00:57<00:17,  2.86s/it]\u001b[A\n","Training loss: 0.43041426, IoU: 0.9569605157058543 |:  81%|████████  | 21/26 [00:57<00:14,  2.86s/it]\u001b[A\n","Training loss: 0.44327506, IoU: 0.951411176482635 |:  81%|████████  | 21/26 [01:00<00:14,  2.86s/it] \u001b[A\n","Training loss: 0.44327506, IoU: 0.951411176482635 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.86s/it]\u001b[A\n","Training loss: 0.46053123, IoU: 0.9503033541193592 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.86s/it]\u001b[A\n","Training loss: 0.46053123, IoU: 0.9503033541193592 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.86s/it]\u001b[A\n","Training loss: 0.46259016, IoU: 0.9551142388446876 |:  88%|████████▊ | 23/26 [01:06<00:08,  2.86s/it]\u001b[A\n","Training loss: 0.46259016, IoU: 0.9551142388446876 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.86s/it]\u001b[A\n","Training loss: 0.4627275, IoU: 0.9465342743990514 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.86s/it] \u001b[A\n","Training loss: 0.4627275, IoU: 0.9465342743990514 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.87s/it]\u001b[A\n","Training loss: 0.46966588, IoU: 0.9422739666862053 |:  96%|█████████▌| 25/26 [01:12<00:02,  2.87s/it]\u001b[A\n","Training loss: 0.46966588, IoU: 0.9422739666862053 |: 100%|██████████| 26/26 [01:12<00:00,  2.78s/it]\n","Epoch Loop:  43%|████▎     | 65/150 [1:38:13<1:52:32, 79.44s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8256325013881294\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44910088, IoU: 0.9524094712565957 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44910088, IoU: 0.9524094712565957 |:   4%|▍         | 1/26 [00:02<01:11,  2.87s/it]\u001b[A\n","Training loss: 0.4165848, IoU: 0.9473868068679883 |:   4%|▍         | 1/26 [00:05<01:11,  2.87s/it] \u001b[A\n","Training loss: 0.4165848, IoU: 0.9473868068679883 |:   8%|▊         | 2/26 [00:05<01:08,  2.85s/it]\u001b[A\n","Training loss: 0.5008591, IoU: 0.9463499727664836 |:   8%|▊         | 2/26 [00:08<01:08,  2.85s/it]\u001b[A\n","Training loss: 0.5008591, IoU: 0.9463499727664836 |:  12%|█▏        | 3/26 [00:08<01:05,  2.84s/it]\u001b[A\n","Training loss: 0.51171476, IoU: 0.957615091215517 |:  12%|█▏        | 3/26 [00:11<01:05,  2.84s/it]\u001b[A\n","Training loss: 0.51171476, IoU: 0.957615091215517 |:  15%|█▌        | 4/26 [00:11<01:02,  2.84s/it]\u001b[A\n","Training loss: 0.43788773, IoU: 0.9453938293655169 |:  15%|█▌        | 4/26 [00:14<01:02,  2.84s/it]\u001b[A\n","Training loss: 0.43788773, IoU: 0.9453938293655169 |:  19%|█▉        | 5/26 [00:14<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.42152372, IoU: 0.9456721803044893 |:  19%|█▉        | 5/26 [00:17<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.42152372, IoU: 0.9456721803044893 |:  23%|██▎       | 6/26 [00:17<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.42482853, IoU: 0.9473349997531784 |:  23%|██▎       | 6/26 [00:19<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.42482853, IoU: 0.9473349997531784 |:  27%|██▋       | 7/26 [00:19<00:54,  2.85s/it]\u001b[A\n","Training loss: 0.46123612, IoU: 0.9463748762461722 |:  27%|██▋       | 7/26 [00:22<00:54,  2.85s/it]\u001b[A\n","Training loss: 0.46123612, IoU: 0.9463748762461722 |:  31%|███       | 8/26 [00:22<00:51,  2.85s/it]\u001b[A\n","Training loss: 0.39889586, IoU: 0.9336268574573473 |:  31%|███       | 8/26 [00:25<00:51,  2.85s/it]\u001b[A\n","Training loss: 0.39889586, IoU: 0.9336268574573473 |:  35%|███▍      | 9/26 [00:25<00:48,  2.85s/it]\u001b[A\n","Training loss: 0.4477188, IoU: 0.9495172830844749 |:  35%|███▍      | 9/26 [00:28<00:48,  2.85s/it] \u001b[A\n","Training loss: 0.4477188, IoU: 0.9495172830844749 |:  38%|███▊      | 10/26 [00:28<00:45,  2.84s/it]\u001b[A\n","Training loss: 0.53435767, IoU: 0.945005961661928 |:  38%|███▊      | 10/26 [00:29<00:45,  2.84s/it]\u001b[A\n","Training loss: 0.53435767, IoU: 0.945005961661928 |:  42%|████▏     | 11/26 [00:29<00:34,  2.27s/it]\u001b[A\n","Training loss: 0.44180027, IoU: 0.9598098755171046 |:  42%|████▏     | 11/26 [00:32<00:34,  2.27s/it]\u001b[A\n","Training loss: 0.44180027, IoU: 0.9598098755171046 |:  46%|████▌     | 12/26 [00:32<00:34,  2.44s/it]\u001b[A\n","Training loss: 0.47473347, IoU: 0.9561730827172226 |:  46%|████▌     | 12/26 [00:35<00:34,  2.44s/it]\u001b[A\n","Training loss: 0.47473347, IoU: 0.9561730827172226 |:  50%|█████     | 13/26 [00:35<00:33,  2.56s/it]\u001b[A\n","Training loss: 0.466649, IoU: 0.9325952810266198 |:  50%|█████     | 13/26 [00:37<00:33,  2.56s/it]  \u001b[A\n","Training loss: 0.466649, IoU: 0.9325952810266198 |:  54%|█████▍    | 14/26 [00:38<00:32,  2.67s/it]\u001b[A\n","Training loss: 0.44633144, IoU: 0.9548116521595568 |:  54%|█████▍    | 14/26 [00:40<00:32,  2.67s/it]\u001b[A\n","Training loss: 0.44633144, IoU: 0.9548116521595568 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.74s/it]\u001b[A\n","Training loss: 0.49386305, IoU: 0.9470057580237515 |:  58%|█████▊    | 15/26 [00:43<00:30,  2.74s/it]\u001b[A\n","Training loss: 0.49386305, IoU: 0.9470057580237515 |:  62%|██████▏   | 16/26 [00:43<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.49444777, IoU: 0.9519561884101878 |:  62%|██████▏   | 16/26 [00:46<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.49444777, IoU: 0.9519561884101878 |:  65%|██████▌   | 17/26 [00:46<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.44154263, IoU: 0.9536199594646985 |:  65%|██████▌   | 17/26 [00:49<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.44154263, IoU: 0.9536199594646985 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.83s/it]\u001b[A\n","Training loss: 0.4456123, IoU: 0.9360985413899695 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.83s/it] \u001b[A\n","Training loss: 0.4456123, IoU: 0.9360985413899695 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.84s/it]\u001b[A\n","Training loss: 0.48187107, IoU: 0.9435843039661655 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.84s/it]\u001b[A\n","Training loss: 0.48187107, IoU: 0.9435843039661655 |:  77%|███████▋  | 20/26 [00:55<00:17,  2.85s/it]\u001b[A\n","Training loss: 0.48494974, IoU: 0.9423367254692556 |:  77%|███████▋  | 20/26 [00:58<00:17,  2.85s/it]\u001b[A\n","Training loss: 0.48494974, IoU: 0.9423367254692556 |:  81%|████████  | 21/26 [00:58<00:14,  2.86s/it]\u001b[A\n","Training loss: 0.42664593, IoU: 0.9484421826981492 |:  81%|████████  | 21/26 [01:01<00:14,  2.86s/it]\u001b[A\n","Training loss: 0.42664593, IoU: 0.9484421826981492 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.86s/it]\u001b[A\n","Training loss: 0.41123772, IoU: 0.9497145131415801 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.86s/it]\u001b[A\n","Training loss: 0.41123772, IoU: 0.9497145131415801 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.85s/it]\u001b[A\n","Training loss: 0.46661672, IoU: 0.9453140173488179 |:  88%|████████▊ | 23/26 [01:06<00:08,  2.85s/it]\u001b[A\n","Training loss: 0.46661672, IoU: 0.9453140173488179 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.85s/it]\u001b[A\n","Training loss: 0.48766094, IoU: 0.9503056963912914 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.85s/it]\u001b[A\n","Training loss: 0.48766094, IoU: 0.9503056963912914 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.85s/it]\u001b[A\n","Training loss: 0.43707505, IoU: 0.9489435046281519 |:  96%|█████████▌| 25/26 [01:12<00:02,  2.85s/it]\u001b[A\n","Training loss: 0.43707505, IoU: 0.9489435046281519 |: 100%|██████████| 26/26 [01:12<00:00,  2.78s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.8256325013881294 to 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  44%|████▍     | 66/150 [1:39:36<1:52:38, 80.46s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.3994323, IoU: 0.9512575925582966 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.3994323, IoU: 0.9512575925582966 |:   4%|▍         | 1/26 [00:02<01:13,  2.92s/it]\u001b[A\n","Training loss: 0.4158936, IoU: 0.9464204905421305 |:   4%|▍         | 1/26 [00:05<01:13,  2.92s/it]\u001b[A\n","Training loss: 0.4158936, IoU: 0.9464204905421305 |:   8%|▊         | 2/26 [00:05<01:08,  2.87s/it]\u001b[A\n","Training loss: 0.4574992, IoU: 0.9444392972387742 |:   8%|▊         | 2/26 [00:08<01:08,  2.87s/it]\u001b[A\n","Training loss: 0.4574992, IoU: 0.9444392972387742 |:  12%|█▏        | 3/26 [00:08<01:05,  2.86s/it]\u001b[A\n","Training loss: 0.46235734, IoU: 0.9504385388811373 |:  12%|█▏        | 3/26 [00:11<01:05,  2.86s/it]\u001b[A\n","Training loss: 0.46235734, IoU: 0.9504385388811373 |:  15%|█▌        | 4/26 [00:11<01:03,  2.88s/it]\u001b[A\n","Training loss: 0.54650867, IoU: 0.9456553129270727 |:  15%|█▌        | 4/26 [00:14<01:03,  2.88s/it]\u001b[A\n","Training loss: 0.54650867, IoU: 0.9456553129270727 |:  19%|█▉        | 5/26 [00:14<01:00,  2.87s/it]\u001b[A\n","Training loss: 0.43413085, IoU: 0.9425706472196901 |:  19%|█▉        | 5/26 [00:17<01:00,  2.87s/it]\u001b[A\n","Training loss: 0.43413085, IoU: 0.9425706472196901 |:  23%|██▎       | 6/26 [00:17<00:57,  2.87s/it]\u001b[A\n","Training loss: 0.47980243, IoU: 0.9480944673337257 |:  23%|██▎       | 6/26 [00:20<00:57,  2.87s/it]\u001b[A\n","Training loss: 0.47980243, IoU: 0.9480944673337257 |:  27%|██▋       | 7/26 [00:20<00:54,  2.88s/it]\u001b[A\n","Training loss: 0.4260832, IoU: 0.9496347399635592 |:  27%|██▋       | 7/26 [00:22<00:54,  2.88s/it] \u001b[A\n","Training loss: 0.4260832, IoU: 0.9496347399635592 |:  31%|███       | 8/26 [00:22<00:51,  2.87s/it]\u001b[A\n","Training loss: 0.42639574, IoU: 0.9529464425485284 |:  31%|███       | 8/26 [00:25<00:51,  2.87s/it]\u001b[A\n","Training loss: 0.42639574, IoU: 0.9529464425485284 |:  35%|███▍      | 9/26 [00:25<00:48,  2.85s/it]\u001b[A\n","Training loss: 0.45654893, IoU: 0.9589245359908124 |:  35%|███▍      | 9/26 [00:28<00:48,  2.85s/it]\u001b[A\n","Training loss: 0.45654893, IoU: 0.9589245359908124 |:  38%|███▊      | 10/26 [00:28<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.43438298, IoU: 0.9550944154753881 |:  38%|███▊      | 10/26 [00:31<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.43438298, IoU: 0.9550944154753881 |:  42%|████▏     | 11/26 [00:31<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.5038223, IoU: 0.9545925855028076 |:  42%|████▏     | 11/26 [00:32<00:42,  2.82s/it] \u001b[A\n","Training loss: 0.5038223, IoU: 0.9545925855028076 |:  46%|████▌     | 12/26 [00:32<00:31,  2.25s/it]\u001b[A\n","Training loss: 0.42297837, IoU: 0.9425528407189926 |:  46%|████▌     | 12/26 [00:35<00:31,  2.25s/it]\u001b[A\n","Training loss: 0.42297837, IoU: 0.9425528407189926 |:  50%|█████     | 13/26 [00:35<00:31,  2.42s/it]\u001b[A\n","Training loss: 0.45130956, IoU: 0.9549571092550967 |:  50%|█████     | 13/26 [00:37<00:31,  2.42s/it]\u001b[A\n","Training loss: 0.45130956, IoU: 0.9549571092550967 |:  54%|█████▍    | 14/26 [00:37<00:30,  2.54s/it]\u001b[A\n","Training loss: 0.4481891, IoU: 0.9571619067548525 |:  54%|█████▍    | 14/26 [00:40<00:30,  2.54s/it] \u001b[A\n","Training loss: 0.4481891, IoU: 0.9571619067548525 |:  58%|█████▊    | 15/26 [00:40<00:28,  2.62s/it]\u001b[A\n","Training loss: 0.4323499, IoU: 0.9544427476530822 |:  58%|█████▊    | 15/26 [00:43<00:28,  2.62s/it]\u001b[A\n","Training loss: 0.4323499, IoU: 0.9544427476530822 |:  62%|██████▏   | 16/26 [00:43<00:26,  2.66s/it]\u001b[A\n","Training loss: 0.40573537, IoU: 0.9482887206753795 |:  62%|██████▏   | 16/26 [00:46<00:26,  2.66s/it]\u001b[A\n","Training loss: 0.40573537, IoU: 0.9482887206753795 |:  65%|██████▌   | 17/26 [00:46<00:24,  2.70s/it]\u001b[A\n","Training loss: 0.5072586, IoU: 0.9495789199513804 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.70s/it] \u001b[A\n","Training loss: 0.5072586, IoU: 0.9495789199513804 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.72s/it]\u001b[A\n","Training loss: 0.44568512, IoU: 0.9604758634503677 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.72s/it]\u001b[A\n","Training loss: 0.44568512, IoU: 0.9604758634503677 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.74s/it]\u001b[A\n","Training loss: 0.4847185, IoU: 0.9513075800389921 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.74s/it] \u001b[A\n","Training loss: 0.4847185, IoU: 0.9513075800389921 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.74s/it]\u001b[A\n","Training loss: 0.43468198, IoU: 0.9423956353828236 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.74s/it]\u001b[A\n","Training loss: 0.43468198, IoU: 0.9423956353828236 |:  81%|████████  | 21/26 [00:57<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.46335965, IoU: 0.9513761038806428 |:  81%|████████  | 21/26 [01:00<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.46335965, IoU: 0.9513761038806428 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.47934556, IoU: 0.9542530361410525 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.47934556, IoU: 0.9542530361410525 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.51307523, IoU: 0.9520133776261447 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.51307523, IoU: 0.9520133776261447 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.4200036, IoU: 0.9505820939019465 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.79s/it] \u001b[A\n","Training loss: 0.4200036, IoU: 0.9505820939019465 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.5001193, IoU: 0.9573373084220905 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.5001193, IoU: 0.9573373084220905 |: 100%|██████████| 26/26 [01:11<00:00,  2.75s/it]\n","Epoch Loop:  45%|████▍     | 67/150 [1:40:55<1:50:57, 80.21s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.49710387, IoU: 0.9537953718662467 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.49710387, IoU: 0.9537953718662467 |:   4%|▍         | 1/26 [00:02<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.46076867, IoU: 0.9521428034502847 |:   4%|▍         | 1/26 [00:05<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.46076867, IoU: 0.9521428034502847 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.4735492, IoU: 0.9450069348127601 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it] \u001b[A\n","Training loss: 0.4735492, IoU: 0.9450069348127601 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.48018193, IoU: 0.9510754106555215 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.48018193, IoU: 0.9510754106555215 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.4238951, IoU: 0.9468136222910216 |:  15%|█▌        | 4/26 [00:14<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.4238951, IoU: 0.9468136222910216 |:  19%|█▉        | 5/26 [00:14<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.46814907, IoU: 0.9405994190652232 |:  19%|█▉        | 5/26 [00:16<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.46814907, IoU: 0.9405994190652232 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.45120895, IoU: 0.9590597670533778 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.45120895, IoU: 0.9590597670533778 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.49874038, IoU: 0.9569005516316956 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.49874038, IoU: 0.9569005516316956 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.44948238, IoU: 0.9444381169324222 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.44948238, IoU: 0.9444381169324222 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.4250811, IoU: 0.9509275188188926 |:  35%|███▍      | 9/26 [00:28<00:47,  2.80s/it] \u001b[A\n","Training loss: 0.4250811, IoU: 0.9509275188188926 |:  38%|███▊      | 10/26 [00:28<00:44,  2.81s/it]\u001b[A\n","Training loss: 0.44236806, IoU: 0.9528503221887764 |:  38%|███▊      | 10/26 [00:30<00:44,  2.81s/it]\u001b[A\n","Training loss: 0.44236806, IoU: 0.9528503221887764 |:  42%|████▏     | 11/26 [00:30<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.4779775, IoU: 0.9481244436431654 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it] \u001b[A\n","Training loss: 0.4779775, IoU: 0.9481244436431654 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.50134397, IoU: 0.9535385643461535 |:  46%|████▌     | 12/26 [00:34<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.50134397, IoU: 0.9535385643461535 |:  50%|█████     | 13/26 [00:34<00:29,  2.24s/it]\u001b[A\n","Training loss: 0.42409986, IoU: 0.9465259971853252 |:  50%|█████     | 13/26 [00:37<00:29,  2.24s/it]\u001b[A\n","Training loss: 0.42409986, IoU: 0.9465259971853252 |:  54%|█████▍    | 14/26 [00:37<00:28,  2.41s/it]\u001b[A\n","Training loss: 0.471122, IoU: 0.9568345971041615 |:  54%|█████▍    | 14/26 [00:40<00:28,  2.41s/it]  \u001b[A\n","Training loss: 0.471122, IoU: 0.9568345971041615 |:  58%|█████▊    | 15/26 [00:40<00:27,  2.52s/it]\u001b[A\n","Training loss: 0.5348705, IoU: 0.959545452620972 |:  58%|█████▊    | 15/26 [00:42<00:27,  2.52s/it]\u001b[A\n","Training loss: 0.5348705, IoU: 0.959545452620972 |:  62%|██████▏   | 16/26 [00:42<00:25,  2.59s/it]\u001b[A\n","Training loss: 0.4527246, IoU: 0.9490702048841584 |:  62%|██████▏   | 16/26 [00:45<00:25,  2.59s/it]\u001b[A\n","Training loss: 0.4527246, IoU: 0.9490702048841584 |:  65%|██████▌   | 17/26 [00:45<00:23,  2.65s/it]\u001b[A\n","Training loss: 0.45854005, IoU: 0.9462594412433573 |:  65%|██████▌   | 17/26 [00:48<00:23,  2.65s/it]\u001b[A\n","Training loss: 0.45854005, IoU: 0.9462594412433573 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.44754893, IoU: 0.9445935231381175 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.70s/it]\u001b[A\n","Training loss: 0.44754893, IoU: 0.9445935231381175 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.73s/it]\u001b[A\n","Training loss: 0.42096108, IoU: 0.9614137168822985 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.73s/it]\u001b[A\n","Training loss: 0.42096108, IoU: 0.9614137168822985 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.45083648, IoU: 0.9485281192280747 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.45083648, IoU: 0.9485281192280747 |:  81%|████████  | 21/26 [00:56<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.4268912, IoU: 0.9446439195100612 |:  81%|████████  | 21/26 [00:59<00:13,  2.76s/it] \u001b[A\n","Training loss: 0.4268912, IoU: 0.9446439195100612 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.4728318, IoU: 0.942873316734549 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it] \u001b[A\n","Training loss: 0.4728318, IoU: 0.942873316734549 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.48583153, IoU: 0.9554168824095057 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.48583153, IoU: 0.9554168824095057 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.51832914, IoU: 0.952535830892742 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.78s/it] \u001b[A\n","Training loss: 0.51832914, IoU: 0.952535830892742 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.40310028, IoU: 0.9496513411443228 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.40310028, IoU: 0.9496513411443228 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  45%|████▌     | 68/150 [1:42:14<1:49:03, 79.80s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.42237663, IoU: 0.9556917281527628 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.42237663, IoU: 0.9556917281527628 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.46789658, IoU: 0.9530208415081225 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.46789658, IoU: 0.9530208415081225 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.45902696, IoU: 0.9514058472193281 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.45902696, IoU: 0.9514058472193281 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.47157764, IoU: 0.9524531804740806 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.47157764, IoU: 0.9524531804740806 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.4772598, IoU: 0.9550980922462396 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it] \u001b[A\n","Training loss: 0.4772598, IoU: 0.9550980922462396 |:  19%|█▉        | 5/26 [00:13<00:58,  2.76s/it]\u001b[A\n","Training loss: 0.47471523, IoU: 0.9475111802694326 |:  19%|█▉        | 5/26 [00:16<00:58,  2.76s/it]\u001b[A\n","Training loss: 0.47471523, IoU: 0.9475111802694326 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43960226, IoU: 0.9482171469568337 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43960226, IoU: 0.9482171469568337 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.46715993, IoU: 0.9601176728954145 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.46715993, IoU: 0.9601176728954145 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.50771856, IoU: 0.949068285403138 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it] \u001b[A\n","Training loss: 0.50771856, IoU: 0.949068285403138 |:  35%|███▍      | 9/26 [00:24<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.3805511, IoU: 0.9446634928488129 |:  35%|███▍      | 9/26 [00:27<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.3805511, IoU: 0.9446634928488129 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.43396673, IoU: 0.9501122414287816 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.43396673, IoU: 0.9501122414287816 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.4399141, IoU: 0.9504078865730634 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it] \u001b[A\n","Training loss: 0.4399141, IoU: 0.9504078865730634 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.4236347, IoU: 0.9561993805153464 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.4236347, IoU: 0.9561993805153464 |:  50%|█████     | 13/26 [00:36<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.44648638, IoU: 0.9481422014628845 |:  50%|█████     | 13/26 [00:36<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.44648638, IoU: 0.9481422014628845 |:  54%|█████▍    | 14/26 [00:36<00:26,  2.22s/it]\u001b[A\n","Training loss: 0.4457661, IoU: 0.9476257232431882 |:  54%|█████▍    | 14/26 [00:39<00:26,  2.22s/it] \u001b[A\n","Training loss: 0.4457661, IoU: 0.9476257232431882 |:  58%|█████▊    | 15/26 [00:39<00:26,  2.39s/it]\u001b[A\n","Training loss: 0.46645337, IoU: 0.9414388355373458 |:  58%|█████▊    | 15/26 [00:42<00:26,  2.39s/it]\u001b[A\n","Training loss: 0.46645337, IoU: 0.9414388355373458 |:  62%|██████▏   | 16/26 [00:42<00:25,  2.51s/it]\u001b[A\n","Training loss: 0.47759032, IoU: 0.9415245007454226 |:  62%|██████▏   | 16/26 [00:45<00:25,  2.51s/it]\u001b[A\n","Training loss: 0.47759032, IoU: 0.9415245007454226 |:  65%|██████▌   | 17/26 [00:45<00:23,  2.58s/it]\u001b[A\n","Training loss: 0.3994878, IoU: 0.9437506615759169 |:  65%|██████▌   | 17/26 [00:48<00:23,  2.58s/it] \u001b[A\n","Training loss: 0.3994878, IoU: 0.9437506615759169 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.64s/it]\u001b[A\n","Training loss: 0.4470402, IoU: 0.9478824240151658 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.64s/it]\u001b[A\n","Training loss: 0.4470402, IoU: 0.9478824240151658 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.48646992, IoU: 0.9618766825391789 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.48646992, IoU: 0.9618766825391789 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.48298907, IoU: 0.9543145224323902 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.48298907, IoU: 0.9543145224323902 |:  81%|████████  | 21/26 [00:56<00:13,  2.72s/it]\u001b[A\n","Training loss: 0.48933902, IoU: 0.9553638566756856 |:  81%|████████  | 21/26 [00:59<00:13,  2.72s/it]\u001b[A\n","Training loss: 0.48933902, IoU: 0.9553638566756856 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.73s/it]\u001b[A\n","Training loss: 0.41148642, IoU: 0.9507517760298346 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.73s/it]\u001b[A\n","Training loss: 0.41148642, IoU: 0.9507517760298346 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.44289207, IoU: 0.9521557277235586 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.44289207, IoU: 0.9521557277235586 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.45805675, IoU: 0.9393683213007643 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.45805675, IoU: 0.9393683213007643 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.46482024, IoU: 0.951550171960348 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it] \u001b[A\n","Training loss: 0.46482024, IoU: 0.951550171960348 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  46%|████▌     | 69/150 [1:43:33<1:47:07, 79.35s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47273666, IoU: 0.9495276157018135 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47273666, IoU: 0.9495276157018135 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.4643728, IoU: 0.9588986009350667 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it] \u001b[A\n","Training loss: 0.4643728, IoU: 0.9588986009350667 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.4197053, IoU: 0.9507208227480028 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.4197053, IoU: 0.9507208227480028 |:  12%|█▏        | 3/26 [00:08<01:04,  2.83s/it]\u001b[A\n","Training loss: 0.4239597, IoU: 0.9556029458372054 |:  12%|█▏        | 3/26 [00:11<01:04,  2.83s/it]\u001b[A\n","Training loss: 0.4239597, IoU: 0.9556029458372054 |:  15%|█▌        | 4/26 [00:11<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.41363662, IoU: 0.9397368056252658 |:  15%|█▌        | 4/26 [00:14<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.41363662, IoU: 0.9397368056252658 |:  19%|█▉        | 5/26 [00:14<00:59,  2.83s/it]\u001b[A\n","Training loss: 0.4743133, IoU: 0.9570277177118144 |:  19%|█▉        | 5/26 [00:16<00:59,  2.83s/it] \u001b[A\n","Training loss: 0.4743133, IoU: 0.9570277177118144 |:  23%|██▎       | 6/26 [00:16<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.4319718, IoU: 0.9528538768383703 |:  23%|██▎       | 6/26 [00:19<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.4319718, IoU: 0.9528538768383703 |:  27%|██▋       | 7/26 [00:19<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.41491225, IoU: 0.9587931740614335 |:  27%|██▋       | 7/26 [00:22<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.41491225, IoU: 0.9587931740614335 |:  31%|███       | 8/26 [00:22<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.42975596, IoU: 0.9546555594233517 |:  31%|███       | 8/26 [00:25<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.42975596, IoU: 0.9546555594233517 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.49430847, IoU: 0.9439752761627196 |:  35%|███▍      | 9/26 [00:28<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.49430847, IoU: 0.9439752761627196 |:  38%|███▊      | 10/26 [00:28<00:44,  2.81s/it]\u001b[A\n","Training loss: 0.4939754, IoU: 0.9488931254801296 |:  38%|███▊      | 10/26 [00:30<00:44,  2.81s/it] \u001b[A\n","Training loss: 0.4939754, IoU: 0.9488931254801296 |:  42%|████▏     | 11/26 [00:30<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.48237965, IoU: 0.9523157557964469 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.48237965, IoU: 0.9523157557964469 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.44580162, IoU: 0.9559714096427139 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.44580162, IoU: 0.9559714096427139 |:  50%|█████     | 13/26 [00:36<00:36,  2.81s/it]\u001b[A\n","Training loss: 0.5369612, IoU: 0.9494515121975297 |:  50%|█████     | 13/26 [00:39<00:36,  2.81s/it] \u001b[A\n","Training loss: 0.5369612, IoU: 0.9494515121975297 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.37656146, IoU: 0.9572585851055124 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.37656146, IoU: 0.9572585851055124 |:  58%|█████▊    | 15/26 [00:40<00:24,  2.25s/it]\u001b[A\n","Training loss: 0.4294045, IoU: 0.9494527544230735 |:  58%|█████▊    | 15/26 [00:43<00:24,  2.25s/it] \u001b[A\n","Training loss: 0.4294045, IoU: 0.9494527544230735 |:  62%|██████▏   | 16/26 [00:43<00:24,  2.42s/it]\u001b[A\n","Training loss: 0.44165418, IoU: 0.9570262103255396 |:  62%|██████▏   | 16/26 [00:45<00:24,  2.42s/it]\u001b[A\n","Training loss: 0.44165418, IoU: 0.9570262103255396 |:  65%|██████▌   | 17/26 [00:45<00:22,  2.53s/it]\u001b[A\n","Training loss: 0.4468791, IoU: 0.9483532899726506 |:  65%|██████▌   | 17/26 [00:48<00:22,  2.53s/it] \u001b[A\n","Training loss: 0.4468791, IoU: 0.9483532899726506 |:  69%|██████▉   | 18/26 [00:48<00:20,  2.62s/it]\u001b[A\n","Training loss: 0.4423349, IoU: 0.956292345327663 |:  69%|██████▉   | 18/26 [00:51<00:20,  2.62s/it] \u001b[A\n","Training loss: 0.4423349, IoU: 0.956292345327663 |:  73%|███████▎  | 19/26 [00:51<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.46842015, IoU: 0.944157322279499 |:  73%|███████▎  | 19/26 [00:54<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.46842015, IoU: 0.944157322279499 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.72s/it]\u001b[A\n","Training loss: 0.40277117, IoU: 0.9488026487829466 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.72s/it]\u001b[A\n","Training loss: 0.40277117, IoU: 0.9488026487829466 |:  81%|████████  | 21/26 [00:57<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.43405762, IoU: 0.9476257035067104 |:  81%|████████  | 21/26 [01:00<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.43405762, IoU: 0.9476257035067104 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.46948475, IoU: 0.9552279353133089 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.46948475, IoU: 0.9552279353133089 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4612351, IoU: 0.9539344336704101 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.4612351, IoU: 0.9539344336704101 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.45251873, IoU: 0.9546346542076282 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.45251873, IoU: 0.9546346542076282 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.4462976, IoU: 0.9594488347263606 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.77s/it] \u001b[A\n","Training loss: 0.4462976, IoU: 0.9594488347263606 |: 100%|██████████| 26/26 [01:11<00:00,  2.74s/it]\n","Epoch Loop:  47%|████▋     | 70/150 [1:44:52<1:45:41, 79.26s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48638922, IoU: 0.9516066913377652 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48638922, IoU: 0.9516066913377652 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.39542395, IoU: 0.9470889820485564 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.39542395, IoU: 0.9470889820485564 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.43593952, IoU: 0.9490966524134211 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.43593952, IoU: 0.9490966524134211 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.44990915, IoU: 0.9529245206287237 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.44990915, IoU: 0.9529245206287237 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.4551577, IoU: 0.9580426211288601 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it] \u001b[A\n","Training loss: 0.4551577, IoU: 0.9580426211288601 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.4432307, IoU: 0.9536864166346347 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.4432307, IoU: 0.9536864166346347 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43765578, IoU: 0.9500473445910861 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43765578, IoU: 0.9500473445910861 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.44801462, IoU: 0.9371007382368786 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.44801462, IoU: 0.9371007382368786 |:  31%|███       | 8/26 [00:22<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.49437967, IoU: 0.9457525612217694 |:  31%|███       | 8/26 [00:25<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.49437967, IoU: 0.9457525612217694 |:  35%|███▍      | 9/26 [00:25<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.4667745, IoU: 0.9567523772013729 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it] \u001b[A\n","Training loss: 0.4667745, IoU: 0.9567523772013729 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.45238006, IoU: 0.9414539607228114 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.45238006, IoU: 0.9414539607228114 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.41593382, IoU: 0.9447555040227835 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.41593382, IoU: 0.9447555040227835 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.49024403, IoU: 0.9393090023836267 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.49024403, IoU: 0.9393090023836267 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.41164, IoU: 0.9493039489382848 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it]   \u001b[A\n","Training loss: 0.41164, IoU: 0.9493039489382848 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.4750838, IoU: 0.9451689200394967 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.4750838, IoU: 0.9451689200394967 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.50436884, IoU: 0.9553159628631327 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.50436884, IoU: 0.9553159628631327 |:  62%|██████▏   | 16/26 [00:42<00:22,  2.22s/it]\u001b[A\n","Training loss: 0.38654423, IoU: 0.9518361287634128 |:  62%|██████▏   | 16/26 [00:45<00:22,  2.22s/it]\u001b[A\n","Training loss: 0.38654423, IoU: 0.9518361287634128 |:  65%|██████▌   | 17/26 [00:45<00:21,  2.39s/it]\u001b[A\n","Training loss: 0.42840075, IoU: 0.947999352402539 |:  65%|██████▌   | 17/26 [00:48<00:21,  2.39s/it] \u001b[A\n","Training loss: 0.42840075, IoU: 0.947999352402539 |:  69%|██████▉   | 18/26 [00:48<00:20,  2.50s/it]\u001b[A\n","Training loss: 0.44844985, IoU: 0.9530998228418307 |:  69%|██████▉   | 18/26 [00:50<00:20,  2.50s/it]\u001b[A\n","Training loss: 0.44844985, IoU: 0.9530998228418307 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.58s/it]\u001b[A\n","Training loss: 0.45284745, IoU: 0.9535526408843386 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.58s/it]\u001b[A\n","Training loss: 0.45284745, IoU: 0.9535526408843386 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.64s/it]\u001b[A\n","Training loss: 0.47337043, IoU: 0.958118866610672 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.64s/it] \u001b[A\n","Training loss: 0.47337043, IoU: 0.958118866610672 |:  81%|████████  | 21/26 [00:56<00:13,  2.69s/it]\u001b[A\n","Training loss: 0.4624561, IoU: 0.9384402146596061 |:  81%|████████  | 21/26 [00:59<00:13,  2.69s/it]\u001b[A\n","Training loss: 0.4624561, IoU: 0.9384402146596061 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.72s/it]\u001b[A\n","Training loss: 0.48581553, IoU: 0.9496889229147911 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.72s/it]\u001b[A\n","Training loss: 0.48581553, IoU: 0.9496889229147911 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.75s/it]\u001b[A\n","Training loss: 0.48037088, IoU: 0.948660992362705 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.75s/it] \u001b[A\n","Training loss: 0.48037088, IoU: 0.948660992362705 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.44071674, IoU: 0.9532440463616263 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.44071674, IoU: 0.9532440463616263 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.47704795, IoU: 0.9535242852730667 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.47704795, IoU: 0.9535242852730667 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  47%|████▋     | 71/150 [1:46:10<1:43:59, 78.98s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48026937, IoU: 0.9565378836501882 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48026937, IoU: 0.9565378836501882 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.46190083, IoU: 0.9614217899160288 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.46190083, IoU: 0.9614217899160288 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.41944984, IoU: 0.9480998788997175 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.41944984, IoU: 0.9480998788997175 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.47919905, IoU: 0.9486751430775735 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.47919905, IoU: 0.9486751430775735 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.46173447, IoU: 0.9588828375786367 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.46173447, IoU: 0.9588828375786367 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.47507608, IoU: 0.9443279131061276 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.47507608, IoU: 0.9443279131061276 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.4267086, IoU: 0.928413775871403 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]  \u001b[A\n","Training loss: 0.4267086, IoU: 0.928413775871403 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.4367273, IoU: 0.9451648081049706 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.4367273, IoU: 0.9451648081049706 |:  31%|███       | 8/26 [00:22<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.44103625, IoU: 0.9428644984498712 |:  31%|███       | 8/26 [00:24<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.44103625, IoU: 0.9428644984498712 |:  35%|███▍      | 9/26 [00:25<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.44067425, IoU: 0.9383609000951817 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.44067425, IoU: 0.9383609000951817 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.47954917, IoU: 0.9362449287616676 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.47954917, IoU: 0.9362449287616676 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.50912243, IoU: 0.9378011337889451 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.50912243, IoU: 0.9378011337889451 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.4013933, IoU: 0.9533192728733554 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it] \u001b[A\n","Training loss: 0.4013933, IoU: 0.9533192728733554 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.46174848, IoU: 0.9558668871932433 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.46174848, IoU: 0.9558668871932433 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.44378096, IoU: 0.9501439373073062 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.44378096, IoU: 0.9501439373073062 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.4614513, IoU: 0.9531139717003327 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it] \u001b[A\n","Training loss: 0.4614513, IoU: 0.9531139717003327 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.38036904, IoU: 0.9570480324265819 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.38036904, IoU: 0.9570480324265819 |:  65%|██████▌   | 17/26 [00:45<00:20,  2.23s/it]\u001b[A\n","Training loss: 0.45086938, IoU: 0.9447452582248821 |:  65%|██████▌   | 17/26 [00:48<00:20,  2.23s/it]\u001b[A\n","Training loss: 0.45086938, IoU: 0.9447452582248821 |:  69%|██████▉   | 18/26 [00:48<00:19,  2.39s/it]\u001b[A\n","Training loss: 0.48761296, IoU: 0.954723120241944 |:  69%|██████▉   | 18/26 [00:50<00:19,  2.39s/it] \u001b[A\n","Training loss: 0.48761296, IoU: 0.954723120241944 |:  73%|███████▎  | 19/26 [00:50<00:17,  2.50s/it]\u001b[A\n","Training loss: 0.45789528, IoU: 0.9477326758827155 |:  73%|███████▎  | 19/26 [00:53<00:17,  2.50s/it]\u001b[A\n","Training loss: 0.45789528, IoU: 0.9477326758827155 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.60s/it]\u001b[A\n","Training loss: 0.4405202, IoU: 0.9412509328381968 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.60s/it] \u001b[A\n","Training loss: 0.4405202, IoU: 0.9412509328381968 |:  81%|████████  | 21/26 [00:56<00:13,  2.67s/it]\u001b[A\n","Training loss: 0.4702404, IoU: 0.9498568691002862 |:  81%|████████  | 21/26 [00:59<00:13,  2.67s/it]\u001b[A\n","Training loss: 0.4702404, IoU: 0.9498568691002862 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.45750648, IoU: 0.9428873659251557 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.70s/it]\u001b[A\n","Training loss: 0.45750648, IoU: 0.9428873659251557 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.72s/it]\u001b[A\n","Training loss: 0.4353665, IoU: 0.9487864853625881 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.72s/it] \u001b[A\n","Training loss: 0.4353665, IoU: 0.9487864853625881 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.75s/it]\u001b[A\n","Training loss: 0.4730608, IoU: 0.9481457627366742 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.75s/it]\u001b[A\n","Training loss: 0.4730608, IoU: 0.9481457627366742 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.48082405, IoU: 0.9530332117291457 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.48082405, IoU: 0.9530332117291457 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  48%|████▊     | 72/150 [1:47:28<1:42:27, 78.82s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.42088008, IoU: 0.9551127543551619 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.42088008, IoU: 0.9551127543551619 |:   4%|▍         | 1/26 [00:02<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.51944107, IoU: 0.9538948674092845 |:   4%|▍         | 1/26 [00:05<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.51944107, IoU: 0.9538948674092845 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.49203134, IoU: 0.9494936263629637 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.49203134, IoU: 0.9494936263629637 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.43036112, IoU: 0.947160004624715 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it] \u001b[A\n","Training loss: 0.43036112, IoU: 0.947160004624715 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.45357537, IoU: 0.9490246599982984 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.45357537, IoU: 0.9490246599982984 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.46270177, IoU: 0.9477161300562195 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.46270177, IoU: 0.9477161300562195 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.41541374, IoU: 0.9521402418143983 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.41541374, IoU: 0.9521402418143983 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.44471106, IoU: 0.9482448041884518 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.44471106, IoU: 0.9482448041884518 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.44572812, IoU: 0.9575243414886088 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.44572812, IoU: 0.9575243414886088 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.48425168, IoU: 0.9458672472878773 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.48425168, IoU: 0.9458672472878773 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.41358858, IoU: 0.9573500410458676 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.41358858, IoU: 0.9573500410458676 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.46875226, IoU: 0.9368630685835494 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.46875226, IoU: 0.9368630685835494 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.39091778, IoU: 0.9397124908002582 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.39091778, IoU: 0.9397124908002582 |:  50%|█████     | 13/26 [00:36<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.43790093, IoU: 0.9489255901266126 |:  50%|█████     | 13/26 [00:38<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.43790093, IoU: 0.9489255901266126 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.47242805, IoU: 0.9523358178225348 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.47242805, IoU: 0.9523358178225348 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.4849879, IoU: 0.9383130849270476 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.77s/it] \u001b[A\n","Training loss: 0.4849879, IoU: 0.9383130849270476 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44975, IoU: 0.9543662577910857 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]  \u001b[A\n","Training loss: 0.44975, IoU: 0.9543662577910857 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.78s/it]\u001b[A\n","Training loss: 0.4648153, IoU: 0.9593282992931911 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.78s/it]\u001b[A\n","Training loss: 0.4648153, IoU: 0.9593282992931911 |:  69%|██████▉   | 18/26 [00:48<00:17,  2.23s/it]\u001b[A\n","Training loss: 0.4775529, IoU: 0.9552806872526243 |:  69%|██████▉   | 18/26 [00:50<00:17,  2.23s/it]\u001b[A\n","Training loss: 0.4775529, IoU: 0.9552806872526243 |:  73%|███████▎  | 19/26 [00:50<00:16,  2.40s/it]\u001b[A\n","Training loss: 0.4588247, IoU: 0.9390507901749334 |:  73%|███████▎  | 19/26 [00:53<00:16,  2.40s/it]\u001b[A\n","Training loss: 0.4588247, IoU: 0.9390507901749334 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.51s/it]\u001b[A\n","Training loss: 0.43172282, IoU: 0.9412529856320452 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.51s/it]\u001b[A\n","Training loss: 0.43172282, IoU: 0.9412529856320452 |:  81%|████████  | 21/26 [00:56<00:13,  2.60s/it]\u001b[A\n","Training loss: 0.4284581, IoU: 0.9424017062057696 |:  81%|████████  | 21/26 [00:59<00:13,  2.60s/it] \u001b[A\n","Training loss: 0.4284581, IoU: 0.9424017062057696 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.68s/it]\u001b[A\n","Training loss: 0.46104595, IoU: 0.9564711930274675 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.68s/it]\u001b[A\n","Training loss: 0.46104595, IoU: 0.9564711930274675 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.71s/it]\u001b[A\n","Training loss: 0.47350198, IoU: 0.9497075549496384 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.71s/it]\u001b[A\n","Training loss: 0.47350198, IoU: 0.9497075549496384 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.44687197, IoU: 0.9587133563743496 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.44687197, IoU: 0.9587133563743496 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.74s/it]\u001b[A\n","Training loss: 0.45341745, IoU: 0.9590264085361281 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.74s/it]\u001b[A\n","Training loss: 0.45341745, IoU: 0.9590264085361281 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  49%|████▊     | 73/150 [1:48:47<1:40:58, 78.68s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48422068, IoU: 0.9450571417427256 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48422068, IoU: 0.9450571417427256 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.46477145, IoU: 0.9356037448330611 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.46477145, IoU: 0.9356037448330611 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.4355075, IoU: 0.9461339139510194 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it] \u001b[A\n","Training loss: 0.4355075, IoU: 0.9461339139510194 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.42937776, IoU: 0.9608443177547974 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.42937776, IoU: 0.9608443177547974 |:  15%|█▌        | 4/26 [00:11<01:01,  2.77s/it]\u001b[A\n","Training loss: 0.41806012, IoU: 0.9395505490773237 |:  15%|█▌        | 4/26 [00:13<01:01,  2.77s/it]\u001b[A\n","Training loss: 0.41806012, IoU: 0.9395505490773237 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.49110293, IoU: 0.9527403843921376 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.49110293, IoU: 0.9527403843921376 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.42972103, IoU: 0.9535324601811368 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.42972103, IoU: 0.9535324601811368 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.44957173, IoU: 0.9509139074636339 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.44957173, IoU: 0.9509139074636339 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.4501496, IoU: 0.9515700585077508 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it] \u001b[A\n","Training loss: 0.4501496, IoU: 0.9515700585077508 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.43835264, IoU: 0.9564168834688925 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.43835264, IoU: 0.9564168834688925 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.4449689, IoU: 0.9513123549053175 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it] \u001b[A\n","Training loss: 0.4449689, IoU: 0.9513123549053175 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.49711773, IoU: 0.9439911621035258 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.49711773, IoU: 0.9439911621035258 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.4463425, IoU: 0.9571057431872202 |:  46%|████▌     | 12/26 [00:36<00:38,  2.77s/it] \u001b[A\n","Training loss: 0.4463425, IoU: 0.9571057431872202 |:  50%|█████     | 13/26 [00:36<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.4840107, IoU: 0.9482010457044149 |:  50%|█████     | 13/26 [00:38<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.4840107, IoU: 0.9482010457044149 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.44380233, IoU: 0.9500639638953889 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.44380233, IoU: 0.9500639638953889 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.4609363, IoU: 0.9514949250759905 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.76s/it] \u001b[A\n","Training loss: 0.4609363, IoU: 0.9514949250759905 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.4614783, IoU: 0.9513161272676234 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.4614783, IoU: 0.9513161272676234 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.78s/it]\u001b[A\n","Training loss: 0.3950341, IoU: 0.9353499167345698 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.78s/it]\u001b[A\n","Training loss: 0.3950341, IoU: 0.9353499167345698 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.4256142, IoU: 0.9516986636551854 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.4256142, IoU: 0.9516986636551854 |:  73%|███████▎  | 19/26 [00:50<00:15,  2.23s/it]\u001b[A\n","Training loss: 0.45500726, IoU: 0.942846257424089 |:  73%|███████▎  | 19/26 [00:53<00:15,  2.23s/it]\u001b[A\n","Training loss: 0.45500726, IoU: 0.942846257424089 |:  77%|███████▋  | 20/26 [00:53<00:14,  2.39s/it]\u001b[A\n","Training loss: 0.46554178, IoU: 0.9481719878234542 |:  77%|███████▋  | 20/26 [00:56<00:14,  2.39s/it]\u001b[A\n","Training loss: 0.46554178, IoU: 0.9481719878234542 |:  81%|████████  | 21/26 [00:56<00:12,  2.51s/it]\u001b[A\n","Training loss: 0.4445237, IoU: 0.9561909888088991 |:  81%|████████  | 21/26 [00:59<00:12,  2.51s/it] \u001b[A\n","Training loss: 0.4445237, IoU: 0.9561909888088991 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.59s/it]\u001b[A\n","Training loss: 0.44833767, IoU: 0.9531625828100632 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.59s/it]\u001b[A\n","Training loss: 0.44833767, IoU: 0.9531625828100632 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.65s/it]\u001b[A\n","Training loss: 0.47524652, IoU: 0.9600595323707266 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.65s/it]\u001b[A\n","Training loss: 0.47524652, IoU: 0.9600595323707266 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.69s/it]\u001b[A\n","Training loss: 0.48730984, IoU: 0.944598960723507 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.69s/it] \u001b[A\n","Training loss: 0.48730984, IoU: 0.944598960723507 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.71s/it]\u001b[A\n","Training loss: 0.49722725, IoU: 0.9448770019332068 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.71s/it]\u001b[A\n","Training loss: 0.49722725, IoU: 0.9448770019332068 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  49%|████▉     | 74/150 [1:50:05<1:39:29, 78.54s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.43952572, IoU: 0.9483467355856796 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.43952572, IoU: 0.9483467355856796 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.45780268, IoU: 0.9510522195069872 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.45780268, IoU: 0.9510522195069872 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.48454183, IoU: 0.9500022971607094 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.48454183, IoU: 0.9500022971607094 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.43643308, IoU: 0.9568321309094807 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.43643308, IoU: 0.9568321309094807 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.48542494, IoU: 0.9369111089160911 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.48542494, IoU: 0.9369111089160911 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.48692882, IoU: 0.9414962588725712 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.48692882, IoU: 0.9414962588725712 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43553507, IoU: 0.9540785290684802 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43553507, IoU: 0.9540785290684802 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.47807217, IoU: 0.9501751831460163 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.47807217, IoU: 0.9501751831460163 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.4478745, IoU: 0.9594692493387278 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it] \u001b[A\n","Training loss: 0.4478745, IoU: 0.9594692493387278 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.41583535, IoU: 0.9547286450654426 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.41583535, IoU: 0.9547286450654426 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.46295375, IoU: 0.9576266555699868 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.46295375, IoU: 0.9576266555699868 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.4194891, IoU: 0.9310221953625204 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it] \u001b[A\n","Training loss: 0.4194891, IoU: 0.9310221953625204 |:  46%|████▌     | 12/26 [00:33<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.45513272, IoU: 0.9535689535689535 |:  46%|████▌     | 12/26 [00:36<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.45513272, IoU: 0.9535689535689535 |:  50%|█████     | 13/26 [00:36<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.43819755, IoU: 0.9539583032230091 |:  50%|█████     | 13/26 [00:38<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.43819755, IoU: 0.9539583032230091 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.53424466, IoU: 0.9445641485226458 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.53424466, IoU: 0.9445641485226458 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.4348285, IoU: 0.9604775348631596 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it] \u001b[A\n","Training loss: 0.4348285, IoU: 0.9604775348631596 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.41640896, IoU: 0.9523983536561911 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.41640896, IoU: 0.9523983536561911 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.4151397, IoU: 0.9524321049563573 |:  65%|██████▌   | 17/26 [00:49<00:25,  2.79s/it] \u001b[A\n","Training loss: 0.4151397, IoU: 0.9524321049563573 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.39137942, IoU: 0.9556406602390974 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.39137942, IoU: 0.9556406602390974 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.36373168, IoU: 0.9588837302181619 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.36373168, IoU: 0.9588837302181619 |:  77%|███████▋  | 20/26 [00:53<00:13,  2.23s/it]\u001b[A\n","Training loss: 0.4753611, IoU: 0.9522186611840117 |:  77%|███████▋  | 20/26 [00:56<00:13,  2.23s/it] \u001b[A\n","Training loss: 0.4753611, IoU: 0.9522186611840117 |:  81%|████████  | 21/26 [00:56<00:11,  2.39s/it]\u001b[A\n","Training loss: 0.48877877, IoU: 0.9498865716694693 |:  81%|████████  | 21/26 [00:59<00:11,  2.39s/it]\u001b[A\n","Training loss: 0.48877877, IoU: 0.9498865716694693 |:  85%|████████▍ | 22/26 [00:59<00:09,  2.50s/it]\u001b[A\n","Training loss: 0.48862195, IoU: 0.9433550553652926 |:  85%|████████▍ | 22/26 [01:01<00:09,  2.50s/it]\u001b[A\n","Training loss: 0.48862195, IoU: 0.9433550553652926 |:  88%|████████▊ | 23/26 [01:01<00:07,  2.58s/it]\u001b[A\n","Training loss: 0.42428666, IoU: 0.9470007800707129 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.58s/it]\u001b[A\n","Training loss: 0.42428666, IoU: 0.9470007800707129 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.63s/it]\u001b[A\n","Training loss: 0.4132955, IoU: 0.9372368445581918 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.63s/it] \u001b[A\n","Training loss: 0.4132955, IoU: 0.9372368445581918 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.5344981, IoU: 0.9428685491862298 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.5344981, IoU: 0.9428685491862298 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  50%|█████     | 75/150 [1:51:23<1:38:01, 78.42s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4544071, IoU: 0.9455138955729584 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4544071, IoU: 0.9455138955729584 |:   4%|▍         | 1/26 [00:02<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.44545668, IoU: 0.95006764615129 |:   4%|▍         | 1/26 [00:05<01:08,  2.74s/it] \u001b[A\n","Training loss: 0.44545668, IoU: 0.95006764615129 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.4346586, IoU: 0.9527713061236229 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.4346586, IoU: 0.9527713061236229 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4164191, IoU: 0.9469904559168032 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4164191, IoU: 0.9469904559168032 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.5131701, IoU: 0.9523936555017001 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.5131701, IoU: 0.9523936555017001 |:  19%|█▉        | 5/26 [00:13<00:57,  2.76s/it]\u001b[A\n","Training loss: 0.43851984, IoU: 0.9542269185326209 |:  19%|█▉        | 5/26 [00:16<00:57,  2.76s/it]\u001b[A\n","Training loss: 0.43851984, IoU: 0.9542269185326209 |:  23%|██▎       | 6/26 [00:16<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.49106115, IoU: 0.9405995158357411 |:  23%|██▎       | 6/26 [00:19<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.49106115, IoU: 0.9405995158357411 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.45651382, IoU: 0.9575126305728136 |:  27%|██▋       | 7/26 [00:22<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.45651382, IoU: 0.9575126305728136 |:  31%|███       | 8/26 [00:22<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.41180217, IoU: 0.9567874441068464 |:  31%|███       | 8/26 [00:24<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.41180217, IoU: 0.9567874441068464 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.41912067, IoU: 0.9565640092068454 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.41912067, IoU: 0.9565640092068454 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.42775694, IoU: 0.9613385161399358 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.42775694, IoU: 0.9613385161399358 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.439641, IoU: 0.9472509849039501 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it]  \u001b[A\n","Training loss: 0.439641, IoU: 0.9472509849039501 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.46728766, IoU: 0.9501714352697541 |:  46%|████▌     | 12/26 [00:35<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.46728766, IoU: 0.9501714352697541 |:  50%|█████     | 13/26 [00:35<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.43440127, IoU: 0.954985055327854 |:  50%|█████     | 13/26 [00:38<00:35,  2.77s/it] \u001b[A\n","Training loss: 0.43440127, IoU: 0.954985055327854 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.44780552, IoU: 0.9563895839547184 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.44780552, IoU: 0.9563895839547184 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.45709127, IoU: 0.9511648160760517 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.45709127, IoU: 0.9511648160760517 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.45834553, IoU: 0.9484222393639115 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.45834553, IoU: 0.9484222393639115 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.47768462, IoU: 0.9524993912804047 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.47768462, IoU: 0.9524993912804047 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.4559903, IoU: 0.9443101548336642 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it] \u001b[A\n","Training loss: 0.4559903, IoU: 0.9443101548336642 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.46962142, IoU: 0.9495299052989393 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.46962142, IoU: 0.9495299052989393 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4622514, IoU: 0.9591731216667784 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it] \u001b[A\n","Training loss: 0.4622514, IoU: 0.9591731216667784 |:  81%|████████  | 21/26 [00:56<00:11,  2.23s/it]\u001b[A\n","Training loss: 0.4609747, IoU: 0.9517354474882612 |:  81%|████████  | 21/26 [00:59<00:11,  2.23s/it]\u001b[A\n","Training loss: 0.4609747, IoU: 0.9517354474882612 |:  85%|████████▍ | 22/26 [00:59<00:09,  2.38s/it]\u001b[A\n","Training loss: 0.41444632, IoU: 0.9574306599463555 |:  85%|████████▍ | 22/26 [01:01<00:09,  2.38s/it]\u001b[A\n","Training loss: 0.41444632, IoU: 0.9574306599463555 |:  88%|████████▊ | 23/26 [01:01<00:07,  2.51s/it]\u001b[A\n","Training loss: 0.47641137, IoU: 0.9437576093519554 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.51s/it]\u001b[A\n","Training loss: 0.47641137, IoU: 0.9437576093519554 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.59s/it]\u001b[A\n","Training loss: 0.52060133, IoU: 0.9626209959688126 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.59s/it]\u001b[A\n","Training loss: 0.52060133, IoU: 0.9626209959688126 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.64s/it]\u001b[A\n","Training loss: 0.4094555, IoU: 0.9493192344531645 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.64s/it] \u001b[A\n","Training loss: 0.4094555, IoU: 0.9493192344531645 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  51%|█████     | 76/150 [1:52:41<1:36:32, 78.28s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.489228, IoU: 0.9497067357088854 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.489228, IoU: 0.9497067357088854 |:   4%|▍         | 1/26 [00:02<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.4648094, IoU: 0.9553022520098495 |:   4%|▍         | 1/26 [00:05<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.4648094, IoU: 0.9553022520098495 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.45631522, IoU: 0.9500654783066544 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.45631522, IoU: 0.9500654783066544 |:  12%|█▏        | 3/26 [00:08<01:03,  2.76s/it]\u001b[A\n","Training loss: 0.49660125, IoU: 0.947915707455286 |:  12%|█▏        | 3/26 [00:11<01:03,  2.76s/it] \u001b[A\n","Training loss: 0.49660125, IoU: 0.947915707455286 |:  15%|█▌        | 4/26 [00:11<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.45042303, IoU: 0.9489402149436567 |:  15%|█▌        | 4/26 [00:13<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.45042303, IoU: 0.9489402149436567 |:  19%|█▉        | 5/26 [00:13<00:58,  2.76s/it]\u001b[A\n","Training loss: 0.45417866, IoU: 0.9594917380428085 |:  19%|█▉        | 5/26 [00:16<00:58,  2.76s/it]\u001b[A\n","Training loss: 0.45417866, IoU: 0.9594917380428085 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.38840103, IoU: 0.9549814116945742 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.38840103, IoU: 0.9549814116945742 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.4895205, IoU: 0.9292147446736557 |:  27%|██▋       | 7/26 [00:22<00:52,  2.76s/it] \u001b[A\n","Training loss: 0.4895205, IoU: 0.9292147446736557 |:  31%|███       | 8/26 [00:22<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.44145995, IoU: 0.9426170099746208 |:  31%|███       | 8/26 [00:24<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.44145995, IoU: 0.9426170099746208 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.47675985, IoU: 0.9550772497269828 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.47675985, IoU: 0.9550772497269828 |:  38%|███▊      | 10/26 [00:27<00:44,  2.75s/it]\u001b[A\n","Training loss: 0.4563459, IoU: 0.9392093954066699 |:  38%|███▊      | 10/26 [00:30<00:44,  2.75s/it] \u001b[A\n","Training loss: 0.4563459, IoU: 0.9392093954066699 |:  42%|████▏     | 11/26 [00:30<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.46455318, IoU: 0.9490455031216604 |:  42%|████▏     | 11/26 [00:33<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.46455318, IoU: 0.9490455031216604 |:  46%|████▌     | 12/26 [00:33<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.49823487, IoU: 0.9502515319521447 |:  46%|████▌     | 12/26 [00:35<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.49823487, IoU: 0.9502515319521447 |:  50%|█████     | 13/26 [00:35<00:35,  2.75s/it]\u001b[A\n","Training loss: 0.43406677, IoU: 0.947083096777767 |:  50%|█████     | 13/26 [00:38<00:35,  2.75s/it] \u001b[A\n","Training loss: 0.43406677, IoU: 0.947083096777767 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.5358426, IoU: 0.9369100810151564 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.5358426, IoU: 0.9369100810151564 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.44298586, IoU: 0.9609952009802253 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.44298586, IoU: 0.9609952009802253 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.43374154, IoU: 0.9452308499985417 |:  62%|██████▏   | 16/26 [00:46<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.43374154, IoU: 0.9452308499985417 |:  65%|██████▌   | 17/26 [00:46<00:24,  2.75s/it]\u001b[A\n","Training loss: 0.5047824, IoU: 0.9550359406596768 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.75s/it] \u001b[A\n","Training loss: 0.5047824, IoU: 0.9550359406596768 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.75s/it]\u001b[A\n","Training loss: 0.40612945, IoU: 0.9499139359793264 |:  69%|██████▉   | 18/26 [00:52<00:21,  2.75s/it]\u001b[A\n","Training loss: 0.40612945, IoU: 0.9499139359793264 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.75s/it]\u001b[A\n","Training loss: 0.49928033, IoU: 0.9408631002420661 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.75s/it]\u001b[A\n","Training loss: 0.49928033, IoU: 0.9408631002420661 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.74s/it]\u001b[A\n","Training loss: 0.5084814, IoU: 0.9570643340387402 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.74s/it] \u001b[A\n","Training loss: 0.5084814, IoU: 0.9570643340387402 |:  81%|████████  | 21/26 [00:57<00:13,  2.74s/it]\u001b[A\n","Training loss: 0.37916964, IoU: 0.9414493252613357 |:  81%|████████  | 21/26 [00:58<00:13,  2.74s/it]\u001b[A\n","Training loss: 0.37916964, IoU: 0.9414493252613357 |:  85%|████████▍ | 22/26 [00:58<00:08,  2.20s/it]\u001b[A\n","Training loss: 0.43064314, IoU: 0.9533277177154181 |:  85%|████████▍ | 22/26 [01:01<00:08,  2.20s/it]\u001b[A\n","Training loss: 0.43064314, IoU: 0.9533277177154181 |:  88%|████████▊ | 23/26 [01:01<00:07,  2.36s/it]\u001b[A\n","Training loss: 0.47181195, IoU: 0.9463676851664605 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.36s/it]\u001b[A\n","Training loss: 0.47181195, IoU: 0.9463676851664605 |:  92%|█████████▏| 24/26 [01:04<00:04,  2.48s/it]\u001b[A\n","Training loss: 0.5043795, IoU: 0.9501416430594901 |:  92%|█████████▏| 24/26 [01:06<00:04,  2.48s/it] \u001b[A\n","Training loss: 0.5043795, IoU: 0.9501416430594901 |:  96%|█████████▌| 25/26 [01:06<00:02,  2.55s/it]\u001b[A\n","Training loss: 0.42547697, IoU: 0.9509831366023338 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.55s/it]\u001b[A\n","Training loss: 0.42547697, IoU: 0.9509831366023338 |: 100%|██████████| 26/26 [01:09<00:00,  2.68s/it]\n","Epoch Loop:  51%|█████▏    | 77/150 [1:53:59<1:34:59, 78.07s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47718698, IoU: 0.9540321488588509 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47718698, IoU: 0.9540321488588509 |:   4%|▍         | 1/26 [00:02<01:08,  2.73s/it]\u001b[A\n","Training loss: 0.4308983, IoU: 0.9501084698929625 |:   4%|▍         | 1/26 [00:05<01:08,  2.73s/it] \u001b[A\n","Training loss: 0.4308983, IoU: 0.9501084698929625 |:   8%|▊         | 2/26 [00:05<01:05,  2.74s/it]\u001b[A\n","Training loss: 0.4736026, IoU: 0.9504152579371122 |:   8%|▊         | 2/26 [00:08<01:05,  2.74s/it]\u001b[A\n","Training loss: 0.4736026, IoU: 0.9504152579371122 |:  12%|█▏        | 3/26 [00:08<01:03,  2.75s/it]\u001b[A\n","Training loss: 0.41577, IoU: 0.9444259716025549 |:  12%|█▏        | 3/26 [00:11<01:03,  2.75s/it]  \u001b[A\n","Training loss: 0.41577, IoU: 0.9444259716025549 |:  15%|█▌        | 4/26 [00:11<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.47340629, IoU: 0.9523310925070537 |:  15%|█▌        | 4/26 [00:13<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.47340629, IoU: 0.9523310925070537 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.44716918, IoU: 0.9597024712205718 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.44716918, IoU: 0.9597024712205718 |:  23%|██▎       | 6/26 [00:16<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.46425632, IoU: 0.9553017718715393 |:  23%|██▎       | 6/26 [00:19<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.46425632, IoU: 0.9553017718715393 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.49724072, IoU: 0.9428260496274706 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.49724072, IoU: 0.9428260496274706 |:  31%|███       | 8/26 [00:22<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.40730268, IoU: 0.9507023172905525 |:  31%|███       | 8/26 [00:24<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.40730268, IoU: 0.9507023172905525 |:  35%|███▍      | 9/26 [00:24<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.43705967, IoU: 0.9454413665565168 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.43705967, IoU: 0.9454413665565168 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.4641311, IoU: 0.9384124713508456 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it] \u001b[A\n","Training loss: 0.4641311, IoU: 0.9384124713508456 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.43099952, IoU: 0.9390290034692669 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.43099952, IoU: 0.9390290034692669 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.48160824, IoU: 0.9471953255425709 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.48160824, IoU: 0.9471953255425709 |:  50%|█████     | 13/26 [00:36<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.48212194, IoU: 0.9455555342089703 |:  50%|█████     | 13/26 [00:38<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.48212194, IoU: 0.9455555342089703 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.5062564, IoU: 0.9431112519039581 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it] \u001b[A\n","Training loss: 0.5062564, IoU: 0.9431112519039581 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.42479995, IoU: 0.9414703045335538 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.42479995, IoU: 0.9414703045335538 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.4718683, IoU: 0.9491088489161231 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.78s/it] \u001b[A\n","Training loss: 0.4718683, IoU: 0.9491088489161231 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.42979097, IoU: 0.9598595233795878 |:  65%|██████▌   | 17/26 [00:49<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.42979097, IoU: 0.9598595233795878 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.4772461, IoU: 0.956678068607641 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.79s/it]  \u001b[A\n","Training loss: 0.4772461, IoU: 0.956678068607641 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.5066834, IoU: 0.9462781751658975 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.5066834, IoU: 0.9462781751658975 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.43770763, IoU: 0.9577322666473601 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.43770763, IoU: 0.9577322666473601 |:  81%|████████  | 21/26 [00:58<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.46260262, IoU: 0.9446283875280896 |:  81%|████████  | 21/26 [01:01<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.46260262, IoU: 0.9446283875280896 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.50232786, IoU: 0.9622353744593671 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.50232786, IoU: 0.9622353744593671 |:  88%|████████▊ | 23/26 [01:01<00:06,  2.23s/it]\u001b[A\n","Training loss: 0.4434694, IoU: 0.9525429819288467 |:  88%|████████▊ | 23/26 [01:04<00:06,  2.23s/it] \u001b[A\n","Training loss: 0.4434694, IoU: 0.9525429819288467 |:  92%|█████████▏| 24/26 [01:04<00:04,  2.39s/it]\u001b[A\n","Training loss: 0.47611463, IoU: 0.9596583248772075 |:  92%|█████████▏| 24/26 [01:07<00:04,  2.39s/it]\u001b[A\n","Training loss: 0.47611463, IoU: 0.9596583248772075 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.50s/it]\u001b[A\n","Training loss: 0.48463067, IoU: 0.9378227685098658 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.50s/it]\u001b[A\n","Training loss: 0.48463067, IoU: 0.9378227685098658 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  52%|█████▏    | 78/150 [1:55:17<1:33:40, 78.07s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.8263041804715802\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4967366, IoU: 0.9507456587457818 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4967366, IoU: 0.9507456587457818 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.47604242, IoU: 0.9541718929815007 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.47604242, IoU: 0.9541718929815007 |:   8%|▊         | 2/26 [00:05<01:06,  2.75s/it]\u001b[A\n","Training loss: 0.4451329, IoU: 0.9511184922880442 |:   8%|▊         | 2/26 [00:08<01:06,  2.75s/it] \u001b[A\n","Training loss: 0.4451329, IoU: 0.9511184922880442 |:  12%|█▏        | 3/26 [00:08<01:03,  2.75s/it]\u001b[A\n","Training loss: 0.45937276, IoU: 0.9320491006007972 |:  12%|█▏        | 3/26 [00:11<01:03,  2.75s/it]\u001b[A\n","Training loss: 0.45937276, IoU: 0.9320491006007972 |:  15%|█▌        | 4/26 [00:11<01:00,  2.75s/it]\u001b[A\n","Training loss: 0.5123996, IoU: 0.9447803119031536 |:  15%|█▌        | 4/26 [00:13<01:00,  2.75s/it] \u001b[A\n","Training loss: 0.5123996, IoU: 0.9447803119031536 |:  19%|█▉        | 5/26 [00:13<00:57,  2.75s/it]\u001b[A\n","Training loss: 0.42008936, IoU: 0.9464943730704113 |:  19%|█▉        | 5/26 [00:16<00:57,  2.75s/it]\u001b[A\n","Training loss: 0.42008936, IoU: 0.9464943730704113 |:  23%|██▎       | 6/26 [00:16<00:54,  2.74s/it]\u001b[A\n","Training loss: 0.4210059, IoU: 0.9467170079372432 |:  23%|██▎       | 6/26 [00:19<00:54,  2.74s/it] \u001b[A\n","Training loss: 0.4210059, IoU: 0.9467170079372432 |:  27%|██▋       | 7/26 [00:19<00:52,  2.75s/it]\u001b[A\n","Training loss: 0.48335004, IoU: 0.9613230770832141 |:  27%|██▋       | 7/26 [00:21<00:52,  2.75s/it]\u001b[A\n","Training loss: 0.48335004, IoU: 0.9613230770832141 |:  31%|███       | 8/26 [00:21<00:49,  2.74s/it]\u001b[A\n","Training loss: 0.43821713, IoU: 0.9415834977370314 |:  31%|███       | 8/26 [00:24<00:49,  2.74s/it]\u001b[A\n","Training loss: 0.43821713, IoU: 0.9415834977370314 |:  35%|███▍      | 9/26 [00:24<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.38072318, IoU: 0.9438465411191291 |:  35%|███▍      | 9/26 [00:27<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.38072318, IoU: 0.9438465411191291 |:  38%|███▊      | 10/26 [00:27<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.44427294, IoU: 0.9471391981183787 |:  38%|███▊      | 10/26 [00:30<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.44427294, IoU: 0.9471391981183787 |:  42%|████▏     | 11/26 [00:30<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.44191143, IoU: 0.947309880711757 |:  42%|████▏     | 11/26 [00:33<00:41,  2.76s/it] \u001b[A\n","Training loss: 0.44191143, IoU: 0.947309880711757 |:  46%|████▌     | 12/26 [00:33<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.4541303, IoU: 0.9526495755741908 |:  46%|████▌     | 12/26 [00:35<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.4541303, IoU: 0.9526495755741908 |:  50%|█████     | 13/26 [00:35<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.43881866, IoU: 0.9580315344677476 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.43881866, IoU: 0.9580315344677476 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.42413908, IoU: 0.9535827217946423 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.42413908, IoU: 0.9535827217946423 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.47095883, IoU: 0.9453752478051544 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.47095883, IoU: 0.9453752478051544 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.45912004, IoU: 0.957416169512446 |:  62%|██████▏   | 16/26 [00:46<00:27,  2.75s/it] \u001b[A\n","Training loss: 0.45912004, IoU: 0.957416169512446 |:  65%|██████▌   | 17/26 [00:46<00:24,  2.75s/it]\u001b[A\n","Training loss: 0.45967865, IoU: 0.9483980966184254 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.75s/it]\u001b[A\n","Training loss: 0.45967865, IoU: 0.9483980966184254 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.75s/it]\u001b[A\n","Training loss: 0.44568664, IoU: 0.9520296009795728 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.75s/it]\u001b[A\n","Training loss: 0.44568664, IoU: 0.9520296009795728 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.75s/it]\u001b[A\n","Training loss: 0.45095566, IoU: 0.9549901412379957 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.75s/it]\u001b[A\n","Training loss: 0.45095566, IoU: 0.9549901412379957 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.44642156, IoU: 0.949892056384665 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.75s/it] \u001b[A\n","Training loss: 0.44642156, IoU: 0.949892056384665 |:  81%|████████  | 21/26 [00:57<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.47100097, IoU: 0.9586125115164503 |:  81%|████████  | 21/26 [01:00<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.47100097, IoU: 0.9586125115164503 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.4633674, IoU: 0.9530457579556229 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.76s/it] \u001b[A\n","Training loss: 0.4633674, IoU: 0.9530457579556229 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.75s/it]\u001b[A\n","Training loss: 0.51531655, IoU: 0.9607018387213075 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.75s/it]\u001b[A\n","Training loss: 0.51531655, IoU: 0.9607018387213075 |:  92%|█████████▏| 24/26 [01:04<00:04,  2.21s/it]\u001b[A\n","Training loss: 0.43433172, IoU: 0.9498492257731617 |:  92%|█████████▏| 24/26 [01:07<00:04,  2.21s/it]\u001b[A\n","Training loss: 0.43433172, IoU: 0.9498492257731617 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.37s/it]\u001b[A\n","Training loss: 0.42858022, IoU: 0.9518029259320437 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.37s/it]\u001b[A\n","Training loss: 0.42858022, IoU: 0.9518029259320437 |: 100%|██████████| 26/26 [01:09<00:00,  2.68s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric improved from 0.8263041804715802 to 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch Loop:  53%|█████▎    | 79/150 [1:56:37<1:33:01, 78.62s/it]\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4771543, IoU: 0.9549562132801241 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4771543, IoU: 0.9549562132801241 |:   4%|▍         | 1/26 [00:02<01:12,  2.88s/it]\u001b[A\n","Training loss: 0.37966302, IoU: 0.9521718877091695 |:   4%|▍         | 1/26 [00:05<01:12,  2.88s/it]\u001b[A\n","Training loss: 0.37966302, IoU: 0.9521718877091695 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.44423363, IoU: 0.941842407152575 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it] \u001b[A\n","Training loss: 0.44423363, IoU: 0.941842407152575 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.44713864, IoU: 0.9416984526808204 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.44713864, IoU: 0.9416984526808204 |:  15%|█▌        | 4/26 [00:11<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.49818605, IoU: 0.9377046079026233 |:  15%|█▌        | 4/26 [00:14<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.49818605, IoU: 0.9377046079026233 |:  19%|█▉        | 5/26 [00:14<00:59,  2.82s/it]\u001b[A\n","Training loss: 0.45989132, IoU: 0.9538443322855192 |:  19%|█▉        | 5/26 [00:16<00:59,  2.82s/it]\u001b[A\n","Training loss: 0.45989132, IoU: 0.9538443322855192 |:  23%|██▎       | 6/26 [00:16<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.4724996, IoU: 0.9494216550883189 |:  23%|██▎       | 6/26 [00:19<00:56,  2.83s/it] \u001b[A\n","Training loss: 0.4724996, IoU: 0.9494216550883189 |:  27%|██▋       | 7/26 [00:19<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.4715575, IoU: 0.9550750902919072 |:  27%|██▋       | 7/26 [00:22<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.4715575, IoU: 0.9550750902919072 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.42575383, IoU: 0.9565590294322471 |:  31%|███       | 8/26 [00:25<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.42575383, IoU: 0.9565590294322471 |:  35%|███▍      | 9/26 [00:25<00:47,  2.82s/it]\u001b[A\n","Training loss: 0.4636956, IoU: 0.9555428273009829 |:  35%|███▍      | 9/26 [00:28<00:47,  2.82s/it] \u001b[A\n","Training loss: 0.4636956, IoU: 0.9555428273009829 |:  38%|███▊      | 10/26 [00:28<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.43760428, IoU: 0.9367521187222799 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.43760428, IoU: 0.9367521187222799 |:  42%|████▏     | 11/26 [00:30<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.44870505, IoU: 0.9424400812457685 |:  42%|████▏     | 11/26 [00:33<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.44870505, IoU: 0.9424400812457685 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.3909769, IoU: 0.9513236549957301 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it] \u001b[A\n","Training loss: 0.3909769, IoU: 0.9513236549957301 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.42089036, IoU: 0.9328867898248857 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.42089036, IoU: 0.9328867898248857 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.4756776, IoU: 0.9492593202000409 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.79s/it] \u001b[A\n","Training loss: 0.4756776, IoU: 0.9492593202000409 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.42152938, IoU: 0.951031051400749 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.42152938, IoU: 0.951031051400749 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.44870725, IoU: 0.9405356943243595 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.44870725, IoU: 0.9405356943243595 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.39525014, IoU: 0.9489212102612441 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.39525014, IoU: 0.9489212102612441 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.47013748, IoU: 0.9518921702686864 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.47013748, IoU: 0.9518921702686864 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.45518515, IoU: 0.9434242839026551 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.45518515, IoU: 0.9434242839026551 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.42160344, IoU: 0.9500719427583049 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.42160344, IoU: 0.9500719427583049 |:  81%|████████  | 21/26 [00:58<00:14,  2.80s/it]\u001b[A\n","Training loss: 0.4488899, IoU: 0.9280414048407823 |:  81%|████████  | 21/26 [01:01<00:14,  2.80s/it] \u001b[A\n","Training loss: 0.4488899, IoU: 0.9280414048407823 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.49124664, IoU: 0.9507089629476299 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.49124664, IoU: 0.9507089629476299 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.47346067, IoU: 0.9460362379575654 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.47346067, IoU: 0.9460362379575654 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.42203707, IoU: 0.9416924806052798 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.42203707, IoU: 0.9416924806052798 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.24s/it]\u001b[A\n","Training loss: 0.45152718, IoU: 0.9535644167929214 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.24s/it]\u001b[A\n","Training loss: 0.45152718, IoU: 0.9535644167929214 |: 100%|██████████| 26/26 [01:11<00:00,  2.73s/it]\n","Epoch Loop:  53%|█████▎    | 80/150 [1:57:56<1:31:52, 78.75s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45312372, IoU: 0.9563079477365847 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45312372, IoU: 0.9563079477365847 |:   4%|▍         | 1/26 [00:02<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.3930834, IoU: 0.9489330870370508 |:   4%|▍         | 1/26 [00:05<01:08,  2.75s/it] \u001b[A\n","Training loss: 0.3930834, IoU: 0.9489330870370508 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.4116337, IoU: 0.9502276912220348 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.4116337, IoU: 0.9502276912220348 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.40896413, IoU: 0.9549371426688416 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.40896413, IoU: 0.9549371426688416 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.45396802, IoU: 0.9582565680940787 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.45396802, IoU: 0.9582565680940787 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.45901766, IoU: 0.954200751965364 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it] \u001b[A\n","Training loss: 0.45901766, IoU: 0.954200751965364 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.41982108, IoU: 0.9304002457412927 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.41982108, IoU: 0.9304002457412927 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.4526602, IoU: 0.9459915353724037 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it] \u001b[A\n","Training loss: 0.4526602, IoU: 0.9459915353724037 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.43917036, IoU: 0.9493645257624366 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.43917036, IoU: 0.9493645257624366 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.45077813, IoU: 0.9478381861353404 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.45077813, IoU: 0.9478381861353404 |:  38%|███▊      | 10/26 [00:27<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.44074458, IoU: 0.9511177596491555 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.44074458, IoU: 0.9511177596491555 |:  42%|████▏     | 11/26 [00:30<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.4936754, IoU: 0.9606471573746835 |:  42%|████▏     | 11/26 [00:33<00:41,  2.80s/it] \u001b[A\n","Training loss: 0.4936754, IoU: 0.9606471573746835 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.41618273, IoU: 0.9535582184272502 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.41618273, IoU: 0.9535582184272502 |:  50%|█████     | 13/26 [00:36<00:36,  2.81s/it]\u001b[A\n","Training loss: 0.519411, IoU: 0.9487229213037441 |:  50%|█████     | 13/26 [00:39<00:36,  2.81s/it]  \u001b[A\n","Training loss: 0.519411, IoU: 0.9487229213037441 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.42481425, IoU: 0.9421209036128002 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.42481425, IoU: 0.9421209036128002 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.80s/it]\u001b[A\n","Training loss: 0.4765134, IoU: 0.9536193334242714 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.80s/it] \u001b[A\n","Training loss: 0.4765134, IoU: 0.9536193334242714 |:  62%|██████▏   | 16/26 [00:44<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.465325, IoU: 0.9493706618116887 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.80s/it] \u001b[A\n","Training loss: 0.465325, IoU: 0.9493706618116887 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.40391338, IoU: 0.9459723239764943 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.40391338, IoU: 0.9459723239764943 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.45222753, IoU: 0.9469926620674193 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.45222753, IoU: 0.9469926620674193 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.4676348, IoU: 0.9418592677208536 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.80s/it] \u001b[A\n","Training loss: 0.4676348, IoU: 0.9418592677208536 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.46574628, IoU: 0.9420055739974793 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.46574628, IoU: 0.9420055739974793 |:  81%|████████  | 21/26 [00:58<00:14,  2.80s/it]\u001b[A\n","Training loss: 0.4504649, IoU: 0.9487811439185294 |:  81%|████████  | 21/26 [01:01<00:14,  2.80s/it] \u001b[A\n","Training loss: 0.4504649, IoU: 0.9487811439185294 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.48352852, IoU: 0.9499209928343586 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.48352852, IoU: 0.9499209928343586 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.44279295, IoU: 0.9489580571381763 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.44279295, IoU: 0.9489580571381763 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.47532812, IoU: 0.958326580525393 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.80s/it] \u001b[A\n","Training loss: 0.47532812, IoU: 0.958326580525393 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.56955063, IoU: 0.9318113702834819 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.56955063, IoU: 0.9318113702834819 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  54%|█████▍    | 81/150 [1:59:15<1:30:35, 78.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44975245, IoU: 0.9453616476286252 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44975245, IoU: 0.9453616476286252 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.4891133, IoU: 0.9432237690157731 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it] \u001b[A\n","Training loss: 0.4891133, IoU: 0.9432237690157731 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.44176996, IoU: 0.948646656576811 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.44176996, IoU: 0.948646656576811 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.512549, IoU: 0.9510276725226777 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it] \u001b[A\n","Training loss: 0.512549, IoU: 0.9510276725226777 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46613157, IoU: 0.9398718948790912 |:  15%|█▌        | 4/26 [00:14<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46613157, IoU: 0.9398718948790912 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.4907423, IoU: 0.95237484431829 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it]   \u001b[A\n","Training loss: 0.4907423, IoU: 0.95237484431829 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.49498123, IoU: 0.9537705657407985 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.49498123, IoU: 0.9537705657407985 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.41682142, IoU: 0.9502868407086356 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.41682142, IoU: 0.9502868407086356 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.4595878, IoU: 0.935609001367611 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]  \u001b[A\n","Training loss: 0.4595878, IoU: 0.935609001367611 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.46335846, IoU: 0.9568493653402608 |:  35%|███▍      | 9/26 [00:27<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.46335846, IoU: 0.9568493653402608 |:  38%|███▊      | 10/26 [00:27<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.48294267, IoU: 0.9523209130325513 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.48294267, IoU: 0.9523209130325513 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.4786486, IoU: 0.9549883295680068 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it] \u001b[A\n","Training loss: 0.4786486, IoU: 0.9549883295680068 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.43480965, IoU: 0.9608743339124696 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.43480965, IoU: 0.9608743339124696 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.44675338, IoU: 0.953551716556935 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it] \u001b[A\n","Training loss: 0.44675338, IoU: 0.953551716556935 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.41631794, IoU: 0.9472366937221294 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.41631794, IoU: 0.9472366937221294 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.5237506, IoU: 0.948363624383138 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]  \u001b[A\n","Training loss: 0.5237506, IoU: 0.948363624383138 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.51367265, IoU: 0.9536247987482709 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.51367265, IoU: 0.9536247987482709 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.4607432, IoU: 0.9550640050087817 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.79s/it] \u001b[A\n","Training loss: 0.4607432, IoU: 0.9550640050087817 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.46565372, IoU: 0.9579584827342196 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.46565372, IoU: 0.9579584827342196 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.44277382, IoU: 0.9596667764514041 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.44277382, IoU: 0.9596667764514041 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.44272774, IoU: 0.9579918217819228 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.44272774, IoU: 0.9579918217819228 |:  81%|████████  | 21/26 [00:58<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.4117716, IoU: 0.963338903674362 |:  81%|████████  | 21/26 [01:01<00:13,  2.80s/it]  \u001b[A\n","Training loss: 0.4117716, IoU: 0.963338903674362 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.5138735, IoU: 0.9523403996471912 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.5138735, IoU: 0.9523403996471912 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.46431494, IoU: 0.9523321667514183 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.46431494, IoU: 0.9523321667514183 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.44278914, IoU: 0.9411231906847785 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.44278914, IoU: 0.9411231906847785 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.462568, IoU: 0.9576992837825276 |:  96%|█████████▌| 25/26 [01:12<00:02,  2.80s/it]  \u001b[A\n","Training loss: 0.462568, IoU: 0.9576992837825276 |: 100%|██████████| 26/26 [01:12<00:00,  2.79s/it]\n","Epoch Loop:  55%|█████▍    | 82/150 [2:00:35<1:29:53, 79.31s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4137812, IoU: 0.9487153169797119 |:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4137812, IoU: 0.9487153169797119 |:   4%|▍         | 1/26 [00:00<00:23,  1.06it/s]\u001b[A\n","Training loss: 0.45280576, IoU: 0.9595403727247842 |:   4%|▍         | 1/26 [00:03<00:23,  1.06it/s]\u001b[A\n","Training loss: 0.45280576, IoU: 0.9595403727247842 |:   8%|▊         | 2/26 [00:03<00:48,  2.02s/it]\u001b[A\n","Training loss: 0.47078356, IoU: 0.9538532304542523 |:   8%|▊         | 2/26 [00:06<00:48,  2.02s/it]\u001b[A\n","Training loss: 0.47078356, IoU: 0.9538532304542523 |:  12%|█▏        | 3/26 [00:06<00:54,  2.38s/it]\u001b[A\n","Training loss: 0.47296137, IoU: 0.9466475393582723 |:  12%|█▏        | 3/26 [00:09<00:54,  2.38s/it]\u001b[A\n","Training loss: 0.47296137, IoU: 0.9466475393582723 |:  15%|█▌        | 4/26 [00:09<00:55,  2.54s/it]\u001b[A\n","Training loss: 0.46942502, IoU: 0.952208812543285 |:  15%|█▌        | 4/26 [00:12<00:55,  2.54s/it] \u001b[A\n","Training loss: 0.46942502, IoU: 0.952208812543285 |:  19%|█▉        | 5/26 [00:12<00:55,  2.63s/it]\u001b[A\n","Training loss: 0.4728919, IoU: 0.9478484367104064 |:  19%|█▉        | 5/26 [00:14<00:55,  2.63s/it]\u001b[A\n","Training loss: 0.4728919, IoU: 0.9478484367104064 |:  23%|██▎       | 6/26 [00:14<00:53,  2.69s/it]\u001b[A\n","Training loss: 0.4926989, IoU: 0.963121468213015 |:  23%|██▎       | 6/26 [00:17<00:53,  2.69s/it] \u001b[A\n","Training loss: 0.4926989, IoU: 0.963121468213015 |:  27%|██▋       | 7/26 [00:17<00:52,  2.74s/it]\u001b[A\n","Training loss: 0.44672117, IoU: 0.9469904637801339 |:  27%|██▋       | 7/26 [00:20<00:52,  2.74s/it]\u001b[A\n","Training loss: 0.44672117, IoU: 0.9469904637801339 |:  31%|███       | 8/26 [00:20<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.42444566, IoU: 0.9534776010563866 |:  31%|███       | 8/26 [00:23<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.42444566, IoU: 0.9534776010563866 |:  35%|███▍      | 9/26 [00:23<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.4397319, IoU: 0.9511982405581677 |:  35%|███▍      | 9/26 [00:26<00:46,  2.75s/it] \u001b[A\n","Training loss: 0.4397319, IoU: 0.9511982405581677 |:  38%|███▊      | 10/26 [00:26<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.4576234, IoU: 0.9576485789332214 |:  38%|███▊      | 10/26 [00:28<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.4576234, IoU: 0.9576485789332214 |:  42%|████▏     | 11/26 [00:28<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.47419423, IoU: 0.9599954632360089 |:  42%|████▏     | 11/26 [00:31<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.47419423, IoU: 0.9599954632360089 |:  46%|████▌     | 12/26 [00:31<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.4666447, IoU: 0.935253214379428 |:  46%|████▌     | 12/26 [00:34<00:39,  2.79s/it]  \u001b[A\n","Training loss: 0.4666447, IoU: 0.935253214379428 |:  50%|█████     | 13/26 [00:34<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.41792455, IoU: 0.9457900173378498 |:  50%|█████     | 13/26 [00:37<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.41792455, IoU: 0.9457900173378498 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.52178407, IoU: 0.9452777760248716 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.52178407, IoU: 0.9452777760248716 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.4368711, IoU: 0.9475110530451495 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.78s/it] \u001b[A\n","Training loss: 0.4368711, IoU: 0.9475110530451495 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.45885, IoU: 0.9483235156525973 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]  \u001b[A\n","Training loss: 0.45885, IoU: 0.9483235156525973 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.42867178, IoU: 0.9572189879296514 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.42867178, IoU: 0.9572189879296514 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.4277013, IoU: 0.9497832963235346 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it] \u001b[A\n","Training loss: 0.4277013, IoU: 0.9497832963235346 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.4447357, IoU: 0.9500999362936522 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.4447357, IoU: 0.9500999362936522 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.45855737, IoU: 0.951259114024876 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.45855737, IoU: 0.951259114024876 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.39715242, IoU: 0.9546546515847744 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.39715242, IoU: 0.9546546515847744 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.46700954, IoU: 0.9484599686773291 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.46700954, IoU: 0.9484599686773291 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.4089279, IoU: 0.9499615442012099 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it] \u001b[A\n","Training loss: 0.4089279, IoU: 0.9499615442012099 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.52304584, IoU: 0.9557868151226563 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.52304584, IoU: 0.9557868151226563 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.46628037, IoU: 0.9431669063563775 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.46628037, IoU: 0.9431669063563775 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  55%|█████▌    | 83/150 [2:01:54<1:28:19, 79.10s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4277411, IoU: 0.9440840820007631 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4277411, IoU: 0.9440840820007631 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.48881024, IoU: 0.9603596240294238 |:   4%|▍         | 1/26 [00:03<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.48881024, IoU: 0.9603596240294238 |:   8%|▊         | 2/26 [00:03<00:40,  1.71s/it]\u001b[A\n","Training loss: 0.40064126, IoU: 0.9504394492448042 |:   8%|▊         | 2/26 [00:06<00:40,  1.71s/it]\u001b[A\n","Training loss: 0.40064126, IoU: 0.9504394492448042 |:  12%|█▏        | 3/26 [00:06<00:50,  2.21s/it]\u001b[A\n","Training loss: 0.4657114, IoU: 0.9644800457157752 |:  12%|█▏        | 3/26 [00:09<00:50,  2.21s/it] \u001b[A\n","Training loss: 0.4657114, IoU: 0.9644800457157752 |:  15%|█▌        | 4/26 [00:09<00:53,  2.43s/it]\u001b[A\n","Training loss: 0.45618245, IoU: 0.9560024494671907 |:  15%|█▌        | 4/26 [00:12<00:53,  2.43s/it]\u001b[A\n","Training loss: 0.45618245, IoU: 0.9560024494671907 |:  19%|█▉        | 5/26 [00:12<00:53,  2.56s/it]\u001b[A\n","Training loss: 0.50411415, IoU: 0.9609184094127207 |:  19%|█▉        | 5/26 [00:14<00:53,  2.56s/it]\u001b[A\n","Training loss: 0.50411415, IoU: 0.9609184094127207 |:  23%|██▎       | 6/26 [00:14<00:52,  2.63s/it]\u001b[A\n","Training loss: 0.4915542, IoU: 0.9555660049834982 |:  23%|██▎       | 6/26 [00:17<00:52,  2.63s/it] \u001b[A\n","Training loss: 0.4915542, IoU: 0.9555660049834982 |:  27%|██▋       | 7/26 [00:17<00:50,  2.68s/it]\u001b[A\n","Training loss: 0.48997015, IoU: 0.9568572570037451 |:  27%|██▋       | 7/26 [00:20<00:50,  2.68s/it]\u001b[A\n","Training loss: 0.48997015, IoU: 0.9568572570037451 |:  31%|███       | 8/26 [00:20<00:48,  2.72s/it]\u001b[A\n","Training loss: 0.4221148, IoU: 0.943961195506379 |:  31%|███       | 8/26 [00:23<00:48,  2.72s/it]  \u001b[A\n","Training loss: 0.4221148, IoU: 0.943961195506379 |:  35%|███▍      | 9/26 [00:23<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.4297323, IoU: 0.9508247358991784 |:  35%|███▍      | 9/26 [00:26<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.4297323, IoU: 0.9508247358991784 |:  38%|███▊      | 10/26 [00:26<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.42737442, IoU: 0.9521180875836902 |:  38%|███▊      | 10/26 [00:28<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.42737442, IoU: 0.9521180875836902 |:  42%|████▏     | 11/26 [00:28<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.46952403, IoU: 0.9561223668910238 |:  42%|████▏     | 11/26 [00:31<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.46952403, IoU: 0.9561223668910238 |:  46%|████▌     | 12/26 [00:31<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.4352624, IoU: 0.9428927589367553 |:  46%|████▌     | 12/26 [00:34<00:38,  2.77s/it] \u001b[A\n","Training loss: 0.4352624, IoU: 0.9428927589367553 |:  50%|█████     | 13/26 [00:34<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.42891768, IoU: 0.9467420313208117 |:  50%|█████     | 13/26 [00:37<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.42891768, IoU: 0.9467420313208117 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.46447664, IoU: 0.9555418197385147 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.46447664, IoU: 0.9555418197385147 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.4672579, IoU: 0.9564764363342563 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it] \u001b[A\n","Training loss: 0.4672579, IoU: 0.9564764363342563 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.45748705, IoU: 0.9514702013652034 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.45748705, IoU: 0.9514702013652034 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.42734215, IoU: 0.9428110932029122 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.42734215, IoU: 0.9428110932029122 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.42162645, IoU: 0.9550441854289312 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.42162645, IoU: 0.9550441854289312 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.37784335, IoU: 0.9494525227298527 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.37784335, IoU: 0.9494525227298527 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.42531812, IoU: 0.9490175533039817 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.42531812, IoU: 0.9490175533039817 |:  81%|████████  | 21/26 [00:56<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.46026745, IoU: 0.9590513610733998 |:  81%|████████  | 21/26 [00:59<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.46026745, IoU: 0.9590513610733998 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.4563346, IoU: 0.9495828791682753 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it] \u001b[A\n","Training loss: 0.4563346, IoU: 0.9495828791682753 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.45473137, IoU: 0.9510517532602576 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.45473137, IoU: 0.9510517532602576 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.44243324, IoU: 0.9555987858027408 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.44243324, IoU: 0.9555987858027408 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4869369, IoU: 0.9449047109180607 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it] \u001b[A\n","Training loss: 0.4869369, IoU: 0.9449047109180607 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  56%|█████▌    | 84/150 [2:03:13<1:26:55, 79.02s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4585725, IoU: 0.9558527586785175 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4585725, IoU: 0.9558527586785175 |:   4%|▍         | 1/26 [00:02<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.43427512, IoU: 0.9370662820207788 |:   4%|▍         | 1/26 [00:05<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.43427512, IoU: 0.9370662820207788 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.40237764, IoU: 0.9528001532581031 |:   8%|▊         | 2/26 [00:06<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.40237764, IoU: 0.9528001532581031 |:  12%|█▏        | 3/26 [00:06<00:44,  1.95s/it]\u001b[A\n","Training loss: 0.5486235, IoU: 0.9532771813558835 |:  12%|█▏        | 3/26 [00:09<00:44,  1.95s/it] \u001b[A\n","Training loss: 0.5486235, IoU: 0.9532771813558835 |:  15%|█▌        | 4/26 [00:09<00:50,  2.29s/it]\u001b[A\n","Training loss: 0.4677513, IoU: 0.9575042661807994 |:  15%|█▌        | 4/26 [00:12<00:50,  2.29s/it]\u001b[A\n","Training loss: 0.4677513, IoU: 0.9575042661807994 |:  19%|█▉        | 5/26 [00:12<00:51,  2.47s/it]\u001b[A\n","Training loss: 0.45782074, IoU: 0.9483980276226309 |:  19%|█▉        | 5/26 [00:14<00:51,  2.47s/it]\u001b[A\n","Training loss: 0.45782074, IoU: 0.9483980276226309 |:  23%|██▎       | 6/26 [00:14<00:51,  2.57s/it]\u001b[A\n","Training loss: 0.4465339, IoU: 0.9519732564351099 |:  23%|██▎       | 6/26 [00:17<00:51,  2.57s/it] \u001b[A\n","Training loss: 0.4465339, IoU: 0.9519732564351099 |:  27%|██▋       | 7/26 [00:17<00:50,  2.64s/it]\u001b[A\n","Training loss: 0.48490235, IoU: 0.9552786471714859 |:  27%|██▋       | 7/26 [00:20<00:50,  2.64s/it]\u001b[A\n","Training loss: 0.48490235, IoU: 0.9552786471714859 |:  31%|███       | 8/26 [00:20<00:48,  2.68s/it]\u001b[A\n","Training loss: 0.4524644, IoU: 0.9559202360235275 |:  31%|███       | 8/26 [00:23<00:48,  2.68s/it] \u001b[A\n","Training loss: 0.4524644, IoU: 0.9559202360235275 |:  35%|███▍      | 9/26 [00:23<00:46,  2.71s/it]\u001b[A\n","Training loss: 0.41685402, IoU: 0.94568949487066 |:  35%|███▍      | 9/26 [00:25<00:46,  2.71s/it] \u001b[A\n","Training loss: 0.41685402, IoU: 0.94568949487066 |:  38%|███▊      | 10/26 [00:26<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.34220362, IoU: 0.9460847483323226 |:  38%|███▊      | 10/26 [00:28<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.34220362, IoU: 0.9460847483323226 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.45587203, IoU: 0.945250950012397 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it] \u001b[A\n","Training loss: 0.45587203, IoU: 0.945250950012397 |:  46%|████▌     | 12/26 [00:31<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.41171858, IoU: 0.9579220156372593 |:  46%|████▌     | 12/26 [00:34<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.41171858, IoU: 0.9579220156372593 |:  50%|█████     | 13/26 [00:34<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.43183482, IoU: 0.9458472771524186 |:  50%|█████     | 13/26 [00:37<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.43183482, IoU: 0.9458472771524186 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.45403033, IoU: 0.9551182346917972 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.45403033, IoU: 0.9551182346917972 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.45850462, IoU: 0.9564002349596576 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.45850462, IoU: 0.9564002349596576 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.477094, IoU: 0.9556623445158187 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.79s/it]  \u001b[A\n","Training loss: 0.477094, IoU: 0.9556623445158187 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.40703964, IoU: 0.9419611839362638 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.40703964, IoU: 0.9419611839362638 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.49280238, IoU: 0.9577302116487905 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.49280238, IoU: 0.9577302116487905 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.40034357, IoU: 0.9595924387344479 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.40034357, IoU: 0.9595924387344479 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.44816235, IoU: 0.9603272178162491 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.44816235, IoU: 0.9603272178162491 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.43400764, IoU: 0.9391276085027933 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.43400764, IoU: 0.9391276085027933 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.46574044, IoU: 0.9561068797230002 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.46574044, IoU: 0.9561068797230002 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.46045056, IoU: 0.9511343999856745 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.46045056, IoU: 0.9511343999856745 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.48732567, IoU: 0.9570241507454994 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.48732567, IoU: 0.9570241507454994 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.44916105, IoU: 0.950743637739645 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it] \u001b[A\n","Training loss: 0.44916105, IoU: 0.950743637739645 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  57%|█████▋    | 85/150 [2:04:31<1:25:30, 78.93s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46567875, IoU: 0.9555815858185882 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46567875, IoU: 0.9555815858185882 |:   4%|▍         | 1/26 [00:02<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.45202667, IoU: 0.9496524694496683 |:   4%|▍         | 1/26 [00:05<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.45202667, IoU: 0.9496524694496683 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.472529, IoU: 0.9562668922769839 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]  \u001b[A\n","Training loss: 0.472529, IoU: 0.9562668922769839 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.39260906, IoU: 0.9498847322644871 |:  12%|█▏        | 3/26 [00:09<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.39260906, IoU: 0.9498847322644871 |:  15%|█▌        | 4/26 [00:09<00:45,  2.06s/it]\u001b[A\n","Training loss: 0.4551589, IoU: 0.9590741678331397 |:  15%|█▌        | 4/26 [00:12<00:45,  2.06s/it] \u001b[A\n","Training loss: 0.4551589, IoU: 0.9590741678331397 |:  19%|█▉        | 5/26 [00:12<00:48,  2.33s/it]\u001b[A\n","Training loss: 0.49040008, IoU: 0.9453501748311485 |:  19%|█▉        | 5/26 [00:14<00:48,  2.33s/it]\u001b[A\n","Training loss: 0.49040008, IoU: 0.9453501748311485 |:  23%|██▎       | 6/26 [00:14<00:49,  2.48s/it]\u001b[A\n","Training loss: 0.42741203, IoU: 0.9635924148901778 |:  23%|██▎       | 6/26 [00:17<00:49,  2.48s/it]\u001b[A\n","Training loss: 0.42741203, IoU: 0.9635924148901778 |:  27%|██▋       | 7/26 [00:17<00:49,  2.59s/it]\u001b[A\n","Training loss: 0.44941628, IoU: 0.9566499218399309 |:  27%|██▋       | 7/26 [00:20<00:49,  2.59s/it]\u001b[A\n","Training loss: 0.44941628, IoU: 0.9566499218399309 |:  31%|███       | 8/26 [00:20<00:47,  2.65s/it]\u001b[A\n","Training loss: 0.4607528, IoU: 0.9498163189646456 |:  31%|███       | 8/26 [00:23<00:47,  2.65s/it] \u001b[A\n","Training loss: 0.4607528, IoU: 0.9498163189646456 |:  35%|███▍      | 9/26 [00:23<00:45,  2.70s/it]\u001b[A\n","Training loss: 0.40261075, IoU: 0.9557384974451618 |:  35%|███▍      | 9/26 [00:26<00:45,  2.70s/it]\u001b[A\n","Training loss: 0.40261075, IoU: 0.9557384974451618 |:  38%|███▊      | 10/26 [00:26<00:43,  2.73s/it]\u001b[A\n","Training loss: 0.44796234, IoU: 0.9509885428061489 |:  38%|███▊      | 10/26 [00:28<00:43,  2.73s/it]\u001b[A\n","Training loss: 0.44796234, IoU: 0.9509885428061489 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.47132212, IoU: 0.9528786355585149 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.47132212, IoU: 0.9528786355585149 |:  46%|████▌     | 12/26 [00:31<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.42859536, IoU: 0.9450727088265134 |:  46%|████▌     | 12/26 [00:34<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.42859536, IoU: 0.9450727088265134 |:  50%|█████     | 13/26 [00:34<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.5010954, IoU: 0.9464704449779077 |:  50%|█████     | 13/26 [00:37<00:35,  2.76s/it] \u001b[A\n","Training loss: 0.5010954, IoU: 0.9464704449779077 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.44488186, IoU: 0.953867861698405 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.44488186, IoU: 0.953867861698405 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.4521768, IoU: 0.9516715458269558 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.4521768, IoU: 0.9516715458269558 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.4722591, IoU: 0.9561868043216811 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.4722591, IoU: 0.9561868043216811 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.4720942, IoU: 0.9529621725510752 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.4720942, IoU: 0.9529621725510752 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.4373512, IoU: 0.9510020206822775 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.4373512, IoU: 0.9510020206822775 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.4541291, IoU: 0.9574748118528349 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.4541291, IoU: 0.9574748118528349 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.4310227, IoU: 0.9581011278761729 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.4310227, IoU: 0.9581011278761729 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.45304596, IoU: 0.9614493066477524 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.45304596, IoU: 0.9614493066477524 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.46033126, IoU: 0.9544208321427475 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.46033126, IoU: 0.9544208321427475 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4162523, IoU: 0.953263225339841 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]  \u001b[A\n","Training loss: 0.4162523, IoU: 0.953263225339841 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.44997418, IoU: 0.9440514904092354 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.44997418, IoU: 0.9440514904092354 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4828476, IoU: 0.9533294835799166 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it] \u001b[A\n","Training loss: 0.4828476, IoU: 0.9533294835799166 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  57%|█████▋    | 86/150 [2:05:50<1:24:07, 78.87s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.50618523, IoU: 0.9405162199783246 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.50618523, IoU: 0.9405162199783246 |:   4%|▍         | 1/26 [00:02<01:11,  2.86s/it]\u001b[A\n","Training loss: 0.47848386, IoU: 0.9454336814473532 |:   4%|▍         | 1/26 [00:05<01:11,  2.86s/it]\u001b[A\n","Training loss: 0.47848386, IoU: 0.9454336814473532 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.4182526, IoU: 0.9572272130210622 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it] \u001b[A\n","Training loss: 0.4182526, IoU: 0.9572272130210622 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.44384888, IoU: 0.9445533629295081 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.44384888, IoU: 0.9445533629295081 |:  15%|█▌        | 4/26 [00:11<01:02,  2.83s/it]\u001b[A\n","Training loss: 0.3251122, IoU: 0.9332766235128238 |:  15%|█▌        | 4/26 [00:12<01:02,  2.83s/it] \u001b[A\n","Training loss: 0.3251122, IoU: 0.9332766235128238 |:  19%|█▉        | 5/26 [00:12<00:45,  2.16s/it]\u001b[A\n","Training loss: 0.41882375, IoU: 0.9581867405090675 |:  19%|█▉        | 5/26 [00:15<00:45,  2.16s/it]\u001b[A\n","Training loss: 0.41882375, IoU: 0.9581867405090675 |:  23%|██▎       | 6/26 [00:15<00:47,  2.37s/it]\u001b[A\n","Training loss: 0.4415828, IoU: 0.9463533357399881 |:  23%|██▎       | 6/26 [00:17<00:47,  2.37s/it] \u001b[A\n","Training loss: 0.4415828, IoU: 0.9463533357399881 |:  27%|██▋       | 7/26 [00:17<00:47,  2.51s/it]\u001b[A\n","Training loss: 0.4622084, IoU: 0.9530384601850874 |:  27%|██▋       | 7/26 [00:20<00:47,  2.51s/it]\u001b[A\n","Training loss: 0.4622084, IoU: 0.9530384601850874 |:  31%|███       | 8/26 [00:20<00:46,  2.59s/it]\u001b[A\n","Training loss: 0.4216208, IoU: 0.9507655351525173 |:  31%|███       | 8/26 [00:23<00:46,  2.59s/it]\u001b[A\n","Training loss: 0.4216208, IoU: 0.9507655351525173 |:  35%|███▍      | 9/26 [00:23<00:45,  2.65s/it]\u001b[A\n","Training loss: 0.41490027, IoU: 0.938156828916778 |:  35%|███▍      | 9/26 [00:26<00:45,  2.65s/it]\u001b[A\n","Training loss: 0.41490027, IoU: 0.938156828916778 |:  38%|███▊      | 10/26 [00:26<00:43,  2.70s/it]\u001b[A\n","Training loss: 0.44996247, IoU: 0.9562083545375422 |:  38%|███▊      | 10/26 [00:28<00:43,  2.70s/it]\u001b[A\n","Training loss: 0.44996247, IoU: 0.9562083545375422 |:  42%|████▏     | 11/26 [00:28<00:40,  2.72s/it]\u001b[A\n","Training loss: 0.47001714, IoU: 0.9487557971861725 |:  42%|████▏     | 11/26 [00:31<00:40,  2.72s/it]\u001b[A\n","Training loss: 0.47001714, IoU: 0.9487557971861725 |:  46%|████▌     | 12/26 [00:31<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.50360763, IoU: 0.9613546943102839 |:  46%|████▌     | 12/26 [00:34<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.50360763, IoU: 0.9613546943102839 |:  50%|█████     | 13/26 [00:34<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.4637341, IoU: 0.9510532281278291 |:  50%|█████     | 13/26 [00:37<00:35,  2.76s/it] \u001b[A\n","Training loss: 0.4637341, IoU: 0.9510532281278291 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.42256552, IoU: 0.9592749998392603 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.42256552, IoU: 0.9592749998392603 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.43894178, IoU: 0.9633115477610837 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.43894178, IoU: 0.9633115477610837 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44773728, IoU: 0.9528551053827056 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44773728, IoU: 0.9528551053827056 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.46684453, IoU: 0.9562645318892192 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.46684453, IoU: 0.9562645318892192 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.47689435, IoU: 0.9534266895227242 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.47689435, IoU: 0.9534266895227242 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.4631981, IoU: 0.9482087557927769 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.78s/it] \u001b[A\n","Training loss: 0.4631981, IoU: 0.9482087557927769 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.38652888, IoU: 0.955918985405383 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.38652888, IoU: 0.955918985405383 |:  81%|████████  | 21/26 [00:56<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.4609177, IoU: 0.9467431538304999 |:  81%|████████  | 21/26 [00:59<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.4609177, IoU: 0.9467431538304999 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.48407024, IoU: 0.9485068175793271 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.48407024, IoU: 0.9485068175793271 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.41989762, IoU: 0.9406563814292334 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.41989762, IoU: 0.9406563814292334 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.44915506, IoU: 0.951576772037925 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.80s/it] \u001b[A\n","Training loss: 0.44915506, IoU: 0.951576772037925 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.40350664, IoU: 0.9540146146543921 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.40350664, IoU: 0.9540146146543921 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  58%|█████▊    | 87/150 [2:07:09<1:22:49, 78.88s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48423064, IoU: 0.9395628039072249 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48423064, IoU: 0.9395628039072249 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.3847077, IoU: 0.9485081797605912 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it] \u001b[A\n","Training loss: 0.3847077, IoU: 0.9485081797605912 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.5097094, IoU: 0.951666100041062 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it] \u001b[A\n","Training loss: 0.5097094, IoU: 0.951666100041062 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.4112247, IoU: 0.9419374940082447 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.4112247, IoU: 0.9419374940082447 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.45252523, IoU: 0.9537236445869485 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.45252523, IoU: 0.9537236445869485 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.4092369, IoU: 0.9544395742016281 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it] \u001b[A\n","Training loss: 0.4092369, IoU: 0.9544395742016281 |:  23%|██▎       | 6/26 [00:14<00:43,  2.17s/it]\u001b[A\n","Training loss: 0.43000844, IoU: 0.942751352183609 |:  23%|██▎       | 6/26 [00:17<00:43,  2.17s/it]\u001b[A\n","Training loss: 0.43000844, IoU: 0.942751352183609 |:  27%|██▋       | 7/26 [00:17<00:45,  2.38s/it]\u001b[A\n","Training loss: 0.5050799, IoU: 0.9520928391953809 |:  27%|██▋       | 7/26 [00:20<00:45,  2.38s/it]\u001b[A\n","Training loss: 0.5050799, IoU: 0.9520928391953809 |:  31%|███       | 8/26 [00:20<00:45,  2.50s/it]\u001b[A\n","Training loss: 0.469137, IoU: 0.9574410910490211 |:  31%|███       | 8/26 [00:23<00:45,  2.50s/it] \u001b[A\n","Training loss: 0.469137, IoU: 0.9574410910490211 |:  35%|███▍      | 9/26 [00:23<00:44,  2.60s/it]\u001b[A\n","Training loss: 0.46047944, IoU: 0.9538012594736535 |:  35%|███▍      | 9/26 [00:26<00:44,  2.60s/it]\u001b[A\n","Training loss: 0.46047944, IoU: 0.9538012594736535 |:  38%|███▊      | 10/26 [00:26<00:42,  2.66s/it]\u001b[A\n","Training loss: 0.5159284, IoU: 0.9563923241137587 |:  38%|███▊      | 10/26 [00:28<00:42,  2.66s/it] \u001b[A\n","Training loss: 0.5159284, IoU: 0.9563923241137587 |:  42%|████▏     | 11/26 [00:28<00:40,  2.69s/it]\u001b[A\n","Training loss: 0.45048326, IoU: 0.9511382719478781 |:  42%|████▏     | 11/26 [00:31<00:40,  2.69s/it]\u001b[A\n","Training loss: 0.45048326, IoU: 0.9511382719478781 |:  46%|████▌     | 12/26 [00:31<00:38,  2.72s/it]\u001b[A\n","Training loss: 0.45039314, IoU: 0.951935432459085 |:  46%|████▌     | 12/26 [00:34<00:38,  2.72s/it] \u001b[A\n","Training loss: 0.45039314, IoU: 0.951935432459085 |:  50%|█████     | 13/26 [00:34<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.4428027, IoU: 0.9505665160061736 |:  50%|█████     | 13/26 [00:37<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.4428027, IoU: 0.9505665160061736 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.48604596, IoU: 0.9522132637914466 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.48604596, IoU: 0.9522132637914466 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.45700666, IoU: 0.9560277958509396 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.45700666, IoU: 0.9560277958509396 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.4415368, IoU: 0.9537997239658171 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.79s/it] \u001b[A\n","Training loss: 0.4415368, IoU: 0.9537997239658171 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.5033985, IoU: 0.9542198323411059 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.5033985, IoU: 0.9542198323411059 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.4511856, IoU: 0.9400381253788247 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.4511856, IoU: 0.9400381253788247 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.4450726, IoU: 0.9533559463092393 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.4450726, IoU: 0.9533559463092393 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.39093345, IoU: 0.9538336713995943 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.39093345, IoU: 0.9538336713995943 |:  81%|████████  | 21/26 [00:57<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.5001185, IoU: 0.956509797680591 |:  81%|████████  | 21/26 [00:59<00:14,  2.81s/it]  \u001b[A\n","Training loss: 0.5001185, IoU: 0.956509797680591 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.44205794, IoU: 0.9567669129861947 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.44205794, IoU: 0.9567669129861947 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.45313603, IoU: 0.9350443125118113 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.45313603, IoU: 0.9350443125118113 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.43236196, IoU: 0.9541056352046142 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.43236196, IoU: 0.9541056352046142 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.81s/it]\u001b[A\n","Training loss: 0.4645179, IoU: 0.9556829341791196 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.81s/it] \u001b[A\n","Training loss: 0.4645179, IoU: 0.9556829341791196 |: 100%|██████████| 26/26 [01:11<00:00,  2.73s/it]\n","Epoch Loop:  59%|█████▊    | 88/150 [2:08:28<1:21:35, 78.95s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46317345, IoU: 0.9591821194142207 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46317345, IoU: 0.9591821194142207 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.42215037, IoU: 0.9452955007167091 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.42215037, IoU: 0.9452955007167091 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.5157118, IoU: 0.9492224824124086 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it] \u001b[A\n","Training loss: 0.5157118, IoU: 0.9492224824124086 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.45715022, IoU: 0.9520229945214962 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.45715022, IoU: 0.9520229945214962 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.45682722, IoU: 0.9542944331922706 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.45682722, IoU: 0.9542944331922706 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4612869, IoU: 0.9462420188996133 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it] \u001b[A\n","Training loss: 0.4612869, IoU: 0.9462420188996133 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.5369036, IoU: 0.9636668823107722 |:  23%|██▎       | 6/26 [00:17<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.5369036, IoU: 0.9636668823107722 |:  27%|██▋       | 7/26 [00:17<00:41,  2.19s/it]\u001b[A\n","Training loss: 0.4858375, IoU: 0.953397636916349 |:  27%|██▋       | 7/26 [00:20<00:41,  2.19s/it] \u001b[A\n","Training loss: 0.4858375, IoU: 0.953397636916349 |:  31%|███       | 8/26 [00:20<00:42,  2.38s/it]\u001b[A\n","Training loss: 0.4673576, IoU: 0.9458843315403562 |:  31%|███       | 8/26 [00:23<00:42,  2.38s/it]\u001b[A\n","Training loss: 0.4673576, IoU: 0.9458843315403562 |:  35%|███▍      | 9/26 [00:23<00:42,  2.50s/it]\u001b[A\n","Training loss: 0.424662, IoU: 0.9562784104794956 |:  35%|███▍      | 9/26 [00:26<00:42,  2.50s/it] \u001b[A\n","Training loss: 0.424662, IoU: 0.9562784104794956 |:  38%|███▊      | 10/26 [00:26<00:41,  2.59s/it]\u001b[A\n","Training loss: 0.41628388, IoU: 0.9503209775315727 |:  38%|███▊      | 10/26 [00:28<00:41,  2.59s/it]\u001b[A\n","Training loss: 0.41628388, IoU: 0.9503209775315727 |:  42%|████▏     | 11/26 [00:28<00:39,  2.66s/it]\u001b[A\n","Training loss: 0.48508117, IoU: 0.9562061141837958 |:  42%|████▏     | 11/26 [00:31<00:39,  2.66s/it]\u001b[A\n","Training loss: 0.48508117, IoU: 0.9562061141837958 |:  46%|████▌     | 12/26 [00:31<00:37,  2.70s/it]\u001b[A\n","Training loss: 0.49565184, IoU: 0.9489756686988521 |:  46%|████▌     | 12/26 [00:34<00:37,  2.70s/it]\u001b[A\n","Training loss: 0.49565184, IoU: 0.9489756686988521 |:  50%|█████     | 13/26 [00:34<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.45644647, IoU: 0.9561965984900163 |:  50%|█████     | 13/26 [00:37<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.45644647, IoU: 0.9561965984900163 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.46486515, IoU: 0.9341124269285334 |:  54%|█████▍    | 14/26 [00:40<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.46486515, IoU: 0.9341124269285334 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.4961989, IoU: 0.9535819565776334 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.76s/it] \u001b[A\n","Training loss: 0.4961989, IoU: 0.9535819565776334 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.46679503, IoU: 0.9568988210852846 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.46679503, IoU: 0.9568988210852846 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.45873982, IoU: 0.955839143789515 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.45873982, IoU: 0.955839143789515 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.3887275, IoU: 0.9602633395223144 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.3887275, IoU: 0.9602633395223144 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.4609714, IoU: 0.9597327446019912 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.4609714, IoU: 0.9597327446019912 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.4885993, IoU: 0.9517194677381127 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.4885993, IoU: 0.9517194677381127 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47095436, IoU: 0.9574094002106142 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47095436, IoU: 0.9574094002106142 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.44531694, IoU: 0.9497486524410457 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.44531694, IoU: 0.9497486524410457 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.45684043, IoU: 0.9545345097637206 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.45684043, IoU: 0.9545345097637206 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.42070565, IoU: 0.9561256471571518 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.42070565, IoU: 0.9561256471571518 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4415291, IoU: 0.9431350081640838 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it] \u001b[A\n","Training loss: 0.4415291, IoU: 0.9431350081640838 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  59%|█████▉    | 89/150 [2:09:47<1:20:10, 78.86s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.43076724, IoU: 0.9468398597736937 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.43076724, IoU: 0.9468398597736937 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.48332906, IoU: 0.9484049124336894 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.48332906, IoU: 0.9484049124336894 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.41063982, IoU: 0.9540613731075223 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.41063982, IoU: 0.9540613731075223 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.520697, IoU: 0.9573096814958695 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it]  \u001b[A\n","Training loss: 0.520697, IoU: 0.9573096814958695 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.4554816, IoU: 0.9585233681526163 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.4554816, IoU: 0.9585233681526163 |:  19%|█▉        | 5/26 [00:13<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.46074378, IoU: 0.9635441593788826 |:  19%|█▉        | 5/26 [00:16<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.46074378, IoU: 0.9635441593788826 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.49586272, IoU: 0.9563638492099301 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.49586272, IoU: 0.9563638492099301 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.38803095, IoU: 0.9356396371537957 |:  27%|██▋       | 7/26 [00:20<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.38803095, IoU: 0.9356396371537957 |:  31%|███       | 8/26 [00:20<00:39,  2.21s/it]\u001b[A\n","Training loss: 0.46580335, IoU: 0.9617629321982151 |:  31%|███       | 8/26 [00:23<00:39,  2.21s/it]\u001b[A\n","Training loss: 0.46580335, IoU: 0.9617629321982151 |:  35%|███▍      | 9/26 [00:23<00:40,  2.39s/it]\u001b[A\n","Training loss: 0.4973207, IoU: 0.9576323897415128 |:  35%|███▍      | 9/26 [00:26<00:40,  2.39s/it] \u001b[A\n","Training loss: 0.4973207, IoU: 0.9576323897415128 |:  38%|███▊      | 10/26 [00:26<00:40,  2.51s/it]\u001b[A\n","Training loss: 0.44048515, IoU: 0.9538924791180142 |:  38%|███▊      | 10/26 [00:28<00:40,  2.51s/it]\u001b[A\n","Training loss: 0.44048515, IoU: 0.9538924791180142 |:  42%|████▏     | 11/26 [00:28<00:38,  2.60s/it]\u001b[A\n","Training loss: 0.43399262, IoU: 0.9546271121224553 |:  42%|████▏     | 11/26 [00:31<00:38,  2.60s/it]\u001b[A\n","Training loss: 0.43399262, IoU: 0.9546271121224553 |:  46%|████▌     | 12/26 [00:31<00:37,  2.66s/it]\u001b[A\n","Training loss: 0.44580096, IoU: 0.9497575304263403 |:  46%|████▌     | 12/26 [00:34<00:37,  2.66s/it]\u001b[A\n","Training loss: 0.44580096, IoU: 0.9497575304263403 |:  50%|█████     | 13/26 [00:34<00:35,  2.70s/it]\u001b[A\n","Training loss: 0.42308027, IoU: 0.9532842500360906 |:  50%|█████     | 13/26 [00:37<00:35,  2.70s/it]\u001b[A\n","Training loss: 0.42308027, IoU: 0.9532842500360906 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.43984225, IoU: 0.9423774662894514 |:  54%|█████▍    | 14/26 [00:40<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.43984225, IoU: 0.9423774662894514 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.44675505, IoU: 0.9579931882216592 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.44675505, IoU: 0.9579931882216592 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44679186, IoU: 0.9559298188472178 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44679186, IoU: 0.9559298188472178 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4063842, IoU: 0.9509896571638579 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.4063842, IoU: 0.9509896571638579 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.38275635, IoU: 0.9576116863922705 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.38275635, IoU: 0.9576116863922705 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.41370595, IoU: 0.9471516686475624 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.41370595, IoU: 0.9471516686475624 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.48468697, IoU: 0.9549340030757997 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.48468697, IoU: 0.9549340030757997 |:  81%|████████  | 21/26 [00:56<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.4280231, IoU: 0.9549573573021309 |:  81%|████████  | 21/26 [00:59<00:13,  2.80s/it] \u001b[A\n","Training loss: 0.4280231, IoU: 0.9549573573021309 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.3915382, IoU: 0.9541104288387747 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.3915382, IoU: 0.9541104288387747 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.4576692, IoU: 0.9402093272228692 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.4576692, IoU: 0.9402093272228692 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.48526666, IoU: 0.9538938822456402 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.48526666, IoU: 0.9538938822456402 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.81s/it]\u001b[A\n","Training loss: 0.45616958, IoU: 0.9495777557692513 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.81s/it]\u001b[A\n","Training loss: 0.45616958, IoU: 0.9495777557692513 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  60%|██████    | 90/150 [2:11:05<1:18:50, 78.85s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4325596, IoU: 0.9609385013714784 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4325596, IoU: 0.9609385013714784 |:   4%|▍         | 1/26 [00:02<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.47308427, IoU: 0.9469363235883059 |:   4%|▍         | 1/26 [00:05<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.47308427, IoU: 0.9469363235883059 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.46412632, IoU: 0.9450840760819627 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.46412632, IoU: 0.9450840760819627 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.5122173, IoU: 0.9501239688946252 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it] \u001b[A\n","Training loss: 0.5122173, IoU: 0.9501239688946252 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.49072587, IoU: 0.9655836150328097 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.49072587, IoU: 0.9655836150328097 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.41857034, IoU: 0.9580351057505754 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.41857034, IoU: 0.9580351057505754 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.48112053, IoU: 0.9423125971482331 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.48112053, IoU: 0.9423125971482331 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.47674757, IoU: 0.9533678391936229 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.47674757, IoU: 0.9533678391936229 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.45704755, IoU: 0.9528141802792713 |:  31%|███       | 8/26 [00:23<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.45704755, IoU: 0.9528141802792713 |:  35%|███▍      | 9/26 [00:23<00:37,  2.21s/it]\u001b[A\n","Training loss: 0.4696175, IoU: 0.9440431649883984 |:  35%|███▍      | 9/26 [00:26<00:37,  2.21s/it] \u001b[A\n","Training loss: 0.4696175, IoU: 0.9440431649883984 |:  38%|███▊      | 10/26 [00:26<00:38,  2.39s/it]\u001b[A\n","Training loss: 0.48198497, IoU: 0.9504339445871688 |:  38%|███▊      | 10/26 [00:28<00:38,  2.39s/it]\u001b[A\n","Training loss: 0.48198497, IoU: 0.9504339445871688 |:  42%|████▏     | 11/26 [00:28<00:37,  2.51s/it]\u001b[A\n","Training loss: 0.45012075, IoU: 0.9499679452933005 |:  42%|████▏     | 11/26 [00:31<00:37,  2.51s/it]\u001b[A\n","Training loss: 0.45012075, IoU: 0.9499679452933005 |:  46%|████▌     | 12/26 [00:31<00:36,  2.59s/it]\u001b[A\n","Training loss: 0.43510672, IoU: 0.9449173583925912 |:  46%|████▌     | 12/26 [00:34<00:36,  2.59s/it]\u001b[A\n","Training loss: 0.43510672, IoU: 0.9449173583925912 |:  50%|█████     | 13/26 [00:34<00:34,  2.65s/it]\u001b[A\n","Training loss: 0.4538928, IoU: 0.9601258553859405 |:  50%|█████     | 13/26 [00:37<00:34,  2.65s/it] \u001b[A\n","Training loss: 0.4538928, IoU: 0.9601258553859405 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.69s/it]\u001b[A\n","Training loss: 0.41953826, IoU: 0.9561686832379892 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.69s/it]\u001b[A\n","Training loss: 0.41953826, IoU: 0.9561686832379892 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.73s/it]\u001b[A\n","Training loss: 0.44045, IoU: 0.9633049817739976 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.73s/it]   \u001b[A\n","Training loss: 0.44045, IoU: 0.9633049817739976 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.39283043, IoU: 0.9584997547023937 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.39283043, IoU: 0.9584997547023937 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.4719727, IoU: 0.9538456899371172 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.76s/it] \u001b[A\n","Training loss: 0.4719727, IoU: 0.9538456899371172 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45127898, IoU: 0.9477798872438262 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45127898, IoU: 0.9477798872438262 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.37686375, IoU: 0.9556456318960023 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.37686375, IoU: 0.9556456318960023 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.427704, IoU: 0.9471178836983298 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]  \u001b[A\n","Training loss: 0.427704, IoU: 0.9471178836983298 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.43794164, IoU: 0.9512674634226852 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.43794164, IoU: 0.9512674634226852 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.42041925, IoU: 0.9571868772930175 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.42041925, IoU: 0.9571868772930175 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.47565937, IoU: 0.9550520203346348 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.47565937, IoU: 0.9550520203346348 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.43583226, IoU: 0.9467015762550272 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.43583226, IoU: 0.9467015762550272 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.46948725, IoU: 0.9517415974748457 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.46948725, IoU: 0.9517415974748457 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  61%|██████    | 91/150 [2:12:24<1:17:26, 78.76s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.43447432, IoU: 0.9561725099962735 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.43447432, IoU: 0.9561725099962735 |:   4%|▍         | 1/26 [00:02<01:10,  2.80s/it]\u001b[A\n","Training loss: 0.45541674, IoU: 0.9463000681932381 |:   4%|▍         | 1/26 [00:05<01:10,  2.80s/it]\u001b[A\n","Training loss: 0.45541674, IoU: 0.9463000681932381 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.44872126, IoU: 0.9543694944668071 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.44872126, IoU: 0.9543694944668071 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.46470302, IoU: 0.9411097404331625 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.46470302, IoU: 0.9411097404331625 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.40008613, IoU: 0.953714877564401 |:  15%|█▌        | 4/26 [00:14<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.40008613, IoU: 0.953714877564401 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.46903282, IoU: 0.9643809118879028 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.46903282, IoU: 0.9643809118879028 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.47223312, IoU: 0.9547429024710814 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.47223312, IoU: 0.9547429024710814 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.4947691, IoU: 0.958537832555161 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]  \u001b[A\n","Training loss: 0.4947691, IoU: 0.958537832555161 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.39352438, IoU: 0.9432856114153607 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.39352438, IoU: 0.9432856114153607 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.4180942, IoU: 0.9583196269277656 |:  35%|███▍      | 9/26 [00:26<00:47,  2.80s/it] \u001b[A\n","Training loss: 0.4180942, IoU: 0.9583196269277656 |:  38%|███▊      | 10/26 [00:26<00:35,  2.23s/it]\u001b[A\n","Training loss: 0.5175216, IoU: 0.9452800221320363 |:  38%|███▊      | 10/26 [00:28<00:35,  2.23s/it]\u001b[A\n","Training loss: 0.5175216, IoU: 0.9452800221320363 |:  42%|████▏     | 11/26 [00:28<00:36,  2.40s/it]\u001b[A\n","Training loss: 0.52303904, IoU: 0.952256829273769 |:  42%|████▏     | 11/26 [00:31<00:36,  2.40s/it]\u001b[A\n","Training loss: 0.52303904, IoU: 0.952256829273769 |:  46%|████▌     | 12/26 [00:31<00:35,  2.52s/it]\u001b[A\n","Training loss: 0.45656124, IoU: 0.9502991243813564 |:  46%|████▌     | 12/26 [00:34<00:35,  2.52s/it]\u001b[A\n","Training loss: 0.45656124, IoU: 0.9502991243813564 |:  50%|█████     | 13/26 [00:34<00:33,  2.59s/it]\u001b[A\n","Training loss: 0.42490512, IoU: 0.9494930109074625 |:  50%|█████     | 13/26 [00:37<00:33,  2.59s/it]\u001b[A\n","Training loss: 0.42490512, IoU: 0.9494930109074625 |:  54%|█████▍    | 14/26 [00:37<00:31,  2.67s/it]\u001b[A\n","Training loss: 0.43758523, IoU: 0.9495566403589887 |:  54%|█████▍    | 14/26 [00:40<00:31,  2.67s/it]\u001b[A\n","Training loss: 0.43758523, IoU: 0.9495566403589887 |:  58%|█████▊    | 15/26 [00:40<00:29,  2.70s/it]\u001b[A\n","Training loss: 0.43576324, IoU: 0.95803317117748 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.70s/it]  \u001b[A\n","Training loss: 0.43576324, IoU: 0.95803317117748 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.73s/it]\u001b[A\n","Training loss: 0.457527, IoU: 0.9465033783373086 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.73s/it]\u001b[A\n","Training loss: 0.457527, IoU: 0.9465033783373086 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.74s/it]\u001b[A\n","Training loss: 0.4378047, IoU: 0.9628192748643496 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.74s/it]\u001b[A\n","Training loss: 0.4378047, IoU: 0.9628192748643496 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.75s/it]\u001b[A\n","Training loss: 0.44176576, IoU: 0.9510848538218518 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.75s/it]\u001b[A\n","Training loss: 0.44176576, IoU: 0.9510848538218518 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.75s/it]\u001b[A\n","Training loss: 0.4705652, IoU: 0.9619223441741271 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.75s/it] \u001b[A\n","Training loss: 0.4705652, IoU: 0.9619223441741271 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.43697864, IoU: 0.9594311426413111 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.43697864, IoU: 0.9594311426413111 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.40999308, IoU: 0.9474734567757823 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.40999308, IoU: 0.9474734567757823 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.47715276, IoU: 0.9512620320620198 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.47715276, IoU: 0.9512620320620198 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.48422503, IoU: 0.9556508197076444 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.48422503, IoU: 0.9556508197076444 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.43542308, IoU: 0.9589194626710732 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.43542308, IoU: 0.9589194626710732 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.5158545, IoU: 0.9488775579270357 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it] \u001b[A\n","Training loss: 0.5158545, IoU: 0.9488775579270357 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  61%|██████▏   | 92/150 [2:13:43<1:16:05, 78.71s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.39780125, IoU: 0.9511469133209941 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.39780125, IoU: 0.9511469133209941 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.4769799, IoU: 0.9447209473286841 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it] \u001b[A\n","Training loss: 0.4769799, IoU: 0.9447209473286841 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.448241, IoU: 0.9584485344442056 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it] \u001b[A\n","Training loss: 0.448241, IoU: 0.9584485344442056 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.43446308, IoU: 0.9542172454569587 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.43446308, IoU: 0.9542172454569587 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46800852, IoU: 0.956338447372215 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.46800852, IoU: 0.956338447372215 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.42450494, IoU: 0.9585818809704227 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.42450494, IoU: 0.9585818809704227 |:  23%|██▎       | 6/26 [00:16<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.44977248, IoU: 0.9439036245585245 |:  23%|██▎       | 6/26 [00:19<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.44977248, IoU: 0.9439036245585245 |:  27%|██▋       | 7/26 [00:19<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.42790088, IoU: 0.956609727729433 |:  27%|██▋       | 7/26 [00:22<00:53,  2.81s/it] \u001b[A\n","Training loss: 0.42790088, IoU: 0.956609727729433 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.43086487, IoU: 0.9420689768112145 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.43086487, IoU: 0.9420689768112145 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.4098278, IoU: 0.946859175083967 |:  35%|███▍      | 9/26 [00:27<00:47,  2.80s/it]  \u001b[A\n","Training loss: 0.4098278, IoU: 0.946859175083967 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.46126667, IoU: 0.95135516292743 |:  38%|███▊      | 10/26 [00:28<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.46126667, IoU: 0.95135516292743 |:  42%|████▏     | 11/26 [00:28<00:33,  2.23s/it]\u001b[A\n","Training loss: 0.42325464, IoU: 0.957009169155627 |:  42%|████▏     | 11/26 [00:31<00:33,  2.23s/it]\u001b[A\n","Training loss: 0.42325464, IoU: 0.957009169155627 |:  46%|████▌     | 12/26 [00:31<00:33,  2.40s/it]\u001b[A\n","Training loss: 0.45205706, IoU: 0.9541907448116167 |:  46%|████▌     | 12/26 [00:34<00:33,  2.40s/it]\u001b[A\n","Training loss: 0.45205706, IoU: 0.9541907448116167 |:  50%|█████     | 13/26 [00:34<00:32,  2.51s/it]\u001b[A\n","Training loss: 0.45251286, IoU: 0.9537889419965259 |:  50%|█████     | 13/26 [00:37<00:32,  2.51s/it]\u001b[A\n","Training loss: 0.45251286, IoU: 0.9537889419965259 |:  54%|█████▍    | 14/26 [00:37<00:31,  2.59s/it]\u001b[A\n","Training loss: 0.4552155, IoU: 0.9494939000532737 |:  54%|█████▍    | 14/26 [00:40<00:31,  2.59s/it] \u001b[A\n","Training loss: 0.4552155, IoU: 0.9494939000532737 |:  58%|█████▊    | 15/26 [00:40<00:29,  2.65s/it]\u001b[A\n","Training loss: 0.47149318, IoU: 0.9520744840605827 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.65s/it]\u001b[A\n","Training loss: 0.47149318, IoU: 0.9520744840605827 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.69s/it]\u001b[A\n","Training loss: 0.469288, IoU: 0.942103639220009 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.69s/it]   \u001b[A\n","Training loss: 0.469288, IoU: 0.942103639220009 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.72s/it]\u001b[A\n","Training loss: 0.46099603, IoU: 0.9533097183837116 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.72s/it]\u001b[A\n","Training loss: 0.46099603, IoU: 0.9533097183837116 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.74s/it]\u001b[A\n","Training loss: 0.5261331, IoU: 0.9584988137449468 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.74s/it] \u001b[A\n","Training loss: 0.5261331, IoU: 0.9584988137449468 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.75s/it]\u001b[A\n","Training loss: 0.46185756, IoU: 0.9511730981256891 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.75s/it]\u001b[A\n","Training loss: 0.46185756, IoU: 0.9511730981256891 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.42629415, IoU: 0.9559355941742476 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.42629415, IoU: 0.9559355941742476 |:  81%|████████  | 21/26 [00:56<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.456815, IoU: 0.9509067922225128 |:  81%|████████  | 21/26 [00:59<00:13,  2.76s/it]  \u001b[A\n","Training loss: 0.456815, IoU: 0.9509067922225128 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.4343325, IoU: 0.9533124811775833 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.4343325, IoU: 0.9533124811775833 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.486318, IoU: 0.9577005840762374 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it] \u001b[A\n","Training loss: 0.486318, IoU: 0.9577005840762374 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.46541166, IoU: 0.9492211860336758 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.46541166, IoU: 0.9492211860336758 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4416399, IoU: 0.9579168508943883 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it] \u001b[A\n","Training loss: 0.4416399, IoU: 0.9579168508943883 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  62%|██████▏   | 93/150 [2:15:01<1:14:45, 78.69s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48206568, IoU: 0.9536095118537437 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48206568, IoU: 0.9536095118537437 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.42376277, IoU: 0.9565509203732375 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.42376277, IoU: 0.9565509203732375 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.47461772, IoU: 0.9478766719438422 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.47461772, IoU: 0.9478766719438422 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.4165423, IoU: 0.9494620374654237 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it] \u001b[A\n","Training loss: 0.4165423, IoU: 0.9494620374654237 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.4443367, IoU: 0.9519058996670937 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.4443367, IoU: 0.9519058996670937 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.49414313, IoU: 0.9526096740629613 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.49414313, IoU: 0.9526096740629613 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43840694, IoU: 0.9583237478260069 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43840694, IoU: 0.9583237478260069 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.5080586, IoU: 0.9585563100371715 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it] \u001b[A\n","Training loss: 0.5080586, IoU: 0.9585563100371715 |:  31%|███       | 8/26 [00:22<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.41584724, IoU: 0.9456929981477098 |:  31%|███       | 8/26 [00:25<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.41584724, IoU: 0.9456929981477098 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.43762898, IoU: 0.9460602212377539 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.43762898, IoU: 0.9460602212377539 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.49077445, IoU: 0.9581282898181022 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.49077445, IoU: 0.9581282898181022 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.35129938, IoU: 0.957685649685579 |:  42%|████▏     | 11/26 [00:31<00:41,  2.78s/it] \u001b[A\n","Training loss: 0.35129938, IoU: 0.957685649685579 |:  46%|████▌     | 12/26 [00:31<00:31,  2.23s/it]\u001b[A\n","Training loss: 0.4223483, IoU: 0.9541761920808353 |:  46%|████▌     | 12/26 [00:34<00:31,  2.23s/it]\u001b[A\n","Training loss: 0.4223483, IoU: 0.9541761920808353 |:  50%|█████     | 13/26 [00:34<00:31,  2.39s/it]\u001b[A\n","Training loss: 0.4654439, IoU: 0.9598190040590244 |:  50%|█████     | 13/26 [00:37<00:31,  2.39s/it]\u001b[A\n","Training loss: 0.4654439, IoU: 0.9598190040590244 |:  54%|█████▍    | 14/26 [00:37<00:30,  2.50s/it]\u001b[A\n","Training loss: 0.45413914, IoU: 0.954776673701554 |:  54%|█████▍    | 14/26 [00:39<00:30,  2.50s/it]\u001b[A\n","Training loss: 0.45413914, IoU: 0.954776673701554 |:  58%|█████▊    | 15/26 [00:39<00:28,  2.59s/it]\u001b[A\n","Training loss: 0.42003447, IoU: 0.9599918765231519 |:  58%|█████▊    | 15/26 [00:42<00:28,  2.59s/it]\u001b[A\n","Training loss: 0.42003447, IoU: 0.9599918765231519 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.65s/it]\u001b[A\n","Training loss: 0.41954625, IoU: 0.9436008261017486 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.65s/it]\u001b[A\n","Training loss: 0.41954625, IoU: 0.9436008261017486 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.69s/it]\u001b[A\n","Training loss: 0.47842908, IoU: 0.9551201229926679 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.69s/it]\u001b[A\n","Training loss: 0.47842908, IoU: 0.9551201229926679 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.73s/it]\u001b[A\n","Training loss: 0.4874649, IoU: 0.9532101032793686 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.73s/it] \u001b[A\n","Training loss: 0.4874649, IoU: 0.9532101032793686 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.44826224, IoU: 0.9503424995558363 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.44826224, IoU: 0.9503424995558363 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.41965333, IoU: 0.9508458829871426 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.41965333, IoU: 0.9508458829871426 |:  81%|████████  | 21/26 [00:56<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.4628593, IoU: 0.96244117971943 |:  81%|████████  | 21/26 [00:59<00:13,  2.79s/it]   \u001b[A\n","Training loss: 0.4628593, IoU: 0.96244117971943 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.4546031, IoU: 0.9555615472457358 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.4546031, IoU: 0.9555615472457358 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.48612005, IoU: 0.9572889017826601 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.48612005, IoU: 0.9572889017826601 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.4995389, IoU: 0.9373983089274759 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.80s/it] \u001b[A\n","Training loss: 0.4995389, IoU: 0.9373983089274759 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.5193913, IoU: 0.9481372902199973 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.5193913, IoU: 0.9481372902199973 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  63%|██████▎   | 94/150 [2:16:20<1:13:27, 78.70s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.43920538, IoU: 0.950953394043027 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.43920538, IoU: 0.950953394043027 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.44718653, IoU: 0.9523015521926605 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.44718653, IoU: 0.9523015521926605 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.45391476, IoU: 0.951835171535853 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it] \u001b[A\n","Training loss: 0.45391476, IoU: 0.951835171535853 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.4149735, IoU: 0.9556292696630732 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.4149735, IoU: 0.9556292696630732 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.45389515, IoU: 0.9538253657627435 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.45389515, IoU: 0.9538253657627435 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.45376962, IoU: 0.9516460047804313 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.45376962, IoU: 0.9516460047804313 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.4945493, IoU: 0.9470795127049083 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it] \u001b[A\n","Training loss: 0.4945493, IoU: 0.9470795127049083 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.43173298, IoU: 0.953087321051731 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.43173298, IoU: 0.953087321051731 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.45893428, IoU: 0.9490625537526518 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.45893428, IoU: 0.9490625537526518 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.42207617, IoU: 0.9522263903949669 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.42207617, IoU: 0.9522263903949669 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.45140153, IoU: 0.962520443185221 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it] \u001b[A\n","Training loss: 0.45140153, IoU: 0.962520443185221 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.52150905, IoU: 0.9421260972869347 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.52150905, IoU: 0.9421260972869347 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.39591756, IoU: 0.9626708391876357 |:  46%|████▌     | 12/26 [00:34<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.39591756, IoU: 0.9626708391876357 |:  50%|█████     | 13/26 [00:34<00:28,  2.23s/it]\u001b[A\n","Training loss: 0.44103003, IoU: 0.9540810255237633 |:  50%|█████     | 13/26 [00:37<00:28,  2.23s/it]\u001b[A\n","Training loss: 0.44103003, IoU: 0.9540810255237633 |:  54%|█████▍    | 14/26 [00:37<00:28,  2.39s/it]\u001b[A\n","Training loss: 0.3979091, IoU: 0.9538249250411935 |:  54%|█████▍    | 14/26 [00:40<00:28,  2.39s/it] \u001b[A\n","Training loss: 0.3979091, IoU: 0.9538249250411935 |:  58%|█████▊    | 15/26 [00:40<00:27,  2.53s/it]\u001b[A\n","Training loss: 0.47359824, IoU: 0.9511333409695443 |:  58%|█████▊    | 15/26 [00:42<00:27,  2.53s/it]\u001b[A\n","Training loss: 0.47359824, IoU: 0.9511333409695443 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.60s/it]\u001b[A\n","Training loss: 0.52793586, IoU: 0.9378321195276764 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.60s/it]\u001b[A\n","Training loss: 0.52793586, IoU: 0.9378321195276764 |:  65%|██████▌   | 17/26 [00:45<00:23,  2.66s/it]\u001b[A\n","Training loss: 0.45405877, IoU: 0.9540752159338374 |:  65%|██████▌   | 17/26 [00:48<00:23,  2.66s/it]\u001b[A\n","Training loss: 0.45405877, IoU: 0.9540752159338374 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.69s/it]\u001b[A\n","Training loss: 0.48593116, IoU: 0.9518056121348638 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.69s/it]\u001b[A\n","Training loss: 0.48593116, IoU: 0.9518056121348638 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.71s/it]\u001b[A\n","Training loss: 0.48321617, IoU: 0.9520505200594354 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.71s/it]\u001b[A\n","Training loss: 0.48321617, IoU: 0.9520505200594354 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.47539812, IoU: 0.9440704917202613 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.75s/it]\u001b[A\n","Training loss: 0.47539812, IoU: 0.9440704917202613 |:  81%|████████  | 21/26 [00:56<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.4804204, IoU: 0.9533251220919716 |:  81%|████████  | 21/26 [00:59<00:13,  2.75s/it] \u001b[A\n","Training loss: 0.4804204, IoU: 0.9533251220919716 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.75s/it]\u001b[A\n","Training loss: 0.3996777, IoU: 0.9654872002759614 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.75s/it]\u001b[A\n","Training loss: 0.3996777, IoU: 0.9654872002759614 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.46031907, IoU: 0.9548864922142998 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.46031907, IoU: 0.9548864922142998 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.41898817, IoU: 0.9561698158740926 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.41898817, IoU: 0.9561698158740926 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4618473, IoU: 0.9545326684567191 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it] \u001b[A\n","Training loss: 0.4618473, IoU: 0.9545326684567191 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  63%|██████▎   | 95/150 [2:17:39<1:12:06, 78.66s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.462317, IoU: 0.9444166166161414 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.462317, IoU: 0.9444166166161414 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.46697927, IoU: 0.9608420823438957 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.46697927, IoU: 0.9608420823438957 |:   8%|▊         | 2/26 [00:05<01:07,  2.79s/it]\u001b[A\n","Training loss: 0.5111389, IoU: 0.9518209816717279 |:   8%|▊         | 2/26 [00:08<01:07,  2.79s/it] \u001b[A\n","Training loss: 0.5111389, IoU: 0.9518209816717279 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.48898178, IoU: 0.9560366265943914 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.48898178, IoU: 0.9560366265943914 |:  15%|█▌        | 4/26 [00:11<01:01,  2.77s/it]\u001b[A\n","Training loss: 0.4145401, IoU: 0.9410227878807569 |:  15%|█▌        | 4/26 [00:13<01:01,  2.77s/it] \u001b[A\n","Training loss: 0.4145401, IoU: 0.9410227878807569 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.44751394, IoU: 0.9581803790990597 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.44751394, IoU: 0.9581803790990597 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.44229597, IoU: 0.9630468276337149 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.44229597, IoU: 0.9630468276337149 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.43457812, IoU: 0.948845732458139 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it] \u001b[A\n","Training loss: 0.43457812, IoU: 0.948845732458139 |:  31%|███       | 8/26 [00:22<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.43870854, IoU: 0.9680785421763959 |:  31%|███       | 8/26 [00:24<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.43870854, IoU: 0.9680785421763959 |:  35%|███▍      | 9/26 [00:25<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.45413134, IoU: 0.9612384619645183 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.45413134, IoU: 0.9612384619645183 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.43770933, IoU: 0.9545854947636292 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.43770933, IoU: 0.9545854947636292 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.46150422, IoU: 0.9438593620328919 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.46150422, IoU: 0.9438593620328919 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.510854, IoU: 0.951108558249458 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]   \u001b[A\n","Training loss: 0.510854, IoU: 0.951108558249458 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.35567963, IoU: 0.9511585264210701 |:  50%|█████     | 13/26 [00:37<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.35567963, IoU: 0.9511585264210701 |:  54%|█████▍    | 14/26 [00:37<00:26,  2.23s/it]\u001b[A\n","Training loss: 0.45178267, IoU: 0.9509249854380383 |:  54%|█████▍    | 14/26 [00:39<00:26,  2.23s/it]\u001b[A\n","Training loss: 0.45178267, IoU: 0.9509249854380383 |:  58%|█████▊    | 15/26 [00:39<00:26,  2.39s/it]\u001b[A\n","Training loss: 0.40850353, IoU: 0.9528083307872492 |:  58%|█████▊    | 15/26 [00:42<00:26,  2.39s/it]\u001b[A\n","Training loss: 0.40850353, IoU: 0.9528083307872492 |:  62%|██████▏   | 16/26 [00:42<00:25,  2.50s/it]\u001b[A\n","Training loss: 0.4254716, IoU: 0.9483077417798859 |:  62%|██████▏   | 16/26 [00:45<00:25,  2.50s/it] \u001b[A\n","Training loss: 0.4254716, IoU: 0.9483077417798859 |:  65%|██████▌   | 17/26 [00:45<00:23,  2.59s/it]\u001b[A\n","Training loss: 0.45779496, IoU: 0.9337393627598444 |:  65%|██████▌   | 17/26 [00:48<00:23,  2.59s/it]\u001b[A\n","Training loss: 0.45779496, IoU: 0.9337393627598444 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.64s/it]\u001b[A\n","Training loss: 0.4783473, IoU: 0.9584932541558944 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.64s/it] \u001b[A\n","Training loss: 0.4783473, IoU: 0.9584932541558944 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.67s/it]\u001b[A\n","Training loss: 0.43663824, IoU: 0.958265384522775 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.67s/it]\u001b[A\n","Training loss: 0.43663824, IoU: 0.958265384522775 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.71s/it]\u001b[A\n","Training loss: 0.44364548, IoU: 0.9524345556576732 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.71s/it]\u001b[A\n","Training loss: 0.44364548, IoU: 0.9524345556576732 |:  81%|████████  | 21/26 [00:56<00:13,  2.74s/it]\u001b[A\n","Training loss: 0.46759343, IoU: 0.9367441929337901 |:  81%|████████  | 21/26 [00:59<00:13,  2.74s/it]\u001b[A\n","Training loss: 0.46759343, IoU: 0.9367441929337901 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.45479238, IoU: 0.9518230469140743 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.45479238, IoU: 0.9518230469140743 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.44105497, IoU: 0.961764937377633 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.44105497, IoU: 0.961764937377633 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.420641, IoU: 0.9569126480592478 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it] \u001b[A\n","Training loss: 0.420641, IoU: 0.9569126480592478 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4583127, IoU: 0.9406363970957272 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4583127, IoU: 0.9406363970957272 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  64%|██████▍   | 96/150 [2:18:57<1:10:43, 78.58s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44046724, IoU: 0.952822998526808 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44046724, IoU: 0.952822998526808 |:   4%|▍         | 1/26 [00:02<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.43459827, IoU: 0.9604190366770174 |:   4%|▍         | 1/26 [00:05<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.43459827, IoU: 0.9604190366770174 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.44279397, IoU: 0.9450998956133324 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.44279397, IoU: 0.9450998956133324 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.42270812, IoU: 0.9523424397892251 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.42270812, IoU: 0.9523424397892251 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.39584613, IoU: 0.9517779733770049 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.39584613, IoU: 0.9517779733770049 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.43102905, IoU: 0.9640737000592335 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.43102905, IoU: 0.9640737000592335 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.40031543, IoU: 0.9461522211328564 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.40031543, IoU: 0.9461522211328564 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.5398633, IoU: 0.9608238632748374 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it] \u001b[A\n","Training loss: 0.5398633, IoU: 0.9608238632748374 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.45712972, IoU: 0.9599919005496705 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.45712972, IoU: 0.9599919005496705 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.4425037, IoU: 0.958422919051741 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]  \u001b[A\n","Training loss: 0.4425037, IoU: 0.958422919051741 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.48012888, IoU: 0.9486905591967647 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.48012888, IoU: 0.9486905591967647 |:  42%|████▏     | 11/26 [00:30<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.5104709, IoU: 0.9411603388384423 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it] \u001b[A\n","Training loss: 0.5104709, IoU: 0.9411603388384423 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.45324242, IoU: 0.9485227305334238 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.45324242, IoU: 0.9485227305334238 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.45865992, IoU: 0.9566995880316745 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.45865992, IoU: 0.9566995880316745 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.5359679, IoU: 0.942263811048839 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.78s/it]  \u001b[A\n","Training loss: 0.5359679, IoU: 0.942263811048839 |:  58%|█████▊    | 15/26 [00:40<00:24,  2.23s/it]\u001b[A\n","Training loss: 0.43797615, IoU: 0.9534541656594773 |:  58%|█████▊    | 15/26 [00:42<00:24,  2.23s/it]\u001b[A\n","Training loss: 0.43797615, IoU: 0.9534541656594773 |:  62%|██████▏   | 16/26 [00:42<00:23,  2.39s/it]\u001b[A\n","Training loss: 0.44509202, IoU: 0.9483265845979431 |:  62%|██████▏   | 16/26 [00:45<00:23,  2.39s/it]\u001b[A\n","Training loss: 0.44509202, IoU: 0.9483265845979431 |:  65%|██████▌   | 17/26 [00:45<00:22,  2.51s/it]\u001b[A\n","Training loss: 0.5006653, IoU: 0.9397100716780004 |:  65%|██████▌   | 17/26 [00:48<00:22,  2.51s/it] \u001b[A\n","Training loss: 0.5006653, IoU: 0.9397100716780004 |:  69%|██████▉   | 18/26 [00:48<00:20,  2.59s/it]\u001b[A\n","Training loss: 0.47249973, IoU: 0.9508390300569991 |:  69%|██████▉   | 18/26 [00:51<00:20,  2.59s/it]\u001b[A\n","Training loss: 0.47249973, IoU: 0.9508390300569991 |:  73%|███████▎  | 19/26 [00:51<00:18,  2.65s/it]\u001b[A\n","Training loss: 0.46481174, IoU: 0.9565393574949889 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.65s/it]\u001b[A\n","Training loss: 0.46481174, IoU: 0.9565393574949889 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.69s/it]\u001b[A\n","Training loss: 0.45265195, IoU: 0.9575732818379877 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.69s/it]\u001b[A\n","Training loss: 0.45265195, IoU: 0.9575732818379877 |:  81%|████████  | 21/26 [00:56<00:13,  2.72s/it]\u001b[A\n","Training loss: 0.44700834, IoU: 0.9464398955777397 |:  81%|████████  | 21/26 [00:59<00:13,  2.72s/it]\u001b[A\n","Training loss: 0.44700834, IoU: 0.9464398955777397 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.73s/it]\u001b[A\n","Training loss: 0.44545692, IoU: 0.9449615692425032 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.73s/it]\u001b[A\n","Training loss: 0.44545692, IoU: 0.9449615692425032 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.75s/it]\u001b[A\n","Training loss: 0.4463513, IoU: 0.9492203823323583 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.75s/it] \u001b[A\n","Training loss: 0.4463513, IoU: 0.9492203823323583 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.4636593, IoU: 0.9626427514629025 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.4636593, IoU: 0.9626427514629025 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.45217896, IoU: 0.9609806198291709 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.45217896, IoU: 0.9609806198291709 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  65%|██████▍   | 97/150 [2:20:15<1:09:23, 78.56s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45285314, IoU: 0.9521073960162098 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45285314, IoU: 0.9521073960162098 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.4758986, IoU: 0.9576704192339791 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it] \u001b[A\n","Training loss: 0.4758986, IoU: 0.9576704192339791 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.48003715, IoU: 0.9589887004370372 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.48003715, IoU: 0.9589887004370372 |:  12%|█▏        | 3/26 [00:08<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.5138548, IoU: 0.9564105089099242 |:  12%|█▏        | 3/26 [00:11<01:05,  2.83s/it] \u001b[A\n","Training loss: 0.5138548, IoU: 0.9564105089099242 |:  15%|█▌        | 4/26 [00:11<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.42146543, IoU: 0.9574949348482441 |:  15%|█▌        | 4/26 [00:14<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.42146543, IoU: 0.9574949348482441 |:  19%|█▉        | 5/26 [00:14<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.40284145, IoU: 0.9476067348602306 |:  19%|█▉        | 5/26 [00:16<00:59,  2.84s/it]\u001b[A\n","Training loss: 0.40284145, IoU: 0.9476067348602306 |:  23%|██▎       | 6/26 [00:16<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.46344694, IoU: 0.9474927409632816 |:  23%|██▎       | 6/26 [00:19<00:56,  2.83s/it]\u001b[A\n","Training loss: 0.46344694, IoU: 0.9474927409632816 |:  27%|██▋       | 7/26 [00:19<00:53,  2.84s/it]\u001b[A\n","Training loss: 0.4135341, IoU: 0.9571128613695343 |:  27%|██▋       | 7/26 [00:22<00:53,  2.84s/it] \u001b[A\n","Training loss: 0.4135341, IoU: 0.9571128613695343 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.43669677, IoU: 0.9524437056790596 |:  31%|███       | 8/26 [00:25<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.43669677, IoU: 0.9524437056790596 |:  35%|███▍      | 9/26 [00:25<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.45882183, IoU: 0.9477855520094589 |:  35%|███▍      | 9/26 [00:28<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.45882183, IoU: 0.9477855520094589 |:  38%|███▊      | 10/26 [00:28<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.43281424, IoU: 0.955219925132954 |:  38%|███▊      | 10/26 [00:31<00:45,  2.82s/it] \u001b[A\n","Training loss: 0.43281424, IoU: 0.955219925132954 |:  42%|████▏     | 11/26 [00:31<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.4053074, IoU: 0.9587571870853605 |:  42%|████▏     | 11/26 [00:33<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.4053074, IoU: 0.9587571870853605 |:  46%|████▌     | 12/26 [00:33<00:39,  2.82s/it]\u001b[A\n","Training loss: 0.5270741, IoU: 0.9596532485890901 |:  46%|████▌     | 12/26 [00:36<00:39,  2.82s/it]\u001b[A\n","Training loss: 0.5270741, IoU: 0.9596532485890901 |:  50%|█████     | 13/26 [00:36<00:36,  2.85s/it]\u001b[A\n","Training loss: 0.45395708, IoU: 0.9502560450552318 |:  50%|█████     | 13/26 [00:39<00:36,  2.85s/it]\u001b[A\n","Training loss: 0.45395708, IoU: 0.9502560450552318 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.83s/it]\u001b[A\n","Training loss: 0.49584287, IoU: 0.9522108159287643 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.83s/it]\u001b[A\n","Training loss: 0.49584287, IoU: 0.9522108159287643 |:  58%|█████▊    | 15/26 [00:42<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.41277155, IoU: 0.9640398626580688 |:  58%|█████▊    | 15/26 [00:43<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.41277155, IoU: 0.9640398626580688 |:  62%|██████▏   | 16/26 [00:43<00:22,  2.26s/it]\u001b[A\n","Training loss: 0.44780648, IoU: 0.9566713032960387 |:  62%|██████▏   | 16/26 [00:46<00:22,  2.26s/it]\u001b[A\n","Training loss: 0.44780648, IoU: 0.9566713032960387 |:  65%|██████▌   | 17/26 [00:46<00:21,  2.41s/it]\u001b[A\n","Training loss: 0.46816337, IoU: 0.9646915584415584 |:  65%|██████▌   | 17/26 [00:48<00:21,  2.41s/it]\u001b[A\n","Training loss: 0.46816337, IoU: 0.9646915584415584 |:  69%|██████▉   | 18/26 [00:48<00:20,  2.51s/it]\u001b[A\n","Training loss: 0.40625766, IoU: 0.9546411394007221 |:  69%|██████▉   | 18/26 [00:51<00:20,  2.51s/it]\u001b[A\n","Training loss: 0.40625766, IoU: 0.9546411394007221 |:  73%|███████▎  | 19/26 [00:51<00:18,  2.59s/it]\u001b[A\n","Training loss: 0.38912457, IoU: 0.941155630943147 |:  73%|███████▎  | 19/26 [00:54<00:18,  2.59s/it] \u001b[A\n","Training loss: 0.38912457, IoU: 0.941155630943147 |:  77%|███████▋  | 20/26 [00:54<00:15,  2.65s/it]\u001b[A\n","Training loss: 0.45834368, IoU: 0.9552125537348004 |:  77%|███████▋  | 20/26 [00:57<00:15,  2.65s/it]\u001b[A\n","Training loss: 0.45834368, IoU: 0.9552125537348004 |:  81%|████████  | 21/26 [00:57<00:13,  2.68s/it]\u001b[A\n","Training loss: 0.4822079, IoU: 0.9563042241958036 |:  81%|████████  | 21/26 [00:59<00:13,  2.68s/it] \u001b[A\n","Training loss: 0.4822079, IoU: 0.9563042241958036 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.72s/it]\u001b[A\n","Training loss: 0.5065368, IoU: 0.958484582968248 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.72s/it] \u001b[A\n","Training loss: 0.5065368, IoU: 0.958484582968248 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.74s/it]\u001b[A\n","Training loss: 0.4412764, IoU: 0.9528880075630058 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.74s/it]\u001b[A\n","Training loss: 0.4412764, IoU: 0.9528880075630058 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.75s/it]\u001b[A\n","Training loss: 0.43392462, IoU: 0.9515252701123381 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.75s/it]\u001b[A\n","Training loss: 0.43392462, IoU: 0.9515252701123381 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.44492406, IoU: 0.947570491774106 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.76s/it] \u001b[A\n","Training loss: 0.44492406, IoU: 0.947570491774106 |: 100%|██████████| 26/26 [01:11<00:00,  2.74s/it]\n","Epoch Loop:  65%|██████▌   | 98/150 [2:21:35<1:08:12, 78.70s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.443923, IoU: 0.9494657412883454 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.443923, IoU: 0.9494657412883454 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.3653045, IoU: 0.9441195849118761 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.3653045, IoU: 0.9441195849118761 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.47811294, IoU: 0.9522218747334603 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.47811294, IoU: 0.9522218747334603 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.42787874, IoU: 0.9462041529791145 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.42787874, IoU: 0.9462041529791145 |:  15%|█▌        | 4/26 [00:11<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.4193641, IoU: 0.9503091285518918 |:  15%|█▌        | 4/26 [00:14<01:02,  2.82s/it] \u001b[A\n","Training loss: 0.4193641, IoU: 0.9503091285518918 |:  19%|█▉        | 5/26 [00:14<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.44417787, IoU: 0.947245574488591 |:  19%|█▉        | 5/26 [00:16<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.44417787, IoU: 0.947245574488591 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.46479344, IoU: 0.9608993353533597 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.46479344, IoU: 0.9608993353533597 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.46329796, IoU: 0.9585672214096533 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.46329796, IoU: 0.9585672214096533 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.4601164, IoU: 0.9637674016915899 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it] \u001b[A\n","Training loss: 0.4601164, IoU: 0.9637674016915899 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.5320146, IoU: 0.9568225666954959 |:  35%|███▍      | 9/26 [00:28<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.5320146, IoU: 0.9568225666954959 |:  38%|███▊      | 10/26 [00:28<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.43157572, IoU: 0.9417199522468924 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.43157572, IoU: 0.9417199522468924 |:  42%|████▏     | 11/26 [00:30<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.4676425, IoU: 0.9538860196946297 |:  42%|████▏     | 11/26 [00:33<00:41,  2.80s/it] \u001b[A\n","Training loss: 0.4676425, IoU: 0.9538860196946297 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.5107819, IoU: 0.958459246227555 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it] \u001b[A\n","Training loss: 0.5107819, IoU: 0.958459246227555 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.45830548, IoU: 0.9404619588421143 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.45830548, IoU: 0.9404619588421143 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.5056376, IoU: 0.9553732336339883 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.79s/it] \u001b[A\n","Training loss: 0.5056376, IoU: 0.9553732336339883 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.4195876, IoU: 0.954669603524229 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it] \u001b[A\n","Training loss: 0.4195876, IoU: 0.954669603524229 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.586212, IoU: 0.9708891849515575 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.586212, IoU: 0.9708891849515575 |:  65%|██████▌   | 17/26 [00:45<00:20,  2.24s/it]\u001b[A\n","Training loss: 0.38434976, IoU: 0.9537283892034989 |:  65%|██████▌   | 17/26 [00:48<00:20,  2.24s/it]\u001b[A\n","Training loss: 0.38434976, IoU: 0.9537283892034989 |:  69%|██████▉   | 18/26 [00:48<00:19,  2.40s/it]\u001b[A\n","Training loss: 0.44609776, IoU: 0.9543450459006014 |:  69%|██████▉   | 18/26 [00:51<00:19,  2.40s/it]\u001b[A\n","Training loss: 0.44609776, IoU: 0.9543450459006014 |:  73%|███████▎  | 19/26 [00:51<00:17,  2.51s/it]\u001b[A\n","Training loss: 0.42334914, IoU: 0.9521034847364556 |:  73%|███████▎  | 19/26 [00:54<00:17,  2.51s/it]\u001b[A\n","Training loss: 0.42334914, IoU: 0.9521034847364556 |:  77%|███████▋  | 20/26 [00:54<00:15,  2.59s/it]\u001b[A\n","Training loss: 0.4661426, IoU: 0.9586647707274494 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.59s/it] \u001b[A\n","Training loss: 0.4661426, IoU: 0.9586647707274494 |:  81%|████████  | 21/26 [00:56<00:13,  2.66s/it]\u001b[A\n","Training loss: 0.51042634, IoU: 0.9502093687918646 |:  81%|████████  | 21/26 [00:59<00:13,  2.66s/it]\u001b[A\n","Training loss: 0.51042634, IoU: 0.9502093687918646 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.69s/it]\u001b[A\n","Training loss: 0.46978706, IoU: 0.9519494640915446 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.69s/it]\u001b[A\n","Training loss: 0.46978706, IoU: 0.9519494640915446 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.72s/it]\u001b[A\n","Training loss: 0.47986275, IoU: 0.9538241402267555 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.72s/it]\u001b[A\n","Training loss: 0.47986275, IoU: 0.9538241402267555 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.74s/it]\u001b[A\n","Training loss: 0.47060394, IoU: 0.9459957105164353 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.74s/it]\u001b[A\n","Training loss: 0.47060394, IoU: 0.9459957105164353 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.75s/it]\u001b[A\n","Training loss: 0.42640555, IoU: 0.9527489447556347 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.75s/it]\u001b[A\n","Training loss: 0.42640555, IoU: 0.9527489447556347 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  66%|██████▌   | 99/150 [2:22:53<1:06:53, 78.69s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46822047, IoU: 0.9513510537453201 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46822047, IoU: 0.9513510537453201 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.42209873, IoU: 0.9628750159581259 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.42209873, IoU: 0.9628750159581259 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.47008353, IoU: 0.9542566051157148 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.47008353, IoU: 0.9542566051157148 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.4462035, IoU: 0.9445334797795913 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it] \u001b[A\n","Training loss: 0.4462035, IoU: 0.9445334797795913 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.43734366, IoU: 0.9501594481296781 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.43734366, IoU: 0.9501594481296781 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.44501713, IoU: 0.9552736404572221 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.44501713, IoU: 0.9552736404572221 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43700856, IoU: 0.9516892577313611 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.43700856, IoU: 0.9516892577313611 |:  27%|██▋       | 7/26 [00:19<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.41807312, IoU: 0.9492719086876622 |:  27%|██▋       | 7/26 [00:22<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.41807312, IoU: 0.9492719086876622 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.42622164, IoU: 0.9492230304535463 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.42622164, IoU: 0.9492230304535463 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.47743595, IoU: 0.9565735796349762 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.47743595, IoU: 0.9565735796349762 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.46285114, IoU: 0.9626745100295324 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.46285114, IoU: 0.9626745100295324 |:  42%|████▏     | 11/26 [00:30<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.38902694, IoU: 0.9573625576572187 |:  42%|████▏     | 11/26 [00:33<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.38902694, IoU: 0.9573625576572187 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.44748226, IoU: 0.9578209530978031 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.44748226, IoU: 0.9578209530978031 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.49080992, IoU: 0.9459864272230873 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.49080992, IoU: 0.9459864272230873 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.4180004, IoU: 0.9591401567542647 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.79s/it] \u001b[A\n","Training loss: 0.4180004, IoU: 0.9591401567542647 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.42955005, IoU: 0.9507676141051108 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.42955005, IoU: 0.9507676141051108 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44758162, IoU: 0.9496531053341772 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44758162, IoU: 0.9496531053341772 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.47096932, IoU: 0.9420695935414952 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.47096932, IoU: 0.9420695935414952 |:  69%|██████▉   | 18/26 [00:48<00:17,  2.22s/it]\u001b[A\n","Training loss: 0.4498609, IoU: 0.9557273452359041 |:  69%|██████▉   | 18/26 [00:51<00:17,  2.22s/it] \u001b[A\n","Training loss: 0.4498609, IoU: 0.9557273452359041 |:  73%|███████▎  | 19/26 [00:51<00:16,  2.39s/it]\u001b[A\n","Training loss: 0.48620385, IoU: 0.9531856259678816 |:  73%|███████▎  | 19/26 [00:53<00:16,  2.39s/it]\u001b[A\n","Training loss: 0.48620385, IoU: 0.9531856259678816 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.51s/it]\u001b[A\n","Training loss: 0.4529468, IoU: 0.9592141277042481 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.51s/it] \u001b[A\n","Training loss: 0.4529468, IoU: 0.9592141277042481 |:  81%|████████  | 21/26 [00:56<00:12,  2.59s/it]\u001b[A\n","Training loss: 0.43857267, IoU: 0.959114139693356 |:  81%|████████  | 21/26 [00:59<00:12,  2.59s/it]\u001b[A\n","Training loss: 0.43857267, IoU: 0.959114139693356 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.64s/it]\u001b[A\n","Training loss: 0.46429312, IoU: 0.9495310351900644 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.64s/it]\u001b[A\n","Training loss: 0.46429312, IoU: 0.9495310351900644 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.4044462, IoU: 0.9555571375871286 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.69s/it] \u001b[A\n","Training loss: 0.4044462, IoU: 0.9555571375871286 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.71s/it]\u001b[A\n","Training loss: 0.45326558, IoU: 0.9597949633250759 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.71s/it]\u001b[A\n","Training loss: 0.45326558, IoU: 0.9597949633250759 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.72s/it]\u001b[A\n","Training loss: 0.4273634, IoU: 0.9519308383782792 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.72s/it] \u001b[A\n","Training loss: 0.4273634, IoU: 0.9519308383782792 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  67%|██████▋   | 100/150 [2:24:12<1:05:29, 78.59s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.49264327, IoU: 0.9523739847416033 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.49264327, IoU: 0.9523739847416033 |:   4%|▍         | 1/26 [00:02<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.45779085, IoU: 0.9503236200586204 |:   4%|▍         | 1/26 [00:05<01:08,  2.75s/it]\u001b[A\n","Training loss: 0.45779085, IoU: 0.9503236200586204 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.44891375, IoU: 0.9579875841582397 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.44891375, IoU: 0.9579875841582397 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.43631425, IoU: 0.9526100740503359 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.43631425, IoU: 0.9526100740503359 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.43382362, IoU: 0.9570521757882309 |:  15%|█▌        | 4/26 [00:14<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.43382362, IoU: 0.9570521757882309 |:  19%|█▉        | 5/26 [00:14<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.3871643, IoU: 0.9617106701149455 |:  19%|█▉        | 5/26 [00:16<00:59,  2.81s/it] \u001b[A\n","Training loss: 0.3871643, IoU: 0.9617106701149455 |:  23%|██▎       | 6/26 [00:16<00:56,  2.82s/it]\u001b[A\n","Training loss: 0.4213433, IoU: 0.9528534481626866 |:  23%|██▎       | 6/26 [00:19<00:56,  2.82s/it]\u001b[A\n","Training loss: 0.4213433, IoU: 0.9528534481626866 |:  27%|██▋       | 7/26 [00:19<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.4914161, IoU: 0.9499031534389507 |:  27%|██▋       | 7/26 [00:22<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.4914161, IoU: 0.9499031534389507 |:  31%|███       | 8/26 [00:22<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.5193647, IoU: 0.952560566096409 |:  31%|███       | 8/26 [00:25<00:50,  2.81s/it] \u001b[A\n","Training loss: 0.5193647, IoU: 0.952560566096409 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.47607827, IoU: 0.943120715815676 |:  35%|███▍      | 9/26 [00:28<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.47607827, IoU: 0.943120715815676 |:  38%|███▊      | 10/26 [00:28<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.48219746, IoU: 0.955674305405393 |:  38%|███▊      | 10/26 [00:30<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.48219746, IoU: 0.955674305405393 |:  42%|████▏     | 11/26 [00:30<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.46593428, IoU: 0.9583245059168911 |:  42%|████▏     | 11/26 [00:33<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.46593428, IoU: 0.9583245059168911 |:  46%|████▌     | 12/26 [00:33<00:39,  2.82s/it]\u001b[A\n","Training loss: 0.45567, IoU: 0.9486642950038207 |:  46%|████▌     | 12/26 [00:36<00:39,  2.82s/it]   \u001b[A\n","Training loss: 0.45567, IoU: 0.9486642950038207 |:  50%|█████     | 13/26 [00:36<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.4480675, IoU: 0.961006391273619 |:  50%|█████     | 13/26 [00:39<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.4480675, IoU: 0.961006391273619 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.4027862, IoU: 0.9463403956863318 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.4027862, IoU: 0.9463403956863318 |:  58%|█████▊    | 15/26 [00:42<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.45940006, IoU: 0.9552091325474878 |:  58%|█████▊    | 15/26 [00:45<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.45940006, IoU: 0.9552091325474878 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.82s/it]\u001b[A\n","Training loss: 0.43268847, IoU: 0.9597302761400918 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.82s/it]\u001b[A\n","Training loss: 0.43268847, IoU: 0.9597302761400918 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.4960221, IoU: 0.9318346259482874 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.82s/it] \u001b[A\n","Training loss: 0.4960221, IoU: 0.9318346259482874 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.82s/it]\u001b[A\n","Training loss: 0.50727487, IoU: 0.9596101757926603 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.82s/it]\u001b[A\n","Training loss: 0.50727487, IoU: 0.9596101757926603 |:  73%|███████▎  | 19/26 [00:51<00:15,  2.26s/it]\u001b[A\n","Training loss: 0.40631586, IoU: 0.9556149811049567 |:  73%|███████▎  | 19/26 [00:54<00:15,  2.26s/it]\u001b[A\n","Training loss: 0.40631586, IoU: 0.9556149811049567 |:  77%|███████▋  | 20/26 [00:54<00:14,  2.44s/it]\u001b[A\n","Training loss: 0.46031743, IoU: 0.9595627472071773 |:  77%|███████▋  | 20/26 [00:57<00:14,  2.44s/it]\u001b[A\n","Training loss: 0.46031743, IoU: 0.9595627472071773 |:  81%|████████  | 21/26 [00:57<00:12,  2.55s/it]\u001b[A\n","Training loss: 0.4359857, IoU: 0.9569907855238718 |:  81%|████████  | 21/26 [01:00<00:12,  2.55s/it] \u001b[A\n","Training loss: 0.4359857, IoU: 0.9569907855238718 |:  85%|████████▍ | 22/26 [01:00<00:10,  2.65s/it]\u001b[A\n","Training loss: 0.46747878, IoU: 0.956444594981892 |:  85%|████████▍ | 22/26 [01:03<00:10,  2.65s/it]\u001b[A\n","Training loss: 0.46747878, IoU: 0.956444594981892 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.70s/it]\u001b[A\n","Training loss: 0.4437566, IoU: 0.9581371744748363 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.70s/it]\u001b[A\n","Training loss: 0.4437566, IoU: 0.9581371744748363 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.4488304, IoU: 0.9541213211388867 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.73s/it]\u001b[A\n","Training loss: 0.4488304, IoU: 0.9541213211388867 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.75s/it]\u001b[A\n","Training loss: 0.4796166, IoU: 0.953023985217423 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.75s/it] \u001b[A\n","Training loss: 0.4796166, IoU: 0.953023985217423 |: 100%|██████████| 26/26 [01:11<00:00,  2.75s/it]\n","Epoch Loop:  67%|██████▋   | 101/150 [2:25:31<1:04:21, 78.82s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4478179, IoU: 0.944438281055468 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4478179, IoU: 0.944438281055468 |:   4%|▍         | 1/26 [00:02<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.4477687, IoU: 0.9570859640169285 |:   4%|▍         | 1/26 [00:05<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.4477687, IoU: 0.9570859640169285 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.5059905, IoU: 0.963077395132387 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it] \u001b[A\n","Training loss: 0.5059905, IoU: 0.963077395132387 |:  12%|█▏        | 3/26 [00:08<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.44188032, IoU: 0.9522432624696938 |:  12%|█▏        | 3/26 [00:11<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.44188032, IoU: 0.9522432624696938 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.4514452, IoU: 0.9539318863105042 |:  15%|█▌        | 4/26 [00:14<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.4514452, IoU: 0.9539318863105042 |:  19%|█▉        | 5/26 [00:14<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.40750268, IoU: 0.9573073192994467 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.40750268, IoU: 0.9573073192994467 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.46631822, IoU: 0.9603429456880841 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.46631822, IoU: 0.9603429456880841 |:  27%|██▋       | 7/26 [00:19<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.4105844, IoU: 0.957094502954323 |:  27%|██▋       | 7/26 [00:22<00:52,  2.79s/it]  \u001b[A\n","Training loss: 0.4105844, IoU: 0.957094502954323 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.5184219, IoU: 0.9513060914805983 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.5184219, IoU: 0.9513060914805983 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.47125494, IoU: 0.9514870595911266 |:  35%|███▍      | 9/26 [00:27<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.47125494, IoU: 0.9514870595911266 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.5100871, IoU: 0.9531738732743645 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it] \u001b[A\n","Training loss: 0.5100871, IoU: 0.9531738732743645 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.45673257, IoU: 0.9536752711993531 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.45673257, IoU: 0.9536752711993531 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.4832885, IoU: 0.9537061300071624 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it] \u001b[A\n","Training loss: 0.4832885, IoU: 0.9537061300071624 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.43238345, IoU: 0.9533309090909091 |:  50%|█████     | 13/26 [00:39<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.43238345, IoU: 0.9533309090909091 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.4289965, IoU: 0.9468304651947941 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.80s/it] \u001b[A\n","Training loss: 0.4289965, IoU: 0.9468304651947941 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.411757, IoU: 0.9538855066089493 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it] \u001b[A\n","Training loss: 0.411757, IoU: 0.9538855066089493 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.45720458, IoU: 0.9535588372718649 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.45720458, IoU: 0.9535588372718649 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.5050296, IoU: 0.9538955491308544 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.78s/it] \u001b[A\n","Training loss: 0.5050296, IoU: 0.9538955491308544 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.43084726, IoU: 0.9548407511998197 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.43084726, IoU: 0.9548407511998197 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.4721185, IoU: 0.9671640607970196 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it] \u001b[A\n","Training loss: 0.4721185, IoU: 0.9671640607970196 |:  77%|███████▋  | 20/26 [00:53<00:13,  2.22s/it]\u001b[A\n","Training loss: 0.45044097, IoU: 0.9469723329588723 |:  77%|███████▋  | 20/26 [00:56<00:13,  2.22s/it]\u001b[A\n","Training loss: 0.45044097, IoU: 0.9469723329588723 |:  81%|████████  | 21/26 [00:56<00:11,  2.38s/it]\u001b[A\n","Training loss: 0.4210343, IoU: 0.9495162090161571 |:  81%|████████  | 21/26 [00:59<00:11,  2.38s/it] \u001b[A\n","Training loss: 0.4210343, IoU: 0.9495162090161571 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.50s/it]\u001b[A\n","Training loss: 0.4861943, IoU: 0.9527462003272507 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.50s/it]\u001b[A\n","Training loss: 0.4861943, IoU: 0.9527462003272507 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.59s/it]\u001b[A\n","Training loss: 0.4655319, IoU: 0.9523555723470717 |:  88%|████████▊ | 23/26 [01:05<00:07,  2.59s/it]\u001b[A\n","Training loss: 0.4655319, IoU: 0.9523555723470717 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.65s/it]\u001b[A\n","Training loss: 0.42122677, IoU: 0.9525827619033074 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.65s/it]\u001b[A\n","Training loss: 0.42122677, IoU: 0.9525827619033074 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.41019526, IoU: 0.9622867958138499 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.68s/it]\u001b[A\n","Training loss: 0.41019526, IoU: 0.9622867958138499 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  68%|██████▊   | 102/150 [2:26:49<1:02:58, 78.71s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45892638, IoU: 0.9602367786592907 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45892638, IoU: 0.9602367786592907 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.4406982, IoU: 0.954065399254619 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]  \u001b[A\n","Training loss: 0.4406982, IoU: 0.954065399254619 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.423359, IoU: 0.957794521704067 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it] \u001b[A\n","Training loss: 0.423359, IoU: 0.957794521704067 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.435604, IoU: 0.9526693471625823 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.435604, IoU: 0.9526693471625823 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.45970497, IoU: 0.9517111991269267 |:  15%|█▌        | 4/26 [00:14<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.45970497, IoU: 0.9517111991269267 |:  19%|█▉        | 5/26 [00:14<00:59,  2.83s/it]\u001b[A\n","Training loss: 0.51589423, IoU: 0.9545764021342862 |:  19%|█▉        | 5/26 [00:16<00:59,  2.83s/it]\u001b[A\n","Training loss: 0.51589423, IoU: 0.9545764021342862 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.4185914, IoU: 0.9560011460682465 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it] \u001b[A\n","Training loss: 0.4185914, IoU: 0.9560011460682465 |:  27%|██▋       | 7/26 [00:19<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.45488662, IoU: 0.9578599984495952 |:  27%|██▋       | 7/26 [00:22<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.45488662, IoU: 0.9578599984495952 |:  31%|███       | 8/26 [00:22<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.45514286, IoU: 0.9612915825486238 |:  31%|███       | 8/26 [00:25<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.45514286, IoU: 0.9612915825486238 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.45274323, IoU: 0.961847948465267 |:  35%|███▍      | 9/26 [00:27<00:47,  2.80s/it] \u001b[A\n","Training loss: 0.45274323, IoU: 0.961847948465267 |:  38%|███▊      | 10/26 [00:27<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.40810627, IoU: 0.955913037801136 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.40810627, IoU: 0.955913037801136 |:  42%|████▏     | 11/26 [00:30<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.5087442, IoU: 0.9500963081144614 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.5087442, IoU: 0.9500963081144614 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.4717514, IoU: 0.9497905755417979 |:  46%|████▌     | 12/26 [00:36<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.4717514, IoU: 0.9497905755417979 |:  50%|█████     | 13/26 [00:36<00:36,  2.82s/it]\u001b[A\n","Training loss: 0.46540472, IoU: 0.9500502001747617 |:  50%|█████     | 13/26 [00:39<00:36,  2.82s/it]\u001b[A\n","Training loss: 0.46540472, IoU: 0.9500502001747617 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.44247988, IoU: 0.9508138006988546 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.44247988, IoU: 0.9508138006988546 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.46913403, IoU: 0.9604098901072167 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.46913403, IoU: 0.9604098901072167 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.44527316, IoU: 0.9462752797405957 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.44527316, IoU: 0.9462752797405957 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.38610289, IoU: 0.9598451630583722 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.38610289, IoU: 0.9598451630583722 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.45465022, IoU: 0.9616398759943072 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.45465022, IoU: 0.9616398759943072 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.42430657, IoU: 0.9607280881605413 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.42430657, IoU: 0.9607280881605413 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.49249554, IoU: 0.967535557103774 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it] \u001b[A\n","Training loss: 0.49249554, IoU: 0.967535557103774 |:  81%|████████  | 21/26 [00:56<00:11,  2.22s/it]\u001b[A\n","Training loss: 0.43154022, IoU: 0.9547025481540931 |:  81%|████████  | 21/26 [00:59<00:11,  2.22s/it]\u001b[A\n","Training loss: 0.43154022, IoU: 0.9547025481540931 |:  85%|████████▍ | 22/26 [00:59<00:09,  2.39s/it]\u001b[A\n","Training loss: 0.39730194, IoU: 0.9574997376685 |:  85%|████████▍ | 22/26 [01:02<00:09,  2.39s/it]   \u001b[A\n","Training loss: 0.39730194, IoU: 0.9574997376685 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.51s/it]\u001b[A\n","Training loss: 0.49405327, IoU: 0.9577555235872789 |:  88%|████████▊ | 23/26 [01:05<00:07,  2.51s/it]\u001b[A\n","Training loss: 0.49405327, IoU: 0.9577555235872789 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.59s/it]\u001b[A\n","Training loss: 0.42680338, IoU: 0.9501580647776092 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.59s/it]\u001b[A\n","Training loss: 0.42680338, IoU: 0.9501580647776092 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.64s/it]\u001b[A\n","Training loss: 0.4364936, IoU: 0.9547697449986611 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.64s/it] \u001b[A\n","Training loss: 0.4364936, IoU: 0.9547697449986611 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  69%|██████▊   | 103/150 [2:28:08<1:01:36, 78.64s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4533133, IoU: 0.9573661652239684 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4533133, IoU: 0.9573661652239684 |:   4%|▍         | 1/26 [00:02<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.45633864, IoU: 0.9553292213851651 |:   4%|▍         | 1/26 [00:05<01:08,  2.76s/it]\u001b[A\n","Training loss: 0.45633864, IoU: 0.9553292213851651 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.4540148, IoU: 0.962173642816754 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it]  \u001b[A\n","Training loss: 0.4540148, IoU: 0.962173642816754 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.46024263, IoU: 0.9427212309776282 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.46024263, IoU: 0.9427212309776282 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.43069118, IoU: 0.9585965969118013 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.43069118, IoU: 0.9585965969118013 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.50283104, IoU: 0.9516139053356559 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.50283104, IoU: 0.9516139053356559 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.5056137, IoU: 0.9410055262239917 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it] \u001b[A\n","Training loss: 0.5056137, IoU: 0.9410055262239917 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.45483834, IoU: 0.9526942186958364 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.45483834, IoU: 0.9526942186958364 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.4929037, IoU: 0.9516189007489397 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it] \u001b[A\n","Training loss: 0.4929037, IoU: 0.9516189007489397 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.4065963, IoU: 0.9534141032888089 |:  35%|███▍      | 9/26 [00:27<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.4065963, IoU: 0.9534141032888089 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.397484, IoU: 0.953588978756764 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]  \u001b[A\n","Training loss: 0.397484, IoU: 0.953588978756764 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.4495396, IoU: 0.9538779251268599 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.4495396, IoU: 0.9538779251268599 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.44803488, IoU: 0.9523008030755474 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.44803488, IoU: 0.9523008030755474 |:  50%|█████     | 13/26 [00:36<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.45514494, IoU: 0.9574974123576797 |:  50%|█████     | 13/26 [00:38<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.45514494, IoU: 0.9574974123576797 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.46203065, IoU: 0.9513052706750511 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.46203065, IoU: 0.9513052706750511 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.81s/it]\u001b[A\n","Training loss: 0.4272106, IoU: 0.9476725544209647 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.81s/it] \u001b[A\n","Training loss: 0.4272106, IoU: 0.9476725544209647 |:  62%|██████▏   | 16/26 [00:44<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.4573644, IoU: 0.9503518272819729 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.81s/it]\u001b[A\n","Training loss: 0.4573644, IoU: 0.9503518272819729 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.5097437, IoU: 0.9547217756234676 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.5097437, IoU: 0.9547217756234676 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.41339198, IoU: 0.9567541063986271 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.41339198, IoU: 0.9567541063986271 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.82s/it]\u001b[A\n","Training loss: 0.4428404, IoU: 0.9579557675223267 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.82s/it] \u001b[A\n","Training loss: 0.4428404, IoU: 0.9579557675223267 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.83s/it]\u001b[A\n","Training loss: 0.41364312, IoU: 0.9562935130953697 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.83s/it]\u001b[A\n","Training loss: 0.41364312, IoU: 0.9562935130953697 |:  81%|████████  | 21/26 [00:58<00:14,  2.83s/it]\u001b[A\n","Training loss: 0.4667341, IoU: 0.9326205159187023 |:  81%|████████  | 21/26 [00:59<00:14,  2.83s/it] \u001b[A\n","Training loss: 0.4667341, IoU: 0.9326205159187023 |:  85%|████████▍ | 22/26 [00:59<00:09,  2.27s/it]\u001b[A\n","Training loss: 0.46693814, IoU: 0.9503649291884586 |:  85%|████████▍ | 22/26 [01:02<00:09,  2.27s/it]\u001b[A\n","Training loss: 0.46693814, IoU: 0.9503649291884586 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.45s/it]\u001b[A\n","Training loss: 0.47461104, IoU: 0.964223772544358 |:  88%|████████▊ | 23/26 [01:05<00:07,  2.45s/it] \u001b[A\n","Training loss: 0.47461104, IoU: 0.964223772544358 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.56s/it]\u001b[A\n","Training loss: 0.4203477, IoU: 0.952131315635282 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.56s/it] \u001b[A\n","Training loss: 0.4203477, IoU: 0.952131315635282 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.63s/it]\u001b[A\n","Training loss: 0.46308357, IoU: 0.9635644441313089 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.63s/it]\u001b[A\n","Training loss: 0.46308357, IoU: 0.9635644441313089 |: 100%|██████████| 26/26 [01:11<00:00,  2.73s/it]\n","Epoch Loop:  69%|██████▉   | 104/150 [2:29:27<1:00:22, 78.75s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.53204143, IoU: 0.9396441073512252 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.53204143, IoU: 0.9396441073512252 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.4894209, IoU: 0.9442276871031199 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it] \u001b[A\n","Training loss: 0.4894209, IoU: 0.9442276871031199 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.458676, IoU: 0.9586887965975481 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it] \u001b[A\n","Training loss: 0.458676, IoU: 0.9586887965975481 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.48779082, IoU: 0.944898175647009 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.48779082, IoU: 0.944898175647009 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.46066684, IoU: 0.9538230397716878 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.46066684, IoU: 0.9538230397716878 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4776139, IoU: 0.9606747976746837 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it] \u001b[A\n","Training loss: 0.4776139, IoU: 0.9606747976746837 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.47790048, IoU: 0.9618106991964409 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.47790048, IoU: 0.9618106991964409 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.4229551, IoU: 0.9604645444748023 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it] \u001b[A\n","Training loss: 0.4229551, IoU: 0.9604645444748023 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.4213577, IoU: 0.9495179759782326 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.4213577, IoU: 0.9495179759782326 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.42250633, IoU: 0.953131297037405 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.42250633, IoU: 0.953131297037405 |:  38%|███▊      | 10/26 [00:27<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.52572197, IoU: 0.9456853055916775 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.52572197, IoU: 0.9456853055916775 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.45032287, IoU: 0.9500296289543259 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.45032287, IoU: 0.9500296289543259 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.41645807, IoU: 0.9548765022879357 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.41645807, IoU: 0.9548765022879357 |:  50%|█████     | 13/26 [00:36<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.40972283, IoU: 0.9460716143183411 |:  50%|█████     | 13/26 [00:39<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.40972283, IoU: 0.9460716143183411 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.48539877, IoU: 0.9581820301652411 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.48539877, IoU: 0.9581820301652411 |:  58%|█████▊    | 15/26 [00:42<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.42524567, IoU: 0.9528514353049456 |:  58%|█████▊    | 15/26 [00:44<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.42524567, IoU: 0.9528514353049456 |:  62%|██████▏   | 16/26 [00:44<00:28,  2.82s/it]\u001b[A\n","Training loss: 0.5111512, IoU: 0.9541515374708722 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.82s/it] \u001b[A\n","Training loss: 0.5111512, IoU: 0.9541515374708722 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.4431981, IoU: 0.9449473383143243 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.4431981, IoU: 0.9449473383143243 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.45737177, IoU: 0.9597302712938205 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.45737177, IoU: 0.9597302712938205 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.43867797, IoU: 0.9664830835226051 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.80s/it]\u001b[A\n","Training loss: 0.43867797, IoU: 0.9664830835226051 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.45562518, IoU: 0.9571758497044457 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.45562518, IoU: 0.9571758497044457 |:  81%|████████  | 21/26 [00:58<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.42272943, IoU: 0.9542051646529258 |:  81%|████████  | 21/26 [01:01<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.42272943, IoU: 0.9542051646529258 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.46074843, IoU: 0.965822367215278 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it] \u001b[A\n","Training loss: 0.46074843, IoU: 0.965822367215278 |:  88%|████████▊ | 23/26 [01:02<00:06,  2.23s/it]\u001b[A\n","Training loss: 0.41748783, IoU: 0.9561762603195708 |:  88%|████████▊ | 23/26 [01:05<00:06,  2.23s/it]\u001b[A\n","Training loss: 0.41748783, IoU: 0.9561762603195708 |:  92%|█████████▏| 24/26 [01:05<00:04,  2.40s/it]\u001b[A\n","Training loss: 0.42822152, IoU: 0.9539531123686338 |:  92%|█████████▏| 24/26 [01:08<00:04,  2.40s/it]\u001b[A\n","Training loss: 0.42822152, IoU: 0.9539531123686338 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.53s/it]\u001b[A\n","Training loss: 0.45296764, IoU: 0.9571565228921597 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.53s/it]\u001b[A\n","Training loss: 0.45296764, IoU: 0.9571565228921597 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  70%|███████   | 105/150 [2:30:46<59:04, 78.78s/it]  "]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4568004, IoU: 0.9557741494894966 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4568004, IoU: 0.9557741494894966 |:   4%|▍         | 1/26 [00:02<01:10,  2.81s/it]\u001b[A\n","Training loss: 0.46436566, IoU: 0.9508393810068887 |:   4%|▍         | 1/26 [00:05<01:10,  2.81s/it]\u001b[A\n","Training loss: 0.46436566, IoU: 0.9508393810068887 |:   8%|▊         | 2/26 [00:05<01:08,  2.85s/it]\u001b[A\n","Training loss: 0.45688975, IoU: 0.9524551696023307 |:   8%|▊         | 2/26 [00:08<01:08,  2.85s/it]\u001b[A\n","Training loss: 0.45688975, IoU: 0.9524551696023307 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.37685165, IoU: 0.9526367007407786 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.37685165, IoU: 0.9526367007407786 |:  15%|█▌        | 4/26 [00:11<01:02,  2.83s/it]\u001b[A\n","Training loss: 0.4742192, IoU: 0.9551618144388936 |:  15%|█▌        | 4/26 [00:14<01:02,  2.83s/it] \u001b[A\n","Training loss: 0.4742192, IoU: 0.9551618144388936 |:  19%|█▉        | 5/26 [00:14<00:59,  2.82s/it]\u001b[A\n","Training loss: 0.4640048, IoU: 0.9539949766290435 |:  19%|█▉        | 5/26 [00:16<00:59,  2.82s/it]\u001b[A\n","Training loss: 0.4640048, IoU: 0.9539949766290435 |:  23%|██▎       | 6/26 [00:16<00:56,  2.82s/it]\u001b[A\n","Training loss: 0.43959177, IoU: 0.9522255413949978 |:  23%|██▎       | 6/26 [00:19<00:56,  2.82s/it]\u001b[A\n","Training loss: 0.43959177, IoU: 0.9522255413949978 |:  27%|██▋       | 7/26 [00:19<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.4262293, IoU: 0.9532100792994087 |:  27%|██▋       | 7/26 [00:22<00:53,  2.82s/it] \u001b[A\n","Training loss: 0.4262293, IoU: 0.9532100792994087 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.47578388, IoU: 0.9578128743581276 |:  31%|███       | 8/26 [00:25<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.47578388, IoU: 0.9578128743581276 |:  35%|███▍      | 9/26 [00:25<00:47,  2.82s/it]\u001b[A\n","Training loss: 0.4506349, IoU: 0.9611777383807836 |:  35%|███▍      | 9/26 [00:28<00:47,  2.82s/it] \u001b[A\n","Training loss: 0.4506349, IoU: 0.9611777383807836 |:  38%|███▊      | 10/26 [00:28<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.46697912, IoU: 0.9554683459449381 |:  38%|███▊      | 10/26 [00:30<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.46697912, IoU: 0.9554683459449381 |:  42%|████▏     | 11/26 [00:30<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.42122263, IoU: 0.9568318628888905 |:  42%|████▏     | 11/26 [00:33<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.42122263, IoU: 0.9568318628888905 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.4970312, IoU: 0.9432675749752133 |:  46%|████▌     | 12/26 [00:36<00:39,  2.81s/it] \u001b[A\n","Training loss: 0.4970312, IoU: 0.9432675749752133 |:  50%|█████     | 13/26 [00:36<00:36,  2.81s/it]\u001b[A\n","Training loss: 0.44272113, IoU: 0.953648860948974 |:  50%|█████     | 13/26 [00:39<00:36,  2.81s/it]\u001b[A\n","Training loss: 0.44272113, IoU: 0.953648860948974 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.4862504, IoU: 0.9489958437160717 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.82s/it]\u001b[A\n","Training loss: 0.4862504, IoU: 0.9489958437160717 |:  58%|█████▊    | 15/26 [00:42<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.40745118, IoU: 0.9504717379807635 |:  58%|█████▊    | 15/26 [00:45<00:31,  2.83s/it]\u001b[A\n","Training loss: 0.40745118, IoU: 0.9504717379807635 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.82s/it]\u001b[A\n","Training loss: 0.44001588, IoU: 0.9499888537613489 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.82s/it]\u001b[A\n","Training loss: 0.44001588, IoU: 0.9499888537613489 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.42682084, IoU: 0.9515461786287522 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.82s/it]\u001b[A\n","Training loss: 0.42682084, IoU: 0.9515461786287522 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.43509668, IoU: 0.9588871997994954 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.43509668, IoU: 0.9588871997994954 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.4529452, IoU: 0.9431763766959298 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.81s/it] \u001b[A\n","Training loss: 0.4529452, IoU: 0.9431763766959298 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.4560107, IoU: 0.9519586814050333 |:  77%|███████▋  | 20/26 [00:59<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.4560107, IoU: 0.9519586814050333 |:  81%|████████  | 21/26 [00:59<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.44942212, IoU: 0.9468429963415934 |:  81%|████████  | 21/26 [01:01<00:14,  2.81s/it]\u001b[A\n","Training loss: 0.44942212, IoU: 0.9468429963415934 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.47600925, IoU: 0.9622172833050072 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.47600925, IoU: 0.9622172833050072 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.82s/it]\u001b[A\n","Training loss: 0.37553018, IoU: 0.9204462347491961 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.82s/it]\u001b[A\n","Training loss: 0.37553018, IoU: 0.9204462347491961 |:  92%|█████████▏| 24/26 [01:05<00:04,  2.26s/it]\u001b[A\n","Training loss: 0.42680368, IoU: 0.9485538082589634 |:  92%|█████████▏| 24/26 [01:08<00:04,  2.26s/it]\u001b[A\n","Training loss: 0.42680368, IoU: 0.9485538082589634 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.45s/it]\u001b[A\n","Training loss: 0.4970889, IoU: 0.9648637001513829 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.45s/it] \u001b[A\n","Training loss: 0.4970889, IoU: 0.9648637001513829 |: 100%|██████████| 26/26 [01:11<00:00,  2.75s/it]\n","Epoch Loop:  71%|███████   | 106/150 [2:32:05<57:55, 78.98s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.48973322, IoU: 0.9522738796457325 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.48973322, IoU: 0.9522738796457325 |:   4%|▍         | 1/26 [00:02<01:10,  2.80s/it]\u001b[A\n","Training loss: 0.44186586, IoU: 0.957679663583141 |:   4%|▍         | 1/26 [00:05<01:10,  2.80s/it] \u001b[A\n","Training loss: 0.44186586, IoU: 0.957679663583141 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.404069, IoU: 0.9423989301815643 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it] \u001b[A\n","Training loss: 0.404069, IoU: 0.9423989301815643 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.4318139, IoU: 0.9588817903104404 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.4318139, IoU: 0.9588817903104404 |:  15%|█▌        | 4/26 [00:11<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.46520567, IoU: 0.9558975160470351 |:  15%|█▌        | 4/26 [00:14<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.46520567, IoU: 0.9558975160470351 |:  19%|█▉        | 5/26 [00:14<00:59,  2.82s/it]\u001b[A\n","Training loss: 0.4465521, IoU: 0.950532945963832 |:  19%|█▉        | 5/26 [00:16<00:59,  2.82s/it]  \u001b[A\n","Training loss: 0.4465521, IoU: 0.950532945963832 |:  23%|██▎       | 6/26 [00:16<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.48118192, IoU: 0.9588112432738601 |:  23%|██▎       | 6/26 [00:19<00:56,  2.84s/it]\u001b[A\n","Training loss: 0.48118192, IoU: 0.9588112432738601 |:  27%|██▋       | 7/26 [00:19<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.4707772, IoU: 0.9620668016554331 |:  27%|██▋       | 7/26 [00:22<00:53,  2.82s/it] \u001b[A\n","Training loss: 0.4707772, IoU: 0.9620668016554331 |:  31%|███       | 8/26 [00:22<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.41791338, IoU: 0.9571972264219801 |:  31%|███       | 8/26 [00:25<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.41791338, IoU: 0.9571972264219801 |:  35%|███▍      | 9/26 [00:25<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.45374915, IoU: 0.9607932090615062 |:  35%|███▍      | 9/26 [00:28<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.45374915, IoU: 0.9607932090615062 |:  38%|███▊      | 10/26 [00:28<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.4458405, IoU: 0.9488502625384755 |:  38%|███▊      | 10/26 [00:31<00:45,  2.83s/it] \u001b[A\n","Training loss: 0.4458405, IoU: 0.9488502625384755 |:  42%|████▏     | 11/26 [00:31<00:42,  2.83s/it]\u001b[A\n","Training loss: 0.5239186, IoU: 0.9583846635264666 |:  42%|████▏     | 11/26 [00:33<00:42,  2.83s/it]\u001b[A\n","Training loss: 0.5239186, IoU: 0.9583846635264666 |:  46%|████▌     | 12/26 [00:33<00:39,  2.82s/it]\u001b[A\n","Training loss: 0.43086055, IoU: 0.96159927555643 |:  46%|████▌     | 12/26 [00:36<00:39,  2.82s/it] \u001b[A\n","Training loss: 0.43086055, IoU: 0.96159927555643 |:  50%|█████     | 13/26 [00:36<00:36,  2.82s/it]\u001b[A\n","Training loss: 0.44393894, IoU: 0.952448525597542 |:  50%|█████     | 13/26 [00:39<00:36,  2.82s/it]\u001b[A\n","Training loss: 0.44393894, IoU: 0.952448525597542 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.81s/it]\u001b[A\n","Training loss: 0.40707925, IoU: 0.9463298720436297 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.81s/it]\u001b[A\n","Training loss: 0.40707925, IoU: 0.9463298720436297 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.81s/it]\u001b[A\n","Training loss: 0.4261181, IoU: 0.9464259697932799 |:  58%|█████▊    | 15/26 [00:45<00:30,  2.81s/it] \u001b[A\n","Training loss: 0.4261181, IoU: 0.9464259697932799 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.82s/it]\u001b[A\n","Training loss: 0.45688534, IoU: 0.9476965124297226 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.82s/it]\u001b[A\n","Training loss: 0.45688534, IoU: 0.9476965124297226 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.81s/it]\u001b[A\n","Training loss: 0.4123789, IoU: 0.9515469627832142 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.81s/it] \u001b[A\n","Training loss: 0.4123789, IoU: 0.9515469627832142 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.48005575, IoU: 0.9575491326325268 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.81s/it]\u001b[A\n","Training loss: 0.48005575, IoU: 0.9575491326325268 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.48000145, IoU: 0.9470783746113434 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.48000145, IoU: 0.9470783746113434 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.81s/it]\u001b[A\n","Training loss: 0.3674013, IoU: 0.9531190671747297 |:  77%|███████▋  | 20/26 [00:59<00:16,  2.81s/it] \u001b[A\n","Training loss: 0.3674013, IoU: 0.9531190671747297 |:  81%|████████  | 21/26 [00:59<00:14,  2.82s/it]\u001b[A\n","Training loss: 0.4968585, IoU: 0.9523034164619382 |:  81%|████████  | 21/26 [01:01<00:14,  2.82s/it]\u001b[A\n","Training loss: 0.4968585, IoU: 0.9523034164619382 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.43129146, IoU: 0.9532607544866206 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.43129146, IoU: 0.9532607544866206 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.46016765, IoU: 0.9592759746495103 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.46016765, IoU: 0.9592759746495103 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.41186857, IoU: 0.9424042902926619 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.81s/it]\u001b[A\n","Training loss: 0.41186857, IoU: 0.9424042902926619 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.25s/it]\u001b[A\n","Training loss: 0.4195312, IoU: 0.955152805781473 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.25s/it]  \u001b[A\n","Training loss: 0.4195312, IoU: 0.955152805781473 |: 100%|██████████| 26/26 [01:11<00:00,  2.75s/it]\n","Epoch Loop:  71%|███████▏  | 107/150 [2:33:24<56:41, 79.10s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.43696868, IoU: 0.958112001838414 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.43696868, IoU: 0.958112001838414 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.43949, IoU: 0.9612315593547498 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]  \u001b[A\n","Training loss: 0.43949, IoU: 0.9612315593547498 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.45750993, IoU: 0.9567914438502674 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.45750993, IoU: 0.9567914438502674 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.4566729, IoU: 0.9563985126574467 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it] \u001b[A\n","Training loss: 0.4566729, IoU: 0.9563985126574467 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.44834143, IoU: 0.9564580608516444 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.44834143, IoU: 0.9564580608516444 |:  19%|█▉        | 5/26 [00:14<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.44476527, IoU: 0.9645904673316096 |:  19%|█▉        | 5/26 [00:16<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.44476527, IoU: 0.9645904673316096 |:  23%|██▎       | 6/26 [00:16<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.4614423, IoU: 0.9602830840345992 |:  23%|██▎       | 6/26 [00:19<00:56,  2.81s/it] \u001b[A\n","Training loss: 0.4614423, IoU: 0.9602830840345992 |:  27%|██▋       | 7/26 [00:19<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.50065625, IoU: 0.9483412084443729 |:  27%|██▋       | 7/26 [00:22<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.50065625, IoU: 0.9483412084443729 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.4681008, IoU: 0.9522936580681769 |:  31%|███       | 8/26 [00:25<00:50,  2.82s/it] \u001b[A\n","Training loss: 0.4681008, IoU: 0.9522936580681769 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.43118012, IoU: 0.95627437363107 |:  35%|███▍      | 9/26 [00:28<00:47,  2.81s/it] \u001b[A\n","Training loss: 0.43118012, IoU: 0.95627437363107 |:  38%|███▊      | 10/26 [00:28<00:44,  2.81s/it]\u001b[A\n","Training loss: 0.3669686, IoU: 0.9504119150090825 |:  38%|███▊      | 10/26 [00:30<00:44,  2.81s/it]\u001b[A\n","Training loss: 0.3669686, IoU: 0.9504119150090825 |:  42%|████▏     | 11/26 [00:30<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.4880262, IoU: 0.9498147759837842 |:  42%|████▏     | 11/26 [00:33<00:42,  2.82s/it]\u001b[A\n","Training loss: 0.4880262, IoU: 0.9498147759837842 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.43207273, IoU: 0.9620298021756437 |:  46%|████▌     | 12/26 [00:36<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.43207273, IoU: 0.9620298021756437 |:  50%|█████     | 13/26 [00:36<00:36,  2.82s/it]\u001b[A\n","Training loss: 0.41041437, IoU: 0.9631311323128132 |:  50%|█████     | 13/26 [00:39<00:36,  2.82s/it]\u001b[A\n","Training loss: 0.41041437, IoU: 0.9631311323128132 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.83s/it]\u001b[A\n","Training loss: 0.4279592, IoU: 0.9593251129166719 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.83s/it] \u001b[A\n","Training loss: 0.4279592, IoU: 0.9593251129166719 |:  58%|█████▊    | 15/26 [00:42<00:31,  2.84s/it]\u001b[A\n","Training loss: 0.3800826, IoU: 0.9616939920449195 |:  58%|█████▊    | 15/26 [00:45<00:31,  2.84s/it]\u001b[A\n","Training loss: 0.3800826, IoU: 0.9616939920449195 |:  62%|██████▏   | 16/26 [00:45<00:28,  2.84s/it]\u001b[A\n","Training loss: 0.44912815, IoU: 0.9569912260213699 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.84s/it]\u001b[A\n","Training loss: 0.44912815, IoU: 0.9569912260213699 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.83s/it]\u001b[A\n","Training loss: 0.4789611, IoU: 0.9609409552654917 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.83s/it] \u001b[A\n","Training loss: 0.4789611, IoU: 0.9609409552654917 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.83s/it]\u001b[A\n","Training loss: 0.4332354, IoU: 0.9383649583738782 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.83s/it]\u001b[A\n","Training loss: 0.4332354, IoU: 0.9383649583738782 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.81s/it]\u001b[A\n","Training loss: 0.4600554, IoU: 0.949403787591528 |:  73%|███████▎  | 19/26 [00:56<00:19,  2.81s/it] \u001b[A\n","Training loss: 0.4600554, IoU: 0.949403787591528 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.47038385, IoU: 0.9492860625957239 |:  77%|███████▋  | 20/26 [00:59<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.47038385, IoU: 0.9492860625957239 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47474176, IoU: 0.9486962000181407 |:  81%|████████  | 21/26 [01:01<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47474176, IoU: 0.9486962000181407 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.49214295, IoU: 0.9538207048660571 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.49214295, IoU: 0.9538207048660571 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4959553, IoU: 0.9639561157542265 |:  88%|████████▊ | 23/26 [01:07<00:08,  2.78s/it] \u001b[A\n","Training loss: 0.4959553, IoU: 0.9639561157542265 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.45067567, IoU: 0.9501600837671033 |:  92%|█████████▏| 24/26 [01:10<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.45067567, IoU: 0.9501600837671033 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.38920358, IoU: 0.9504054517495824 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.38920358, IoU: 0.9504054517495824 |: 100%|██████████| 26/26 [01:11<00:00,  2.73s/it]\n","Epoch Loop:  72%|███████▏  | 108/150 [2:34:43<55:20, 79.06s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46840888, IoU: 0.953600626715167 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46840888, IoU: 0.953600626715167 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.43380573, IoU: 0.9551108095884215 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.43380573, IoU: 0.9551108095884215 |:   8%|▊         | 2/26 [00:05<01:08,  2.84s/it]\u001b[A\n","Training loss: 0.42584065, IoU: 0.9565116506277173 |:   8%|▊         | 2/26 [00:08<01:08,  2.84s/it]\u001b[A\n","Training loss: 0.42584065, IoU: 0.9565116506277173 |:  12%|█▏        | 3/26 [00:08<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.42319745, IoU: 0.9522111171331723 |:  12%|█▏        | 3/26 [00:11<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.42319745, IoU: 0.9522111171331723 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46586362, IoU: 0.9498902789403434 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.46586362, IoU: 0.9498902789403434 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.42341438, IoU: 0.9399837814172852 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.42341438, IoU: 0.9399837814172852 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.4615818, IoU: 0.9573316782967597 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it] \u001b[A\n","Training loss: 0.4615818, IoU: 0.9573316782967597 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.52004325, IoU: 0.9402903512079902 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.52004325, IoU: 0.9402903512079902 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.45237908, IoU: 0.9532393672172548 |:  31%|███       | 8/26 [00:25<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.45237908, IoU: 0.9532393672172548 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.43800342, IoU: 0.959941513681621 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it] \u001b[A\n","Training loss: 0.43800342, IoU: 0.959941513681621 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.45207173, IoU: 0.9597705333995257 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.45207173, IoU: 0.9597705333995257 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.46030265, IoU: 0.9620810535434555 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.46030265, IoU: 0.9620810535434555 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.42333835, IoU: 0.9570014018728186 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.42333835, IoU: 0.9570014018728186 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.4349041, IoU: 0.9611416349111122 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it] \u001b[A\n","Training loss: 0.4349041, IoU: 0.9611416349111122 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.48115766, IoU: 0.957824807409331 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.48115766, IoU: 0.957824807409331 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.5035019, IoU: 0.943457208958946 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.77s/it] \u001b[A\n","Training loss: 0.5035019, IoU: 0.943457208958946 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.44358096, IoU: 0.9440980653636399 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.80s/it]\u001b[A\n","Training loss: 0.44358096, IoU: 0.9440980653636399 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.4636764, IoU: 0.9539930345903596 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.79s/it] \u001b[A\n","Training loss: 0.4636764, IoU: 0.9539930345903596 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.41860706, IoU: 0.9483464353166124 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.41860706, IoU: 0.9483464353166124 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.45916316, IoU: 0.9489295752578127 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.45916316, IoU: 0.9489295752578127 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4192709, IoU: 0.956155424407604 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.77s/it]  \u001b[A\n","Training loss: 0.4192709, IoU: 0.956155424407604 |:  81%|████████  | 21/26 [00:58<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.45777088, IoU: 0.9612460410138365 |:  81%|████████  | 21/26 [01:01<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.45777088, IoU: 0.9612460410138365 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.4717896, IoU: 0.9555532730439005 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.77s/it] \u001b[A\n","Training loss: 0.4717896, IoU: 0.9555532730439005 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.45646417, IoU: 0.9443655967775696 |:  88%|████████▊ | 23/26 [01:06<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.45646417, IoU: 0.9443655967775696 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.45655504, IoU: 0.958651826129223 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.78s/it] \u001b[A\n","Training loss: 0.45655504, IoU: 0.958651826129223 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.41959935, IoU: 0.9543259371302986 |:  96%|█████████▌| 25/26 [01:12<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.41959935, IoU: 0.9543259371302986 |: 100%|██████████| 26/26 [01:12<00:00,  2.78s/it]\n","Epoch Loop:  73%|███████▎  | 109/150 [2:36:04<54:14, 79.39s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.37206626, IoU: 0.9566533599467731 |:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.37206626, IoU: 0.9566533599467731 |:   4%|▍         | 1/26 [00:00<00:23,  1.06it/s]\u001b[A\n","Training loss: 0.45853403, IoU: 0.949273712159386 |:   4%|▍         | 1/26 [00:03<00:23,  1.06it/s] \u001b[A\n","Training loss: 0.45853403, IoU: 0.949273712159386 |:   8%|▊         | 2/26 [00:03<00:48,  2.02s/it]\u001b[A\n","Training loss: 0.4171704, IoU: 0.9547064305684996 |:   8%|▊         | 2/26 [00:06<00:48,  2.02s/it]\u001b[A\n","Training loss: 0.4171704, IoU: 0.9547064305684996 |:  12%|█▏        | 3/26 [00:06<00:54,  2.38s/it]\u001b[A\n","Training loss: 0.5039544, IoU: 0.9487505799407702 |:  12%|█▏        | 3/26 [00:09<00:54,  2.38s/it]\u001b[A\n","Training loss: 0.5039544, IoU: 0.9487505799407702 |:  15%|█▌        | 4/26 [00:09<00:55,  2.54s/it]\u001b[A\n","Training loss: 0.46398532, IoU: 0.9542578691029556 |:  15%|█▌        | 4/26 [00:12<00:55,  2.54s/it]\u001b[A\n","Training loss: 0.46398532, IoU: 0.9542578691029556 |:  19%|█▉        | 5/26 [00:12<00:54,  2.61s/it]\u001b[A\n","Training loss: 0.43878922, IoU: 0.9555692209474811 |:  19%|█▉        | 5/26 [00:14<00:54,  2.61s/it]\u001b[A\n","Training loss: 0.43878922, IoU: 0.9555692209474811 |:  23%|██▎       | 6/26 [00:14<00:53,  2.67s/it]\u001b[A\n","Training loss: 0.44293094, IoU: 0.9536677834597073 |:  23%|██▎       | 6/26 [00:17<00:53,  2.67s/it]\u001b[A\n","Training loss: 0.44293094, IoU: 0.9536677834597073 |:  27%|██▋       | 7/26 [00:17<00:51,  2.71s/it]\u001b[A\n","Training loss: 0.51490986, IoU: 0.9339795120861943 |:  27%|██▋       | 7/26 [00:20<00:51,  2.71s/it]\u001b[A\n","Training loss: 0.51490986, IoU: 0.9339795120861943 |:  31%|███       | 8/26 [00:20<00:49,  2.73s/it]\u001b[A\n","Training loss: 0.4434237, IoU: 0.9485469305758415 |:  31%|███       | 8/26 [00:23<00:49,  2.73s/it] \u001b[A\n","Training loss: 0.4434237, IoU: 0.9485469305758415 |:  35%|███▍      | 9/26 [00:23<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.48626247, IoU: 0.9604682570774655 |:  35%|███▍      | 9/26 [00:25<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.48626247, IoU: 0.9604682570774655 |:  38%|███▊      | 10/26 [00:25<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.38786548, IoU: 0.9405036780915694 |:  38%|███▊      | 10/26 [00:28<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.38786548, IoU: 0.9405036780915694 |:  42%|████▏     | 11/26 [00:28<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.4743304, IoU: 0.9485486510588673 |:  42%|████▏     | 11/26 [00:31<00:41,  2.76s/it] \u001b[A\n","Training loss: 0.4743304, IoU: 0.9485486510588673 |:  46%|████▌     | 12/26 [00:31<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.47179842, IoU: 0.9562706943515634 |:  46%|████▌     | 12/26 [00:34<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.47179842, IoU: 0.9562706943515634 |:  50%|█████     | 13/26 [00:34<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.48067644, IoU: 0.9573475714777816 |:  50%|█████     | 13/26 [00:37<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.48067644, IoU: 0.9573475714777816 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.4594752, IoU: 0.9610445543488404 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.77s/it] \u001b[A\n","Training loss: 0.4594752, IoU: 0.9610445543488404 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.41577482, IoU: 0.9475419936657661 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.41577482, IoU: 0.9475419936657661 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.49423614, IoU: 0.9522417447304274 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.49423614, IoU: 0.9522417447304274 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4199393, IoU: 0.9584780977949741 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.4199393, IoU: 0.9584780977949741 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.47346053, IoU: 0.9532409732825573 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.47346053, IoU: 0.9532409732825573 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.42752627, IoU: 0.9365115136113542 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.42752627, IoU: 0.9365115136113542 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.4479162, IoU: 0.953960255533377 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]  \u001b[A\n","Training loss: 0.4479162, IoU: 0.953960255533377 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.46914077, IoU: 0.9569327942389315 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.46914077, IoU: 0.9569327942389315 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.44161767, IoU: 0.9519660137831881 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.44161767, IoU: 0.9519660137831881 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.40233615, IoU: 0.9470964780291244 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.40233615, IoU: 0.9470964780291244 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.4819256, IoU: 0.9599048241112251 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it] \u001b[A\n","Training loss: 0.4819256, IoU: 0.9599048241112251 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4983583, IoU: 0.9521831016288799 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.4983583, IoU: 0.9521831016288799 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  73%|███████▎  | 110/150 [2:37:22<52:43, 79.08s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5017524, IoU: 0.9488256143190535 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5017524, IoU: 0.9488256143190535 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.4928627, IoU: 0.972562048075044 |:   4%|▍         | 1/26 [00:03<01:09,  2.80s/it] \u001b[A\n","Training loss: 0.4928627, IoU: 0.972562048075044 |:   8%|▊         | 2/26 [00:03<00:41,  1.72s/it]\u001b[A\n","Training loss: 0.42067593, IoU: 0.9496849788602474 |:   8%|▊         | 2/26 [00:06<00:41,  1.72s/it]\u001b[A\n","Training loss: 0.42067593, IoU: 0.9496849788602474 |:  12%|█▏        | 3/26 [00:06<00:51,  2.22s/it]\u001b[A\n","Training loss: 0.44756776, IoU: 0.9552433609618091 |:  12%|█▏        | 3/26 [00:09<00:51,  2.22s/it]\u001b[A\n","Training loss: 0.44756776, IoU: 0.9552433609618091 |:  15%|█▌        | 4/26 [00:09<00:54,  2.48s/it]\u001b[A\n","Training loss: 0.41938642, IoU: 0.9541262660593228 |:  15%|█▌        | 4/26 [00:12<00:54,  2.48s/it]\u001b[A\n","Training loss: 0.41938642, IoU: 0.9541262660593228 |:  19%|█▉        | 5/26 [00:12<00:54,  2.59s/it]\u001b[A\n","Training loss: 0.42183197, IoU: 0.9353609067981089 |:  19%|█▉        | 5/26 [00:15<00:54,  2.59s/it]\u001b[A\n","Training loss: 0.42183197, IoU: 0.9353609067981089 |:  23%|██▎       | 6/26 [00:15<00:53,  2.65s/it]\u001b[A\n","Training loss: 0.47250146, IoU: 0.9360396501171592 |:  23%|██▎       | 6/26 [00:17<00:53,  2.65s/it]\u001b[A\n","Training loss: 0.47250146, IoU: 0.9360396501171592 |:  27%|██▋       | 7/26 [00:17<00:51,  2.70s/it]\u001b[A\n","Training loss: 0.45429993, IoU: 0.9478510181493286 |:  27%|██▋       | 7/26 [00:20<00:51,  2.70s/it]\u001b[A\n","Training loss: 0.45429993, IoU: 0.9478510181493286 |:  31%|███       | 8/26 [00:20<00:48,  2.72s/it]\u001b[A\n","Training loss: 0.47015917, IoU: 0.9575991712258388 |:  31%|███       | 8/26 [00:23<00:48,  2.72s/it]\u001b[A\n","Training loss: 0.47015917, IoU: 0.9575991712258388 |:  35%|███▍      | 9/26 [00:23<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.5079586, IoU: 0.9631810441196443 |:  35%|███▍      | 9/26 [00:26<00:46,  2.75s/it] \u001b[A\n","Training loss: 0.5079586, IoU: 0.9631810441196443 |:  38%|███▊      | 10/26 [00:26<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.37749746, IoU: 0.961305892180811 |:  38%|███▊      | 10/26 [00:28<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.37749746, IoU: 0.961305892180811 |:  42%|████▏     | 11/26 [00:28<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.4270239, IoU: 0.9547496451652516 |:  42%|████▏     | 11/26 [00:31<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.4270239, IoU: 0.9547496451652516 |:  46%|████▌     | 12/26 [00:31<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.46867383, IoU: 0.9593194394074576 |:  46%|████▌     | 12/26 [00:34<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.46867383, IoU: 0.9593194394074576 |:  50%|█████     | 13/26 [00:34<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.4503286, IoU: 0.9536879868058314 |:  50%|█████     | 13/26 [00:37<00:36,  2.77s/it] \u001b[A\n","Training loss: 0.4503286, IoU: 0.9536879868058314 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.40989935, IoU: 0.9494903972821188 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.40989935, IoU: 0.9494903972821188 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.45845363, IoU: 0.9500697732743708 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.45845363, IoU: 0.9500697732743708 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.45835426, IoU: 0.9491439549556159 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.45835426, IoU: 0.9491439549556159 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.43477666, IoU: 0.951197104818366 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.78s/it] \u001b[A\n","Training loss: 0.43477666, IoU: 0.951197104818366 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.38383427, IoU: 0.9610241445991559 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.38383427, IoU: 0.9610241445991559 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.44298995, IoU: 0.9622758612643932 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.44298995, IoU: 0.9622758612643932 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.44478387, IoU: 0.9626447668417292 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.44478387, IoU: 0.9626447668417292 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.49214345, IoU: 0.9521318708254182 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.49214345, IoU: 0.9521318708254182 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.42468774, IoU: 0.9436446837629044 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.42468774, IoU: 0.9436446837629044 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.4692031, IoU: 0.9476161732433052 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it] \u001b[A\n","Training loss: 0.4692031, IoU: 0.9476161732433052 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.4398857, IoU: 0.9540087409312197 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.4398857, IoU: 0.9540087409312197 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.45738477, IoU: 0.9478630178657088 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.45738477, IoU: 0.9478630178657088 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  74%|███████▍  | 111/150 [2:38:40<51:17, 78.91s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45949197, IoU: 0.9548771098179396 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45949197, IoU: 0.9548771098179396 |:   4%|▍         | 1/26 [00:02<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.4423948, IoU: 0.9562980901346524 |:   4%|▍         | 1/26 [00:05<01:10,  2.82s/it] \u001b[A\n","Training loss: 0.4423948, IoU: 0.9562980901346524 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.51586604, IoU: 0.9429284196116575 |:   8%|▊         | 2/26 [00:06<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.51586604, IoU: 0.9429284196116575 |:  12%|█▏        | 3/26 [00:06<00:45,  1.96s/it]\u001b[A\n","Training loss: 0.4710888, IoU: 0.9609761831989279 |:  12%|█▏        | 3/26 [00:09<00:45,  1.96s/it] \u001b[A\n","Training loss: 0.4710888, IoU: 0.9609761831989279 |:  15%|█▌        | 4/26 [00:09<00:50,  2.29s/it]\u001b[A\n","Training loss: 0.4814323, IoU: 0.9555247779095731 |:  15%|█▌        | 4/26 [00:12<00:50,  2.29s/it]\u001b[A\n","Training loss: 0.4814323, IoU: 0.9555247779095731 |:  19%|█▉        | 5/26 [00:12<00:51,  2.46s/it]\u001b[A\n","Training loss: 0.48300648, IoU: 0.9574794866400168 |:  19%|█▉        | 5/26 [00:14<00:51,  2.46s/it]\u001b[A\n","Training loss: 0.48300648, IoU: 0.9574794866400168 |:  23%|██▎       | 6/26 [00:14<00:51,  2.60s/it]\u001b[A\n","Training loss: 0.4339356, IoU: 0.9584974798499563 |:  23%|██▎       | 6/26 [00:17<00:51,  2.60s/it] \u001b[A\n","Training loss: 0.4339356, IoU: 0.9584974798499563 |:  27%|██▋       | 7/26 [00:17<00:50,  2.66s/it]\u001b[A\n","Training loss: 0.4221895, IoU: 0.9533896557767446 |:  27%|██▋       | 7/26 [00:20<00:50,  2.66s/it]\u001b[A\n","Training loss: 0.4221895, IoU: 0.9533896557767446 |:  31%|███       | 8/26 [00:20<00:48,  2.70s/it]\u001b[A\n","Training loss: 0.4576168, IoU: 0.9533913955178536 |:  31%|███       | 8/26 [00:23<00:48,  2.70s/it]\u001b[A\n","Training loss: 0.4576168, IoU: 0.9533913955178536 |:  35%|███▍      | 9/26 [00:23<00:46,  2.72s/it]\u001b[A\n","Training loss: 0.40704215, IoU: 0.9555624098874534 |:  35%|███▍      | 9/26 [00:26<00:46,  2.72s/it]\u001b[A\n","Training loss: 0.40704215, IoU: 0.9555624098874534 |:  38%|███▊      | 10/26 [00:26<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.44573295, IoU: 0.9543422891964153 |:  38%|███▊      | 10/26 [00:28<00:43,  2.74s/it]\u001b[A\n","Training loss: 0.44573295, IoU: 0.9543422891964153 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.5175511, IoU: 0.9632720962583717 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it] \u001b[A\n","Training loss: 0.5175511, IoU: 0.9632720962583717 |:  46%|████▌     | 12/26 [00:31<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.48105252, IoU: 0.9520683640775779 |:  46%|████▌     | 12/26 [00:34<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.48105252, IoU: 0.9520683640775779 |:  50%|█████     | 13/26 [00:34<00:35,  2.75s/it]\u001b[A\n","Training loss: 0.48511484, IoU: 0.9509552323923581 |:  50%|█████     | 13/26 [00:37<00:35,  2.75s/it]\u001b[A\n","Training loss: 0.48511484, IoU: 0.9509552323923581 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.75s/it]\u001b[A\n","Training loss: 0.39878443, IoU: 0.9503932768388034 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.75s/it]\u001b[A\n","Training loss: 0.39878443, IoU: 0.9503932768388034 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.43926394, IoU: 0.9523768412849153 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.43926394, IoU: 0.9523768412849153 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.42939427, IoU: 0.9595469777775729 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.42939427, IoU: 0.9595469777775729 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.5127935, IoU: 0.9602516863862428 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.5127935, IoU: 0.9602516863862428 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.44364494, IoU: 0.9602737493190582 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.44364494, IoU: 0.9602737493190582 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.41598067, IoU: 0.9491379827476575 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.41598067, IoU: 0.9491379827476575 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.42984563, IoU: 0.9439236708103499 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.42984563, IoU: 0.9439236708103499 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.41222972, IoU: 0.9429374222293582 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.41222972, IoU: 0.9429374222293582 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.44268188, IoU: 0.9535102749985022 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.44268188, IoU: 0.9535102749985022 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4637648, IoU: 0.9544416301324321 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.4637648, IoU: 0.9544416301324321 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.4523828, IoU: 0.9542684689476545 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.4523828, IoU: 0.9542684689476545 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.54755735, IoU: 0.9530085539116707 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.54755735, IoU: 0.9530085539116707 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  75%|███████▍  | 112/150 [2:39:59<49:52, 78.74s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.39585963, IoU: 0.9551652304520548 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.39585963, IoU: 0.9551652304520548 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.39466086, IoU: 0.9583158563259657 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.39466086, IoU: 0.9583158563259657 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.4197404, IoU: 0.9540978621022865 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it] \u001b[A\n","Training loss: 0.4197404, IoU: 0.9540978621022865 |:  12%|█▏        | 3/26 [00:08<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.32989162, IoU: 0.942003216380892 |:  12%|█▏        | 3/26 [00:09<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.32989162, IoU: 0.942003216380892 |:  15%|█▌        | 4/26 [00:09<00:45,  2.08s/it]\u001b[A\n","Training loss: 0.445513, IoU: 0.9567846871681046 |:  15%|█▌        | 4/26 [00:12<00:45,  2.08s/it] \u001b[A\n","Training loss: 0.445513, IoU: 0.9567846871681046 |:  19%|█▉        | 5/26 [00:12<00:49,  2.34s/it]\u001b[A\n","Training loss: 0.47317368, IoU: 0.9507023633151045 |:  19%|█▉        | 5/26 [00:14<00:49,  2.34s/it]\u001b[A\n","Training loss: 0.47317368, IoU: 0.9507023633151045 |:  23%|██▎       | 6/26 [00:14<00:49,  2.48s/it]\u001b[A\n","Training loss: 0.49635753, IoU: 0.947998441865078 |:  23%|██▎       | 6/26 [00:17<00:49,  2.48s/it] \u001b[A\n","Training loss: 0.49635753, IoU: 0.947998441865078 |:  27%|██▋       | 7/26 [00:17<00:48,  2.57s/it]\u001b[A\n","Training loss: 0.39018914, IoU: 0.9425828779960532 |:  27%|██▋       | 7/26 [00:20<00:48,  2.57s/it]\u001b[A\n","Training loss: 0.39018914, IoU: 0.9425828779960532 |:  31%|███       | 8/26 [00:20<00:47,  2.64s/it]\u001b[A\n","Training loss: 0.4439811, IoU: 0.9526085289031478 |:  31%|███       | 8/26 [00:23<00:47,  2.64s/it] \u001b[A\n","Training loss: 0.4439811, IoU: 0.9526085289031478 |:  35%|███▍      | 9/26 [00:23<00:45,  2.67s/it]\u001b[A\n","Training loss: 0.4795094, IoU: 0.9589857770009043 |:  35%|███▍      | 9/26 [00:26<00:45,  2.67s/it]\u001b[A\n","Training loss: 0.4795094, IoU: 0.9589857770009043 |:  38%|███▊      | 10/26 [00:26<00:43,  2.71s/it]\u001b[A\n","Training loss: 0.40202, IoU: 0.9555431572211631 |:  38%|███▊      | 10/26 [00:28<00:43,  2.71s/it]  \u001b[A\n","Training loss: 0.40202, IoU: 0.9555431572211631 |:  42%|████▏     | 11/26 [00:28<00:40,  2.73s/it]\u001b[A\n","Training loss: 0.47904065, IoU: 0.960105183373401 |:  42%|████▏     | 11/26 [00:31<00:40,  2.73s/it]\u001b[A\n","Training loss: 0.47904065, IoU: 0.960105183373401 |:  46%|████▌     | 12/26 [00:31<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.46739122, IoU: 0.9536367950605928 |:  46%|████▌     | 12/26 [00:34<00:38,  2.74s/it]\u001b[A\n","Training loss: 0.46739122, IoU: 0.9536367950605928 |:  50%|█████     | 13/26 [00:34<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.4809559, IoU: 0.9588349480179995 |:  50%|█████     | 13/26 [00:37<00:35,  2.76s/it] \u001b[A\n","Training loss: 0.4809559, IoU: 0.9588349480179995 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.45585975, IoU: 0.9559328873314219 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.45585975, IoU: 0.9559328873314219 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.42264938, IoU: 0.9524140912737589 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.76s/it]\u001b[A\n","Training loss: 0.42264938, IoU: 0.9524140912737589 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.41014737, IoU: 0.9589319063352967 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.41014737, IoU: 0.9589319063352967 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.39902043, IoU: 0.9529939633871776 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.39902043, IoU: 0.9529939633871776 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.43274337, IoU: 0.9578159444149901 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.43274337, IoU: 0.9578159444149901 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.42735028, IoU: 0.9455106317846799 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.42735028, IoU: 0.9455106317846799 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.80s/it]\u001b[A\n","Training loss: 0.4422377, IoU: 0.9497617844172377 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.80s/it] \u001b[A\n","Training loss: 0.4422377, IoU: 0.9497617844172377 |:  81%|████████  | 21/26 [00:56<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.45838997, IoU: 0.955581163303945 |:  81%|████████  | 21/26 [00:59<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.45838997, IoU: 0.955581163303945 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.45398873, IoU: 0.9583333333333334 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.45398873, IoU: 0.9583333333333334 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.47272527, IoU: 0.9587446692620677 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.47272527, IoU: 0.9587446692620677 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.40519935, IoU: 0.9563441218692389 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.40519935, IoU: 0.9563441218692389 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.45954585, IoU: 0.9370269002373897 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.45954585, IoU: 0.9370269002373897 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  75%|███████▌  | 113/150 [2:41:17<48:27, 78.58s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4644633, IoU: 0.9547196583614306 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4644633, IoU: 0.9547196583614306 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.48447672, IoU: 0.9470743140413698 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.48447672, IoU: 0.9470743140413698 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.4699195, IoU: 0.9644687876352512 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it] \u001b[A\n","Training loss: 0.4699195, IoU: 0.9644687876352512 |:  12%|█▏        | 3/26 [00:08<01:03,  2.76s/it]\u001b[A\n","Training loss: 0.4137061, IoU: 0.9634449136859753 |:  12%|█▏        | 3/26 [00:11<01:03,  2.76s/it]\u001b[A\n","Training loss: 0.4137061, IoU: 0.9634449136859753 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.4634614, IoU: 0.967034232574209 |:  15%|█▌        | 4/26 [00:12<01:00,  2.77s/it] \u001b[A\n","Training loss: 0.4634614, IoU: 0.967034232574209 |:  19%|█▉        | 5/26 [00:12<00:44,  2.11s/it]\u001b[A\n","Training loss: 0.49105242, IoU: 0.9615614176290254 |:  19%|█▉        | 5/26 [00:14<00:44,  2.11s/it]\u001b[A\n","Training loss: 0.49105242, IoU: 0.9615614176290254 |:  23%|██▎       | 6/26 [00:14<00:46,  2.33s/it]\u001b[A\n","Training loss: 0.45534748, IoU: 0.946501476878458 |:  23%|██▎       | 6/26 [00:17<00:46,  2.33s/it] \u001b[A\n","Training loss: 0.45534748, IoU: 0.946501476878458 |:  27%|██▋       | 7/26 [00:17<00:46,  2.47s/it]\u001b[A\n","Training loss: 0.45219955, IoU: 0.9551910486022102 |:  27%|██▋       | 7/26 [00:20<00:46,  2.47s/it]\u001b[A\n","Training loss: 0.45219955, IoU: 0.9551910486022102 |:  31%|███       | 8/26 [00:20<00:46,  2.56s/it]\u001b[A\n","Training loss: 0.44229522, IoU: 0.9471523165559734 |:  31%|███       | 8/26 [00:23<00:46,  2.56s/it]\u001b[A\n","Training loss: 0.44229522, IoU: 0.9471523165559734 |:  35%|███▍      | 9/26 [00:23<00:45,  2.65s/it]\u001b[A\n","Training loss: 0.42406225, IoU: 0.9502411160227338 |:  35%|███▍      | 9/26 [00:25<00:45,  2.65s/it]\u001b[A\n","Training loss: 0.42406225, IoU: 0.9502411160227338 |:  38%|███▊      | 10/26 [00:25<00:42,  2.68s/it]\u001b[A\n","Training loss: 0.4248277, IoU: 0.9413428644901204 |:  38%|███▊      | 10/26 [00:28<00:42,  2.68s/it] \u001b[A\n","Training loss: 0.4248277, IoU: 0.9413428644901204 |:  42%|████▏     | 11/26 [00:28<00:40,  2.71s/it]\u001b[A\n","Training loss: 0.518451, IoU: 0.9575073784544582 |:  42%|████▏     | 11/26 [00:31<00:40,  2.71s/it] \u001b[A\n","Training loss: 0.518451, IoU: 0.9575073784544582 |:  46%|████▌     | 12/26 [00:31<00:38,  2.73s/it]\u001b[A\n","Training loss: 0.42987305, IoU: 0.946234390267954 |:  46%|████▌     | 12/26 [00:34<00:38,  2.73s/it]\u001b[A\n","Training loss: 0.42987305, IoU: 0.946234390267954 |:  50%|█████     | 13/26 [00:34<00:35,  2.74s/it]\u001b[A\n","Training loss: 0.37670925, IoU: 0.9531816639273903 |:  50%|█████     | 13/26 [00:36<00:35,  2.74s/it]\u001b[A\n","Training loss: 0.37670925, IoU: 0.9531816639273903 |:  54%|█████▍    | 14/26 [00:36<00:33,  2.75s/it]\u001b[A\n","Training loss: 0.43873304, IoU: 0.957678127247573 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.75s/it] \u001b[A\n","Training loss: 0.43873304, IoU: 0.957678127247573 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.42595422, IoU: 0.9508988242996262 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.42595422, IoU: 0.9508988242996262 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.44410092, IoU: 0.9586356644827154 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.44410092, IoU: 0.9586356644827154 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.46326032, IoU: 0.9635771215387969 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.46326032, IoU: 0.9635771215387969 |:  69%|██████▉   | 18/26 [00:47<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.45076168, IoU: 0.9568629451984897 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.45076168, IoU: 0.9568629451984897 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.45447922, IoU: 0.9496763793784787 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.45447922, IoU: 0.9496763793784787 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.38492605, IoU: 0.9536194763530994 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.38492605, IoU: 0.9536194763530994 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47171557, IoU: 0.9407597317177107 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.47171557, IoU: 0.9407597317177107 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.45532557, IoU: 0.9582940298153723 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.45532557, IoU: 0.9582940298153723 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.53443205, IoU: 0.9529107903381242 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.53443205, IoU: 0.9529107903381242 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.83s/it]\u001b[A\n","Training loss: 0.4299896, IoU: 0.9555662158556858 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.83s/it] \u001b[A\n","Training loss: 0.4299896, IoU: 0.9555662158556858 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.82s/it]\u001b[A\n","Training loss: 0.46008092, IoU: 0.9593514163007917 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.82s/it]\u001b[A\n","Training loss: 0.46008092, IoU: 0.9593514163007917 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  76%|███████▌  | 114/150 [2:42:35<47:06, 78.52s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4596013, IoU: 0.9485734903618038 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4596013, IoU: 0.9485734903618038 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.4514876, IoU: 0.9496367205682945 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.4514876, IoU: 0.9496367205682945 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.51001966, IoU: 0.9570850073626993 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.51001966, IoU: 0.9570850073626993 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.48103058, IoU: 0.9638497813633162 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.48103058, IoU: 0.9638497813633162 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.39218307, IoU: 0.9574661123674625 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.39218307, IoU: 0.9574661123674625 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.4740054, IoU: 0.9649554234204055 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it] \u001b[A\n","Training loss: 0.4740054, IoU: 0.9649554234204055 |:  23%|██▎       | 6/26 [00:14<00:43,  2.18s/it]\u001b[A\n","Training loss: 0.42058337, IoU: 0.9584186482424937 |:  23%|██▎       | 6/26 [00:17<00:43,  2.18s/it]\u001b[A\n","Training loss: 0.42058337, IoU: 0.9584186482424937 |:  27%|██▋       | 7/26 [00:17<00:45,  2.38s/it]\u001b[A\n","Training loss: 0.4473682, IoU: 0.9600331452664417 |:  27%|██▋       | 7/26 [00:20<00:45,  2.38s/it] \u001b[A\n","Training loss: 0.4473682, IoU: 0.9600331452664417 |:  31%|███       | 8/26 [00:20<00:45,  2.50s/it]\u001b[A\n","Training loss: 0.4631672, IoU: 0.9488106989763492 |:  31%|███       | 8/26 [00:23<00:45,  2.50s/it]\u001b[A\n","Training loss: 0.4631672, IoU: 0.9488106989763492 |:  35%|███▍      | 9/26 [00:23<00:44,  2.59s/it]\u001b[A\n","Training loss: 0.38460413, IoU: 0.9550769630166474 |:  35%|███▍      | 9/26 [00:26<00:44,  2.59s/it]\u001b[A\n","Training loss: 0.38460413, IoU: 0.9550769630166474 |:  38%|███▊      | 10/26 [00:26<00:42,  2.66s/it]\u001b[A\n","Training loss: 0.52266127, IoU: 0.9353865840121359 |:  38%|███▊      | 10/26 [00:28<00:42,  2.66s/it]\u001b[A\n","Training loss: 0.52266127, IoU: 0.9353865840121359 |:  42%|████▏     | 11/26 [00:28<00:40,  2.69s/it]\u001b[A\n","Training loss: 0.42143282, IoU: 0.9424501846428724 |:  42%|████▏     | 11/26 [00:31<00:40,  2.69s/it]\u001b[A\n","Training loss: 0.42143282, IoU: 0.9424501846428724 |:  46%|████▌     | 12/26 [00:31<00:38,  2.72s/it]\u001b[A\n","Training loss: 0.414975, IoU: 0.9424464571068399 |:  46%|████▌     | 12/26 [00:34<00:38,  2.72s/it]  \u001b[A\n","Training loss: 0.414975, IoU: 0.9424464571068399 |:  50%|█████     | 13/26 [00:34<00:35,  2.75s/it]\u001b[A\n","Training loss: 0.49062073, IoU: 0.9598344430448084 |:  50%|█████     | 13/26 [00:37<00:35,  2.75s/it]\u001b[A\n","Training loss: 0.49062073, IoU: 0.9598344430448084 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.43739602, IoU: 0.9450059171310056 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.43739602, IoU: 0.9450059171310056 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.4467174, IoU: 0.9595717068274424 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it] \u001b[A\n","Training loss: 0.4467174, IoU: 0.9595717068274424 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.47720063, IoU: 0.9551684639640424 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.47720063, IoU: 0.9551684639640424 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.43076593, IoU: 0.9562717125413694 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.43076593, IoU: 0.9562717125413694 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.44561958, IoU: 0.9584987907921058 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.44561958, IoU: 0.9584987907921058 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.43291062, IoU: 0.9500875942044967 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.43291062, IoU: 0.9500875942044967 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4087422, IoU: 0.9468353119823302 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it] \u001b[A\n","Training loss: 0.4087422, IoU: 0.9468353119823302 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.49317682, IoU: 0.9504397058858854 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.49317682, IoU: 0.9504397058858854 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.45707297, IoU: 0.9509852724859182 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.45707297, IoU: 0.9509852724859182 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4961617, IoU: 0.9544089174876146 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.4961617, IoU: 0.9544089174876146 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.45604715, IoU: 0.9516863789387435 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.45604715, IoU: 0.9516863789387435 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.49067062, IoU: 0.9469969156085557 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.49067062, IoU: 0.9469969156085557 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  77%|███████▋  | 115/150 [2:43:54<45:47, 78.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47556716, IoU: 0.9557692877093593 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47556716, IoU: 0.9557692877093593 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.39401013, IoU: 0.9456385228049536 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.39401013, IoU: 0.9456385228049536 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4249948, IoU: 0.9533384154592859 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it] \u001b[A\n","Training loss: 0.4249948, IoU: 0.9533384154592859 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.4344566, IoU: 0.9451785279257714 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.4344566, IoU: 0.9451785279257714 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.47037518, IoU: 0.9597582481855321 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.47037518, IoU: 0.9597582481855321 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4538424, IoU: 0.9517108527370564 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it] \u001b[A\n","Training loss: 0.4538424, IoU: 0.9517108527370564 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.38392752, IoU: 0.9652941011209649 |:  23%|██▎       | 6/26 [00:17<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.38392752, IoU: 0.9652941011209649 |:  27%|██▋       | 7/26 [00:17<00:41,  2.19s/it]\u001b[A\n","Training loss: 0.43452534, IoU: 0.9471800714330647 |:  27%|██▋       | 7/26 [00:20<00:41,  2.19s/it]\u001b[A\n","Training loss: 0.43452534, IoU: 0.9471800714330647 |:  31%|███       | 8/26 [00:20<00:42,  2.38s/it]\u001b[A\n","Training loss: 0.43420446, IoU: 0.9526688465385181 |:  31%|███       | 8/26 [00:23<00:42,  2.38s/it]\u001b[A\n","Training loss: 0.43420446, IoU: 0.9526688465385181 |:  35%|███▍      | 9/26 [00:23<00:42,  2.51s/it]\u001b[A\n","Training loss: 0.46362478, IoU: 0.9367296650547491 |:  35%|███▍      | 9/26 [00:26<00:42,  2.51s/it]\u001b[A\n","Training loss: 0.46362478, IoU: 0.9367296650547491 |:  38%|███▊      | 10/26 [00:26<00:41,  2.59s/it]\u001b[A\n","Training loss: 0.42951006, IoU: 0.93149134239434 |:  38%|███▊      | 10/26 [00:28<00:41,  2.59s/it]  \u001b[A\n","Training loss: 0.42951006, IoU: 0.93149134239434 |:  42%|████▏     | 11/26 [00:28<00:39,  2.65s/it]\u001b[A\n","Training loss: 0.48787567, IoU: 0.9464815522890844 |:  42%|████▏     | 11/26 [00:31<00:39,  2.65s/it]\u001b[A\n","Training loss: 0.48787567, IoU: 0.9464815522890844 |:  46%|████▌     | 12/26 [00:31<00:37,  2.69s/it]\u001b[A\n","Training loss: 0.49857968, IoU: 0.936642466646025 |:  46%|████▌     | 12/26 [00:34<00:37,  2.69s/it] \u001b[A\n","Training loss: 0.49857968, IoU: 0.936642466646025 |:  50%|█████     | 13/26 [00:34<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.46831667, IoU: 0.9467572400308627 |:  50%|█████     | 13/26 [00:37<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.46831667, IoU: 0.9467572400308627 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.40622985, IoU: 0.9566624405307357 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.40622985, IoU: 0.9566624405307357 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.45276487, IoU: 0.9512076452732633 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.45276487, IoU: 0.9512076452732633 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.41709772, IoU: 0.95446617819258 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]  \u001b[A\n","Training loss: 0.41709772, IoU: 0.95446617819258 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4221667, IoU: 0.9565929506662422 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4221667, IoU: 0.9565929506662422 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.43930888, IoU: 0.9567086820988087 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.43930888, IoU: 0.9567086820988087 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.4780887, IoU: 0.9610236761216439 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it] \u001b[A\n","Training loss: 0.4780887, IoU: 0.9610236761216439 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.43348563, IoU: 0.9499905025687239 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.43348563, IoU: 0.9499905025687239 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.46302631, IoU: 0.9467289074895946 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.46302631, IoU: 0.9467289074895946 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.4668151, IoU: 0.951691635621037 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]  \u001b[A\n","Training loss: 0.4668151, IoU: 0.951691635621037 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4263199, IoU: 0.9493492965306429 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4263199, IoU: 0.9493492965306429 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.4088602, IoU: 0.9558204326412226 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.4088602, IoU: 0.9558204326412226 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.48399997, IoU: 0.9468794616055979 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.48399997, IoU: 0.9468794616055979 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  77%|███████▋  | 116/150 [2:45:12<44:28, 78.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47532475, IoU: 0.961140594878063 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47532475, IoU: 0.961140594878063 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.47733384, IoU: 0.9628095567355652 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.47733384, IoU: 0.9628095567355652 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.5222831, IoU: 0.95417339879144 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]   \u001b[A\n","Training loss: 0.5222831, IoU: 0.95417339879144 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.47239432, IoU: 0.9574933685455593 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.47239432, IoU: 0.9574933685455593 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.44860455, IoU: 0.9487378631496187 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.44860455, IoU: 0.9487378631496187 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.44301486, IoU: 0.9610763566558485 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.44301486, IoU: 0.9610763566558485 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.50181645, IoU: 0.948701334258127 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it] \u001b[A\n","Training loss: 0.50181645, IoU: 0.948701334258127 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.42640144, IoU: 0.9347421504472594 |:  27%|██▋       | 7/26 [00:20<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.42640144, IoU: 0.9347421504472594 |:  31%|███       | 8/26 [00:20<00:39,  2.22s/it]\u001b[A\n","Training loss: 0.45629555, IoU: 0.9584279314519675 |:  31%|███       | 8/26 [00:23<00:39,  2.22s/it]\u001b[A\n","Training loss: 0.45629555, IoU: 0.9584279314519675 |:  35%|███▍      | 9/26 [00:23<00:40,  2.39s/it]\u001b[A\n","Training loss: 0.42291468, IoU: 0.957846073455485 |:  35%|███▍      | 9/26 [00:26<00:40,  2.39s/it] \u001b[A\n","Training loss: 0.42291468, IoU: 0.957846073455485 |:  38%|███▊      | 10/26 [00:26<00:40,  2.52s/it]\u001b[A\n","Training loss: 0.432297, IoU: 0.954307091857497 |:  38%|███▊      | 10/26 [00:28<00:40,  2.52s/it]  \u001b[A\n","Training loss: 0.432297, IoU: 0.954307091857497 |:  42%|████▏     | 11/26 [00:28<00:38,  2.60s/it]\u001b[A\n","Training loss: 0.48202422, IoU: 0.9589874193814627 |:  42%|████▏     | 11/26 [00:31<00:38,  2.60s/it]\u001b[A\n","Training loss: 0.48202422, IoU: 0.9589874193814627 |:  46%|████▌     | 12/26 [00:31<00:37,  2.66s/it]\u001b[A\n","Training loss: 0.46037796, IoU: 0.9542700482337225 |:  46%|████▌     | 12/26 [00:34<00:37,  2.66s/it]\u001b[A\n","Training loss: 0.46037796, IoU: 0.9542700482337225 |:  50%|█████     | 13/26 [00:34<00:34,  2.69s/it]\u001b[A\n","Training loss: 0.4284861, IoU: 0.9539891403240481 |:  50%|█████     | 13/26 [00:37<00:34,  2.69s/it] \u001b[A\n","Training loss: 0.4284861, IoU: 0.9539891403240481 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.72s/it]\u001b[A\n","Training loss: 0.49203676, IoU: 0.9572590691593558 |:  54%|█████▍    | 14/26 [00:40<00:32,  2.72s/it]\u001b[A\n","Training loss: 0.49203676, IoU: 0.9572590691593558 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.44479936, IoU: 0.9500276433221632 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.44479936, IoU: 0.9500276433221632 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.43496835, IoU: 0.9519497603344506 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.43496835, IoU: 0.9519497603344506 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.462873, IoU: 0.95267174155648 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.76s/it]    \u001b[A\n","Training loss: 0.462873, IoU: 0.95267174155648 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.48589572, IoU: 0.9527660306845004 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.48589572, IoU: 0.9527660306845004 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.43549678, IoU: 0.939904587852752 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it] \u001b[A\n","Training loss: 0.43549678, IoU: 0.939904587852752 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.42428753, IoU: 0.9481124895349722 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.42428753, IoU: 0.9481124895349722 |:  81%|████████  | 21/26 [00:56<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.47300446, IoU: 0.9604119228673929 |:  81%|████████  | 21/26 [00:59<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.47300446, IoU: 0.9604119228673929 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.41841847, IoU: 0.9594313177933096 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.41841847, IoU: 0.9594313177933096 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.40330878, IoU: 0.9581456253804891 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.40330878, IoU: 0.9581456253804891 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.46540722, IoU: 0.9440410662650206 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.46540722, IoU: 0.9440410662650206 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.46251947, IoU: 0.9507777061478052 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.46251947, IoU: 0.9507777061478052 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  78%|███████▊  | 117/150 [2:46:31<43:10, 78.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5084577, IoU: 0.9600590941228844 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5084577, IoU: 0.9600590941228844 |:   4%|▍         | 1/26 [00:02<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.43042868, IoU: 0.9560409623380509 |:   4%|▍         | 1/26 [00:05<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.43042868, IoU: 0.9560409623380509 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.47335726, IoU: 0.9496395746065314 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.47335726, IoU: 0.9496395746065314 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.5243747, IoU: 0.957900267875541 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it]  \u001b[A\n","Training loss: 0.5243747, IoU: 0.957900267875541 |:  15%|█▌        | 4/26 [00:11<01:01,  2.77s/it]\u001b[A\n","Training loss: 0.4702968, IoU: 0.9576469394149342 |:  15%|█▌        | 4/26 [00:13<01:01,  2.77s/it]\u001b[A\n","Training loss: 0.4702968, IoU: 0.9576469394149342 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.4458421, IoU: 0.9605423653771653 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.4458421, IoU: 0.9605423653771653 |:  23%|██▎       | 6/26 [00:16<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.4983137, IoU: 0.9354850734214208 |:  23%|██▎       | 6/26 [00:19<00:55,  2.77s/it]\u001b[A\n","Training loss: 0.4983137, IoU: 0.9354850734214208 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.37906355, IoU: 0.9548796889591054 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.37906355, IoU: 0.9548796889591054 |:  31%|███       | 8/26 [00:22<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.36288238, IoU: 0.9599371719421027 |:  31%|███       | 8/26 [00:23<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.36288238, IoU: 0.9599371719421027 |:  35%|███▍      | 9/26 [00:23<00:37,  2.20s/it]\u001b[A\n","Training loss: 0.4152435, IoU: 0.9579944245108108 |:  35%|███▍      | 9/26 [00:25<00:37,  2.20s/it] \u001b[A\n","Training loss: 0.4152435, IoU: 0.9579944245108108 |:  38%|███▊      | 10/26 [00:25<00:38,  2.38s/it]\u001b[A\n","Training loss: 0.4790743, IoU: 0.9513139726765528 |:  38%|███▊      | 10/26 [00:28<00:38,  2.38s/it]\u001b[A\n","Training loss: 0.4790743, IoU: 0.9513139726765528 |:  42%|████▏     | 11/26 [00:28<00:37,  2.49s/it]\u001b[A\n","Training loss: 0.43457097, IoU: 0.9667632873776002 |:  42%|████▏     | 11/26 [00:31<00:37,  2.49s/it]\u001b[A\n","Training loss: 0.43457097, IoU: 0.9667632873776002 |:  46%|████▌     | 12/26 [00:31<00:36,  2.58s/it]\u001b[A\n","Training loss: 0.45145854, IoU: 0.9579799363660126 |:  46%|████▌     | 12/26 [00:34<00:36,  2.58s/it]\u001b[A\n","Training loss: 0.45145854, IoU: 0.9579799363660126 |:  50%|█████     | 13/26 [00:34<00:34,  2.64s/it]\u001b[A\n","Training loss: 0.46146852, IoU: 0.952330691307869 |:  50%|█████     | 13/26 [00:36<00:34,  2.64s/it] \u001b[A\n","Training loss: 0.46146852, IoU: 0.952330691307869 |:  54%|█████▍    | 14/26 [00:36<00:32,  2.67s/it]\u001b[A\n","Training loss: 0.5011361, IoU: 0.9527926048136646 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.67s/it]\u001b[A\n","Training loss: 0.5011361, IoU: 0.9527926048136646 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.73s/it]\u001b[A\n","Training loss: 0.42876232, IoU: 0.9539158193426341 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.73s/it]\u001b[A\n","Training loss: 0.42876232, IoU: 0.9539158193426341 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.43485337, IoU: 0.9461268215141637 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.43485337, IoU: 0.9461268215141637 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.78s/it]\u001b[A\n","Training loss: 0.4643336, IoU: 0.9455375251377625 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.78s/it] \u001b[A\n","Training loss: 0.4643336, IoU: 0.9455375251377625 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.4032316, IoU: 0.9583786847052685 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.4032316, IoU: 0.9583786847052685 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.465316, IoU: 0.9554850578350551 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.79s/it] \u001b[A\n","Training loss: 0.465316, IoU: 0.9554850578350551 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.49967623, IoU: 0.9509612659810909 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.49967623, IoU: 0.9509612659810909 |:  81%|████████  | 21/26 [00:56<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.4744199, IoU: 0.9612856811325133 |:  81%|████████  | 21/26 [00:59<00:13,  2.80s/it] \u001b[A\n","Training loss: 0.4744199, IoU: 0.9612856811325133 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.46888882, IoU: 0.962024939955236 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.46888882, IoU: 0.962024939955236 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.49543792, IoU: 0.9547698432332935 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.49543792, IoU: 0.9547698432332935 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.4199645, IoU: 0.9578359349379474 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.80s/it] \u001b[A\n","Training loss: 0.4199645, IoU: 0.9578359349379474 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.48894918, IoU: 0.9643719137713416 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.48894918, IoU: 0.9643719137713416 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  79%|███████▊  | 118/150 [2:47:49<41:52, 78.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.40156528, IoU: 0.9539764645374207 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.40156528, IoU: 0.9539764645374207 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.4732955, IoU: 0.9622906628396187 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it] \u001b[A\n","Training loss: 0.4732955, IoU: 0.9622906628396187 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.43392748, IoU: 0.9587219717091853 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.43392748, IoU: 0.9587219717091853 |:  12%|█▏        | 3/26 [00:08<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.44393328, IoU: 0.9405720022055242 |:  12%|█▏        | 3/26 [00:11<01:05,  2.83s/it]\u001b[A\n","Training loss: 0.44393328, IoU: 0.9405720022055242 |:  15%|█▌        | 4/26 [00:11<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.43306243, IoU: 0.9580957284663351 |:  15%|█▌        | 4/26 [00:14<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.43306243, IoU: 0.9580957284663351 |:  19%|█▉        | 5/26 [00:14<00:59,  2.83s/it]\u001b[A\n","Training loss: 0.55599904, IoU: 0.9623189872526544 |:  19%|█▉        | 5/26 [00:16<00:59,  2.83s/it]\u001b[A\n","Training loss: 0.55599904, IoU: 0.9623189872526544 |:  23%|██▎       | 6/26 [00:16<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.3848024, IoU: 0.956557945537842 |:  23%|██▎       | 6/26 [00:19<00:56,  2.81s/it]  \u001b[A\n","Training loss: 0.3848024, IoU: 0.956557945537842 |:  27%|██▋       | 7/26 [00:19<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.42897895, IoU: 0.9503940898289532 |:  27%|██▋       | 7/26 [00:22<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.42897895, IoU: 0.9503940898289532 |:  31%|███       | 8/26 [00:22<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.48106062, IoU: 0.9587137195660752 |:  31%|███       | 8/26 [00:25<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.48106062, IoU: 0.9587137195660752 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.46852607, IoU: 0.960312556787207 |:  35%|███▍      | 9/26 [00:26<00:47,  2.80s/it] \u001b[A\n","Training loss: 0.46852607, IoU: 0.960312556787207 |:  38%|███▊      | 10/26 [00:26<00:35,  2.23s/it]\u001b[A\n","Training loss: 0.42766207, IoU: 0.9536817618262459 |:  38%|███▊      | 10/26 [00:28<00:35,  2.23s/it]\u001b[A\n","Training loss: 0.42766207, IoU: 0.9536817618262459 |:  42%|████▏     | 11/26 [00:28<00:35,  2.39s/it]\u001b[A\n","Training loss: 0.45641494, IoU: 0.9557770137761329 |:  42%|████▏     | 11/26 [00:31<00:35,  2.39s/it]\u001b[A\n","Training loss: 0.45641494, IoU: 0.9557770137761329 |:  46%|████▌     | 12/26 [00:31<00:35,  2.52s/it]\u001b[A\n","Training loss: 0.47580284, IoU: 0.9520242301366051 |:  46%|████▌     | 12/26 [00:34<00:35,  2.52s/it]\u001b[A\n","Training loss: 0.47580284, IoU: 0.9520242301366051 |:  50%|█████     | 13/26 [00:34<00:33,  2.60s/it]\u001b[A\n","Training loss: 0.4214833, IoU: 0.9594069177080484 |:  50%|█████     | 13/26 [00:37<00:33,  2.60s/it] \u001b[A\n","Training loss: 0.4214833, IoU: 0.9594069177080484 |:  54%|█████▍    | 14/26 [00:37<00:31,  2.66s/it]\u001b[A\n","Training loss: 0.48638368, IoU: 0.9598487725148999 |:  54%|█████▍    | 14/26 [00:40<00:31,  2.66s/it]\u001b[A\n","Training loss: 0.48638368, IoU: 0.9598487725148999 |:  58%|█████▊    | 15/26 [00:40<00:29,  2.70s/it]\u001b[A\n","Training loss: 0.4664123, IoU: 0.9569571768683929 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.70s/it] \u001b[A\n","Training loss: 0.4664123, IoU: 0.9569571768683929 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.72s/it]\u001b[A\n","Training loss: 0.4024341, IoU: 0.954407659277961 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.72s/it] \u001b[A\n","Training loss: 0.4024341, IoU: 0.954407659277961 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.75s/it]\u001b[A\n","Training loss: 0.4284643, IoU: 0.955933611457261 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.75s/it]\u001b[A\n","Training loss: 0.4284643, IoU: 0.955933611457261 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.48668104, IoU: 0.955259641426946 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.48668104, IoU: 0.955259641426946 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.41553465, IoU: 0.9492656450335737 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.41553465, IoU: 0.9492656450335737 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.47135985, IoU: 0.9587607327062152 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.47135985, IoU: 0.9587607327062152 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.39437327, IoU: 0.9544165301595529 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.39437327, IoU: 0.9544165301595529 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.4336722, IoU: 0.9630190445710792 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.81s/it] \u001b[A\n","Training loss: 0.4336722, IoU: 0.9630190445710792 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.44986784, IoU: 0.9481478813264962 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.81s/it]\u001b[A\n","Training loss: 0.44986784, IoU: 0.9481478813264962 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.82s/it]\u001b[A\n","Training loss: 0.42981493, IoU: 0.958967548531415 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.82s/it] \u001b[A\n","Training loss: 0.42981493, IoU: 0.958967548531415 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.510785, IoU: 0.9298981999530963 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.80s/it] \u001b[A\n","Training loss: 0.510785, IoU: 0.9298981999530963 |: 100%|██████████| 26/26 [01:11<00:00,  2.73s/it]\n","Epoch Loop:  79%|███████▉  | 119/150 [2:49:08<40:38, 78.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46122897, IoU: 0.9584736279816305 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46122897, IoU: 0.9584736279816305 |:   4%|▍         | 1/26 [00:02<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.45285642, IoU: 0.9550204495585455 |:   4%|▍         | 1/26 [00:05<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.45285642, IoU: 0.9550204495585455 |:   8%|▊         | 2/26 [00:05<01:07,  2.83s/it]\u001b[A\n","Training loss: 0.4262709, IoU: 0.9584914628621507 |:   8%|▊         | 2/26 [00:08<01:07,  2.83s/it] \u001b[A\n","Training loss: 0.4262709, IoU: 0.9584914628621507 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.39937824, IoU: 0.9460630637656294 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.39937824, IoU: 0.9460630637656294 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.4579826, IoU: 0.9432257953794624 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it] \u001b[A\n","Training loss: 0.4579826, IoU: 0.9432257953794624 |:  19%|█▉        | 5/26 [00:14<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.41319117, IoU: 0.9528900037716563 |:  19%|█▉        | 5/26 [00:16<00:58,  2.81s/it]\u001b[A\n","Training loss: 0.41319117, IoU: 0.9528900037716563 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.44859806, IoU: 0.9584263558459227 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.44859806, IoU: 0.9584263558459227 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.45432618, IoU: 0.9546876078790374 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.45432618, IoU: 0.9546876078790374 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.4615301, IoU: 0.9570691221586795 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it] \u001b[A\n","Training loss: 0.4615301, IoU: 0.9570691221586795 |:  35%|███▍      | 9/26 [00:25<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.43551135, IoU: 0.9554598463400871 |:  35%|███▍      | 9/26 [00:28<00:47,  2.81s/it]\u001b[A\n","Training loss: 0.43551135, IoU: 0.9554598463400871 |:  38%|███▊      | 10/26 [00:28<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.46871972, IoU: 0.9617374756783339 |:  38%|███▊      | 10/26 [00:29<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.46871972, IoU: 0.9617374756783339 |:  42%|████▏     | 11/26 [00:29<00:33,  2.23s/it]\u001b[A\n","Training loss: 0.4783221, IoU: 0.950511617074492 |:  42%|████▏     | 11/26 [00:31<00:33,  2.23s/it]  \u001b[A\n","Training loss: 0.4783221, IoU: 0.950511617074492 |:  46%|████▌     | 12/26 [00:31<00:33,  2.40s/it]\u001b[A\n","Training loss: 0.42657974, IoU: 0.9527672907585409 |:  46%|████▌     | 12/26 [00:34<00:33,  2.40s/it]\u001b[A\n","Training loss: 0.42657974, IoU: 0.9527672907585409 |:  50%|█████     | 13/26 [00:34<00:32,  2.52s/it]\u001b[A\n","Training loss: 0.5101189, IoU: 0.952958077939801 |:  50%|█████     | 13/26 [00:37<00:32,  2.52s/it]  \u001b[A\n","Training loss: 0.5101189, IoU: 0.952958077939801 |:  54%|█████▍    | 14/26 [00:37<00:31,  2.60s/it]\u001b[A\n","Training loss: 0.51145965, IoU: 0.9544413094809301 |:  54%|█████▍    | 14/26 [00:40<00:31,  2.60s/it]\u001b[A\n","Training loss: 0.51145965, IoU: 0.9544413094809301 |:  58%|█████▊    | 15/26 [00:40<00:29,  2.67s/it]\u001b[A\n","Training loss: 0.46395373, IoU: 0.9554028895941584 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.67s/it]\u001b[A\n","Training loss: 0.46395373, IoU: 0.9554028895941584 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.70s/it]\u001b[A\n","Training loss: 0.3789954, IoU: 0.9488605872793923 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.70s/it] \u001b[A\n","Training loss: 0.3789954, IoU: 0.9488605872793923 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.73s/it]\u001b[A\n","Training loss: 0.47100824, IoU: 0.9551316443608764 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.73s/it]\u001b[A\n","Training loss: 0.47100824, IoU: 0.9551316443608764 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.74s/it]\u001b[A\n","Training loss: 0.40437776, IoU: 0.958209517483748 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.74s/it] \u001b[A\n","Training loss: 0.40437776, IoU: 0.958209517483748 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.44348627, IoU: 0.9563144936154157 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.44348627, IoU: 0.9563144936154157 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.44034436, IoU: 0.9558680936491389 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.44034436, IoU: 0.9558680936491389 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.4209939, IoU: 0.9546232631507058 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it] \u001b[A\n","Training loss: 0.4209939, IoU: 0.9546232631507058 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.45131314, IoU: 0.9587837837837838 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.45131314, IoU: 0.9587837837837838 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.46521568, IoU: 0.9525357168614295 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.46521568, IoU: 0.9525357168614295 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.40801495, IoU: 0.9462140411404611 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.40801495, IoU: 0.9462140411404611 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.4701663, IoU: 0.9558342265094677 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it] \u001b[A\n","Training loss: 0.4701663, IoU: 0.9558342265094677 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  80%|████████  | 120/150 [2:50:27<39:21, 78.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47555733, IoU: 0.9588783418967168 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47555733, IoU: 0.9588783418967168 |:   4%|▍         | 1/26 [00:02<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.47330645, IoU: 0.9416966287662691 |:   4%|▍         | 1/26 [00:05<01:09,  2.80s/it]\u001b[A\n","Training loss: 0.47330645, IoU: 0.9416966287662691 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.44561026, IoU: 0.9611819632178058 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.44561026, IoU: 0.9611819632178058 |:  12%|█▏        | 3/26 [00:08<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.44673377, IoU: 0.9540409834662023 |:  12%|█▏        | 3/26 [00:11<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.44673377, IoU: 0.9540409834662023 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.44716, IoU: 0.9571521258104032 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it]   \u001b[A\n","Training loss: 0.44716, IoU: 0.9571521258104032 |:  19%|█▉        | 5/26 [00:14<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.41596517, IoU: 0.9606657676555789 |:  19%|█▉        | 5/26 [00:16<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.41596517, IoU: 0.9606657676555789 |:  23%|██▎       | 6/26 [00:16<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.45071536, IoU: 0.9558150296077589 |:  23%|██▎       | 6/26 [00:19<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.45071536, IoU: 0.9558150296077589 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.44808403, IoU: 0.9593099334180041 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.44808403, IoU: 0.9593099334180041 |:  31%|███       | 8/26 [00:22<00:50,  2.81s/it]\u001b[A\n","Training loss: 0.4275878, IoU: 0.9354779889295206 |:  31%|███       | 8/26 [00:25<00:50,  2.81s/it] \u001b[A\n","Training loss: 0.4275878, IoU: 0.9354779889295206 |:  35%|███▍      | 9/26 [00:25<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.4547103, IoU: 0.9535014679988493 |:  35%|███▍      | 9/26 [00:28<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.4547103, IoU: 0.9535014679988493 |:  38%|███▊      | 10/26 [00:28<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.4098508, IoU: 0.9503407735954978 |:  38%|███▊      | 10/26 [00:30<00:45,  2.82s/it]\u001b[A\n","Training loss: 0.4098508, IoU: 0.9503407735954978 |:  42%|████▏     | 11/26 [00:30<00:42,  2.81s/it]\u001b[A\n","Training loss: 0.399072, IoU: 0.9545318910854159 |:  42%|████▏     | 11/26 [00:31<00:42,  2.81s/it] \u001b[A\n","Training loss: 0.399072, IoU: 0.9545318910854159 |:  46%|████▌     | 12/26 [00:31<00:31,  2.25s/it]\u001b[A\n","Training loss: 0.38381815, IoU: 0.9528751832357253 |:  46%|████▌     | 12/26 [00:34<00:31,  2.25s/it]\u001b[A\n","Training loss: 0.38381815, IoU: 0.9528751832357253 |:  50%|█████     | 13/26 [00:34<00:31,  2.43s/it]\u001b[A\n","Training loss: 0.5087359, IoU: 0.9428513619255458 |:  50%|█████     | 13/26 [00:37<00:31,  2.43s/it] \u001b[A\n","Training loss: 0.5087359, IoU: 0.9428513619255458 |:  54%|█████▍    | 14/26 [00:37<00:30,  2.54s/it]\u001b[A\n","Training loss: 0.43369138, IoU: 0.9604934762721047 |:  54%|█████▍    | 14/26 [00:40<00:30,  2.54s/it]\u001b[A\n","Training loss: 0.43369138, IoU: 0.9604934762721047 |:  58%|█████▊    | 15/26 [00:40<00:28,  2.63s/it]\u001b[A\n","Training loss: 0.4461298, IoU: 0.9622729109311436 |:  58%|█████▊    | 15/26 [00:43<00:28,  2.63s/it] \u001b[A\n","Training loss: 0.4461298, IoU: 0.9622729109311436 |:  62%|██████▏   | 16/26 [00:43<00:26,  2.68s/it]\u001b[A\n","Training loss: 0.49031377, IoU: 0.9499881336154896 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.68s/it]\u001b[A\n","Training loss: 0.49031377, IoU: 0.9499881336154896 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.71s/it]\u001b[A\n","Training loss: 0.42376345, IoU: 0.952375531175057 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.71s/it] \u001b[A\n","Training loss: 0.42376345, IoU: 0.952375531175057 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.73s/it]\u001b[A\n","Training loss: 0.417366, IoU: 0.9573615344885207 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.73s/it] \u001b[A\n","Training loss: 0.417366, IoU: 0.9573615344885207 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.74s/it]\u001b[A\n","Training loss: 0.42605472, IoU: 0.9616096744440269 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.74s/it]\u001b[A\n","Training loss: 0.42605472, IoU: 0.9616096744440269 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.46050015, IoU: 0.9663587809702158 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.46050015, IoU: 0.9663587809702158 |:  81%|████████  | 21/26 [00:57<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.46136343, IoU: 0.9522136606725587 |:  81%|████████  | 21/26 [00:59<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.46136343, IoU: 0.9522136606725587 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.38767368, IoU: 0.9521446140107728 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.38767368, IoU: 0.9521446140107728 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.5016057, IoU: 0.9445629690848015 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.5016057, IoU: 0.9445629690848015 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.4686096, IoU: 0.9600581863646747 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.4686096, IoU: 0.9600581863646747 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.5033811, IoU: 0.960792726118891 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it] \u001b[A\n","Training loss: 0.5033811, IoU: 0.960792726118891 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  81%|████████  | 121/150 [2:51:46<38:03, 78.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45464784, IoU: 0.9421522736182816 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45464784, IoU: 0.9421522736182816 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.4334194, IoU: 0.9558271130835061 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it] \u001b[A\n","Training loss: 0.4334194, IoU: 0.9558271130835061 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.48360592, IoU: 0.9572554715528906 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.48360592, IoU: 0.9572554715528906 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4858104, IoU: 0.9603762603984314 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it] \u001b[A\n","Training loss: 0.4858104, IoU: 0.9603762603984314 |:  15%|█▌        | 4/26 [00:11<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.44181877, IoU: 0.9618279235872925 |:  15%|█▌        | 4/26 [00:13<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.44181877, IoU: 0.9618279235872925 |:  19%|█▉        | 5/26 [00:13<00:58,  2.76s/it]\u001b[A\n","Training loss: 0.47194594, IoU: 0.9602017694681347 |:  19%|█▉        | 5/26 [00:16<00:58,  2.76s/it]\u001b[A\n","Training loss: 0.47194594, IoU: 0.9602017694681347 |:  23%|██▎       | 6/26 [00:16<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.4394461, IoU: 0.9569207953421949 |:  23%|██▎       | 6/26 [00:19<00:55,  2.76s/it] \u001b[A\n","Training loss: 0.4394461, IoU: 0.9569207953421949 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.40534443, IoU: 0.9589256544062145 |:  27%|██▋       | 7/26 [00:22<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.40534443, IoU: 0.9589256544062145 |:  31%|███       | 8/26 [00:22<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.3930186, IoU: 0.9549401953967214 |:  31%|███       | 8/26 [00:24<00:49,  2.76s/it] \u001b[A\n","Training loss: 0.3930186, IoU: 0.9549401953967214 |:  35%|███▍      | 9/26 [00:24<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.44887114, IoU: 0.9560421706780259 |:  35%|███▍      | 9/26 [00:27<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.44887114, IoU: 0.9560421706780259 |:  38%|███▊      | 10/26 [00:27<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.38996157, IoU: 0.952003028264656 |:  38%|███▊      | 10/26 [00:30<00:43,  2.75s/it] \u001b[A\n","Training loss: 0.38996157, IoU: 0.952003028264656 |:  42%|████▏     | 11/26 [00:30<00:41,  2.74s/it]\u001b[A\n","Training loss: 0.4586378, IoU: 0.9571312127285836 |:  42%|████▏     | 11/26 [00:32<00:41,  2.74s/it]\u001b[A\n","Training loss: 0.4586378, IoU: 0.9571312127285836 |:  46%|████▌     | 12/26 [00:32<00:38,  2.72s/it]\u001b[A\n","Training loss: 0.42890403, IoU: 0.965776444357007 |:  46%|████▌     | 12/26 [00:33<00:38,  2.72s/it]\u001b[A\n","Training loss: 0.42890403, IoU: 0.965776444357007 |:  50%|█████     | 13/26 [00:33<00:28,  2.19s/it]\u001b[A\n","Training loss: 0.44157192, IoU: 0.9610204013806659 |:  50%|█████     | 13/26 [00:36<00:28,  2.19s/it]\u001b[A\n","Training loss: 0.44157192, IoU: 0.9610204013806659 |:  54%|█████▍    | 14/26 [00:36<00:28,  2.35s/it]\u001b[A\n","Training loss: 0.4276305, IoU: 0.9541184955680455 |:  54%|█████▍    | 14/26 [00:39<00:28,  2.35s/it] \u001b[A\n","Training loss: 0.4276305, IoU: 0.9541184955680455 |:  58%|█████▊    | 15/26 [00:39<00:27,  2.47s/it]\u001b[A\n","Training loss: 0.44629586, IoU: 0.9596499537095434 |:  58%|█████▊    | 15/26 [00:42<00:27,  2.47s/it]\u001b[A\n","Training loss: 0.44629586, IoU: 0.9596499537095434 |:  62%|██████▏   | 16/26 [00:42<00:25,  2.55s/it]\u001b[A\n","Training loss: 0.47576863, IoU: 0.9468347766319674 |:  62%|██████▏   | 16/26 [00:44<00:25,  2.55s/it]\u001b[A\n","Training loss: 0.47576863, IoU: 0.9468347766319674 |:  65%|██████▌   | 17/26 [00:44<00:23,  2.60s/it]\u001b[A\n","Training loss: 0.4375937, IoU: 0.9602107276849434 |:  65%|██████▌   | 17/26 [00:47<00:23,  2.60s/it] \u001b[A\n","Training loss: 0.4375937, IoU: 0.9602107276849434 |:  69%|██████▉   | 18/26 [00:47<00:21,  2.64s/it]\u001b[A\n","Training loss: 0.45083785, IoU: 0.9493369126766077 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.64s/it]\u001b[A\n","Training loss: 0.45083785, IoU: 0.9493369126766077 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.42457712, IoU: 0.9463564642687591 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.42457712, IoU: 0.9463564642687591 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.443829, IoU: 0.9554092355103613 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.70s/it]  \u001b[A\n","Training loss: 0.443829, IoU: 0.9554092355103613 |:  81%|████████  | 21/26 [00:55<00:13,  2.72s/it]\u001b[A\n","Training loss: 0.47832045, IoU: 0.9656027393614662 |:  81%|████████  | 21/26 [00:58<00:13,  2.72s/it]\u001b[A\n","Training loss: 0.47832045, IoU: 0.9656027393614662 |:  85%|████████▍ | 22/26 [00:58<00:11,  2.75s/it]\u001b[A\n","Training loss: 0.45453194, IoU: 0.9525156664675068 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.75s/it]\u001b[A\n","Training loss: 0.45453194, IoU: 0.9525156664675068 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.40023082, IoU: 0.9555611703471626 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.40023082, IoU: 0.9555611703471626 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.46717358, IoU: 0.9651306194876756 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.46717358, IoU: 0.9651306194876756 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.81s/it]\u001b[A\n","Training loss: 0.45945954, IoU: 0.9601007426183368 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.81s/it]\u001b[A\n","Training loss: 0.45945954, IoU: 0.9601007426183368 |: 100%|██████████| 26/26 [01:10<00:00,  2.69s/it]\n","Epoch Loop:  81%|████████▏ | 122/150 [2:53:04<36:38, 78.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.43704274, IoU: 0.9629258767867425 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.43704274, IoU: 0.9629258767867425 |:   4%|▍         | 1/26 [00:02<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.41858035, IoU: 0.9618509539065432 |:   4%|▍         | 1/26 [00:05<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.41858035, IoU: 0.9618509539065432 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.44827864, IoU: 0.9533579696858865 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.44827864, IoU: 0.9533579696858865 |:  12%|█▏        | 3/26 [00:08<01:03,  2.76s/it]\u001b[A\n","Training loss: 0.4655532, IoU: 0.9544236616863128 |:  12%|█▏        | 3/26 [00:11<01:03,  2.76s/it] \u001b[A\n","Training loss: 0.4655532, IoU: 0.9544236616863128 |:  15%|█▌        | 4/26 [00:11<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.4751073, IoU: 0.9473622643480077 |:  15%|█▌        | 4/26 [00:13<01:00,  2.76s/it]\u001b[A\n","Training loss: 0.4751073, IoU: 0.9473622643480077 |:  19%|█▉        | 5/26 [00:13<00:57,  2.76s/it]\u001b[A\n","Training loss: 0.5022639, IoU: 0.9551136981292433 |:  19%|█▉        | 5/26 [00:16<00:57,  2.76s/it]\u001b[A\n","Training loss: 0.5022639, IoU: 0.9551136981292433 |:  23%|██▎       | 6/26 [00:16<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.4729162, IoU: 0.9466519092418373 |:  23%|██▎       | 6/26 [00:19<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.4729162, IoU: 0.9466519092418373 |:  27%|██▋       | 7/26 [00:19<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.4481735, IoU: 0.9492324872081201 |:  27%|██▋       | 7/26 [00:22<00:52,  2.76s/it]\u001b[A\n","Training loss: 0.4481735, IoU: 0.9492324872081201 |:  31%|███       | 8/26 [00:22<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.4431342, IoU: 0.9653789619396914 |:  31%|███       | 8/26 [00:24<00:49,  2.75s/it]\u001b[A\n","Training loss: 0.4431342, IoU: 0.9653789619396914 |:  35%|███▍      | 9/26 [00:24<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.4569558, IoU: 0.9581962087986667 |:  35%|███▍      | 9/26 [00:27<00:46,  2.75s/it]\u001b[A\n","Training loss: 0.4569558, IoU: 0.9581962087986667 |:  38%|███▊      | 10/26 [00:27<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.49141052, IoU: 0.9604515033100718 |:  38%|███▊      | 10/26 [00:30<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.49141052, IoU: 0.9604515033100718 |:  42%|████▏     | 11/26 [00:30<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.44342896, IoU: 0.9633056581394722 |:  42%|████▏     | 11/26 [00:33<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.44342896, IoU: 0.9633056581394722 |:  46%|████▌     | 12/26 [00:33<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.48671544, IoU: 0.9590783147704001 |:  46%|████▌     | 12/26 [00:35<00:38,  2.75s/it]\u001b[A\n","Training loss: 0.48671544, IoU: 0.9590783147704001 |:  50%|█████     | 13/26 [00:35<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.48878643, IoU: 0.9447799827437446 |:  50%|█████     | 13/26 [00:36<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.48878643, IoU: 0.9447799827437446 |:  54%|█████▍    | 14/26 [00:36<00:26,  2.21s/it]\u001b[A\n","Training loss: 0.44560772, IoU: 0.9546045009303795 |:  54%|█████▍    | 14/26 [00:39<00:26,  2.21s/it]\u001b[A\n","Training loss: 0.44560772, IoU: 0.9546045009303795 |:  58%|█████▊    | 15/26 [00:39<00:26,  2.38s/it]\u001b[A\n","Training loss: 0.44113857, IoU: 0.9485076899649764 |:  58%|█████▊    | 15/26 [00:42<00:26,  2.38s/it]\u001b[A\n","Training loss: 0.44113857, IoU: 0.9485076899649764 |:  62%|██████▏   | 16/26 [00:42<00:24,  2.49s/it]\u001b[A\n","Training loss: 0.42951906, IoU: 0.9551850451695324 |:  62%|██████▏   | 16/26 [00:45<00:24,  2.49s/it]\u001b[A\n","Training loss: 0.42951906, IoU: 0.9551850451695324 |:  65%|██████▌   | 17/26 [00:45<00:23,  2.58s/it]\u001b[A\n","Training loss: 0.43182382, IoU: 0.9583413363503611 |:  65%|██████▌   | 17/26 [00:47<00:23,  2.58s/it]\u001b[A\n","Training loss: 0.43182382, IoU: 0.9583413363503611 |:  69%|██████▉   | 18/26 [00:47<00:21,  2.65s/it]\u001b[A\n","Training loss: 0.42756253, IoU: 0.9482200729059755 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.65s/it]\u001b[A\n","Training loss: 0.42756253, IoU: 0.9482200729059755 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.69s/it]\u001b[A\n","Training loss: 0.45642596, IoU: 0.954948849135163 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.69s/it] \u001b[A\n","Training loss: 0.45642596, IoU: 0.954948849135163 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.71s/it]\u001b[A\n","Training loss: 0.37999338, IoU: 0.9553025415259276 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.71s/it]\u001b[A\n","Training loss: 0.37999338, IoU: 0.9553025415259276 |:  81%|████████  | 21/26 [00:56<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.4260425, IoU: 0.9554740974496791 |:  81%|████████  | 21/26 [00:59<00:13,  2.75s/it] \u001b[A\n","Training loss: 0.4260425, IoU: 0.9554740974496791 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.4234937, IoU: 0.9600608025841099 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.4234937, IoU: 0.9600608025841099 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.42308792, IoU: 0.9603635024629515 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.42308792, IoU: 0.9603635024629515 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.43344608, IoU: 0.9503598954305779 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.43344608, IoU: 0.9503598954305779 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.44281572, IoU: 0.958915139633512 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it] \u001b[A\n","Training loss: 0.44281572, IoU: 0.958915139633512 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  82%|████████▏ | 123/150 [2:54:22<35:18, 78.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44319126, IoU: 0.9568268873012856 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44319126, IoU: 0.9568268873012856 |:   4%|▍         | 1/26 [00:02<01:10,  2.81s/it]\u001b[A\n","Training loss: 0.39872915, IoU: 0.9525991475872859 |:   4%|▍         | 1/26 [00:05<01:10,  2.81s/it]\u001b[A\n","Training loss: 0.39872915, IoU: 0.9525991475872859 |:   8%|▊         | 2/26 [00:05<01:09,  2.89s/it]\u001b[A\n","Training loss: 0.44671118, IoU: 0.9546012237908278 |:   8%|▊         | 2/26 [00:08<01:09,  2.89s/it]\u001b[A\n","Training loss: 0.44671118, IoU: 0.9546012237908278 |:  12%|█▏        | 3/26 [00:08<01:05,  2.85s/it]\u001b[A\n","Training loss: 0.50553966, IoU: 0.9652849127524724 |:  12%|█▏        | 3/26 [00:11<01:05,  2.85s/it]\u001b[A\n","Training loss: 0.50553966, IoU: 0.9652849127524724 |:  15%|█▌        | 4/26 [00:11<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.43221635, IoU: 0.9536681053104721 |:  15%|█▌        | 4/26 [00:14<01:02,  2.82s/it]\u001b[A\n","Training loss: 0.43221635, IoU: 0.9536681053104721 |:  19%|█▉        | 5/26 [00:14<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.44224784, IoU: 0.9582225213818034 |:  19%|█▉        | 5/26 [00:16<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.44224784, IoU: 0.9582225213818034 |:  23%|██▎       | 6/26 [00:16<00:56,  2.82s/it]\u001b[A\n","Training loss: 0.4383385, IoU: 0.9588326772725229 |:  23%|██▎       | 6/26 [00:19<00:56,  2.82s/it] \u001b[A\n","Training loss: 0.4383385, IoU: 0.9588326772725229 |:  27%|██▋       | 7/26 [00:19<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.4622099, IoU: 0.9458968187863254 |:  27%|██▋       | 7/26 [00:22<00:53,  2.82s/it]\u001b[A\n","Training loss: 0.4622099, IoU: 0.9458968187863254 |:  31%|███       | 8/26 [00:22<00:50,  2.83s/it]\u001b[A\n","Training loss: 0.39920464, IoU: 0.962117124377203 |:  31%|███       | 8/26 [00:25<00:50,  2.83s/it]\u001b[A\n","Training loss: 0.39920464, IoU: 0.962117124377203 |:  35%|███▍      | 9/26 [00:25<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.36282092, IoU: 0.9595461461834025 |:  35%|███▍      | 9/26 [00:28<00:48,  2.83s/it]\u001b[A\n","Training loss: 0.36282092, IoU: 0.9595461461834025 |:  38%|███▊      | 10/26 [00:28<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.46059644, IoU: 0.9552154512632143 |:  38%|███▊      | 10/26 [00:31<00:45,  2.83s/it]\u001b[A\n","Training loss: 0.46059644, IoU: 0.9552154512632143 |:  42%|████▏     | 11/26 [00:31<00:42,  2.83s/it]\u001b[A\n","Training loss: 0.43247756, IoU: 0.9531473722676387 |:  42%|████▏     | 11/26 [00:33<00:42,  2.83s/it]\u001b[A\n","Training loss: 0.43247756, IoU: 0.9531473722676387 |:  46%|████▌     | 12/26 [00:33<00:39,  2.83s/it]\u001b[A\n","Training loss: 0.43685895, IoU: 0.949520135733772 |:  46%|████▌     | 12/26 [00:36<00:39,  2.83s/it] \u001b[A\n","Training loss: 0.43685895, IoU: 0.949520135733772 |:  50%|█████     | 13/26 [00:36<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.44211912, IoU: 0.9585076895347308 |:  50%|█████     | 13/26 [00:39<00:36,  2.83s/it]\u001b[A\n","Training loss: 0.44211912, IoU: 0.9585076895347308 |:  54%|█████▍    | 14/26 [00:39<00:34,  2.83s/it]\u001b[A\n","Training loss: 0.4621536, IoU: 0.9512879538924268 |:  54%|█████▍    | 14/26 [00:40<00:34,  2.83s/it] \u001b[A\n","Training loss: 0.4621536, IoU: 0.9512879538924268 |:  58%|█████▊    | 15/26 [00:40<00:25,  2.28s/it]\u001b[A\n","Training loss: 0.5117777, IoU: 0.9563728998826885 |:  58%|█████▊    | 15/26 [00:43<00:25,  2.28s/it]\u001b[A\n","Training loss: 0.5117777, IoU: 0.9563728998826885 |:  62%|██████▏   | 16/26 [00:43<00:24,  2.45s/it]\u001b[A\n","Training loss: 0.39582205, IoU: 0.956869253366907 |:  62%|██████▏   | 16/26 [00:46<00:24,  2.45s/it]\u001b[A\n","Training loss: 0.39582205, IoU: 0.956869253366907 |:  65%|██████▌   | 17/26 [00:46<00:23,  2.57s/it]\u001b[A\n","Training loss: 0.43835694, IoU: 0.9602961058240331 |:  65%|██████▌   | 17/26 [00:49<00:23,  2.57s/it]\u001b[A\n","Training loss: 0.43835694, IoU: 0.9602961058240331 |:  69%|██████▉   | 18/26 [00:49<00:21,  2.63s/it]\u001b[A\n","Training loss: 0.4456283, IoU: 0.9597848360655737 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.63s/it] \u001b[A\n","Training loss: 0.4456283, IoU: 0.9597848360655737 |:  73%|███████▎  | 19/26 [00:51<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.42843693, IoU: 0.9488554714742738 |:  73%|███████▎  | 19/26 [00:54<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.42843693, IoU: 0.9488554714742738 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.72s/it]\u001b[A\n","Training loss: 0.38144243, IoU: 0.9597614913665867 |:  77%|███████▋  | 20/26 [00:57<00:16,  2.72s/it]\u001b[A\n","Training loss: 0.38144243, IoU: 0.9597614913665867 |:  81%|████████  | 21/26 [00:57<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.41983008, IoU: 0.9621718668210962 |:  81%|████████  | 21/26 [01:00<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.41983008, IoU: 0.9621718668210962 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.467926, IoU: 0.9545692655284879 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.77s/it]  \u001b[A\n","Training loss: 0.467926, IoU: 0.9545692655284879 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.49011242, IoU: 0.9445348454379869 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.49011242, IoU: 0.9445348454379869 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.44087642, IoU: 0.9494566876332443 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.44087642, IoU: 0.9494566876332443 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.45534462, IoU: 0.9564006841746183 |:  96%|█████████▌| 25/26 [01:11<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.45534462, IoU: 0.9564006841746183 |: 100%|██████████| 26/26 [01:11<00:00,  2.75s/it]\n","Epoch Loop:  83%|████████▎ | 124/150 [2:55:42<34:09, 78.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47329104, IoU: 0.9602042894300815 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47329104, IoU: 0.9602042894300815 |:   4%|▍         | 1/26 [00:02<01:11,  2.87s/it]\u001b[A\n","Training loss: 0.47819245, IoU: 0.9578152681125018 |:   4%|▍         | 1/26 [00:05<01:11,  2.87s/it]\u001b[A\n","Training loss: 0.47819245, IoU: 0.9578152681125018 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.5312851, IoU: 0.9614463797348743 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it] \u001b[A\n","Training loss: 0.5312851, IoU: 0.9614463797348743 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.45980275, IoU: 0.9629063677402045 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.45980275, IoU: 0.9629063677402045 |:  15%|█▌        | 4/26 [00:11<01:01,  2.82s/it]\u001b[A\n","Training loss: 0.39220545, IoU: 0.950165212279661 |:  15%|█▌        | 4/26 [00:14<01:01,  2.82s/it] \u001b[A\n","Training loss: 0.39220545, IoU: 0.950165212279661 |:  19%|█▉        | 5/26 [00:14<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.46710995, IoU: 0.9639072361308095 |:  19%|█▉        | 5/26 [00:16<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.46710995, IoU: 0.9639072361308095 |:  23%|██▎       | 6/26 [00:16<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.45052165, IoU: 0.9574199063273556 |:  23%|██▎       | 6/26 [00:19<00:56,  2.81s/it]\u001b[A\n","Training loss: 0.45052165, IoU: 0.9574199063273556 |:  27%|██▋       | 7/26 [00:19<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.43653458, IoU: 0.9569903245120903 |:  27%|██▋       | 7/26 [00:22<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.43653458, IoU: 0.9569903245120903 |:  31%|███       | 8/26 [00:22<00:50,  2.82s/it]\u001b[A\n","Training loss: 0.4552757, IoU: 0.9554502849782799 |:  31%|███       | 8/26 [00:25<00:50,  2.82s/it] \u001b[A\n","Training loss: 0.4552757, IoU: 0.9554502849782799 |:  35%|███▍      | 9/26 [00:25<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.46041423, IoU: 0.9505446633031959 |:  35%|███▍      | 9/26 [00:28<00:47,  2.80s/it]\u001b[A\n","Training loss: 0.46041423, IoU: 0.9505446633031959 |:  38%|███▊      | 10/26 [00:28<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.44868866, IoU: 0.9483271667734796 |:  38%|███▊      | 10/26 [00:30<00:44,  2.80s/it]\u001b[A\n","Training loss: 0.44868866, IoU: 0.9483271667734796 |:  42%|████▏     | 11/26 [00:30<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.43326315, IoU: 0.9587190442281827 |:  42%|████▏     | 11/26 [00:33<00:41,  2.80s/it]\u001b[A\n","Training loss: 0.43326315, IoU: 0.9587190442281827 |:  46%|████▌     | 12/26 [00:33<00:39,  2.81s/it]\u001b[A\n","Training loss: 0.46183228, IoU: 0.957595272842498 |:  46%|████▌     | 12/26 [00:36<00:39,  2.81s/it] \u001b[A\n","Training loss: 0.46183228, IoU: 0.957595272842498 |:  50%|█████     | 13/26 [00:36<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.4251639, IoU: 0.9666441546139475 |:  50%|█████     | 13/26 [00:39<00:36,  2.80s/it]\u001b[A\n","Training loss: 0.4251639, IoU: 0.9666441546139475 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.43226597, IoU: 0.957585134990283 |:  54%|█████▍    | 14/26 [00:42<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.43226597, IoU: 0.957585134990283 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.48340976, IoU: 0.9396832022496595 |:  58%|█████▊    | 15/26 [00:43<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.48340976, IoU: 0.9396832022496595 |:  62%|██████▏   | 16/26 [00:43<00:22,  2.24s/it]\u001b[A\n","Training loss: 0.4996212, IoU: 0.956220445669242 |:  62%|██████▏   | 16/26 [00:45<00:22,  2.24s/it]  \u001b[A\n","Training loss: 0.4996212, IoU: 0.956220445669242 |:  65%|██████▌   | 17/26 [00:45<00:21,  2.40s/it]\u001b[A\n","Training loss: 0.46609443, IoU: 0.9482069248199965 |:  65%|██████▌   | 17/26 [00:48<00:21,  2.40s/it]\u001b[A\n","Training loss: 0.46609443, IoU: 0.9482069248199965 |:  69%|██████▉   | 18/26 [00:48<00:20,  2.51s/it]\u001b[A\n","Training loss: 0.45505416, IoU: 0.9564752363355876 |:  69%|██████▉   | 18/26 [00:51<00:20,  2.51s/it]\u001b[A\n","Training loss: 0.45505416, IoU: 0.9564752363355876 |:  73%|███████▎  | 19/26 [00:51<00:18,  2.59s/it]\u001b[A\n","Training loss: 0.42497718, IoU: 0.951379923576654 |:  73%|███████▎  | 19/26 [00:54<00:18,  2.59s/it] \u001b[A\n","Training loss: 0.42497718, IoU: 0.951379923576654 |:  77%|███████▋  | 20/26 [00:54<00:15,  2.65s/it]\u001b[A\n","Training loss: 0.41741174, IoU: 0.9480054692670015 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.65s/it]\u001b[A\n","Training loss: 0.41741174, IoU: 0.9480054692670015 |:  81%|████████  | 21/26 [00:56<00:13,  2.69s/it]\u001b[A\n","Training loss: 0.42152783, IoU: 0.9520605023576588 |:  81%|████████  | 21/26 [00:59<00:13,  2.69s/it]\u001b[A\n","Training loss: 0.42152783, IoU: 0.9520605023576588 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.71s/it]\u001b[A\n","Training loss: 0.470702, IoU: 0.9615331964407939 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.71s/it]  \u001b[A\n","Training loss: 0.470702, IoU: 0.9615331964407939 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.43445033, IoU: 0.9499858795525835 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.43445033, IoU: 0.9499858795525835 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.74s/it]\u001b[A\n","Training loss: 0.45179003, IoU: 0.9577820557559734 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.74s/it]\u001b[A\n","Training loss: 0.45179003, IoU: 0.9577820557559734 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.75s/it]\u001b[A\n","Training loss: 0.4442642, IoU: 0.9448907318390765 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.75s/it] \u001b[A\n","Training loss: 0.4442642, IoU: 0.9448907318390765 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  83%|████████▎ | 125/150 [2:57:01<32:49, 78.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45416027, IoU: 0.9498861488332069 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45416027, IoU: 0.9498861488332069 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.43305176, IoU: 0.9458951593909045 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.43305176, IoU: 0.9458951593909045 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.48415208, IoU: 0.9498543663376919 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.48415208, IoU: 0.9498543663376919 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.49652857, IoU: 0.9562340438967624 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.49652857, IoU: 0.9562340438967624 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.4141198, IoU: 0.9637529930217175 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it] \u001b[A\n","Training loss: 0.4141198, IoU: 0.9637529930217175 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4327872, IoU: 0.9489798930505569 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4327872, IoU: 0.9489798930505569 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.45068955, IoU: 0.9554238247523877 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.45068955, IoU: 0.9554238247523877 |:  27%|██▋       | 7/26 [00:19<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.44242266, IoU: 0.9510172310625653 |:  27%|██▋       | 7/26 [00:22<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.44242266, IoU: 0.9510172310625653 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.4790326, IoU: 0.9593399516031206 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it] \u001b[A\n","Training loss: 0.4790326, IoU: 0.9593399516031206 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.39758042, IoU: 0.9507603457183289 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.39758042, IoU: 0.9507603457183289 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.43952894, IoU: 0.9598945627128437 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.43952894, IoU: 0.9598945627128437 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.42893928, IoU: 0.9539121984883505 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.42893928, IoU: 0.9539121984883505 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.43982312, IoU: 0.9520354320608844 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.43982312, IoU: 0.9520354320608844 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.33956876, IoU: 0.9537405613373193 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.33956876, IoU: 0.9537405613373193 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.4694831, IoU: 0.9567091347937481 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it] \u001b[A\n","Training loss: 0.4694831, IoU: 0.9567091347937481 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.501451, IoU: 0.9531011195581819 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it] \u001b[A\n","Training loss: 0.501451, IoU: 0.9531011195581819 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.42163312, IoU: 0.9564113715639895 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.42163312, IoU: 0.9564113715639895 |:  65%|██████▌   | 17/26 [00:45<00:20,  2.24s/it]\u001b[A\n","Training loss: 0.43003786, IoU: 0.9591450160675962 |:  65%|██████▌   | 17/26 [00:48<00:20,  2.24s/it]\u001b[A\n","Training loss: 0.43003786, IoU: 0.9591450160675962 |:  69%|██████▉   | 18/26 [00:48<00:19,  2.41s/it]\u001b[A\n","Training loss: 0.36148655, IoU: 0.9459421548526116 |:  69%|██████▉   | 18/26 [00:51<00:19,  2.41s/it]\u001b[A\n","Training loss: 0.36148655, IoU: 0.9459421548526116 |:  73%|███████▎  | 19/26 [00:51<00:17,  2.52s/it]\u001b[A\n","Training loss: 0.456155, IoU: 0.9630047913925573 |:  73%|███████▎  | 19/26 [00:53<00:17,  2.52s/it]  \u001b[A\n","Training loss: 0.456155, IoU: 0.9630047913925573 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.60s/it]\u001b[A\n","Training loss: 0.47116685, IoU: 0.9652406352954163 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.60s/it]\u001b[A\n","Training loss: 0.47116685, IoU: 0.9652406352954163 |:  81%|████████  | 21/26 [00:56<00:13,  2.65s/it]\u001b[A\n","Training loss: 0.44801435, IoU: 0.9587991605358216 |:  81%|████████  | 21/26 [00:59<00:13,  2.65s/it]\u001b[A\n","Training loss: 0.44801435, IoU: 0.9587991605358216 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.71s/it]\u001b[A\n","Training loss: 0.44830844, IoU: 0.9653777108039049 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.71s/it]\u001b[A\n","Training loss: 0.44830844, IoU: 0.9653777108039049 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.73s/it]\u001b[A\n","Training loss: 0.4931093, IoU: 0.9603519058884173 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.73s/it] \u001b[A\n","Training loss: 0.4931093, IoU: 0.9603519058884173 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.74s/it]\u001b[A\n","Training loss: 0.4510587, IoU: 0.9578994462834637 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.74s/it]\u001b[A\n","Training loss: 0.4510587, IoU: 0.9578994462834637 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.44555023, IoU: 0.9558875587708845 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.44555023, IoU: 0.9558875587708845 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  84%|████████▍ | 126/150 [2:58:19<31:29, 78.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46448827, IoU: 0.9576657134005888 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46448827, IoU: 0.9576657134005888 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.39593163, IoU: 0.9457458957139415 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.39593163, IoU: 0.9457458957139415 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.49012545, IoU: 0.9555577892961095 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.49012545, IoU: 0.9555577892961095 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.49030277, IoU: 0.9369142426436314 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.49030277, IoU: 0.9369142426436314 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.46421856, IoU: 0.9567311475925897 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.46421856, IoU: 0.9567311475925897 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4965049, IoU: 0.9547814357248808 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it] \u001b[A\n","Training loss: 0.4965049, IoU: 0.9547814357248808 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.41216263, IoU: 0.963850666713967 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.41216263, IoU: 0.963850666713967 |:  27%|██▋       | 7/26 [00:19<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.45419174, IoU: 0.9547503910758676 |:  27%|██▋       | 7/26 [00:22<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.45419174, IoU: 0.9547503910758676 |:  31%|███       | 8/26 [00:22<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.42656356, IoU: 0.9527086949058798 |:  31%|███       | 8/26 [00:25<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.42656356, IoU: 0.9527086949058798 |:  35%|███▍      | 9/26 [00:25<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.43405187, IoU: 0.9651683572609132 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.43405187, IoU: 0.9651683572609132 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.43839738, IoU: 0.9536936511682794 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.43839738, IoU: 0.9536936511682794 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.42464972, IoU: 0.9587468840139944 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.42464972, IoU: 0.9587468840139944 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.39381564, IoU: 0.9504244205943572 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.39381564, IoU: 0.9504244205943572 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.44066462, IoU: 0.9401856275991822 |:  50%|█████     | 13/26 [00:39<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.44066462, IoU: 0.9401856275991822 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.46412838, IoU: 0.9531788075064693 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.46412838, IoU: 0.9531788075064693 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.46994627, IoU: 0.9543226700839268 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.46994627, IoU: 0.9543226700839268 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.79s/it]\u001b[A\n","Training loss: 0.4137747, IoU: 0.9597370343316289 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.79s/it] \u001b[A\n","Training loss: 0.4137747, IoU: 0.9597370343316289 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.54821837, IoU: 0.9531486298469543 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.54821837, IoU: 0.9531486298469543 |:  69%|██████▉   | 18/26 [00:48<00:17,  2.24s/it]\u001b[A\n","Training loss: 0.43819654, IoU: 0.9560581473394448 |:  69%|██████▉   | 18/26 [00:51<00:17,  2.24s/it]\u001b[A\n","Training loss: 0.43819654, IoU: 0.9560581473394448 |:  73%|███████▎  | 19/26 [00:51<00:16,  2.41s/it]\u001b[A\n","Training loss: 0.44627824, IoU: 0.9494098572243822 |:  73%|███████▎  | 19/26 [00:53<00:16,  2.41s/it]\u001b[A\n","Training loss: 0.44627824, IoU: 0.9494098572243822 |:  77%|███████▋  | 20/26 [00:53<00:15,  2.53s/it]\u001b[A\n","Training loss: 0.43114418, IoU: 0.9576523960876302 |:  77%|███████▋  | 20/26 [00:56<00:15,  2.53s/it]\u001b[A\n","Training loss: 0.43114418, IoU: 0.9576523960876302 |:  81%|████████  | 21/26 [00:56<00:13,  2.61s/it]\u001b[A\n","Training loss: 0.4525234, IoU: 0.9593478818501686 |:  81%|████████  | 21/26 [00:59<00:13,  2.61s/it] \u001b[A\n","Training loss: 0.4525234, IoU: 0.9593478818501686 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.66s/it]\u001b[A\n","Training loss: 0.42377198, IoU: 0.9607915375298761 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.66s/it]\u001b[A\n","Training loss: 0.42377198, IoU: 0.9607915375298761 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.51755404, IoU: 0.9542991891480154 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.69s/it]\u001b[A\n","Training loss: 0.51755404, IoU: 0.9542991891480154 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.72s/it]\u001b[A\n","Training loss: 0.46637377, IoU: 0.9555636120252106 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.72s/it]\u001b[A\n","Training loss: 0.46637377, IoU: 0.9555636120252106 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.75s/it]\u001b[A\n","Training loss: 0.44392142, IoU: 0.9593457167935853 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.75s/it]\u001b[A\n","Training loss: 0.44392142, IoU: 0.9593457167935853 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  85%|████████▍ | 127/150 [2:59:38<30:09, 78.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45269325, IoU: 0.9643210168177658 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45269325, IoU: 0.9643210168177658 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.4329223, IoU: 0.9558924984384896 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it] \u001b[A\n","Training loss: 0.4329223, IoU: 0.9558924984384896 |:   8%|▊         | 2/26 [00:05<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.43687108, IoU: 0.9489332459182142 |:   8%|▊         | 2/26 [00:08<01:06,  2.79s/it]\u001b[A\n","Training loss: 0.43687108, IoU: 0.9489332459182142 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.37520513, IoU: 0.9453898497306493 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.37520513, IoU: 0.9453898497306493 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.47302723, IoU: 0.9584785697934078 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.47302723, IoU: 0.9584785697934078 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.47768277, IoU: 0.9631326969841281 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.47768277, IoU: 0.9631326969841281 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.44706574, IoU: 0.962180611975098 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it] \u001b[A\n","Training loss: 0.44706574, IoU: 0.962180611975098 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.40335315, IoU: 0.948731223687276 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.40335315, IoU: 0.948731223687276 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.40733978, IoU: 0.9610638705965092 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.40733978, IoU: 0.9610638705965092 |:  35%|███▍      | 9/26 [00:25<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.47903192, IoU: 0.9606272378955439 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.47903192, IoU: 0.9606272378955439 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.40658298, IoU: 0.9622476515301994 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.40658298, IoU: 0.9622476515301994 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.44392675, IoU: 0.9494418018722443 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.44392675, IoU: 0.9494418018722443 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.4677238, IoU: 0.9604057155208492 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it] \u001b[A\n","Training loss: 0.4677238, IoU: 0.9604057155208492 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.45865333, IoU: 0.9502478199663708 |:  50%|█████     | 13/26 [00:39<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.45865333, IoU: 0.9502478199663708 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.5219443, IoU: 0.962833440022684 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it]  \u001b[A\n","Training loss: 0.5219443, IoU: 0.962833440022684 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.43843925, IoU: 0.9540343594046725 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.43843925, IoU: 0.9540343594046725 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.5082483, IoU: 0.951987456103965 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]  \u001b[A\n","Training loss: 0.5082483, IoU: 0.951987456103965 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4934839, IoU: 0.9444868211088603 |:  65%|██████▌   | 17/26 [00:50<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4934839, IoU: 0.9444868211088603 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45418513, IoU: 0.9625952739349628 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.45418513, IoU: 0.9625952739349628 |:  73%|███████▎  | 19/26 [00:51<00:15,  2.22s/it]\u001b[A\n","Training loss: 0.39506072, IoU: 0.9584877304215099 |:  73%|███████▎  | 19/26 [00:53<00:15,  2.22s/it]\u001b[A\n","Training loss: 0.39506072, IoU: 0.9584877304215099 |:  77%|███████▋  | 20/26 [00:53<00:14,  2.40s/it]\u001b[A\n","Training loss: 0.45943153, IoU: 0.9537908588276909 |:  77%|███████▋  | 20/26 [00:56<00:14,  2.40s/it]\u001b[A\n","Training loss: 0.45943153, IoU: 0.9537908588276909 |:  81%|████████  | 21/26 [00:56<00:12,  2.53s/it]\u001b[A\n","Training loss: 0.42105874, IoU: 0.9552956264853527 |:  81%|████████  | 21/26 [00:59<00:12,  2.53s/it]\u001b[A\n","Training loss: 0.42105874, IoU: 0.9552956264853527 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.62s/it]\u001b[A\n","Training loss: 0.47238714, IoU: 0.9638222090872496 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.62s/it]\u001b[A\n","Training loss: 0.47238714, IoU: 0.9638222090872496 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.68s/it]\u001b[A\n","Training loss: 0.4468465, IoU: 0.954069353980342 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.68s/it]  \u001b[A\n","Training loss: 0.4468465, IoU: 0.954069353980342 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.71s/it]\u001b[A\n","Training loss: 0.50421906, IoU: 0.9568499792214988 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.71s/it]\u001b[A\n","Training loss: 0.50421906, IoU: 0.9568499792214988 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.74s/it]\u001b[A\n","Training loss: 0.44840047, IoU: 0.9557665041247713 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.74s/it]\u001b[A\n","Training loss: 0.44840047, IoU: 0.9557665041247713 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  85%|████████▌ | 128/150 [3:00:57<28:51, 78.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.38612488, IoU: 0.9515332066854719 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.38612488, IoU: 0.9515332066854719 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.4594984, IoU: 0.9370535481873405 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it] \u001b[A\n","Training loss: 0.4594984, IoU: 0.9370535481873405 |:   8%|▊         | 2/26 [00:05<01:07,  2.83s/it]\u001b[A\n","Training loss: 0.41699165, IoU: 0.9517424378223757 |:   8%|▊         | 2/26 [00:08<01:07,  2.83s/it]\u001b[A\n","Training loss: 0.41699165, IoU: 0.9517424378223757 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.46967915, IoU: 0.9558330705159767 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.46967915, IoU: 0.9558330705159767 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.42365286, IoU: 0.957139344934029 |:  15%|█▌        | 4/26 [00:14<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.42365286, IoU: 0.957139344934029 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.45019636, IoU: 0.9634087727977155 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.45019636, IoU: 0.9634087727977155 |:  23%|██▎       | 6/26 [00:16<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.39143783, IoU: 0.9556247546497194 |:  23%|██▎       | 6/26 [00:19<00:55,  2.80s/it]\u001b[A\n","Training loss: 0.39143783, IoU: 0.9556247546497194 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.4296288, IoU: 0.9483128572764735 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it] \u001b[A\n","Training loss: 0.4296288, IoU: 0.9483128572764735 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.48827344, IoU: 0.9602112771677634 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.48827344, IoU: 0.9602112771677634 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.45716763, IoU: 0.9568916346693882 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.45716763, IoU: 0.9568916346693882 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.42050377, IoU: 0.9533679555625084 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.42050377, IoU: 0.9533679555625084 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.49396485, IoU: 0.9608805031446541 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.49396485, IoU: 0.9608805031446541 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.45619178, IoU: 0.9642750347399343 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.45619178, IoU: 0.9642750347399343 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.42004177, IoU: 0.9605801238456583 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.42004177, IoU: 0.9605801238456583 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.48232022, IoU: 0.9577698436786829 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.80s/it]\u001b[A\n","Training loss: 0.48232022, IoU: 0.9577698436786829 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.44624704, IoU: 0.9583846139281251 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.44624704, IoU: 0.9583846139281251 |:  62%|██████▏   | 16/26 [00:44<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.48580858, IoU: 0.9558137976585908 |:  62%|██████▏   | 16/26 [00:47<00:28,  2.80s/it]\u001b[A\n","Training loss: 0.48580858, IoU: 0.9558137976585908 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.48600343, IoU: 0.949833619956239 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.80s/it] \u001b[A\n","Training loss: 0.48600343, IoU: 0.949833619956239 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.45303082, IoU: 0.9652712470107746 |:  69%|██████▉   | 18/26 [00:53<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.45303082, IoU: 0.9652712470107746 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.82s/it]\u001b[A\n","Training loss: 0.52742445, IoU: 0.9640852253106001 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.82s/it]\u001b[A\n","Training loss: 0.52742445, IoU: 0.9640852253106001 |:  77%|███████▋  | 20/26 [00:54<00:13,  2.27s/it]\u001b[A\n","Training loss: 0.5217183, IoU: 0.9621730331711854 |:  77%|███████▋  | 20/26 [00:57<00:13,  2.27s/it] \u001b[A\n","Training loss: 0.5217183, IoU: 0.9621730331711854 |:  81%|████████  | 21/26 [00:57<00:12,  2.44s/it]\u001b[A\n","Training loss: 0.4055187, IoU: 0.9461498291168365 |:  81%|████████  | 21/26 [00:59<00:12,  2.44s/it]\u001b[A\n","Training loss: 0.4055187, IoU: 0.9461498291168365 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.54s/it]\u001b[A\n","Training loss: 0.45756108, IoU: 0.9667024959638081 |:  85%|████████▍ | 22/26 [01:02<00:10,  2.54s/it]\u001b[A\n","Training loss: 0.45756108, IoU: 0.9667024959638081 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.61s/it]\u001b[A\n","Training loss: 0.4316599, IoU: 0.9565529359132572 |:  88%|████████▊ | 23/26 [01:05<00:07,  2.61s/it] \u001b[A\n","Training loss: 0.4316599, IoU: 0.9565529359132572 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.66s/it]\u001b[A\n","Training loss: 0.41152108, IoU: 0.9549907667662917 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.66s/it]\u001b[A\n","Training loss: 0.41152108, IoU: 0.9549907667662917 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.70s/it]\u001b[A\n","Training loss: 0.4499035, IoU: 0.9513618424749613 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.70s/it] \u001b[A\n","Training loss: 0.4499035, IoU: 0.9513618424749613 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  86%|████████▌ | 129/150 [3:02:15<27:33, 78.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46931356, IoU: 0.9468384747292652 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46931356, IoU: 0.9468384747292652 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.38827252, IoU: 0.9453440534300047 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.38827252, IoU: 0.9453440534300047 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.46674746, IoU: 0.9613263404839805 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.46674746, IoU: 0.9613263404839805 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.44200003, IoU: 0.9480751341345386 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.44200003, IoU: 0.9480751341345386 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.4335163, IoU: 0.9376268479884613 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it] \u001b[A\n","Training loss: 0.4335163, IoU: 0.9376268479884613 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.43498254, IoU: 0.9500322515522598 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.43498254, IoU: 0.9500322515522598 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.4430068, IoU: 0.9515264813247609 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it] \u001b[A\n","Training loss: 0.4430068, IoU: 0.9515264813247609 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.3786856, IoU: 0.9440604912124252 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.3786856, IoU: 0.9440604912124252 |:  31%|███       | 8/26 [00:22<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.43938392, IoU: 0.946150536161176 |:  31%|███       | 8/26 [00:25<00:49,  2.78s/it]\u001b[A\n","Training loss: 0.43938392, IoU: 0.946150536161176 |:  35%|███▍      | 9/26 [00:25<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.46587193, IoU: 0.9462349345079671 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.46587193, IoU: 0.9462349345079671 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.43621314, IoU: 0.9471124205334492 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.43621314, IoU: 0.9471124205334492 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.46274313, IoU: 0.951395068319788 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it] \u001b[A\n","Training loss: 0.46274313, IoU: 0.951395068319788 |:  46%|████▌     | 12/26 [00:33<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.4655199, IoU: 0.9421788163181719 |:  46%|████▌     | 12/26 [00:36<00:39,  2.80s/it]\u001b[A\n","Training loss: 0.4655199, IoU: 0.9421788163181719 |:  50%|█████     | 13/26 [00:36<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.46749017, IoU: 0.9554629653700627 |:  50%|█████     | 13/26 [00:39<00:36,  2.79s/it]\u001b[A\n","Training loss: 0.46749017, IoU: 0.9554629653700627 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.45038873, IoU: 0.9602626006338303 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.45038873, IoU: 0.9602626006338303 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.79s/it]\u001b[A\n","Training loss: 0.49722636, IoU: 0.934374635738431 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.79s/it] \u001b[A\n","Training loss: 0.49722636, IoU: 0.934374635738431 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.4679811, IoU: 0.9498022825107618 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.4679811, IoU: 0.9498022825107618 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4810045, IoU: 0.940572995897294 |:  65%|██████▌   | 17/26 [00:50<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.4810045, IoU: 0.940572995897294 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.4796663, IoU: 0.9623537438028809 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.4796663, IoU: 0.9623537438028809 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.5143719, IoU: 0.9474915289360961 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.5143719, IoU: 0.9474915289360961 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.5259859, IoU: 0.9560640126967332 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.5259859, IoU: 0.9560640126967332 |:  81%|████████  | 21/26 [00:56<00:11,  2.23s/it]\u001b[A\n","Training loss: 0.48593417, IoU: 0.948662671079703 |:  81%|████████  | 21/26 [00:59<00:11,  2.23s/it]\u001b[A\n","Training loss: 0.48593417, IoU: 0.948662671079703 |:  85%|████████▍ | 22/26 [00:59<00:09,  2.39s/it]\u001b[A\n","Training loss: 0.47052318, IoU: 0.9521160428098007 |:  85%|████████▍ | 22/26 [01:02<00:09,  2.39s/it]\u001b[A\n","Training loss: 0.47052318, IoU: 0.9521160428098007 |:  88%|████████▊ | 23/26 [01:02<00:07,  2.51s/it]\u001b[A\n","Training loss: 0.49291348, IoU: 0.9572474819849328 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.51s/it]\u001b[A\n","Training loss: 0.49291348, IoU: 0.9572474819849328 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.58s/it]\u001b[A\n","Training loss: 0.44818884, IoU: 0.9513320621805567 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.58s/it]\u001b[A\n","Training loss: 0.44818884, IoU: 0.9513320621805567 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.63s/it]\u001b[A\n","Training loss: 0.48789954, IoU: 0.9442426299756206 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.63s/it]\u001b[A\n","Training loss: 0.48789954, IoU: 0.9442426299756206 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  87%|████████▋ | 130/150 [3:03:34<26:12, 78.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.46916872, IoU: 0.9543858109715125 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.46916872, IoU: 0.9543858109715125 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.4768241, IoU: 0.9478477901384826 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it] \u001b[A\n","Training loss: 0.4768241, IoU: 0.9478477901384826 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.50796336, IoU: 0.9528770576022835 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.50796336, IoU: 0.9528770576022835 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.44644403, IoU: 0.9606290771034299 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.44644403, IoU: 0.9606290771034299 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.50481284, IoU: 0.9493166449502106 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.50481284, IoU: 0.9493166449502106 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.44170013, IoU: 0.9596583278457141 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.44170013, IoU: 0.9596583278457141 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.44990128, IoU: 0.9470745483551072 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.44990128, IoU: 0.9470745483551072 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.5395698, IoU: 0.9375918147044329 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it] \u001b[A\n","Training loss: 0.5395698, IoU: 0.9375918147044329 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.4720654, IoU: 0.9443146350665386 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.4720654, IoU: 0.9443146350665386 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.4636327, IoU: 0.9533911318983143 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.4636327, IoU: 0.9533911318983143 |:  38%|███▊      | 10/26 [00:27<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.45722795, IoU: 0.9553914912876217 |:  38%|███▊      | 10/26 [00:30<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.45722795, IoU: 0.9553914912876217 |:  42%|████▏     | 11/26 [00:30<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.47575894, IoU: 0.9410573318715458 |:  42%|████▏     | 11/26 [00:33<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.47575894, IoU: 0.9410573318715458 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.41842002, IoU: 0.9543430212239423 |:  46%|████▌     | 12/26 [00:36<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.41842002, IoU: 0.9543430212239423 |:  50%|█████     | 13/26 [00:36<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.4375815, IoU: 0.9377538499365593 |:  50%|█████     | 13/26 [00:38<00:35,  2.77s/it] \u001b[A\n","Training loss: 0.4375815, IoU: 0.9377538499365593 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.43541652, IoU: 0.9414245935038814 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.43541652, IoU: 0.9414245935038814 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.45233092, IoU: 0.9419207776405345 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.45233092, IoU: 0.9419207776405345 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.4893332, IoU: 0.9426477858432983 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.78s/it] \u001b[A\n","Training loss: 0.4893332, IoU: 0.9426477858432983 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.41810608, IoU: 0.9424567872523445 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.41810608, IoU: 0.9424567872523445 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.42290884, IoU: 0.945268317827882 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.78s/it] \u001b[A\n","Training loss: 0.42290884, IoU: 0.945268317827882 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.39650124, IoU: 0.9527913887543317 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.39650124, IoU: 0.9527913887543317 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.47300124, IoU: 0.9499571007572649 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.47300124, IoU: 0.9499571007572649 |:  81%|████████  | 21/26 [00:58<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.39896396, IoU: 0.9619116981280633 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.39896396, IoU: 0.9619116981280633 |:  85%|████████▍ | 22/26 [00:59<00:08,  2.23s/it]\u001b[A\n","Training loss: 0.4519672, IoU: 0.9609295874887086 |:  85%|████████▍ | 22/26 [01:01<00:08,  2.23s/it] \u001b[A\n","Training loss: 0.4519672, IoU: 0.9609295874887086 |:  88%|████████▊ | 23/26 [01:01<00:07,  2.39s/it]\u001b[A\n","Training loss: 0.4585868, IoU: 0.9497516722125239 |:  88%|████████▊ | 23/26 [01:04<00:07,  2.39s/it]\u001b[A\n","Training loss: 0.4585868, IoU: 0.9497516722125239 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.50s/it]\u001b[A\n","Training loss: 0.49490288, IoU: 0.9428476037271982 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.50s/it]\u001b[A\n","Training loss: 0.49490288, IoU: 0.9428476037271982 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.59s/it]\u001b[A\n","Training loss: 0.48417857, IoU: 0.9548166624293688 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.59s/it]\u001b[A\n","Training loss: 0.48417857, IoU: 0.9548166624293688 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  87%|████████▋ | 131/150 [3:04:52<24:51, 78.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45058486, IoU: 0.9518048924384621 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45058486, IoU: 0.9518048924384621 |:   4%|▍         | 1/26 [00:02<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.44416714, IoU: 0.9577135279178292 |:   4%|▍         | 1/26 [00:05<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.44416714, IoU: 0.9577135279178292 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4540991, IoU: 0.9526448289831587 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it] \u001b[A\n","Training loss: 0.4540991, IoU: 0.9526448289831587 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.47356772, IoU: 0.9409681662462085 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.47356772, IoU: 0.9409681662462085 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.44503045, IoU: 0.9480356066280579 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.44503045, IoU: 0.9480356066280579 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.39824355, IoU: 0.9556092607316324 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.39824355, IoU: 0.9556092607316324 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.4768142, IoU: 0.9662987997684687 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it] \u001b[A\n","Training loss: 0.4768142, IoU: 0.9662987997684687 |:  27%|██▋       | 7/26 [00:19<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.4467609, IoU: 0.9593218550096826 |:  27%|██▋       | 7/26 [00:22<00:53,  2.80s/it]\u001b[A\n","Training loss: 0.4467609, IoU: 0.9593218550096826 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.39672047, IoU: 0.9564595908489425 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.39672047, IoU: 0.9564595908489425 |:  35%|███▍      | 9/26 [00:25<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.4597051, IoU: 0.9385500580864163 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it] \u001b[A\n","Training loss: 0.4597051, IoU: 0.9385500580864163 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.49162623, IoU: 0.945376464829023 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.49162623, IoU: 0.945376464829023 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.38160968, IoU: 0.9547720729824026 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.38160968, IoU: 0.9547720729824026 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.40457606, IoU: 0.953757103471558 |:  46%|████▌     | 12/26 [00:36<00:38,  2.77s/it] \u001b[A\n","Training loss: 0.40457606, IoU: 0.953757103471558 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.48095793, IoU: 0.9447089551707696 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.48095793, IoU: 0.9447089551707696 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.48227066, IoU: 0.9587213049178871 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.48227066, IoU: 0.9587213049178871 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.44285786, IoU: 0.9540460957844119 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.44285786, IoU: 0.9540460957844119 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.4736374, IoU: 0.9593535995254372 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.78s/it] \u001b[A\n","Training loss: 0.4736374, IoU: 0.9593535995254372 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.44016296, IoU: 0.9608610037826243 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.80s/it]\u001b[A\n","Training loss: 0.44016296, IoU: 0.9608610037826243 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.45611233, IoU: 0.9480729629722744 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.45611233, IoU: 0.9480729629722744 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.51743263, IoU: 0.952305451727923 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.79s/it] \u001b[A\n","Training loss: 0.51743263, IoU: 0.952305451727923 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.48709303, IoU: 0.9408671452636294 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.48709303, IoU: 0.9408671452636294 |:  81%|████████  | 21/26 [00:58<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.42873466, IoU: 0.9571133168825919 |:  81%|████████  | 21/26 [01:01<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.42873466, IoU: 0.9571133168825919 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.81s/it]\u001b[A\n","Training loss: 0.6705423, IoU: 0.8725571999473014 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.81s/it] \u001b[A\n","Training loss: 0.6705423, IoU: 0.8725571999473014 |:  88%|████████▊ | 23/26 [01:02<00:06,  2.25s/it]\u001b[A\n","Training loss: 0.48561472, IoU: 0.9501519420452921 |:  88%|████████▊ | 23/26 [01:05<00:06,  2.25s/it]\u001b[A\n","Training loss: 0.48561472, IoU: 0.9501519420452921 |:  92%|█████████▏| 24/26 [01:05<00:04,  2.42s/it]\u001b[A\n","Training loss: 0.42558247, IoU: 0.9560295390932486 |:  92%|█████████▏| 24/26 [01:08<00:04,  2.42s/it]\u001b[A\n","Training loss: 0.42558247, IoU: 0.9560295390932486 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.55s/it]\u001b[A\n","Training loss: 0.43906048, IoU: 0.9503357586311939 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.55s/it]\u001b[A\n","Training loss: 0.43906048, IoU: 0.9503357586311939 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  88%|████████▊ | 132/150 [3:06:11<23:34, 78.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.42187378, IoU: 0.9624629297404167 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.42187378, IoU: 0.9624629297404167 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.43219256, IoU: 0.945407919435973 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it] \u001b[A\n","Training loss: 0.43219256, IoU: 0.945407919435973 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4884441, IoU: 0.9535409984454634 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4884441, IoU: 0.9535409984454634 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.45852232, IoU: 0.9542905553389459 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.45852232, IoU: 0.9542905553389459 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.450368, IoU: 0.9448904150219074 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]  \u001b[A\n","Training loss: 0.450368, IoU: 0.9448904150219074 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4392834, IoU: 0.9490672025492416 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4392834, IoU: 0.9490672025492416 |:  23%|██▎       | 6/26 [00:16<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.49568355, IoU: 0.9360634563953348 |:  23%|██▎       | 6/26 [00:19<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.49568355, IoU: 0.9360634563953348 |:  27%|██▋       | 7/26 [00:19<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.47862715, IoU: 0.9527778747425585 |:  27%|██▋       | 7/26 [00:22<00:52,  2.79s/it]\u001b[A\n","Training loss: 0.47862715, IoU: 0.9527778747425585 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.41080388, IoU: 0.9576954678100239 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.41080388, IoU: 0.9576954678100239 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.44782895, IoU: 0.9447334955068097 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.44782895, IoU: 0.9447334955068097 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.45622167, IoU: 0.9634825679358582 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.45622167, IoU: 0.9634825679358582 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.4380769, IoU: 0.9553211902719833 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it] \u001b[A\n","Training loss: 0.4380769, IoU: 0.9553211902719833 |:  46%|████▌     | 12/26 [00:33<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.33435524, IoU: 0.9500138268298718 |:  46%|████▌     | 12/26 [00:36<00:39,  2.79s/it]\u001b[A\n","Training loss: 0.33435524, IoU: 0.9500138268298718 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.45190355, IoU: 0.9572915612042843 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.45190355, IoU: 0.9572915612042843 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.44677365, IoU: 0.9371441800489404 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.79s/it]\u001b[A\n","Training loss: 0.44677365, IoU: 0.9371441800489404 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.42229876, IoU: 0.9519247962197847 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.42229876, IoU: 0.9519247962197847 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.46035445, IoU: 0.9577448498322902 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.46035445, IoU: 0.9577448498322902 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4641638, IoU: 0.9580121220599196 |:  65%|██████▌   | 17/26 [00:50<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.4641638, IoU: 0.9580121220599196 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.38490817, IoU: 0.949996019350639 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.38490817, IoU: 0.949996019350639 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.46010694, IoU: 0.9449095065012928 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.46010694, IoU: 0.9449095065012928 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.40943438, IoU: 0.9493419625607216 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.40943438, IoU: 0.9493419625607216 |:  81%|████████  | 21/26 [00:58<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.4512374, IoU: 0.9513281115112725 |:  81%|████████  | 21/26 [01:01<00:13,  2.77s/it] \u001b[A\n","Training loss: 0.4512374, IoU: 0.9513281115112725 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.47068405, IoU: 0.9540013925338761 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.47068405, IoU: 0.9540013925338761 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.5220882, IoU: 0.9605187274966098 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.5220882, IoU: 0.9605187274966098 |:  92%|█████████▏| 24/26 [01:04<00:04,  2.22s/it]\u001b[A\n","Training loss: 0.43234178, IoU: 0.9578203561471874 |:  92%|█████████▏| 24/26 [01:07<00:04,  2.22s/it]\u001b[A\n","Training loss: 0.43234178, IoU: 0.9578203561471874 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.38s/it]\u001b[A\n","Training loss: 0.38934362, IoU: 0.9594744727663519 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.38s/it]\u001b[A\n","Training loss: 0.38934362, IoU: 0.9594744727663519 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  89%|████████▊ | 133/150 [3:07:29<22:13, 78.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4054423, IoU: 0.9509432088180941 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4054423, IoU: 0.9509432088180941 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.49014345, IoU: 0.9584900894673172 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.49014345, IoU: 0.9584900894673172 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4602914, IoU: 0.9574755467510102 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it] \u001b[A\n","Training loss: 0.4602914, IoU: 0.9574755467510102 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4146708, IoU: 0.9468599724870601 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4146708, IoU: 0.9468599724870601 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.3834428, IoU: 0.9482180118070384 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.3834428, IoU: 0.9482180118070384 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.48338687, IoU: 0.9605230753475261 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.48338687, IoU: 0.9605230753475261 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.42291844, IoU: 0.9527115703112842 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.42291844, IoU: 0.9527115703112842 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.4482604, IoU: 0.950796338394911 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it]  \u001b[A\n","Training loss: 0.4482604, IoU: 0.950796338394911 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.4736101, IoU: 0.9444789236212039 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.4736101, IoU: 0.9444789236212039 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.41929862, IoU: 0.9529008391229812 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.41929862, IoU: 0.9529008391229812 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.48756456, IoU: 0.9478238341968912 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.48756456, IoU: 0.9478238341968912 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.39630356, IoU: 0.9565998777323025 |:  42%|████▏     | 11/26 [00:33<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.39630356, IoU: 0.9565998777323025 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.4177573, IoU: 0.9522455433116483 |:  46%|████▌     | 12/26 [00:36<00:38,  2.77s/it] \u001b[A\n","Training loss: 0.4177573, IoU: 0.9522455433116483 |:  50%|█████     | 13/26 [00:36<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.5130548, IoU: 0.9405250964478181 |:  50%|█████     | 13/26 [00:38<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.5130548, IoU: 0.9405250964478181 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.42785448, IoU: 0.9538849107524998 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.42785448, IoU: 0.9538849107524998 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.51936316, IoU: 0.9633150783658616 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.51936316, IoU: 0.9633150783658616 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.4938177, IoU: 0.9598876604850214 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it] \u001b[A\n","Training loss: 0.4938177, IoU: 0.9598876604850214 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.45576113, IoU: 0.9505620787535481 |:  65%|██████▌   | 17/26 [00:49<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.45576113, IoU: 0.9505620787535481 |:  69%|██████▉   | 18/26 [00:49<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.47625142, IoU: 0.9553269732049605 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.47625142, IoU: 0.9553269732049605 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.45990914, IoU: 0.9575463465715173 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.45990914, IoU: 0.9575463465715173 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.45471105, IoU: 0.9639935038725087 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.45471105, IoU: 0.9639935038725087 |:  81%|████████  | 21/26 [00:58<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.42697048, IoU: 0.9536486203700936 |:  81%|████████  | 21/26 [01:00<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.42697048, IoU: 0.9536486203700936 |:  85%|████████▍ | 22/26 [01:00<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.42180225, IoU: 0.9564913885445376 |:  85%|████████▍ | 22/26 [01:03<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.42180225, IoU: 0.9564913885445376 |:  88%|████████▊ | 23/26 [01:03<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4327657, IoU: 0.9501228519142296 |:  88%|████████▊ | 23/26 [01:06<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.4327657, IoU: 0.9501228519142296 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.50089085, IoU: 0.9424167144404102 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.50089085, IoU: 0.9424167144404102 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.23s/it]\u001b[A\n","Training loss: 0.43221837, IoU: 0.9564432482888842 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.23s/it]\u001b[A\n","Training loss: 0.43221837, IoU: 0.9564432482888842 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  89%|████████▉ | 134/150 [3:08:47<20:53, 78.36s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.452491, IoU: 0.9594809353678501 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.452491, IoU: 0.9594809353678501 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.47617918, IoU: 0.9569771255226696 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.47617918, IoU: 0.9569771255226696 |:   8%|▊         | 2/26 [00:05<01:07,  2.83s/it]\u001b[A\n","Training loss: 0.4627974, IoU: 0.9617096774934903 |:   8%|▊         | 2/26 [00:08<01:07,  2.83s/it] \u001b[A\n","Training loss: 0.4627974, IoU: 0.9617096774934903 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.44304478, IoU: 0.9502188103562086 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.44304478, IoU: 0.9502188103562086 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.44620672, IoU: 0.9550670903954802 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.44620672, IoU: 0.9550670903954802 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.43692434, IoU: 0.9528597741207139 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.43692434, IoU: 0.9528597741207139 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.4213924, IoU: 0.9542470438070467 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it] \u001b[A\n","Training loss: 0.4213924, IoU: 0.9542470438070467 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.48705316, IoU: 0.9574251961752154 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.48705316, IoU: 0.9574251961752154 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.39663726, IoU: 0.9498539641682193 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.39663726, IoU: 0.9498539641682193 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.5023427, IoU: 0.9591236524624607 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it] \u001b[A\n","Training loss: 0.5023427, IoU: 0.9591236524624607 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.47374827, IoU: 0.9508966526492152 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.47374827, IoU: 0.9508966526492152 |:  42%|████▏     | 11/26 [00:30<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.44311568, IoU: 0.9485634310512352 |:  42%|████▏     | 11/26 [00:33<00:41,  2.79s/it]\u001b[A\n","Training loss: 0.44311568, IoU: 0.9485634310512352 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.38613397, IoU: 0.9633476069707528 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.38613397, IoU: 0.9633476069707528 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.4932838, IoU: 0.9578134047751001 |:  50%|█████     | 13/26 [00:39<00:36,  2.78s/it] \u001b[A\n","Training loss: 0.4932838, IoU: 0.9578134047751001 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.4412246, IoU: 0.9463873012358323 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.77s/it]\u001b[A\n","Training loss: 0.4412246, IoU: 0.9463873012358323 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.47012097, IoU: 0.9499147646557439 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.47012097, IoU: 0.9499147646557439 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44748172, IoU: 0.9598565064457178 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.44748172, IoU: 0.9598565064457178 |:  65%|██████▌   | 17/26 [00:47<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4674472, IoU: 0.9603563494748005 |:  65%|██████▌   | 17/26 [00:50<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.4674472, IoU: 0.9603563494748005 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.42936915, IoU: 0.9405232288933477 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.42936915, IoU: 0.9405232288933477 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.44452912, IoU: 0.9566226201978689 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.44452912, IoU: 0.9566226201978689 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.40382102, IoU: 0.9535765392852684 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.40382102, IoU: 0.9535765392852684 |:  81%|████████  | 21/26 [00:58<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.5043068, IoU: 0.9551948629653083 |:  81%|████████  | 21/26 [01:01<00:13,  2.78s/it] \u001b[A\n","Training loss: 0.5043068, IoU: 0.9551948629653083 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.41972822, IoU: 0.9519868576033724 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.41972822, IoU: 0.9519868576033724 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.4157142, IoU: 0.9590707824255573 |:  88%|████████▊ | 23/26 [01:06<00:08,  2.79s/it] \u001b[A\n","Training loss: 0.4157142, IoU: 0.9590707824255573 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.492101, IoU: 0.9566424724319461 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.79s/it] \u001b[A\n","Training loss: 0.492101, IoU: 0.9566424724319461 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.43617207, IoU: 0.959572375454351 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.43617207, IoU: 0.959572375454351 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  90%|█████████ | 135/150 [3:10:06<19:35, 78.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4925619, IoU: 0.9599052826893225 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4925619, IoU: 0.9599052826893225 |:   4%|▍         | 1/26 [00:02<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.45552695, IoU: 0.9615440538814255 |:   4%|▍         | 1/26 [00:05<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.45552695, IoU: 0.9615440538814255 |:   8%|▊         | 2/26 [00:05<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.47985357, IoU: 0.9489066924580226 |:   8%|▊         | 2/26 [00:08<01:06,  2.76s/it]\u001b[A\n","Training loss: 0.47985357, IoU: 0.9489066924580226 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.38859165, IoU: 0.9585946020438956 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.38859165, IoU: 0.9585946020438956 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.45884287, IoU: 0.9457640427381586 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.45884287, IoU: 0.9457640427381586 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.4484995, IoU: 0.957060248850985 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]  \u001b[A\n","Training loss: 0.4484995, IoU: 0.957060248850985 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.442865, IoU: 0.9583414532128581 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.442865, IoU: 0.9583414532128581 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.46160305, IoU: 0.9476169217140493 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.46160305, IoU: 0.9476169217140493 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.43941042, IoU: 0.9528524814230163 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.43941042, IoU: 0.9528524814230163 |:  35%|███▍      | 9/26 [00:25<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.43148798, IoU: 0.9615061942790055 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.43148798, IoU: 0.9615061942790055 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.42398217, IoU: 0.9594661527295553 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.42398217, IoU: 0.9594661527295553 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.45609045, IoU: 0.9532752178158329 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.45609045, IoU: 0.9532752178158329 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.4357273, IoU: 0.956469130823082 |:  46%|████▌     | 12/26 [00:36<00:38,  2.78s/it]  \u001b[A\n","Training loss: 0.4357273, IoU: 0.956469130823082 |:  50%|█████     | 13/26 [00:36<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.43140668, IoU: 0.957569903248635 |:  50%|█████     | 13/26 [00:38<00:36,  2.78s/it]\u001b[A\n","Training loss: 0.43140668, IoU: 0.957569903248635 |:  54%|█████▍    | 14/26 [00:38<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.47886288, IoU: 0.9483191708285535 |:  54%|█████▍    | 14/26 [00:41<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.47886288, IoU: 0.9483191708285535 |:  58%|█████▊    | 15/26 [00:41<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.40172908, IoU: 0.9565633553071221 |:  58%|█████▊    | 15/26 [00:44<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.40172908, IoU: 0.9565633553071221 |:  62%|██████▏   | 16/26 [00:44<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.47639626, IoU: 0.9548155083980345 |:  62%|██████▏   | 16/26 [00:47<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.47639626, IoU: 0.9548155083980345 |:  65%|██████▌   | 17/26 [00:47<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.48208094, IoU: 0.9622834651019008 |:  65%|██████▌   | 17/26 [00:50<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.48208094, IoU: 0.9622834651019008 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.39137125, IoU: 0.9520885171263699 |:  69%|██████▉   | 18/26 [00:52<00:22,  2.80s/it]\u001b[A\n","Training loss: 0.39137125, IoU: 0.9520885171263699 |:  73%|███████▎  | 19/26 [00:52<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.41314387, IoU: 0.9540319213686048 |:  73%|███████▎  | 19/26 [00:55<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.41314387, IoU: 0.9540319213686048 |:  77%|███████▋  | 20/26 [00:55<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.42357922, IoU: 0.9578527484355709 |:  77%|███████▋  | 20/26 [00:58<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.42357922, IoU: 0.9578527484355709 |:  81%|████████  | 21/26 [00:58<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.47121403, IoU: 0.9618507098715345 |:  81%|████████  | 21/26 [01:01<00:13,  2.80s/it]\u001b[A\n","Training loss: 0.47121403, IoU: 0.9618507098715345 |:  85%|████████▍ | 22/26 [01:01<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.45050728, IoU: 0.9633424635623888 |:  85%|████████▍ | 22/26 [01:04<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.45050728, IoU: 0.9633424635623888 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.41745132, IoU: 0.9571030723710198 |:  88%|████████▊ | 23/26 [01:06<00:08,  2.79s/it]\u001b[A\n","Training loss: 0.41745132, IoU: 0.9571030723710198 |:  92%|█████████▏| 24/26 [01:06<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.43627217, IoU: 0.947481982538266 |:  92%|█████████▏| 24/26 [01:09<00:05,  2.79s/it] \u001b[A\n","Training loss: 0.43627217, IoU: 0.947481982538266 |:  96%|█████████▌| 25/26 [01:09<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.47937667, IoU: 0.9544837050057599 |:  96%|█████████▌| 25/26 [01:12<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.47937667, IoU: 0.9544837050057599 |: 100%|██████████| 26/26 [01:12<00:00,  2.79s/it]\n","Epoch Loop:  91%|█████████ | 136/150 [3:11:26<18:25, 78.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4539675, IoU: 0.9575425414364641 |:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4539675, IoU: 0.9575425414364641 |:   4%|▍         | 1/26 [00:00<00:23,  1.07it/s]\u001b[A\n","Training loss: 0.43067318, IoU: 0.9554269363648646 |:   4%|▍         | 1/26 [00:03<00:23,  1.07it/s]\u001b[A\n","Training loss: 0.43067318, IoU: 0.9554269363648646 |:   8%|▊         | 2/26 [00:03<00:49,  2.04s/it]\u001b[A\n","Training loss: 0.49442923, IoU: 0.9460069388473776 |:   8%|▊         | 2/26 [00:06<00:49,  2.04s/it]\u001b[A\n","Training loss: 0.49442923, IoU: 0.9460069388473776 |:  12%|█▏        | 3/26 [00:06<00:55,  2.40s/it]\u001b[A\n","Training loss: 0.4625921, IoU: 0.9563947012962393 |:  12%|█▏        | 3/26 [00:09<00:55,  2.40s/it] \u001b[A\n","Training loss: 0.4625921, IoU: 0.9563947012962393 |:  15%|█▌        | 4/26 [00:09<00:56,  2.58s/it]\u001b[A\n","Training loss: 0.47646427, IoU: 0.9538634792339328 |:  15%|█▌        | 4/26 [00:12<00:56,  2.58s/it]\u001b[A\n","Training loss: 0.47646427, IoU: 0.9538634792339328 |:  19%|█▉        | 5/26 [00:12<00:56,  2.67s/it]\u001b[A\n","Training loss: 0.48956084, IoU: 0.9596944085455814 |:  19%|█▉        | 5/26 [00:15<00:56,  2.67s/it]\u001b[A\n","Training loss: 0.48956084, IoU: 0.9596944085455814 |:  23%|██▎       | 6/26 [00:15<00:54,  2.72s/it]\u001b[A\n","Training loss: 0.4438819, IoU: 0.9556797497611308 |:  23%|██▎       | 6/26 [00:17<00:54,  2.72s/it] \u001b[A\n","Training loss: 0.4438819, IoU: 0.9556797497611308 |:  27%|██▋       | 7/26 [00:17<00:51,  2.73s/it]\u001b[A\n","Training loss: 0.38820687, IoU: 0.9520687447869183 |:  27%|██▋       | 7/26 [00:20<00:51,  2.73s/it]\u001b[A\n","Training loss: 0.38820687, IoU: 0.9520687447869183 |:  31%|███       | 8/26 [00:20<00:49,  2.74s/it]\u001b[A\n","Training loss: 0.44275498, IoU: 0.9551598087918268 |:  31%|███       | 8/26 [00:23<00:49,  2.74s/it]\u001b[A\n","Training loss: 0.44275498, IoU: 0.9551598087918268 |:  35%|███▍      | 9/26 [00:23<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.4420244, IoU: 0.9492274737888604 |:  35%|███▍      | 9/26 [00:26<00:46,  2.76s/it] \u001b[A\n","Training loss: 0.4420244, IoU: 0.9492274737888604 |:  38%|███▊      | 10/26 [00:26<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.4722064, IoU: 0.9610423046359583 |:  38%|███▊      | 10/26 [00:28<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.4722064, IoU: 0.9610423046359583 |:  42%|████▏     | 11/26 [00:28<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.42890868, IoU: 0.9489824946406982 |:  42%|████▏     | 11/26 [00:31<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.42890868, IoU: 0.9489824946406982 |:  46%|████▌     | 12/26 [00:31<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.38685223, IoU: 0.9465124264304057 |:  46%|████▌     | 12/26 [00:34<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.38685223, IoU: 0.9465124264304057 |:  50%|█████     | 13/26 [00:34<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.44549945, IoU: 0.957031669977796 |:  50%|█████     | 13/26 [00:37<00:36,  2.77s/it] \u001b[A\n","Training loss: 0.44549945, IoU: 0.957031669977796 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.4462149, IoU: 0.9466177382092749 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.4462149, IoU: 0.9466177382092749 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.38550013, IoU: 0.953478189620738 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.78s/it]\u001b[A\n","Training loss: 0.38550013, IoU: 0.953478189620738 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.4412707, IoU: 0.9527983947005778 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.4412707, IoU: 0.9527983947005778 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.47258326, IoU: 0.9411330005775725 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.47258326, IoU: 0.9411330005775725 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.46712524, IoU: 0.9602589322475868 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.46712524, IoU: 0.9602589322475868 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.48388994, IoU: 0.9407142667104178 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.48388994, IoU: 0.9407142667104178 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.44162393, IoU: 0.9583490510815978 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.44162393, IoU: 0.9583490510815978 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45183247, IoU: 0.9633652789105996 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45183247, IoU: 0.9633652789105996 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.40042937, IoU: 0.9563534691119524 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.40042937, IoU: 0.9563534691119524 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.43572387, IoU: 0.9534749952462446 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.43572387, IoU: 0.9534749952462446 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.43995824, IoU: 0.9619332076097319 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.43995824, IoU: 0.9619332076097319 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.47255492, IoU: 0.9591536207371278 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.80s/it]\u001b[A\n","Training loss: 0.47255492, IoU: 0.9591536207371278 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  91%|█████████▏| 137/150 [3:12:44<17:05, 78.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44742906, IoU: 0.9608937047949604 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44742906, IoU: 0.9608937047949604 |:   4%|▍         | 1/26 [00:02<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.46771646, IoU: 0.9502801507398853 |:   4%|▍         | 1/26 [00:03<01:08,  2.74s/it]\u001b[A\n","Training loss: 0.46771646, IoU: 0.9502801507398853 |:   8%|▊         | 2/26 [00:03<00:40,  1.70s/it]\u001b[A\n","Training loss: 0.48301446, IoU: 0.9552113713506465 |:   8%|▊         | 2/26 [00:06<00:40,  1.70s/it]\u001b[A\n","Training loss: 0.48301446, IoU: 0.9552113713506465 |:  12%|█▏        | 3/26 [00:06<00:50,  2.21s/it]\u001b[A\n","Training loss: 0.47162628, IoU: 0.9535758419803456 |:  12%|█▏        | 3/26 [00:09<00:50,  2.21s/it]\u001b[A\n","Training loss: 0.47162628, IoU: 0.9535758419803456 |:  15%|█▌        | 4/26 [00:09<00:53,  2.43s/it]\u001b[A\n","Training loss: 0.5020729, IoU: 0.9451892039903744 |:  15%|█▌        | 4/26 [00:12<00:53,  2.43s/it] \u001b[A\n","Training loss: 0.5020729, IoU: 0.9451892039903744 |:  19%|█▉        | 5/26 [00:12<00:53,  2.56s/it]\u001b[A\n","Training loss: 0.4409184, IoU: 0.9592844855379773 |:  19%|█▉        | 5/26 [00:14<00:53,  2.56s/it]\u001b[A\n","Training loss: 0.4409184, IoU: 0.9592844855379773 |:  23%|██▎       | 6/26 [00:14<00:53,  2.65s/it]\u001b[A\n","Training loss: 0.4548918, IoU: 0.9617891193863731 |:  23%|██▎       | 6/26 [00:17<00:53,  2.65s/it]\u001b[A\n","Training loss: 0.4548918, IoU: 0.9617891193863731 |:  27%|██▋       | 7/26 [00:17<00:51,  2.69s/it]\u001b[A\n","Training loss: 0.46138993, IoU: 0.9641997141299635 |:  27%|██▋       | 7/26 [00:20<00:51,  2.69s/it]\u001b[A\n","Training loss: 0.46138993, IoU: 0.9641997141299635 |:  31%|███       | 8/26 [00:20<00:48,  2.72s/it]\u001b[A\n","Training loss: 0.43783662, IoU: 0.9421285816746443 |:  31%|███       | 8/26 [00:23<00:48,  2.72s/it]\u001b[A\n","Training loss: 0.43783662, IoU: 0.9421285816746443 |:  35%|███▍      | 9/26 [00:23<00:46,  2.74s/it]\u001b[A\n","Training loss: 0.41803935, IoU: 0.9522938174604211 |:  35%|███▍      | 9/26 [00:26<00:46,  2.74s/it]\u001b[A\n","Training loss: 0.41803935, IoU: 0.9522938174604211 |:  38%|███▊      | 10/26 [00:26<00:43,  2.75s/it]\u001b[A\n","Training loss: 0.4750917, IoU: 0.9523721724371343 |:  38%|███▊      | 10/26 [00:28<00:43,  2.75s/it] \u001b[A\n","Training loss: 0.4750917, IoU: 0.9523721724371343 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.43176275, IoU: 0.9592056220357955 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.43176275, IoU: 0.9592056220357955 |:  46%|████▌     | 12/26 [00:31<00:38,  2.76s/it]\u001b[A\n","Training loss: 0.5184757, IoU: 0.9431906136740587 |:  46%|████▌     | 12/26 [00:34<00:38,  2.76s/it] \u001b[A\n","Training loss: 0.5184757, IoU: 0.9431906136740587 |:  50%|█████     | 13/26 [00:34<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.44318745, IoU: 0.95484189414345 |:  50%|█████     | 13/26 [00:37<00:35,  2.76s/it] \u001b[A\n","Training loss: 0.44318745, IoU: 0.95484189414345 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.45373622, IoU: 0.9604510077530949 |:  54%|█████▍    | 14/26 [00:39<00:33,  2.76s/it]\u001b[A\n","Training loss: 0.45373622, IoU: 0.9604510077530949 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.44252416, IoU: 0.9576265640848264 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.44252416, IoU: 0.9576265640848264 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.77s/it]\u001b[A\n","Training loss: 0.4023145, IoU: 0.9538056038438211 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.77s/it] \u001b[A\n","Training loss: 0.4023145, IoU: 0.9538056038438211 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.45422715, IoU: 0.9548678056695619 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.45422715, IoU: 0.9548678056695619 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.39941615, IoU: 0.9505346641796357 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.78s/it]\u001b[A\n","Training loss: 0.39941615, IoU: 0.9505346641796357 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.40519142, IoU: 0.9595745395134397 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.40519142, IoU: 0.9595745395134397 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.46792346, IoU: 0.9389943245490366 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.46792346, IoU: 0.9389943245490366 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.45251068, IoU: 0.9600442899957379 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.45251068, IoU: 0.9600442899957379 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.4591651, IoU: 0.9617574762496797 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it] \u001b[A\n","Training loss: 0.4591651, IoU: 0.9617574762496797 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.45366043, IoU: 0.9558208653317918 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.45366043, IoU: 0.9558208653317918 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.47798514, IoU: 0.9692191724775865 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.47798514, IoU: 0.9692191724775865 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.43591756, IoU: 0.9588807556422887 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.43591756, IoU: 0.9588807556422887 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  92%|█████████▏| 138/150 [3:14:03<15:44, 78.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.4881121, IoU: 0.955435963516006 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.4881121, IoU: 0.955435963516006 |:   4%|▍         | 1/26 [00:02<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.46461618, IoU: 0.9571941280562271 |:   4%|▍         | 1/26 [00:05<01:10,  2.82s/it]\u001b[A\n","Training loss: 0.46461618, IoU: 0.9571941280562271 |:   8%|▊         | 2/26 [00:05<01:08,  2.85s/it]\u001b[A\n","Training loss: 0.32598722, IoU: 0.9579257760685556 |:   8%|▊         | 2/26 [00:06<01:08,  2.85s/it]\u001b[A\n","Training loss: 0.32598722, IoU: 0.9579257760685556 |:  12%|█▏        | 3/26 [00:06<00:45,  1.99s/it]\u001b[A\n","Training loss: 0.42546275, IoU: 0.9522097565580818 |:  12%|█▏        | 3/26 [00:09<00:45,  1.99s/it]\u001b[A\n","Training loss: 0.42546275, IoU: 0.9522097565580818 |:  15%|█▌        | 4/26 [00:09<00:50,  2.29s/it]\u001b[A\n","Training loss: 0.43744963, IoU: 0.9582116534557086 |:  15%|█▌        | 4/26 [00:12<00:50,  2.29s/it]\u001b[A\n","Training loss: 0.43744963, IoU: 0.9582116534557086 |:  19%|█▉        | 5/26 [00:12<00:52,  2.48s/it]\u001b[A\n","Training loss: 0.41084978, IoU: 0.9438886784145479 |:  19%|█▉        | 5/26 [00:15<00:52,  2.48s/it]\u001b[A\n","Training loss: 0.41084978, IoU: 0.9438886784145479 |:  23%|██▎       | 6/26 [00:15<00:51,  2.58s/it]\u001b[A\n","Training loss: 0.46324015, IoU: 0.9554927875986801 |:  23%|██▎       | 6/26 [00:17<00:51,  2.58s/it]\u001b[A\n","Training loss: 0.46324015, IoU: 0.9554927875986801 |:  27%|██▋       | 7/26 [00:17<00:50,  2.65s/it]\u001b[A\n","Training loss: 0.427801, IoU: 0.9525084156664979 |:  27%|██▋       | 7/26 [00:20<00:50,  2.65s/it]  \u001b[A\n","Training loss: 0.427801, IoU: 0.9525084156664979 |:  31%|███       | 8/26 [00:20<00:48,  2.70s/it]\u001b[A\n","Training loss: 0.4815646, IoU: 0.9481875983632357 |:  31%|███       | 8/26 [00:23<00:48,  2.70s/it]\u001b[A\n","Training loss: 0.4815646, IoU: 0.9481875983632357 |:  35%|███▍      | 9/26 [00:23<00:46,  2.74s/it]\u001b[A\n","Training loss: 0.4616261, IoU: 0.957186124360845 |:  35%|███▍      | 9/26 [00:26<00:46,  2.74s/it] \u001b[A\n","Training loss: 0.4616261, IoU: 0.957186124360845 |:  38%|███▊      | 10/26 [00:26<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.44263107, IoU: 0.9634177196028865 |:  38%|███▊      | 10/26 [00:29<00:44,  2.76s/it]\u001b[A\n","Training loss: 0.44263107, IoU: 0.9634177196028865 |:  42%|████▏     | 11/26 [00:29<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.43207934, IoU: 0.9588868056613732 |:  42%|████▏     | 11/26 [00:31<00:41,  2.76s/it]\u001b[A\n","Training loss: 0.43207934, IoU: 0.9588868056613732 |:  46%|████▌     | 12/26 [00:31<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.46162644, IoU: 0.9560392636758924 |:  46%|████▌     | 12/26 [00:34<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.46162644, IoU: 0.9560392636758924 |:  50%|█████     | 13/26 [00:34<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.44343263, IoU: 0.9589179175048572 |:  50%|█████     | 13/26 [00:37<00:36,  2.77s/it]\u001b[A\n","Training loss: 0.44343263, IoU: 0.9589179175048572 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.48001304, IoU: 0.9494853587098332 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.48001304, IoU: 0.9494853587098332 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.45389873, IoU: 0.955095297102732 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it] \u001b[A\n","Training loss: 0.45389873, IoU: 0.955095297102732 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.45961156, IoU: 0.9421250073319205 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.45961156, IoU: 0.9421250073319205 |:  65%|██████▌   | 17/26 [00:45<00:25,  2.79s/it]\u001b[A\n","Training loss: 0.3933292, IoU: 0.9509402274234862 |:  65%|██████▌   | 17/26 [00:48<00:25,  2.79s/it] \u001b[A\n","Training loss: 0.3933292, IoU: 0.9509402274234862 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.39264694, IoU: 0.9567379699201121 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.79s/it]\u001b[A\n","Training loss: 0.39264694, IoU: 0.9567379699201121 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.41220486, IoU: 0.9489986082513536 |:  73%|███████▎  | 19/26 [00:54<00:19,  2.79s/it]\u001b[A\n","Training loss: 0.41220486, IoU: 0.9489986082513536 |:  77%|███████▋  | 20/26 [00:54<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.44163382, IoU: 0.9552491734566245 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.79s/it]\u001b[A\n","Training loss: 0.44163382, IoU: 0.9552491734566245 |:  81%|████████  | 21/26 [00:56<00:13,  2.79s/it]\u001b[A\n","Training loss: 0.37762648, IoU: 0.954640020249991 |:  81%|████████  | 21/26 [00:59<00:13,  2.79s/it] \u001b[A\n","Training loss: 0.37762648, IoU: 0.954640020249991 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.4683765, IoU: 0.9637826744203649 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.80s/it]\u001b[A\n","Training loss: 0.4683765, IoU: 0.9637826744203649 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.49084973, IoU: 0.9533463599180473 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.80s/it]\u001b[A\n","Training loss: 0.49084973, IoU: 0.9533463599180473 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.42595696, IoU: 0.9615077494395967 |:  92%|█████████▏| 24/26 [01:08<00:05,  2.80s/it]\u001b[A\n","Training loss: 0.42595696, IoU: 0.9615077494395967 |:  96%|█████████▌| 25/26 [01:08<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4347411, IoU: 0.9564428932362208 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it] \u001b[A\n","Training loss: 0.4347411, IoU: 0.9564428932362208 |: 100%|██████████| 26/26 [01:10<00:00,  2.73s/it]\n","Epoch Loop:  93%|█████████▎| 139/150 [3:15:22<14:26, 78.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44664592, IoU: 0.9507282418048688 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44664592, IoU: 0.9507282418048688 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.4712652, IoU: 0.9442243985909813 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it] \u001b[A\n","Training loss: 0.4712652, IoU: 0.9442243985909813 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4831677, IoU: 0.9625128782614946 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4831677, IoU: 0.9625128782614946 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.42856756, IoU: 0.9603717778139388 |:  12%|█▏        | 3/26 [00:09<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.42856756, IoU: 0.9603717778139388 |:  15%|█▌        | 4/26 [00:09<00:45,  2.06s/it]\u001b[A\n","Training loss: 0.45145327, IoU: 0.9555835965261024 |:  15%|█▌        | 4/26 [00:12<00:45,  2.06s/it]\u001b[A\n","Training loss: 0.45145327, IoU: 0.9555835965261024 |:  19%|█▉        | 5/26 [00:12<00:49,  2.34s/it]\u001b[A\n","Training loss: 0.45980674, IoU: 0.9659148275399333 |:  19%|█▉        | 5/26 [00:14<00:49,  2.34s/it]\u001b[A\n","Training loss: 0.45980674, IoU: 0.9659148275399333 |:  23%|██▎       | 6/26 [00:14<00:49,  2.48s/it]\u001b[A\n","Training loss: 0.403724, IoU: 0.9562957224805777 |:  23%|██▎       | 6/26 [00:17<00:49,  2.48s/it]  \u001b[A\n","Training loss: 0.403724, IoU: 0.9562957224805777 |:  27%|██▋       | 7/26 [00:17<00:49,  2.58s/it]\u001b[A\n","Training loss: 0.42648187, IoU: 0.9501058021674831 |:  27%|██▋       | 7/26 [00:20<00:49,  2.58s/it]\u001b[A\n","Training loss: 0.42648187, IoU: 0.9501058021674831 |:  31%|███       | 8/26 [00:20<00:47,  2.65s/it]\u001b[A\n","Training loss: 0.4433497, IoU: 0.9524330315543742 |:  31%|███       | 8/26 [00:23<00:47,  2.65s/it] \u001b[A\n","Training loss: 0.4433497, IoU: 0.9524330315543742 |:  35%|███▍      | 9/26 [00:23<00:45,  2.70s/it]\u001b[A\n","Training loss: 0.4235043, IoU: 0.9567565765345247 |:  35%|███▍      | 9/26 [00:26<00:45,  2.70s/it]\u001b[A\n","Training loss: 0.4235043, IoU: 0.9567565765345247 |:  38%|███▊      | 10/26 [00:26<00:43,  2.73s/it]\u001b[A\n","Training loss: 0.457781, IoU: 0.962007004361206 |:  38%|███▊      | 10/26 [00:28<00:43,  2.73s/it]  \u001b[A\n","Training loss: 0.457781, IoU: 0.962007004361206 |:  42%|████▏     | 11/26 [00:28<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.43044108, IoU: 0.9598852265681042 |:  42%|████▏     | 11/26 [00:31<00:41,  2.75s/it]\u001b[A\n","Training loss: 0.43044108, IoU: 0.9598852265681042 |:  46%|████▌     | 12/26 [00:31<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.4145888, IoU: 0.9639892493380012 |:  46%|████▌     | 12/26 [00:34<00:38,  2.77s/it] \u001b[A\n","Training loss: 0.4145888, IoU: 0.9639892493380012 |:  50%|█████     | 13/26 [00:34<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.44153613, IoU: 0.9439327326524131 |:  50%|█████     | 13/26 [00:37<00:35,  2.77s/it]\u001b[A\n","Training loss: 0.44153613, IoU: 0.9439327326524131 |:  54%|█████▍    | 14/26 [00:37<00:33,  2.78s/it]\u001b[A\n","Training loss: 0.4098293, IoU: 0.9541282429019667 |:  54%|█████▍    | 14/26 [00:40<00:33,  2.78s/it] \u001b[A\n","Training loss: 0.4098293, IoU: 0.9541282429019667 |:  58%|█████▊    | 15/26 [00:40<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.43661094, IoU: 0.959373791668059 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.43661094, IoU: 0.959373791668059 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.46332312, IoU: 0.9572847157594598 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.78s/it]\u001b[A\n","Training loss: 0.46332312, IoU: 0.9572847157594598 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.41829482, IoU: 0.9563626064259676 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.41829482, IoU: 0.9563626064259676 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.4713121, IoU: 0.949317177698279 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.77s/it]  \u001b[A\n","Training loss: 0.4713121, IoU: 0.949317177698279 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.45598853, IoU: 0.9493863551353501 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.45598853, IoU: 0.9493863551353501 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.34648374, IoU: 0.951540807118258 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it] \u001b[A\n","Training loss: 0.34648374, IoU: 0.951540807118258 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.4580261, IoU: 0.9641592920353982 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.4580261, IoU: 0.9641592920353982 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.45903414, IoU: 0.9569269929668589 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.45903414, IoU: 0.9569269929668589 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.5078007, IoU: 0.9552669391937801 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.5078007, IoU: 0.9552669391937801 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.44231823, IoU: 0.9544241890489698 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.44231823, IoU: 0.9544241890489698 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.79s/it]\u001b[A\n","Training loss: 0.4647085, IoU: 0.958883384468151 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.79s/it]  \u001b[A\n","Training loss: 0.4647085, IoU: 0.958883384468151 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  93%|█████████▎| 140/150 [3:16:40<13:06, 78.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.40953285, IoU: 0.9627285154779855 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.40953285, IoU: 0.9627285154779855 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.38099423, IoU: 0.9501692941275349 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.38099423, IoU: 0.9501692941275349 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.46970934, IoU: 0.9590483121694872 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.46970934, IoU: 0.9590483121694872 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4382497, IoU: 0.9570787781313858 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it] \u001b[A\n","Training loss: 0.4382497, IoU: 0.9570787781313858 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.43925747, IoU: 0.9597209772690708 |:  15%|█▌        | 4/26 [00:12<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.43925747, IoU: 0.9597209772690708 |:  19%|█▉        | 5/26 [00:12<00:44,  2.13s/it]\u001b[A\n","Training loss: 0.3988861, IoU: 0.9620845570099096 |:  19%|█▉        | 5/26 [00:14<00:44,  2.13s/it] \u001b[A\n","Training loss: 0.3988861, IoU: 0.9620845570099096 |:  23%|██▎       | 6/26 [00:14<00:46,  2.34s/it]\u001b[A\n","Training loss: 0.46842262, IoU: 0.9603884923651013 |:  23%|██▎       | 6/26 [00:17<00:46,  2.34s/it]\u001b[A\n","Training loss: 0.46842262, IoU: 0.9603884923651013 |:  27%|██▋       | 7/26 [00:17<00:47,  2.49s/it]\u001b[A\n","Training loss: 0.48889267, IoU: 0.9578013204500766 |:  27%|██▋       | 7/26 [00:20<00:47,  2.49s/it]\u001b[A\n","Training loss: 0.48889267, IoU: 0.9578013204500766 |:  31%|███       | 8/26 [00:20<00:46,  2.58s/it]\u001b[A\n","Training loss: 0.45412642, IoU: 0.952740260291761 |:  31%|███       | 8/26 [00:23<00:46,  2.58s/it] \u001b[A\n","Training loss: 0.45412642, IoU: 0.952740260291761 |:  35%|███▍      | 9/26 [00:23<00:44,  2.64s/it]\u001b[A\n","Training loss: 0.47424427, IoU: 0.9534411089816454 |:  35%|███▍      | 9/26 [00:25<00:44,  2.64s/it]\u001b[A\n","Training loss: 0.47424427, IoU: 0.9534411089816454 |:  38%|███▊      | 10/26 [00:25<00:42,  2.68s/it]\u001b[A\n","Training loss: 0.46748996, IoU: 0.9530676301230665 |:  38%|███▊      | 10/26 [00:28<00:42,  2.68s/it]\u001b[A\n","Training loss: 0.46748996, IoU: 0.9530676301230665 |:  42%|████▏     | 11/26 [00:28<00:40,  2.71s/it]\u001b[A\n","Training loss: 0.4544019, IoU: 0.9556301481792284 |:  42%|████▏     | 11/26 [00:31<00:40,  2.71s/it] \u001b[A\n","Training loss: 0.4544019, IoU: 0.9556301481792284 |:  46%|████▌     | 12/26 [00:31<00:38,  2.73s/it]\u001b[A\n","Training loss: 0.43742773, IoU: 0.9646780226184593 |:  46%|████▌     | 12/26 [00:34<00:38,  2.73s/it]\u001b[A\n","Training loss: 0.43742773, IoU: 0.9646780226184593 |:  50%|█████     | 13/26 [00:34<00:35,  2.75s/it]\u001b[A\n","Training loss: 0.4792033, IoU: 0.9554343638640085 |:  50%|█████     | 13/26 [00:37<00:35,  2.75s/it] \u001b[A\n","Training loss: 0.4792033, IoU: 0.9554343638640085 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.75s/it]\u001b[A\n","Training loss: 0.42519313, IoU: 0.9555786105539962 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.75s/it]\u001b[A\n","Training loss: 0.42519313, IoU: 0.9555786105539962 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.44251874, IoU: 0.9542420506909947 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.77s/it]\u001b[A\n","Training loss: 0.44251874, IoU: 0.9542420506909947 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.47210687, IoU: 0.9567065464138904 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.47210687, IoU: 0.9567065464138904 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.77s/it]\u001b[A\n","Training loss: 0.4465298, IoU: 0.9574776150419689 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.77s/it] \u001b[A\n","Training loss: 0.4465298, IoU: 0.9574776150419689 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.4530866, IoU: 0.9576317343207209 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.77s/it]\u001b[A\n","Training loss: 0.4530866, IoU: 0.9576317343207209 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.44804215, IoU: 0.9492764886384147 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.44804215, IoU: 0.9492764886384147 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.46224248, IoU: 0.9525105415831813 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.46224248, IoU: 0.9525105415831813 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45713985, IoU: 0.9644463164455568 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45713985, IoU: 0.9644463164455568 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.48837584, IoU: 0.9464000691732627 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.48837584, IoU: 0.9464000691732627 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.46730977, IoU: 0.9583514967016928 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.46730977, IoU: 0.9583514967016928 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.4239817, IoU: 0.9511344785897039 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it] \u001b[A\n","Training loss: 0.4239817, IoU: 0.9511344785897039 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.4209025, IoU: 0.9458008465699278 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.4209025, IoU: 0.9458008465699278 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  94%|█████████▍| 141/150 [3:17:58<11:46, 78.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.44297236, IoU: 0.9383905888929371 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.44297236, IoU: 0.9383905888929371 |:   4%|▍         | 1/26 [00:02<01:08,  2.73s/it]\u001b[A\n","Training loss: 0.4422211, IoU: 0.9551356805925107 |:   4%|▍         | 1/26 [00:05<01:08,  2.73s/it] \u001b[A\n","Training loss: 0.4422211, IoU: 0.9551356805925107 |:   8%|▊         | 2/26 [00:05<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.40563655, IoU: 0.9555053897209739 |:   8%|▊         | 2/26 [00:08<01:07,  2.80s/it]\u001b[A\n","Training loss: 0.40563655, IoU: 0.9555053897209739 |:  12%|█▏        | 3/26 [00:08<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.44353288, IoU: 0.9593638632183821 |:  12%|█▏        | 3/26 [00:11<01:04,  2.79s/it]\u001b[A\n","Training loss: 0.44353288, IoU: 0.9593638632183821 |:  15%|█▌        | 4/26 [00:11<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.44308457, IoU: 0.9567398784351174 |:  15%|█▌        | 4/26 [00:13<01:01,  2.80s/it]\u001b[A\n","Training loss: 0.44308457, IoU: 0.9567398784351174 |:  19%|█▉        | 5/26 [00:13<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.39789662, IoU: 0.9616774737446301 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.39789662, IoU: 0.9616774737446301 |:  23%|██▎       | 6/26 [00:14<00:43,  2.17s/it]\u001b[A\n","Training loss: 0.47275925, IoU: 0.9546700630187447 |:  23%|██▎       | 6/26 [00:17<00:43,  2.17s/it]\u001b[A\n","Training loss: 0.47275925, IoU: 0.9546700630187447 |:  27%|██▋       | 7/26 [00:17<00:45,  2.38s/it]\u001b[A\n","Training loss: 0.49279818, IoU: 0.9598065314386413 |:  27%|██▋       | 7/26 [00:20<00:45,  2.38s/it]\u001b[A\n","Training loss: 0.49279818, IoU: 0.9598065314386413 |:  31%|███       | 8/26 [00:20<00:45,  2.52s/it]\u001b[A\n","Training loss: 0.4457581, IoU: 0.9547475630846631 |:  31%|███       | 8/26 [00:23<00:45,  2.52s/it] \u001b[A\n","Training loss: 0.4457581, IoU: 0.9547475630846631 |:  35%|███▍      | 9/26 [00:23<00:44,  2.61s/it]\u001b[A\n","Training loss: 0.4479233, IoU: 0.9469926610455006 |:  35%|███▍      | 9/26 [00:26<00:44,  2.61s/it]\u001b[A\n","Training loss: 0.4479233, IoU: 0.9469926610455006 |:  38%|███▊      | 10/26 [00:26<00:42,  2.65s/it]\u001b[A\n","Training loss: 0.4510249, IoU: 0.9495691094929521 |:  38%|███▊      | 10/26 [00:28<00:42,  2.65s/it]\u001b[A\n","Training loss: 0.4510249, IoU: 0.9495691094929521 |:  42%|████▏     | 11/26 [00:28<00:40,  2.68s/it]\u001b[A\n","Training loss: 0.52126235, IoU: 0.9646156870454099 |:  42%|████▏     | 11/26 [00:31<00:40,  2.68s/it]\u001b[A\n","Training loss: 0.52126235, IoU: 0.9646156870454099 |:  46%|████▌     | 12/26 [00:31<00:37,  2.71s/it]\u001b[A\n","Training loss: 0.44432524, IoU: 0.9599828944904941 |:  46%|████▌     | 12/26 [00:34<00:37,  2.71s/it]\u001b[A\n","Training loss: 0.44432524, IoU: 0.9599828944904941 |:  50%|█████     | 13/26 [00:34<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.45660448, IoU: 0.9412106182432949 |:  50%|█████     | 13/26 [00:37<00:35,  2.72s/it]\u001b[A\n","Training loss: 0.45660448, IoU: 0.9412106182432949 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.73s/it]\u001b[A\n","Training loss: 0.44762793, IoU: 0.9559274664294704 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.73s/it]\u001b[A\n","Training loss: 0.44762793, IoU: 0.9559274664294704 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.4591626, IoU: 0.9696541056509306 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.75s/it] \u001b[A\n","Training loss: 0.4591626, IoU: 0.9696541056509306 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.42708462, IoU: 0.9505957472253492 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.76s/it]\u001b[A\n","Training loss: 0.42708462, IoU: 0.9505957472253492 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.4218908, IoU: 0.9624876654228509 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.76s/it] \u001b[A\n","Training loss: 0.4218908, IoU: 0.9624876654228509 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.42850244, IoU: 0.9519280680388907 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.42850244, IoU: 0.9519280680388907 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.44035423, IoU: 0.9554491033337755 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.77s/it]\u001b[A\n","Training loss: 0.44035423, IoU: 0.9554491033337755 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.47200304, IoU: 0.9491777442784706 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.47200304, IoU: 0.9491777442784706 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.4461117, IoU: 0.9575991692427513 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it] \u001b[A\n","Training loss: 0.4461117, IoU: 0.9575991692427513 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.51347494, IoU: 0.9464349337188909 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.51347494, IoU: 0.9464349337188909 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.45813954, IoU: 0.957624410807428 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.45813954, IoU: 0.957624410807428 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.44565254, IoU: 0.9606672139577263 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.44565254, IoU: 0.9606672139577263 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.4198396, IoU: 0.9344235950782878 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it] \u001b[A\n","Training loss: 0.4198396, IoU: 0.9344235950782878 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  95%|█████████▍| 142/150 [3:19:17<10:27, 78.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.42960396, IoU: 0.9617131748609675 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.42960396, IoU: 0.9617131748609675 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.46767962, IoU: 0.959454763009906 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it] \u001b[A\n","Training loss: 0.46767962, IoU: 0.959454763009906 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.45417058, IoU: 0.9638973606365658 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.45417058, IoU: 0.9638973606365658 |:  12%|█▏        | 3/26 [00:08<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.48417896, IoU: 0.9648940270608077 |:  12%|█▏        | 3/26 [00:11<01:03,  2.78s/it]\u001b[A\n","Training loss: 0.48417896, IoU: 0.9648940270608077 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.48054174, IoU: 0.9623967011455421 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.48054174, IoU: 0.9623967011455421 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.47980484, IoU: 0.9649617065389324 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.47980484, IoU: 0.9649617065389324 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.60826755, IoU: 0.9520965143238889 |:  23%|██▎       | 6/26 [00:17<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.60826755, IoU: 0.9520965143238889 |:  27%|██▋       | 7/26 [00:17<00:41,  2.18s/it]\u001b[A\n","Training loss: 0.48206303, IoU: 0.9588592204358194 |:  27%|██▋       | 7/26 [00:20<00:41,  2.18s/it]\u001b[A\n","Training loss: 0.48206303, IoU: 0.9588592204358194 |:  31%|███       | 8/26 [00:20<00:42,  2.37s/it]\u001b[A\n","Training loss: 0.4077234, IoU: 0.9542662980393812 |:  31%|███       | 8/26 [00:23<00:42,  2.37s/it] \u001b[A\n","Training loss: 0.4077234, IoU: 0.9542662980393812 |:  35%|███▍      | 9/26 [00:23<00:42,  2.49s/it]\u001b[A\n","Training loss: 0.46901065, IoU: 0.9563556042464578 |:  35%|███▍      | 9/26 [00:25<00:42,  2.49s/it]\u001b[A\n","Training loss: 0.46901065, IoU: 0.9563556042464578 |:  38%|███▊      | 10/26 [00:25<00:41,  2.60s/it]\u001b[A\n","Training loss: 0.48436236, IoU: 0.9554704010434288 |:  38%|███▊      | 10/26 [00:28<00:41,  2.60s/it]\u001b[A\n","Training loss: 0.48436236, IoU: 0.9554704010434288 |:  42%|████▏     | 11/26 [00:28<00:39,  2.65s/it]\u001b[A\n","Training loss: 0.45550334, IoU: 0.9464740774004808 |:  42%|████▏     | 11/26 [00:31<00:39,  2.65s/it]\u001b[A\n","Training loss: 0.45550334, IoU: 0.9464740774004808 |:  46%|████▌     | 12/26 [00:31<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.44639155, IoU: 0.9492775130062376 |:  46%|████▌     | 12/26 [00:34<00:37,  2.68s/it]\u001b[A\n","Training loss: 0.44639155, IoU: 0.9492775130062376 |:  50%|█████     | 13/26 [00:34<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.37324342, IoU: 0.9489952701659238 |:  50%|█████     | 13/26 [00:37<00:35,  2.73s/it]\u001b[A\n","Training loss: 0.37324342, IoU: 0.9489952701659238 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.45606717, IoU: 0.9630267468195717 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.74s/it]\u001b[A\n","Training loss: 0.45606717, IoU: 0.9630267468195717 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.75s/it]\u001b[A\n","Training loss: 0.4107106, IoU: 0.9674401814018028 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.75s/it] \u001b[A\n","Training loss: 0.4107106, IoU: 0.9674401814018028 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.46560037, IoU: 0.9547721720226939 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.46560037, IoU: 0.9547721720226939 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.43934637, IoU: 0.9509873864233128 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.43934637, IoU: 0.9509873864233128 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.45567006, IoU: 0.9592017445940663 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.45567006, IoU: 0.9592017445940663 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.42439646, IoU: 0.9627951875194523 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.42439646, IoU: 0.9627951875194523 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.47295052, IoU: 0.9583454956017345 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.47295052, IoU: 0.9583454956017345 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45591885, IoU: 0.9563718571624845 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.45591885, IoU: 0.9563718571624845 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.43438697, IoU: 0.9579120829215442 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.43438697, IoU: 0.9579120829215442 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.44724935, IoU: 0.9576233221456413 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.44724935, IoU: 0.9576233221456413 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.46836624, IoU: 0.9534459957838871 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.46836624, IoU: 0.9534459957838871 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.4519366, IoU: 0.9531383729334695 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it] \u001b[A\n","Training loss: 0.4519366, IoU: 0.9531383729334695 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  95%|█████████▌| 143/150 [3:20:35<09:08, 78.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.3882316, IoU: 0.95548005167494 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.3882316, IoU: 0.95548005167494 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.4182395, IoU: 0.9600041603237488 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.4182395, IoU: 0.9600041603237488 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.48831934, IoU: 0.9385076571387212 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.48831934, IoU: 0.9385076571387212 |:  12%|█▏        | 3/26 [00:08<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.49927327, IoU: 0.9511444848402478 |:  12%|█▏        | 3/26 [00:11<01:04,  2.82s/it]\u001b[A\n","Training loss: 0.49927327, IoU: 0.9511444848402478 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.47982123, IoU: 0.9618338644657344 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.47982123, IoU: 0.9618338644657344 |:  19%|█▉        | 5/26 [00:14<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.41351253, IoU: 0.9436787796307204 |:  19%|█▉        | 5/26 [00:16<00:59,  2.81s/it]\u001b[A\n","Training loss: 0.41351253, IoU: 0.9436787796307204 |:  23%|██▎       | 6/26 [00:16<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.46699297, IoU: 0.9608823198503215 |:  23%|██▎       | 6/26 [00:19<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.46699297, IoU: 0.9608823198503215 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.48185468, IoU: 0.935326791334938 |:  27%|██▋       | 7/26 [00:20<00:53,  2.79s/it] \u001b[A\n","Training loss: 0.48185468, IoU: 0.935326791334938 |:  31%|███       | 8/26 [00:20<00:39,  2.21s/it]\u001b[A\n","Training loss: 0.41304055, IoU: 0.9546090108751942 |:  31%|███       | 8/26 [00:23<00:39,  2.21s/it]\u001b[A\n","Training loss: 0.41304055, IoU: 0.9546090108751942 |:  35%|███▍      | 9/26 [00:23<00:40,  2.39s/it]\u001b[A\n","Training loss: 0.4544783, IoU: 0.952693476633044 |:  35%|███▍      | 9/26 [00:26<00:40,  2.39s/it]  \u001b[A\n","Training loss: 0.4544783, IoU: 0.952693476633044 |:  38%|███▊      | 10/26 [00:26<00:40,  2.51s/it]\u001b[A\n","Training loss: 0.43372747, IoU: 0.9573279751663398 |:  38%|███▊      | 10/26 [00:28<00:40,  2.51s/it]\u001b[A\n","Training loss: 0.43372747, IoU: 0.9573279751663398 |:  42%|████▏     | 11/26 [00:28<00:38,  2.58s/it]\u001b[A\n","Training loss: 0.42953867, IoU: 0.9515686622058759 |:  42%|████▏     | 11/26 [00:31<00:38,  2.58s/it]\u001b[A\n","Training loss: 0.42953867, IoU: 0.9515686622058759 |:  46%|████▌     | 12/26 [00:31<00:36,  2.63s/it]\u001b[A\n","Training loss: 0.46734267, IoU: 0.9595793684603802 |:  46%|████▌     | 12/26 [00:34<00:36,  2.63s/it]\u001b[A\n","Training loss: 0.46734267, IoU: 0.9595793684603802 |:  50%|█████     | 13/26 [00:34<00:34,  2.68s/it]\u001b[A\n","Training loss: 0.45646006, IoU: 0.9601007443890972 |:  50%|█████     | 13/26 [00:37<00:34,  2.68s/it]\u001b[A\n","Training loss: 0.45646006, IoU: 0.9601007443890972 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.71s/it]\u001b[A\n","Training loss: 0.45581454, IoU: 0.9571466821366416 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.71s/it]\u001b[A\n","Training loss: 0.45581454, IoU: 0.9571466821366416 |:  58%|█████▊    | 15/26 [00:39<00:30,  2.73s/it]\u001b[A\n","Training loss: 0.4478802, IoU: 0.956675402224153 |:  58%|█████▊    | 15/26 [00:42<00:30,  2.73s/it]  \u001b[A\n","Training loss: 0.4478802, IoU: 0.956675402224153 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.44763458, IoU: 0.9573663183187765 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.44763458, IoU: 0.9573663183187765 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.76s/it]\u001b[A\n","Training loss: 0.47742534, IoU: 0.949065689674186 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.76s/it] \u001b[A\n","Training loss: 0.47742534, IoU: 0.949065689674186 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.41122139, IoU: 0.9567434864542452 |:  69%|██████▉   | 18/26 [00:51<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.41122139, IoU: 0.9567434864542452 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.46668616, IoU: 0.9516261013941096 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.78s/it]\u001b[A\n","Training loss: 0.46668616, IoU: 0.9516261013941096 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.78s/it]\u001b[A\n","Training loss: 0.438098, IoU: 0.9571813047075286 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.78s/it]  \u001b[A\n","Training loss: 0.438098, IoU: 0.9571813047075286 |:  81%|████████  | 21/26 [00:56<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.4529286, IoU: 0.9487022871622105 |:  81%|████████  | 21/26 [00:59<00:13,  2.77s/it]\u001b[A\n","Training loss: 0.4529286, IoU: 0.9487022871622105 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.48896432, IoU: 0.9634861598711576 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.79s/it]\u001b[A\n","Training loss: 0.48896432, IoU: 0.9634861598711576 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.46407756, IoU: 0.9611843522635539 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.46407756, IoU: 0.9611843522635539 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.79s/it]\u001b[A\n","Training loss: 0.46094596, IoU: 0.956105517276531 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.79s/it] \u001b[A\n","Training loss: 0.46094596, IoU: 0.956105517276531 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.41018304, IoU: 0.9490530152550453 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.41018304, IoU: 0.9490530152550453 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  96%|█████████▌| 144/150 [3:21:53<07:50, 78.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47131354, IoU: 0.9591510715190019 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47131354, IoU: 0.9591510715190019 |:   4%|▍         | 1/26 [00:02<01:09,  2.76s/it]\u001b[A\n","Training loss: 0.4226056, IoU: 0.9632520610419225 |:   4%|▍         | 1/26 [00:05<01:09,  2.76s/it] \u001b[A\n","Training loss: 0.4226056, IoU: 0.9632520610419225 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.4309924, IoU: 0.9618402883028527 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.4309924, IoU: 0.9618402883028527 |:  12%|█▏        | 3/26 [00:08<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.47495604, IoU: 0.9584432962006093 |:  12%|█▏        | 3/26 [00:11<01:04,  2.78s/it]\u001b[A\n","Training loss: 0.47495604, IoU: 0.9584432962006093 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.4613995, IoU: 0.9502516134802687 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it] \u001b[A\n","Training loss: 0.4613995, IoU: 0.9502516134802687 |:  19%|█▉        | 5/26 [00:13<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.46878824, IoU: 0.948257844987283 |:  19%|█▉        | 5/26 [00:16<00:58,  2.77s/it]\u001b[A\n","Training loss: 0.46878824, IoU: 0.948257844987283 |:  23%|██▎       | 6/26 [00:16<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.43661612, IoU: 0.9543397912729372 |:  23%|██▎       | 6/26 [00:19<00:55,  2.76s/it]\u001b[A\n","Training loss: 0.43661612, IoU: 0.9543397912729372 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.43720815, IoU: 0.9593091993123908 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.43720815, IoU: 0.9593091993123908 |:  31%|███       | 8/26 [00:22<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.47015637, IoU: 0.9560084205133952 |:  31%|███       | 8/26 [00:23<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.47015637, IoU: 0.9560084205133952 |:  35%|███▍      | 9/26 [00:23<00:37,  2.22s/it]\u001b[A\n","Training loss: 0.43984833, IoU: 0.964621590326258 |:  35%|███▍      | 9/26 [00:25<00:37,  2.22s/it] \u001b[A\n","Training loss: 0.43984833, IoU: 0.964621590326258 |:  38%|███▊      | 10/26 [00:25<00:38,  2.39s/it]\u001b[A\n","Training loss: 0.47037876, IoU: 0.9591318571902707 |:  38%|███▊      | 10/26 [00:28<00:38,  2.39s/it]\u001b[A\n","Training loss: 0.47037876, IoU: 0.9591318571902707 |:  42%|████▏     | 11/26 [00:28<00:37,  2.50s/it]\u001b[A\n","Training loss: 0.4365403, IoU: 0.9601527642450586 |:  42%|████▏     | 11/26 [00:31<00:37,  2.50s/it] \u001b[A\n","Training loss: 0.4365403, IoU: 0.9601527642450586 |:  46%|████▌     | 12/26 [00:31<00:36,  2.59s/it]\u001b[A\n","Training loss: 0.40406886, IoU: 0.9585765231266801 |:  46%|████▌     | 12/26 [00:34<00:36,  2.59s/it]\u001b[A\n","Training loss: 0.40406886, IoU: 0.9585765231266801 |:  50%|█████     | 13/26 [00:34<00:34,  2.65s/it]\u001b[A\n","Training loss: 0.4438312, IoU: 0.9616004760350884 |:  50%|█████     | 13/26 [00:37<00:34,  2.65s/it] \u001b[A\n","Training loss: 0.4438312, IoU: 0.9616004760350884 |:  54%|█████▍    | 14/26 [00:37<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.39983046, IoU: 0.9543290762851945 |:  54%|█████▍    | 14/26 [00:39<00:32,  2.70s/it]\u001b[A\n","Training loss: 0.39983046, IoU: 0.9543290762851945 |:  58%|█████▊    | 15/26 [00:39<00:29,  2.73s/it]\u001b[A\n","Training loss: 0.4840687, IoU: 0.9582707590804757 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.73s/it] \u001b[A\n","Training loss: 0.4840687, IoU: 0.9582707590804757 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.4324832, IoU: 0.9582743443693154 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.75s/it]\u001b[A\n","Training loss: 0.4324832, IoU: 0.9582743443693154 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.75s/it]\u001b[A\n","Training loss: 0.39331055, IoU: 0.9612519307044575 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.75s/it]\u001b[A\n","Training loss: 0.39331055, IoU: 0.9612519307044575 |:  69%|██████▉   | 18/26 [00:48<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.44394946, IoU: 0.9550962078524451 |:  69%|██████▉   | 18/26 [00:50<00:22,  2.76s/it]\u001b[A\n","Training loss: 0.44394946, IoU: 0.9550962078524451 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.41826633, IoU: 0.9450645942932481 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.41826633, IoU: 0.9450645942932481 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.45396018, IoU: 0.9581856251889507 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.45396018, IoU: 0.9581856251889507 |:  81%|████████  | 21/26 [00:56<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.4533091, IoU: 0.9582002243330352 |:  81%|████████  | 21/26 [00:59<00:13,  2.76s/it] \u001b[A\n","Training loss: 0.4533091, IoU: 0.9582002243330352 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.39230248, IoU: 0.9607592205415139 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.39230248, IoU: 0.9607592205415139 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4760321, IoU: 0.9540198000109913 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.4760321, IoU: 0.9540198000109913 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.3852895, IoU: 0.9503883471053872 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.3852895, IoU: 0.9503883471053872 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.41129887, IoU: 0.9562436766664988 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.41129887, IoU: 0.9562436766664988 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  97%|█████████▋| 145/150 [3:23:12<06:31, 78.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.47386032, IoU: 0.9495776329843543 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.47386032, IoU: 0.9495776329843543 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.47154272, IoU: 0.9351139347928302 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.47154272, IoU: 0.9351139347928302 |:   8%|▊         | 2/26 [00:05<01:07,  2.81s/it]\u001b[A\n","Training loss: 0.41354993, IoU: 0.94528490907803 |:   8%|▊         | 2/26 [00:08<01:07,  2.81s/it]  \u001b[A\n","Training loss: 0.41354993, IoU: 0.94528490907803 |:  12%|█▏        | 3/26 [00:08<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.4664336, IoU: 0.9563772060294724 |:  12%|█▏        | 3/26 [00:11<01:04,  2.81s/it]\u001b[A\n","Training loss: 0.4664336, IoU: 0.9563772060294724 |:  15%|█▌        | 4/26 [00:11<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.44140834, IoU: 0.9637418865545805 |:  15%|█▌        | 4/26 [00:13<01:01,  2.79s/it]\u001b[A\n","Training loss: 0.44140834, IoU: 0.9637418865545805 |:  19%|█▉        | 5/26 [00:13<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.47077096, IoU: 0.9618003910233024 |:  19%|█▉        | 5/26 [00:16<00:58,  2.79s/it]\u001b[A\n","Training loss: 0.47077096, IoU: 0.9618003910233024 |:  23%|██▎       | 6/26 [00:16<00:55,  2.79s/it]\u001b[A\n","Training loss: 0.4118384, IoU: 0.9584809395456295 |:  23%|██▎       | 6/26 [00:19<00:55,  2.79s/it] \u001b[A\n","Training loss: 0.4118384, IoU: 0.9584809395456295 |:  27%|██▋       | 7/26 [00:19<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.44726822, IoU: 0.9476572414463695 |:  27%|██▋       | 7/26 [00:22<00:53,  2.79s/it]\u001b[A\n","Training loss: 0.44726822, IoU: 0.9476572414463695 |:  31%|███       | 8/26 [00:22<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.46581984, IoU: 0.9563710455661613 |:  31%|███       | 8/26 [00:25<00:50,  2.79s/it]\u001b[A\n","Training loss: 0.46581984, IoU: 0.9563710455661613 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.47238046, IoU: 0.9662347414560886 |:  35%|███▍      | 9/26 [00:26<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.47238046, IoU: 0.9662347414560886 |:  38%|███▊      | 10/26 [00:26<00:35,  2.23s/it]\u001b[A\n","Training loss: 0.4398573, IoU: 0.9531217105034853 |:  38%|███▊      | 10/26 [00:28<00:35,  2.23s/it] \u001b[A\n","Training loss: 0.4398573, IoU: 0.9531217105034853 |:  42%|████▏     | 11/26 [00:28<00:35,  2.39s/it]\u001b[A\n","Training loss: 0.45169818, IoU: 0.9603316188119886 |:  42%|████▏     | 11/26 [00:31<00:35,  2.39s/it]\u001b[A\n","Training loss: 0.45169818, IoU: 0.9603316188119886 |:  46%|████▌     | 12/26 [00:31<00:35,  2.51s/it]\u001b[A\n","Training loss: 0.39757755, IoU: 0.9571719487489666 |:  46%|████▌     | 12/26 [00:34<00:35,  2.51s/it]\u001b[A\n","Training loss: 0.39757755, IoU: 0.9571719487489666 |:  50%|█████     | 13/26 [00:34<00:33,  2.59s/it]\u001b[A\n","Training loss: 0.43707243, IoU: 0.950837928398115 |:  50%|█████     | 13/26 [00:37<00:33,  2.59s/it] \u001b[A\n","Training loss: 0.43707243, IoU: 0.950837928398115 |:  54%|█████▍    | 14/26 [00:37<00:31,  2.66s/it]\u001b[A\n","Training loss: 0.40370226, IoU: 0.9594679682733374 |:  54%|█████▍    | 14/26 [00:40<00:31,  2.66s/it]\u001b[A\n","Training loss: 0.40370226, IoU: 0.9594679682733374 |:  58%|█████▊    | 15/26 [00:40<00:29,  2.70s/it]\u001b[A\n","Training loss: 0.38768137, IoU: 0.9562663579625529 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.70s/it]\u001b[A\n","Training loss: 0.38768137, IoU: 0.9562663579625529 |:  62%|██████▏   | 16/26 [00:42<00:27,  2.72s/it]\u001b[A\n","Training loss: 0.41257328, IoU: 0.9519445247635177 |:  62%|██████▏   | 16/26 [00:45<00:27,  2.72s/it]\u001b[A\n","Training loss: 0.41257328, IoU: 0.9519445247635177 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.74s/it]\u001b[A\n","Training loss: 0.4824952, IoU: 0.9567376487024258 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.74s/it] \u001b[A\n","Training loss: 0.4824952, IoU: 0.9567376487024258 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.75s/it]\u001b[A\n","Training loss: 0.4566458, IoU: 0.9569274218085646 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.75s/it]\u001b[A\n","Training loss: 0.4566458, IoU: 0.9569274218085646 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.45871976, IoU: 0.954229610493699 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.76s/it]\u001b[A\n","Training loss: 0.45871976, IoU: 0.954229610493699 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4681998, IoU: 0.9445841297629468 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.77s/it]\u001b[A\n","Training loss: 0.4681998, IoU: 0.9445841297629468 |:  81%|████████  | 21/26 [00:56<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.3835447, IoU: 0.9424121956302197 |:  81%|████████  | 21/26 [00:59<00:13,  2.78s/it]\u001b[A\n","Training loss: 0.3835447, IoU: 0.9424121956302197 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.4479588, IoU: 0.9608757552192378 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.78s/it]\u001b[A\n","Training loss: 0.4479588, IoU: 0.9608757552192378 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.41889912, IoU: 0.963096336021921 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.78s/it]\u001b[A\n","Training loss: 0.41889912, IoU: 0.963096336021921 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.3973946, IoU: 0.9502767860937567 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.78s/it]\u001b[A\n","Training loss: 0.3973946, IoU: 0.9502767860937567 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.41729212, IoU: 0.964981261761786 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.78s/it]\u001b[A\n","Training loss: 0.41729212, IoU: 0.964981261761786 |: 100%|██████████| 26/26 [01:10<00:00,  2.72s/it]\n","Epoch Loop:  97%|█████████▋| 146/150 [3:24:30<05:13, 78.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.41533566, IoU: 0.9453091417108468 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.41533566, IoU: 0.9453091417108468 |:   4%|▍         | 1/26 [00:02<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.45452905, IoU: 0.9500306175521843 |:   4%|▍         | 1/26 [00:05<01:09,  2.79s/it]\u001b[A\n","Training loss: 0.45452905, IoU: 0.9500306175521843 |:   8%|▊         | 2/26 [00:05<01:07,  2.82s/it]\u001b[A\n","Training loss: 0.4145398, IoU: 0.95525254101811 |:   8%|▊         | 2/26 [00:08<01:07,  2.82s/it]   \u001b[A\n","Training loss: 0.4145398, IoU: 0.95525254101811 |:  12%|█▏        | 3/26 [00:08<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.44865257, IoU: 0.9561473062860667 |:  12%|█▏        | 3/26 [00:11<01:04,  2.80s/it]\u001b[A\n","Training loss: 0.44865257, IoU: 0.9561473062860667 |:  15%|█▌        | 4/26 [00:11<01:01,  2.81s/it]\u001b[A\n","Training loss: 0.4678604, IoU: 0.9589916399661179 |:  15%|█▌        | 4/26 [00:14<01:01,  2.81s/it] \u001b[A\n","Training loss: 0.4678604, IoU: 0.9589916399661179 |:  19%|█▉        | 5/26 [00:14<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.40700063, IoU: 0.9472164253040747 |:  19%|█▉        | 5/26 [00:16<00:58,  2.80s/it]\u001b[A\n","Training loss: 0.40700063, IoU: 0.9472164253040747 |:  23%|██▎       | 6/26 [00:16<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.41212606, IoU: 0.9516180627794615 |:  23%|██▎       | 6/26 [00:19<00:56,  2.80s/it]\u001b[A\n","Training loss: 0.41212606, IoU: 0.9516180627794615 |:  27%|██▋       | 7/26 [00:19<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.46396506, IoU: 0.9623552823189093 |:  27%|██▋       | 7/26 [00:22<00:53,  2.81s/it]\u001b[A\n","Training loss: 0.46396506, IoU: 0.9623552823189093 |:  31%|███       | 8/26 [00:22<00:50,  2.80s/it]\u001b[A\n","Training loss: 0.3953996, IoU: 0.9496230883594444 |:  31%|███       | 8/26 [00:25<00:50,  2.80s/it] \u001b[A\n","Training loss: 0.3953996, IoU: 0.9496230883594444 |:  35%|███▍      | 9/26 [00:25<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.41747886, IoU: 0.966393503236953 |:  35%|███▍      | 9/26 [00:27<00:47,  2.79s/it]\u001b[A\n","Training loss: 0.41747886, IoU: 0.966393503236953 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.4562572, IoU: 0.9561699741053209 |:  38%|███▊      | 10/26 [00:28<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.4562572, IoU: 0.9561699741053209 |:  42%|████▏     | 11/26 [00:28<00:33,  2.22s/it]\u001b[A\n","Training loss: 0.4536277, IoU: 0.961058734107894 |:  42%|████▏     | 11/26 [00:31<00:33,  2.22s/it] \u001b[A\n","Training loss: 0.4536277, IoU: 0.961058734107894 |:  46%|████▌     | 12/26 [00:31<00:33,  2.39s/it]\u001b[A\n","Training loss: 0.46296126, IoU: 0.9633821237502392 |:  46%|████▌     | 12/26 [00:34<00:33,  2.39s/it]\u001b[A\n","Training loss: 0.46296126, IoU: 0.9633821237502392 |:  50%|█████     | 13/26 [00:34<00:32,  2.51s/it]\u001b[A\n","Training loss: 0.41010797, IoU: 0.9564522117258232 |:  50%|█████     | 13/26 [00:37<00:32,  2.51s/it]\u001b[A\n","Training loss: 0.41010797, IoU: 0.9564522117258232 |:  54%|█████▍    | 14/26 [00:37<00:31,  2.59s/it]\u001b[A\n","Training loss: 0.45468968, IoU: 0.9618609757430341 |:  54%|█████▍    | 14/26 [00:40<00:31,  2.59s/it]\u001b[A\n","Training loss: 0.45468968, IoU: 0.9618609757430341 |:  58%|█████▊    | 15/26 [00:40<00:29,  2.64s/it]\u001b[A\n","Training loss: 0.4828155, IoU: 0.9622955185923431 |:  58%|█████▊    | 15/26 [00:42<00:29,  2.64s/it] \u001b[A\n","Training loss: 0.4828155, IoU: 0.9622955185923431 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.68s/it]\u001b[A\n","Training loss: 0.44783986, IoU: 0.9563678147402257 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.68s/it]\u001b[A\n","Training loss: 0.44783986, IoU: 0.9563678147402257 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.71s/it]\u001b[A\n","Training loss: 0.4857915, IoU: 0.9522503588271478 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.71s/it] \u001b[A\n","Training loss: 0.4857915, IoU: 0.9522503588271478 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.73s/it]\u001b[A\n","Training loss: 0.44724852, IoU: 0.9608019557890894 |:  69%|██████▉   | 18/26 [00:51<00:21,  2.73s/it]\u001b[A\n","Training loss: 0.44724852, IoU: 0.9608019557890894 |:  73%|███████▎  | 19/26 [00:51<00:19,  2.75s/it]\u001b[A\n","Training loss: 0.44406483, IoU: 0.959463270144853 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.75s/it] \u001b[A\n","Training loss: 0.44406483, IoU: 0.959463270144853 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.44533587, IoU: 0.9591866269171971 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.76s/it]\u001b[A\n","Training loss: 0.44533587, IoU: 0.9591866269171971 |:  81%|████████  | 21/26 [00:56<00:13,  2.76s/it]\u001b[A\n","Training loss: 0.3779062, IoU: 0.9511462217136107 |:  81%|████████  | 21/26 [00:59<00:13,  2.76s/it] \u001b[A\n","Training loss: 0.3779062, IoU: 0.9511462217136107 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.43599606, IoU: 0.9527555067938223 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.77s/it]\u001b[A\n","Training loss: 0.43599606, IoU: 0.9527555067938223 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.77s/it]\u001b[A\n","Training loss: 0.4320464, IoU: 0.9614531661712442 |:  88%|████████▊ | 23/26 [01:05<00:08,  2.77s/it] \u001b[A\n","Training loss: 0.4320464, IoU: 0.9614531661712442 |:  92%|█████████▏| 24/26 [01:05<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.43162996, IoU: 0.9539017080795533 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.43162996, IoU: 0.9539017080795533 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.4558733, IoU: 0.9568923810953739 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it] \u001b[A\n","Training loss: 0.4558733, IoU: 0.9568923810953739 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  98%|█████████▊| 147/150 [3:25:48<03:55, 78.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.45670316, IoU: 0.9513021805221817 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.45670316, IoU: 0.9513021805221817 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.46574652, IoU: 0.954828063765212 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it] \u001b[A\n","Training loss: 0.46574652, IoU: 0.954828063765212 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.51998043, IoU: 0.9521682238317095 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.51998043, IoU: 0.9521682238317095 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.43308944, IoU: 0.9571888434016553 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.43308944, IoU: 0.9571888434016553 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.47206223, IoU: 0.9587653180315113 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.47206223, IoU: 0.9587653180315113 |:  19%|█▉        | 5/26 [00:13<00:57,  2.76s/it]\u001b[A\n","Training loss: 0.4876823, IoU: 0.9650687416658386 |:  19%|█▉        | 5/26 [00:16<00:57,  2.76s/it] \u001b[A\n","Training loss: 0.4876823, IoU: 0.9650687416658386 |:  23%|██▎       | 6/26 [00:16<00:55,  2.75s/it]\u001b[A\n","Training loss: 0.46613532, IoU: 0.9599075027518376 |:  23%|██▎       | 6/26 [00:19<00:55,  2.75s/it]\u001b[A\n","Training loss: 0.46613532, IoU: 0.9599075027518376 |:  27%|██▋       | 7/26 [00:19<00:52,  2.75s/it]\u001b[A\n","Training loss: 0.4869597, IoU: 0.9618931709983508 |:  27%|██▋       | 7/26 [00:22<00:52,  2.75s/it] \u001b[A\n","Training loss: 0.4869597, IoU: 0.9618931709983508 |:  31%|███       | 8/26 [00:22<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.39886227, IoU: 0.9573214421630871 |:  31%|███       | 8/26 [00:24<00:49,  2.76s/it]\u001b[A\n","Training loss: 0.39886227, IoU: 0.9573214421630871 |:  35%|███▍      | 9/26 [00:24<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.47919935, IoU: 0.9619273335068065 |:  35%|███▍      | 9/26 [00:27<00:46,  2.76s/it]\u001b[A\n","Training loss: 0.47919935, IoU: 0.9619273335068065 |:  38%|███▊      | 10/26 [00:27<00:44,  2.77s/it]\u001b[A\n","Training loss: 0.4261678, IoU: 0.958944303216946 |:  38%|███▊      | 10/26 [00:30<00:44,  2.77s/it]  \u001b[A\n","Training loss: 0.4261678, IoU: 0.958944303216946 |:  42%|████▏     | 11/26 [00:30<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.45473206, IoU: 0.9548494372167812 |:  42%|████▏     | 11/26 [00:31<00:41,  2.77s/it]\u001b[A\n","Training loss: 0.45473206, IoU: 0.9548494372167812 |:  46%|████▌     | 12/26 [00:31<00:31,  2.22s/it]\u001b[A\n","Training loss: 0.4338194, IoU: 0.9562329005053464 |:  46%|████▌     | 12/26 [00:34<00:31,  2.22s/it] \u001b[A\n","Training loss: 0.4338194, IoU: 0.9562329005053464 |:  50%|█████     | 13/26 [00:34<00:30,  2.38s/it]\u001b[A\n","Training loss: 0.42558485, IoU: 0.9574185574212444 |:  50%|█████     | 13/26 [00:36<00:30,  2.38s/it]\u001b[A\n","Training loss: 0.42558485, IoU: 0.9574185574212444 |:  54%|█████▍    | 14/26 [00:36<00:30,  2.51s/it]\u001b[A\n","Training loss: 0.46867424, IoU: 0.955356263376107 |:  54%|█████▍    | 14/26 [00:39<00:30,  2.51s/it] \u001b[A\n","Training loss: 0.46867424, IoU: 0.955356263376107 |:  58%|█████▊    | 15/26 [00:39<00:28,  2.59s/it]\u001b[A\n","Training loss: 0.4338632, IoU: 0.9640469415928437 |:  58%|█████▊    | 15/26 [00:42<00:28,  2.59s/it]\u001b[A\n","Training loss: 0.4338632, IoU: 0.9640469415928437 |:  62%|██████▏   | 16/26 [00:42<00:26,  2.65s/it]\u001b[A\n","Training loss: 0.43794078, IoU: 0.9602859270556023 |:  62%|██████▏   | 16/26 [00:45<00:26,  2.65s/it]\u001b[A\n","Training loss: 0.43794078, IoU: 0.9602859270556023 |:  65%|██████▌   | 17/26 [00:45<00:24,  2.69s/it]\u001b[A\n","Training loss: 0.44014436, IoU: 0.9589482787794469 |:  65%|██████▌   | 17/26 [00:48<00:24,  2.69s/it]\u001b[A\n","Training loss: 0.44014436, IoU: 0.9589482787794469 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.71s/it]\u001b[A\n","Training loss: 0.4475891, IoU: 0.9544262092256511 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.71s/it] \u001b[A\n","Training loss: 0.4475891, IoU: 0.9544262092256511 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.72s/it]\u001b[A\n","Training loss: 0.46183997, IoU: 0.9555326835825911 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.72s/it]\u001b[A\n","Training loss: 0.46183997, IoU: 0.9555326835825911 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.73s/it]\u001b[A\n","Training loss: 0.45534807, IoU: 0.9628634515325084 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.73s/it]\u001b[A\n","Training loss: 0.45534807, IoU: 0.9628634515325084 |:  81%|████████  | 21/26 [00:56<00:13,  2.74s/it]\u001b[A\n","Training loss: 0.45096573, IoU: 0.9513127912415551 |:  81%|████████  | 21/26 [00:59<00:13,  2.74s/it]\u001b[A\n","Training loss: 0.45096573, IoU: 0.9513127912415551 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.74s/it]\u001b[A\n","Training loss: 0.39928284, IoU: 0.955103591826086 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.74s/it] \u001b[A\n","Training loss: 0.39928284, IoU: 0.955103591826086 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.75s/it]\u001b[A\n","Training loss: 0.438627, IoU: 0.9574845728684809 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.75s/it] \u001b[A\n","Training loss: 0.438627, IoU: 0.9574845728684809 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.44826078, IoU: 0.9513579921898995 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.77s/it]\u001b[A\n","Training loss: 0.44826078, IoU: 0.9513579921898995 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.44070023, IoU: 0.9619006300134586 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.44070023, IoU: 0.9619006300134586 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop:  99%|█████████▊| 148/150 [3:27:06<02:36, 78.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.5032823, IoU: 0.9593187223712664 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.5032823, IoU: 0.9593187223712664 |:   4%|▍         | 1/26 [00:02<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.43566132, IoU: 0.9572132355793476 |:   4%|▍         | 1/26 [00:05<01:09,  2.77s/it]\u001b[A\n","Training loss: 0.43566132, IoU: 0.9572132355793476 |:   8%|▊         | 2/26 [00:05<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.47698092, IoU: 0.9605779355320812 |:   8%|▊         | 2/26 [00:08<01:06,  2.77s/it]\u001b[A\n","Training loss: 0.47698092, IoU: 0.9605779355320812 |:  12%|█▏        | 3/26 [00:08<01:03,  2.76s/it]\u001b[A\n","Training loss: 0.4903623, IoU: 0.9619531448172824 |:  12%|█▏        | 3/26 [00:11<01:03,  2.76s/it] \u001b[A\n","Training loss: 0.4903623, IoU: 0.9619531448172824 |:  15%|█▌        | 4/26 [00:11<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.42698035, IoU: 0.9489999110792553 |:  15%|█▌        | 4/26 [00:13<01:01,  2.78s/it]\u001b[A\n","Training loss: 0.42698035, IoU: 0.9489999110792553 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.47917718, IoU: 0.9587816457366256 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.47917718, IoU: 0.9587816457366256 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.4668652, IoU: 0.9502692275666824 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it] \u001b[A\n","Training loss: 0.4668652, IoU: 0.9502692275666824 |:  27%|██▋       | 7/26 [00:19<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.48829472, IoU: 0.9652223157001797 |:  27%|██▋       | 7/26 [00:22<00:52,  2.78s/it]\u001b[A\n","Training loss: 0.48829472, IoU: 0.9652223157001797 |:  31%|███       | 8/26 [00:22<00:50,  2.78s/it]\u001b[A\n","Training loss: 0.4228838, IoU: 0.9615707913142204 |:  31%|███       | 8/26 [00:24<00:50,  2.78s/it] \u001b[A\n","Training loss: 0.4228838, IoU: 0.9615707913142204 |:  35%|███▍      | 9/26 [00:24<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.40043178, IoU: 0.9485083796505998 |:  35%|███▍      | 9/26 [00:27<00:47,  2.78s/it]\u001b[A\n","Training loss: 0.40043178, IoU: 0.9485083796505998 |:  38%|███▊      | 10/26 [00:27<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.42376834, IoU: 0.9568259155923438 |:  38%|███▊      | 10/26 [00:30<00:44,  2.79s/it]\u001b[A\n","Training loss: 0.42376834, IoU: 0.9568259155923438 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.42739138, IoU: 0.9584287564801294 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.42739138, IoU: 0.9584287564801294 |:  46%|████▌     | 12/26 [00:33<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.52745473, IoU: 0.9567713505461768 |:  46%|████▌     | 12/26 [00:34<00:38,  2.78s/it]\u001b[A\n","Training loss: 0.52745473, IoU: 0.9567713505461768 |:  50%|█████     | 13/26 [00:34<00:28,  2.22s/it]\u001b[A\n","Training loss: 0.4792654, IoU: 0.963384572528923 |:  50%|█████     | 13/26 [00:37<00:28,  2.22s/it]  \u001b[A\n","Training loss: 0.4792654, IoU: 0.963384572528923 |:  54%|█████▍    | 14/26 [00:37<00:28,  2.38s/it]\u001b[A\n","Training loss: 0.44912958, IoU: 0.9606085558241269 |:  54%|█████▍    | 14/26 [00:39<00:28,  2.38s/it]\u001b[A\n","Training loss: 0.44912958, IoU: 0.9606085558241269 |:  58%|█████▊    | 15/26 [00:39<00:27,  2.50s/it]\u001b[A\n","Training loss: 0.45012945, IoU: 0.9583722287047841 |:  58%|█████▊    | 15/26 [00:42<00:27,  2.50s/it]\u001b[A\n","Training loss: 0.45012945, IoU: 0.9583722287047841 |:  62%|██████▏   | 16/26 [00:42<00:25,  2.58s/it]\u001b[A\n","Training loss: 0.37923193, IoU: 0.966819930470567 |:  62%|██████▏   | 16/26 [00:45<00:25,  2.58s/it] \u001b[A\n","Training loss: 0.37923193, IoU: 0.966819930470567 |:  65%|██████▌   | 17/26 [00:45<00:23,  2.64s/it]\u001b[A\n","Training loss: 0.41667432, IoU: 0.9548202699324616 |:  65%|██████▌   | 17/26 [00:48<00:23,  2.64s/it]\u001b[A\n","Training loss: 0.41667432, IoU: 0.9548202699324616 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.69s/it]\u001b[A\n","Training loss: 0.43025032, IoU: 0.9453313872562003 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.69s/it]\u001b[A\n","Training loss: 0.43025032, IoU: 0.9453313872562003 |:  73%|███████▎  | 19/26 [00:50<00:19,  2.71s/it]\u001b[A\n","Training loss: 0.39415413, IoU: 0.9462155340976631 |:  73%|███████▎  | 19/26 [00:53<00:19,  2.71s/it]\u001b[A\n","Training loss: 0.39415413, IoU: 0.9462155340976631 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.74s/it]\u001b[A\n","Training loss: 0.44466764, IoU: 0.958858859539221 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.74s/it] \u001b[A\n","Training loss: 0.44466764, IoU: 0.958858859539221 |:  81%|████████  | 21/26 [00:56<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.40320307, IoU: 0.9590558657954829 |:  81%|████████  | 21/26 [00:59<00:13,  2.75s/it]\u001b[A\n","Training loss: 0.40320307, IoU: 0.9590558657954829 |:  85%|████████▍ | 22/26 [00:59<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.47469783, IoU: 0.9538065769679727 |:  85%|████████▍ | 22/26 [01:02<00:11,  2.76s/it]\u001b[A\n","Training loss: 0.47469783, IoU: 0.9538065769679727 |:  88%|████████▊ | 23/26 [01:02<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.4722164, IoU: 0.9556260858644003 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.76s/it] \u001b[A\n","Training loss: 0.4722164, IoU: 0.9556260858644003 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.42942643, IoU: 0.9527040962119048 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.42942643, IoU: 0.9527040962119048 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.42400196, IoU: 0.9577971547437659 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.77s/it]\u001b[A\n","Training loss: 0.42400196, IoU: 0.9577971547437659 |: 100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n","Epoch Loop:  99%|█████████▉| 149/150 [3:28:25<01:18, 78.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n","Training loss: 0.43752682, IoU: 0.956277063822688 |:   0%|          | 0/26 [00:02<?, ?it/s]\u001b[A\n","Training loss: 0.43752682, IoU: 0.956277063822688 |:   4%|▍         | 1/26 [00:02<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.46679842, IoU: 0.964485783028109 |:   4%|▍         | 1/26 [00:05<01:09,  2.78s/it]\u001b[A\n","Training loss: 0.46679842, IoU: 0.964485783028109 |:   8%|▊         | 2/26 [00:05<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4700362, IoU: 0.9673780883963543 |:   8%|▊         | 2/26 [00:08<01:06,  2.78s/it]\u001b[A\n","Training loss: 0.4700362, IoU: 0.9673780883963543 |:  12%|█▏        | 3/26 [00:08<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4611624, IoU: 0.9619150109512763 |:  12%|█▏        | 3/26 [00:11<01:03,  2.77s/it]\u001b[A\n","Training loss: 0.4611624, IoU: 0.9619150109512763 |:  15%|█▌        | 4/26 [00:11<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.4485189, IoU: 0.9591627405643156 |:  15%|█▌        | 4/26 [00:13<01:00,  2.77s/it]\u001b[A\n","Training loss: 0.4485189, IoU: 0.9591627405643156 |:  19%|█▉        | 5/26 [00:13<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.44579485, IoU: 0.9645728719895392 |:  19%|█▉        | 5/26 [00:16<00:58,  2.78s/it]\u001b[A\n","Training loss: 0.44579485, IoU: 0.9645728719895392 |:  23%|██▎       | 6/26 [00:16<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.44776452, IoU: 0.9529781990866416 |:  23%|██▎       | 6/26 [00:19<00:55,  2.78s/it]\u001b[A\n","Training loss: 0.44776452, IoU: 0.9529781990866416 |:  27%|██▋       | 7/26 [00:19<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.44315773, IoU: 0.9513514177902875 |:  27%|██▋       | 7/26 [00:22<00:52,  2.77s/it]\u001b[A\n","Training loss: 0.44315773, IoU: 0.9513514177902875 |:  31%|███       | 8/26 [00:22<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.39867723, IoU: 0.9566124999420139 |:  31%|███       | 8/26 [00:24<00:49,  2.77s/it]\u001b[A\n","Training loss: 0.39867723, IoU: 0.9566124999420139 |:  35%|███▍      | 9/26 [00:24<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.45885944, IoU: 0.9647537107922455 |:  35%|███▍      | 9/26 [00:27<00:47,  2.77s/it]\u001b[A\n","Training loss: 0.45885944, IoU: 0.9647537107922455 |:  38%|███▊      | 10/26 [00:27<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.48493868, IoU: 0.9622738007136561 |:  38%|███▊      | 10/26 [00:30<00:44,  2.78s/it]\u001b[A\n","Training loss: 0.48493868, IoU: 0.9622738007136561 |:  42%|████▏     | 11/26 [00:30<00:41,  2.78s/it]\u001b[A\n","Training loss: 0.455037, IoU: 0.9464343747529665 |:  42%|████▏     | 11/26 [00:33<00:41,  2.78s/it]  \u001b[A\n","Training loss: 0.455037, IoU: 0.9464343747529665 |:  46%|████▌     | 12/26 [00:33<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.44069108, IoU: 0.9539130077880501 |:  46%|████▌     | 12/26 [00:36<00:38,  2.77s/it]\u001b[A\n","Training loss: 0.44069108, IoU: 0.9539130077880501 |:  50%|█████     | 13/26 [00:36<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.46663064, IoU: 0.9396398418480982 |:  50%|█████     | 13/26 [00:36<00:35,  2.76s/it]\u001b[A\n","Training loss: 0.46663064, IoU: 0.9396398418480982 |:  54%|█████▍    | 14/26 [00:36<00:26,  2.21s/it]\u001b[A\n","Training loss: 0.44538936, IoU: 0.9558819562791953 |:  54%|█████▍    | 14/26 [00:39<00:26,  2.21s/it]\u001b[A\n","Training loss: 0.44538936, IoU: 0.9558819562791953 |:  58%|█████▊    | 15/26 [00:39<00:26,  2.38s/it]\u001b[A\n","Training loss: 0.38740984, IoU: 0.953982089668559 |:  58%|█████▊    | 15/26 [00:42<00:26,  2.38s/it] \u001b[A\n","Training loss: 0.38740984, IoU: 0.953982089668559 |:  62%|██████▏   | 16/26 [00:42<00:24,  2.49s/it]\u001b[A\n","Training loss: 0.42977914, IoU: 0.9530982238075976 |:  62%|██████▏   | 16/26 [00:45<00:24,  2.49s/it]\u001b[A\n","Training loss: 0.42977914, IoU: 0.9530982238075976 |:  65%|██████▌   | 17/26 [00:45<00:23,  2.58s/it]\u001b[A\n","Training loss: 0.4316957, IoU: 0.9577519755873845 |:  65%|██████▌   | 17/26 [00:48<00:23,  2.58s/it] \u001b[A\n","Training loss: 0.4316957, IoU: 0.9577519755873845 |:  69%|██████▉   | 18/26 [00:48<00:21,  2.63s/it]\u001b[A\n","Training loss: 0.46253467, IoU: 0.9500514730148409 |:  69%|██████▉   | 18/26 [00:50<00:21,  2.63s/it]\u001b[A\n","Training loss: 0.46253467, IoU: 0.9500514730148409 |:  73%|███████▎  | 19/26 [00:50<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.40472975, IoU: 0.9546067896870052 |:  73%|███████▎  | 19/26 [00:53<00:18,  2.68s/it]\u001b[A\n","Training loss: 0.40472975, IoU: 0.9546067896870052 |:  77%|███████▋  | 20/26 [00:53<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.46639648, IoU: 0.9681918552951152 |:  77%|███████▋  | 20/26 [00:56<00:16,  2.70s/it]\u001b[A\n","Training loss: 0.46639648, IoU: 0.9681918552951152 |:  81%|████████  | 21/26 [00:56<00:13,  2.72s/it]\u001b[A\n","Training loss: 0.43648458, IoU: 0.9484855671906032 |:  81%|████████  | 21/26 [00:59<00:13,  2.72s/it]\u001b[A\n","Training loss: 0.43648458, IoU: 0.9484855671906032 |:  85%|████████▍ | 22/26 [00:59<00:10,  2.74s/it]\u001b[A\n","Training loss: 0.3850615, IoU: 0.9583881817712088 |:  85%|████████▍ | 22/26 [01:01<00:10,  2.74s/it] \u001b[A\n","Training loss: 0.3850615, IoU: 0.9583881817712088 |:  88%|████████▊ | 23/26 [01:01<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.5357365, IoU: 0.9566246574828272 |:  88%|████████▊ | 23/26 [01:04<00:08,  2.76s/it]\u001b[A\n","Training loss: 0.5357365, IoU: 0.9566246574828272 |:  92%|█████████▏| 24/26 [01:04<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.4052301, IoU: 0.9571504538711995 |:  92%|█████████▏| 24/26 [01:07<00:05,  2.76s/it]\u001b[A\n","Training loss: 0.4052301, IoU: 0.9571504538711995 |:  96%|█████████▌| 25/26 [01:07<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.46088994, IoU: 0.9514887963690062 |:  96%|█████████▌| 25/26 [01:10<00:02,  2.76s/it]\u001b[A\n","Training loss: 0.46088994, IoU: 0.9514887963690062 |: 100%|██████████| 26/26 [01:10<00:00,  2.70s/it]\n","Epoch Loop: 100%|██████████| 150/150 [3:29:43<00:00, 83.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation metric did not improve from 0.835755820272055\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]}],"source":["#=============== Training Process =====================\n","\n","def my_mkdir(paths):\n","    if not isinstance(paths, (list, tuple)):\n","        paths = [paths]\n","    for path in paths:\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","\n","def train(dataset_dir, load_size, batch_size, epochs, epoch_decay, lr, beta_1, NUM_CHANNELS):\n","    # output_dir\n","    output_dir = os.path.join('Final_output')\n","    my_mkdir(output_dir)\n","\n","    models_path_final = os.path.join('Final_output', 'models')\n","    my_mkdir(models_path_final)\n","\n","\n","    # ==============================================================================\n","    # =                                    metrics                                 =\n","    # ==============================================================================\n","\n","    def calc_IoU(mask_1, mask_2):\n","        mask_1 = mask_1 > 0.3\n","        mask_2 = mask_2 > 0.3\n","\n","        TP = mask_1 * mask_2\n","        TP = TP.sum()\n","\n","        FP = ((mask_1 * (1 - mask_2)) + ((1 - mask_1) * mask_2)) * mask_2\n","        FP = FP.sum()\n","\n","        FN = ((mask_1 * (1 - mask_2)) + ((1 - mask_1) * mask_2)) * mask_1\n","        FN = FN.sum()\n","\n","        return TP / (TP + FP + FN)\n","\n","    # ==============================================================================\n","    # =                                    data                                    =\n","    # ==============================================================================\n","\n","    # loss record path\n","    loss_path = '/content/drive/My Drive/Master_Project/TransUNet-single/loss_record'\n","    loss_gray = np.load(loss_path+'/loss_record_test_GaE_gray.npy', allow_pickle=True)\n","    loss_event = np.load(loss_path+'/loss_record_test_GaE_event.npy', allow_pickle=True)\n","    \n","\n","    pred_dir = \"/content/drive/My Drive/Master_Project/predictions/\"\n","    N_CH = NUM_CHANNELS // 2\n","\n","\n","    def generator_train(BS):\n","\n","        gray_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n","                                                                          dtype='float32', rescale=1. / 255,\n","                                                                          brightness_range=None, fill_mode='constant',\n","                                                                          cval=125, zoom_range=[0.9, 1.1],\n","                                                                          rotation_range=180)\n","        gray_pred_gen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n","                                                                          dtype='float32', rescale=1. / 255,\n","                                                                          brightness_range=None, fill_mode='constant',\n","                                                                          cval=125, zoom_range=[0.9, 1.1],\n","                                                                          rotation_range=180)\n","        \n","        event_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n","                                                                          dtype='float32', rescale=1. / 255,\n","                                                                          brightness_range=None, fill_mode='constant',\n","                                                                          cval=125, zoom_range=[0.9, 1.1],\n","                                                                          rotation_range=180)\n","        event_pred_gen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n","                                                                          dtype='float32', rescale=1. / 255,\n","                                                                          brightness_range=None, fill_mode='constant',\n","                                                                          cval=125, zoom_range=[0.9, 1.1],\n","                                                                          rotation_range=180)\n","        train_gt_gen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n","                                                                       dtype='float32', rescale=1. / 255,\n","                                                                       brightness_range=None, fill_mode='constant',\n","                                                                       cval=125, zoom_range=[0.9, 1.1],\n","                                                                       rotation_range=180)\n","\n","        gray_img_iterator = gray_image_gen.flow_from_directory(\n","            dataset_dir + \"Beta_training/Grayscale/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        gray_pred_iterator = gray_pred_gen.flow_from_directory(\n","            pred_dir + \"TU_GaE_final_Gray320/Beta_training\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","             batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        event_img_iterator = event_image_gen.flow_from_directory(\n","            dataset_dir + \"Beta_training/Events/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        event_pred_iterator = event_pred_gen.flow_from_directory(\n","            pred_dir + \"TU_GaE_final_EvB320/Beta_training\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","             batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","\n","        train_gt_generator = train_gt_gen.flow_from_directory(\n","            dataset_dir + \"Beta_training/Masks/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='nearest')\n","\n","        while True:\n","            gray_img = gray_img_iterator.next()\n","            gray_pred = gray_pred_iterator.next()\n","            event_img = event_img_iterator.next()\n","            event_pred = event_pred_iterator.next()\n","            gt = train_gt_generator.next()\n","\n","            # channels concat\n","            idx = (gray_img_iterator.batch_index - 1) * gray_img_iterator.batch_size\n","            gray_slice_names = [gray_img_iterator.filenames[gray_img_iterator.index_array[i]] for i in range(idx, idx + gray_img_iterator.batch_size)]\n","            \n","            idx = (event_img_iterator.batch_index - 1) * event_img_iterator.batch_size\n","            event_slice_names = [event_img_iterator.filenames[event_img_iterator.index_array[i]] for i in range(idx, idx + event_img_iterator.batch_size)]\n","            \n","            images = []\n","\n","            for num in range(len(gray_img)):\n","                idx_gray = np.where(loss_gray[0]==gray_slice_names[num][11:-4])\n","                idx_event = np.where(loss_event[0]==event_slice_names[num][11:-4])\n","                Loss_1 = float(loss_gray[2][idx_gray])\n","                Loss_2 = float(loss_event[2][idx_event])\n","                if (Loss_1+Loss_2) == 0 :\n","                    Loss_1 = 0.5\n","                    Loss_2 = 0.5\n","                N_Gray = round(N_CH * Loss_1 / (Loss_1+Loss_2))\n","                N_Event = N_CH - N_Gray\n","\n","                image_cc = np.zeros(shape=gray_img[num,:,:,:].shape)    # initial zero slice for concat convenience\n","\n","                for _ in range(N_Gray):\n","                    image_cc = np.concatenate((image_cc, gray_img[num,:,:,:], gray_pred[num,:,:,:]), axis=-1)    # concat grayscale\n","                for _ in range(N_Event):\n","                    image_cc = np.concatenate((image_cc, event_img[num,:,:,:], event_pred[num,:,:,:]), axis=-1)    # concat event\n","\n","                image_cc = image_cc[:,:,1:]    # remove zero slice\n","                images.append(image_cc)\n","\n","            yield np.array(images), gt\n","\n","\n","    def generator_val(BS=1):\n","\n","        gray_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","        gray_pred_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","        event_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","        event_pred_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","        val_gt_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","\n","        gray_img_iterator = gray_image_gen.flow_from_directory(\n","            dataset_dir + \"Beta_validation/Grayscale/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        gray_pred_iterator = gray_pred_gen.flow_from_directory(\n","            pred_dir + \"TU_GaE_final_Gray320/Beta_validation\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","             batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        event_img_iterator = event_image_gen.flow_from_directory(\n","            dataset_dir + \"Beta_validation/Events/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        event_pred_iterator = event_pred_gen.flow_from_directory(\n","            pred_dir + \"TU_GaE_final_EvB320/Beta_validation\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","             batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","\n","        val_gt_generator = val_gt_gen.flow_from_directory(\n","            dataset_dir + \"Beta_validation/Masks/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='nearest')\n","\n","        while True:\n","            gray_img = gray_img_iterator.next()\n","            gray_pred = gray_pred_iterator.next()\n","            event_img = event_img_iterator.next()\n","            event_pred = event_pred_iterator.next()\n","            gt = val_gt_generator.next()\n","\n","            # channels concat\n","            idx = (gray_img_iterator.batch_index - 1) * gray_img_iterator.batch_size\n","            gray_slice_names = [gray_img_iterator.filenames[gray_img_iterator.index_array[i]] for i in range(idx, idx + gray_img_iterator.batch_size)]\n","            \n","            idx = (event_img_iterator.batch_index - 1) * event_img_iterator.batch_size\n","            event_slice_names = [event_img_iterator.filenames[event_img_iterator.index_array[i]] for i in range(idx, idx + event_img_iterator.batch_size)]\n","            \n","            images = []\n","\n","            for num in range(BS):\n","                idx_gray = np.where(loss_gray[0]==gray_slice_names[num][11:-4])\n","                idx_event = np.where(loss_event[0]==event_slice_names[num][11:-4])\n","                Loss_1 = float(loss_gray[2][idx_gray])\n","                Loss_2 = float(loss_event[2][idx_event])\n","                if (Loss_1+Loss_2) == 0 :\n","                    Loss_1 = 0.5\n","                    Loss_2 = 0.5\n","                N_Gray = round(N_CH * Loss_1 / (Loss_1+Loss_2))\n","                N_Event = N_CH - N_Gray\n","\n","                image_cc = np.zeros(shape=gray_img[num,:,:,:].shape)    # initial zero slice for concat convenience\n","\n","                for _ in range(N_Gray):\n","                    image_cc = np.concatenate((image_cc, gray_img[num,:,:,:], gray_pred[num,:,:,:]), axis=-1)    # concat grayscale\n","                for _ in range(N_Event):\n","                    image_cc = np.concatenate((image_cc, event_img[num,:,:,:], event_pred[num,:,:,:]), axis=-1)    # concat event\n","\n","                image_cc = image_cc[:,:,1:]    # remove zero slice\n","                images.append(image_cc)\n","\n","            yield np.array(images), gt\n","\n","    # ==============================================================================\n","    # =                                   models                                   =\n","    # ==============================================================================\n","    len_train_set = 420\n","    len_val_set = 60\n","\n","    final_segmentation_model = xception_final((320, 320, NUM_CHANNELS), NUM_CHANNELS)\n","\n","\n","    model_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=beta_1)\n","\n","    # ==============================================================================\n","    # =                                 train step                                 =\n","    # ==============================================================================\n","\n","    @tf.function\n","    def train_step(img, gt):\n","        img_ = tf.convert_to_tensor(img)\n","        gt_ = tf.convert_to_tensor(gt)\n","        with tf.GradientTape(persistent=True) as t_:\n","            final_prediction = final_segmentation_model(img_, training=True)\n","            final_loss = bce_jaccard_loss(gt_, final_prediction)\n","\n","        model_grad = t_.gradient(final_loss, final_segmentation_model.trainable_variables)\n","        model_optimizer.apply_gradients(zip(model_grad, final_segmentation_model.trainable_variables))\n","\n","        return final_loss, final_prediction\n","\n","    @tf.function\n","    def sample(img):\n","        img_ = tf.convert_to_tensor(img)\n","        final_prediction = final_segmentation_model(img_)\n","\n","        return final_prediction\n","\n","\n","\n","    # ==============================================================================\n","    # =                                    run                                     =\n","    # ==============================================================================\n","\n","    t_generator = generator_train(batch_size)\n","    v_generator = generator_val()\n","\n","    best_val_metric = np.NINF\n","\n","    # epoch counter\n","    ep_cnt = tf.Variable(initial_value=0, trainable=False, dtype=tf.int64)\n","\n","    # summary\n","    train_summary_writer = tf.summary.create_file_writer(os.path.join(output_dir, 'summaries', 'train'))\n","\n","    # sample\n","    sample_dir = os.path.join(output_dir, 'samples_training')\n","    my_mkdir(sample_dir)\n","\n","    # main loop\n","    with train_summary_writer.as_default():\n","        loss_record_train = [[],[],[]]\n","        for ep in tqdm.trange(epochs, desc='Epoch Loop'):\n","            # update epoch counter\n","            ep_cnt.assign_add(1)\n","            # train for an epoch\n","            t = tqdm.tqdm(range(int(len_train_set / batch_size)))\n","\n","            a = 0\n","\n","            for _ in t:\n","                img, gt = next(t_generator)\n","                loss, pred_temp = train_step(img, gt)\n","                iou = calc_IoU(pred_temp.numpy(), gt)\n","                loss_record_train[0].append(loss)\n","                loss_record_train[1].append(iou)\n","                t.set_description(\"Training loss: {}, \".format(str(np.array(loss))) + \"IoU: {} |\".format(str(np.array(iou))))\n","\n","            val_metric = []\n","            for _ in range(len_val_set):\n","                img, gt = next(v_generator)\n","                prediction = sample(img).numpy()\n","                val_metric.append(calc_IoU(prediction, gt))\n","\n","            val_metric = np.mean(np.array(val_metric))\n","            loss_record_train[2].append(val_metric)\n","\n","\n","            img = np.concatenate(\n","                (cv2.cvtColor(img[0,:,:,0].astype('float32'), cv2.COLOR_GRAY2RGB), cv2.cvtColor(img[0,:,:,1].astype('float32'), cv2.COLOR_GRAY2RGB), cv2.cvtColor(prediction[0], cv2.COLOR_GRAY2RGB), cv2.cvtColor(gt[0], cv2.COLOR_GRAY2RGB)),\n","                axis=1) * 255\n","\n","            cv2.imwrite(os.path.join(sample_dir, 'epoch_{}-iter_{}.jpg'.format(str(ep).zfill(3),\n","                          str(model_optimizer.iterations.numpy()).zfill(9))), img)\n","\n","            if val_metric >= best_val_metric:\n","                print('Validation metric improved from {} to {}'.format(str(best_val_metric), str(val_metric)))\n","                best_val_metric = copy.deepcopy(val_metric)\n","                final_segmentation_model.save_weights(os.path.join(models_path_final, 'model_{}.h5'.format(str(ep).zfill(3))),\n","                                                          overwrite=True, save_format=None)                                                                                                                  \n","            else:\n","                print('Validation metric did not improve from {}'.format(str(best_val_metric)))\n","\n","        np.save(\"/content/drive/My Drive/Master_Project/Xcep_loss_record_train_Final.npy\", loss_record_train)\n","\n","\n","dataset_dir = \"/content/drive/My Drive/Master_Project/TransUNet-single/datasets/GaE_Dataset_final/\"\n","load_size = [320, 320]\n","batch_size = 8\n","epochs = 150\n","epoch_decay = 25\n","lr = 0.001\n","beta_1 = 0.9\n","NUM_CHANNELS = 8\n","train(dataset_dir, load_size, batch_size, epochs, epoch_decay, lr, beta_1, NUM_CHANNELS)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bcw5dzYANZZT"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":4,"metadata":{"id":"KAOwAB9hS-Ho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650815600593,"user_tz":-480,"elapsed":795485,"user":{"displayName":"A立志做大白","userId":"07587136654976679727"}},"outputId":"80ccf928-3928-41d2-d48f-05c0af24c8c4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/applications/xception.py:133: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 8 input channels.\n","  weights=weights)\n","Testing images:   0%|          | 0/200 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Found 200 images belonging to 1 classes.\n","Found 200 images belonging to 1 classes.\n","Found 200 images belonging to 1 classes.\n","Found 200 images belonging to 1 classes.\n","Found 200 images belonging to 1 classes.\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   0%|          | 1/200 [00:32<1:47:55, 32.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 0 evaluated IoU: 0.6741022850924918\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   1%|          | 2/200 [00:36<52:46, 15.99s/it]  "]},{"output_type":"stream","name":"stdout","text":[" | Case 1 evaluated IoU: 0.8026486837829054\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   2%|▏         | 3/200 [00:42<36:44, 11.19s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 2 evaluated IoU: 0.7517761033369215\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   2%|▏         | 4/200 [00:46<27:02,  8.28s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 3 evaluated IoU: 0.7866408230207246\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   2%|▎         | 5/200 [00:49<21:31,  6.62s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 4 evaluated IoU: 0.5500546050236622\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   3%|▎         | 6/200 [00:53<17:56,  5.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 5 evaluated IoU: 0.8493969899332203\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   4%|▎         | 7/200 [00:56<15:46,  4.90s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 6 evaluated IoU: 0.9064822460776218\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   4%|▍         | 8/200 [01:00<14:21,  4.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 7 evaluated IoU: 0.8927012609117362\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   4%|▍         | 9/200 [01:04<13:16,  4.17s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 8 evaluated IoU: 0.8977511477706015\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   5%|▌         | 10/200 [01:07<12:40,  4.00s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 9 evaluated IoU: 0.9186695131189312\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   6%|▌         | 11/200 [01:11<12:09,  3.86s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 10 evaluated IoU: 0.8749175642998461\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   6%|▌         | 12/200 [01:15<12:19,  3.93s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 11 evaluated IoU: 0.8793837853187562\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   6%|▋         | 13/200 [01:18<11:45,  3.77s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 12 evaluated IoU: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   7%|▋         | 14/200 [01:22<11:26,  3.69s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 13 evaluated IoU: 0.8536890370987912\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   8%|▊         | 15/200 [01:25<11:02,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 14 evaluated IoU: 0.9133680162859081\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   8%|▊         | 16/200 [01:29<10:55,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 15 evaluated IoU: 0.7799200972728851\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   8%|▊         | 17/200 [01:32<10:53,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 16 evaluated IoU: 0.8795208214489446\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:   9%|▉         | 18/200 [01:36<10:48,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 17 evaluated IoU: 0.6434958663742196\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  10%|▉         | 19/200 [01:39<10:48,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 18 evaluated IoU: 0.8739837398373984\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  10%|█         | 20/200 [01:43<10:40,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 19 evaluated IoU: 0.6508126433343304\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  10%|█         | 21/200 [01:46<10:32,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 20 evaluated IoU: 0.7410947786094327\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  11%|█         | 22/200 [01:50<10:26,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 21 evaluated IoU: 0.8838020330934184\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  12%|█▏        | 23/200 [01:53<10:22,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 22 evaluated IoU: 0.9052033123223334\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  12%|█▏        | 24/200 [01:57<10:27,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 23 evaluated IoU: 0.8602452886628776\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  12%|█▎        | 25/200 [02:01<10:23,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 24 evaluated IoU: 0.8309206415330139\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  13%|█▎        | 26/200 [02:04<10:16,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 25 evaluated IoU: 0.9108535300316122\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  14%|█▎        | 27/200 [02:08<10:14,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 26 evaluated IoU: 0.8996679746453365\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  14%|█▍        | 28/200 [02:11<09:58,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 27 evaluated IoU: 0.6652110625909753\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  14%|█▍        | 29/200 [02:14<09:54,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 28 evaluated IoU: 0.9046588594704684\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  15%|█▌        | 30/200 [02:18<09:51,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 29 evaluated IoU: 0.8705055061695635\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  16%|█▌        | 31/200 [02:21<09:48,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 30 evaluated IoU: 0.9274468085106383\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  16%|█▌        | 32/200 [02:25<09:45,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 31 evaluated IoU: 0.8680106504374286\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  16%|█▋        | 33/200 [02:28<09:44,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 32 evaluated IoU: 0.6535988384152666\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  17%|█▋        | 34/200 [02:32<09:51,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 33 evaluated IoU: 0.8826077986383329\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  18%|█▊        | 35/200 [02:36<09:51,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 34 evaluated IoU: 0.9113265417899004\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  18%|█▊        | 36/200 [02:39<09:43,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 35 evaluated IoU: 0.4849412965798877\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  18%|█▊        | 37/200 [02:43<09:42,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 36 evaluated IoU: 0.8135205490257947\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  19%|█▉        | 38/200 [02:46<09:17,  3.44s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 37 evaluated IoU: 0.7508642883413019\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  20%|█▉        | 39/200 [02:49<09:19,  3.47s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 38 evaluated IoU: 0.9222975605954329\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  20%|██        | 40/200 [02:53<09:17,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 39 evaluated IoU: 0.3734199438202247\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  20%|██        | 41/200 [02:57<09:19,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 40 evaluated IoU: 0.5583533173461231\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  21%|██        | 42/200 [03:00<09:16,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 41 evaluated IoU: 0.8987185805815673\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  22%|██▏       | 43/200 [03:04<09:11,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 42 evaluated IoU: 0.797538351765965\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  22%|██▏       | 44/200 [03:08<09:56,  3.82s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 43 evaluated IoU: 0.7708239022181983\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  22%|██▎       | 45/200 [03:12<09:44,  3.77s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 44 evaluated IoU: 0.7500228832951945\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  23%|██▎       | 46/200 [03:15<09:30,  3.71s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 45 evaluated IoU: 0.805524025728339\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  24%|██▎       | 47/200 [03:19<09:22,  3.68s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 46 evaluated IoU: 0.9176849656514073\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  24%|██▍       | 48/200 [03:22<09:08,  3.61s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 47 evaluated IoU: 0.8048542107835153\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  24%|██▍       | 49/200 [03:26<09:01,  3.59s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 48 evaluated IoU: 0.8787549971444889\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  25%|██▌       | 50/200 [03:30<08:56,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 49 evaluated IoU: 0.8519324986390855\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  26%|██▌       | 51/200 [03:33<08:53,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 50 evaluated IoU: 0.9252984212552946\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  26%|██▌       | 52/200 [03:37<08:46,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 51 evaluated IoU: 0.9027284826974268\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  26%|██▋       | 53/200 [03:40<08:36,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 52 evaluated IoU: 0.805183199285076\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  27%|██▋       | 54/200 [03:44<08:35,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 53 evaluated IoU: 0.7973990417522245\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  28%|██▊       | 55/200 [03:47<08:29,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 54 evaluated IoU: 0.8923664633737685\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  28%|██▊       | 56/200 [03:51<08:24,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 55 evaluated IoU: 0.9269008166177753\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  28%|██▊       | 57/200 [03:54<08:23,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 56 evaluated IoU: 0.8394909688013136\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  29%|██▉       | 58/200 [03:58<08:21,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 57 evaluated IoU: 0.7609724612736661\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  30%|██▉       | 59/200 [04:01<08:14,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 58 evaluated IoU: 0.9141622340425531\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  30%|███       | 60/200 [04:05<08:09,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 59 evaluated IoU: 0.7288700782352187\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  30%|███       | 61/200 [04:08<07:56,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 60 evaluated IoU: 0.8661048689138576\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  31%|███       | 62/200 [04:11<07:57,  3.46s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 61 evaluated IoU: 0.8261879865225978\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  32%|███▏      | 63/200 [04:15<07:57,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 62 evaluated IoU: 0.5998672859986729\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  32%|███▏      | 64/200 [04:18<07:54,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 63 evaluated IoU: 0.8599137931034483\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  32%|███▎      | 65/200 [04:22<07:46,  3.46s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 64 evaluated IoU: 0.8724815417344512\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  33%|███▎      | 66/200 [04:25<07:46,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 65 evaluated IoU: 0.906610031420924\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  34%|███▎      | 67/200 [04:29<07:43,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 66 evaluated IoU: 0.7920792079207921\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  34%|███▍      | 68/200 [04:33<07:58,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 67 evaluated IoU: 0.805874929893438\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  34%|███▍      | 69/200 [04:36<07:50,  3.59s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 68 evaluated IoU: 0.8852817914555576\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  35%|███▌      | 70/200 [04:40<07:45,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 69 evaluated IoU: 0.7923891015537041\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  36%|███▌      | 71/200 [04:43<07:41,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 70 evaluated IoU: 0.807185628742515\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  36%|███▌      | 72/200 [04:47<07:33,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 71 evaluated IoU: 0.7450745618809187\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  36%|███▋      | 73/200 [04:50<07:28,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 72 evaluated IoU: 0.9270759821218537\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  37%|███▋      | 74/200 [04:54<07:21,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 73 evaluated IoU: 0.6080599144079886\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  38%|███▊      | 75/200 [04:57<07:08,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 74 evaluated IoU: 0.9125894299561504\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  38%|███▊      | 76/200 [05:00<07:00,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 75 evaluated IoU: 0.847877358490566\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  38%|███▊      | 77/200 [05:04<07:00,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 76 evaluated IoU: 0.879567618376219\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  39%|███▉      | 78/200 [05:07<06:58,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 77 evaluated IoU: 0.8816203836243917\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  40%|███▉      | 79/200 [05:11<06:58,  3.46s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 78 evaluated IoU: 0.8258936206601676\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  40%|████      | 80/200 [05:15<07:02,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 79 evaluated IoU: 0.8053282712574459\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  40%|████      | 81/200 [05:18<07:04,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 80 evaluated IoU: 0.6399509803921568\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  41%|████      | 82/200 [05:22<06:59,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 81 evaluated IoU: 0.906556645851918\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  42%|████▏     | 83/200 [05:26<07:30,  3.85s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 82 evaluated IoU: 0.8500107944732297\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  42%|████▏     | 84/200 [05:30<07:19,  3.79s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 83 evaluated IoU: 0.8801710929519918\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  42%|████▎     | 85/200 [05:33<07:06,  3.71s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 84 evaluated IoU: 0.7225408660739892\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  43%|████▎     | 86/200 [05:37<06:53,  3.63s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 85 evaluated IoU: 0.8255010948290382\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  44%|████▎     | 87/200 [05:40<06:48,  3.61s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 86 evaluated IoU: 0.6771744631624611\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  44%|████▍     | 88/200 [05:44<06:35,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 87 evaluated IoU: 0.8975299852127718\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  44%|████▍     | 89/200 [05:47<06:32,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 88 evaluated IoU: 0.8917710722898653\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  45%|████▌     | 90/200 [05:51<06:28,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 89 evaluated IoU: 0.9065903763959741\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  46%|████▌     | 91/200 [05:54<06:25,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 90 evaluated IoU: 0.7632030914555603\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  46%|████▌     | 92/200 [05:58<06:19,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 91 evaluated IoU: 0.7569009510554395\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  46%|████▋     | 93/200 [06:01<06:15,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 92 evaluated IoU: 0.8952445042620009\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  47%|████▋     | 94/200 [06:05<06:13,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 93 evaluated IoU: 0.7890905823148814\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  48%|████▊     | 95/200 [06:09<06:11,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 94 evaluated IoU: 0.9228640434738855\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  48%|████▊     | 96/200 [06:12<06:05,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 95 evaluated IoU: 0.7914543316346531\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  48%|████▊     | 97/200 [06:15<05:59,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 96 evaluated IoU: 0.7672458106302046\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  49%|████▉     | 98/200 [06:19<05:55,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 97 evaluated IoU: 0.9037263430116375\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  50%|████▉     | 99/200 [06:22<05:52,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 98 evaluated IoU: 0.8928613849625846\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  50%|█████     | 100/200 [06:26<05:53,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 99 evaluated IoU: 0.9064752873936481\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  50%|█████     | 101/200 [06:30<05:50,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 100 evaluated IoU: 0.920578555343842\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  51%|█████     | 102/200 [06:33<05:42,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 101 evaluated IoU: 0.8956279468495499\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  52%|█████▏    | 103/200 [06:37<05:44,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 102 evaluated IoU: 0.9195087117966295\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  52%|█████▏    | 104/200 [06:40<05:38,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 103 evaluated IoU: 0.876797759959272\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  52%|█████▎    | 105/200 [06:44<05:33,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 104 evaluated IoU: 0.8025641025641026\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  53%|█████▎    | 106/200 [06:47<05:24,  3.46s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 105 evaluated IoU: 0.8783431180691454\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  54%|█████▎    | 107/200 [06:50<05:19,  3.44s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 106 evaluated IoU: 0.8722573233773693\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  54%|█████▍    | 108/200 [06:54<05:18,  3.46s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 107 evaluated IoU: 0.879121540312876\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  55%|█████▍    | 109/200 [06:57<05:17,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 108 evaluated IoU: 0.8574519430806358\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  55%|█████▌    | 110/200 [07:01<05:14,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 109 evaluated IoU: 0.9030191399055018\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  56%|█████▌    | 111/200 [07:04<05:10,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 110 evaluated IoU: 0.8814645308924485\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  56%|█████▌    | 112/200 [07:08<05:07,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 111 evaluated IoU: 0.8781749148991883\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  56%|█████▋    | 113/200 [07:11<05:03,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 112 evaluated IoU: 0.816298877274487\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  57%|█████▋    | 114/200 [07:15<05:02,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 113 evaluated IoU: 0.7256033578174187\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  57%|█████▊    | 115/200 [07:18<04:58,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 114 evaluated IoU: 0.6239265620373112\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  58%|█████▊    | 116/200 [07:22<04:56,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 115 evaluated IoU: 0.8835455300304456\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  58%|█████▊    | 117/200 [07:26<04:54,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 116 evaluated IoU: 0.6890181320561067\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  59%|█████▉    | 118/200 [07:29<04:51,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 117 evaluated IoU: 0.8394868585732165\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  60%|█████▉    | 119/200 [07:33<04:45,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 118 evaluated IoU: 0.8837450081348913\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  60%|██████    | 120/200 [07:36<04:43,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 119 evaluated IoU: 0.7290392716401685\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  60%|██████    | 121/200 [07:40<04:38,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 120 evaluated IoU: 0.8535733007164075\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  61%|██████    | 122/200 [07:43<04:37,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 121 evaluated IoU: 0.46640053226879574\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  62%|██████▏   | 123/200 [07:47<04:31,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 122 evaluated IoU: 0.91417881362538\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  62%|██████▏   | 124/200 [07:50<04:27,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 123 evaluated IoU: 0.8554071935522676\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  62%|██████▎   | 125/200 [07:54<04:23,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 124 evaluated IoU: 0.8899601639628197\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  63%|██████▎   | 126/200 [07:57<04:18,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 125 evaluated IoU: 0.9015174055340672\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  64%|██████▎   | 127/200 [08:01<04:15,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 126 evaluated IoU: 0.7826358093126385\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  64%|██████▍   | 128/200 [08:04<04:12,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 127 evaluated IoU: 0.8486545720199683\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  64%|██████▍   | 129/200 [08:08<04:10,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 128 evaluated IoU: 0.8993424691206293\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  65%|██████▌   | 130/200 [08:12<04:16,  3.66s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 129 evaluated IoU: 0.8507397099750988\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  66%|██████▌   | 131/200 [08:15<04:09,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 130 evaluated IoU: 0.8683068017366136\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  66%|██████▌   | 132/200 [08:19<04:04,  3.59s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 131 evaluated IoU: 0.830684863214308\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  66%|██████▋   | 133/200 [08:22<03:58,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 132 evaluated IoU: 0.8855752718946766\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  67%|██████▋   | 134/200 [08:26<03:53,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 133 evaluated IoU: 0.8654591780214911\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  68%|██████▊   | 135/200 [08:29<03:47,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 134 evaluated IoU: 0.8755591451292246\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  68%|██████▊   | 136/200 [08:33<03:43,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 135 evaluated IoU: 0.8931946250541829\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  68%|██████▊   | 137/200 [08:36<03:41,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 136 evaluated IoU: 0.7154019335187393\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  69%|██████▉   | 138/200 [08:40<03:37,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 137 evaluated IoU: 0.9037951723175667\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  70%|██████▉   | 139/200 [08:43<03:34,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 138 evaluated IoU: 0.7770456251563934\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  70%|███████   | 140/200 [08:47<03:30,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 139 evaluated IoU: 0.7932900432900433\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  70%|███████   | 141/200 [08:50<03:26,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 140 evaluated IoU: 0.8743221909533941\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  71%|███████   | 142/200 [08:54<03:22,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 141 evaluated IoU: 0.860439127004996\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  72%|███████▏  | 143/200 [08:57<03:20,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 142 evaluated IoU: 0.8408768012989649\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  72%|███████▏  | 144/200 [09:01<03:16,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 143 evaluated IoU: 0.8665407617248977\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  72%|███████▎  | 145/200 [09:04<03:13,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 144 evaluated IoU: 0.8601203266007735\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  73%|███████▎  | 146/200 [09:08<03:10,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 145 evaluated IoU: 0.7274504328399888\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  74%|███████▎  | 147/200 [09:11<03:04,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 146 evaluated IoU: 0.8326959182254363\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  74%|███████▍  | 148/200 [09:15<03:08,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 147 evaluated IoU: 0.7278352419652752\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  74%|███████▍  | 149/200 [09:19<03:02,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 148 evaluated IoU: 0.8272822665267576\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  75%|███████▌  | 150/200 [09:22<02:57,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 149 evaluated IoU: 0.8329268292682926\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  76%|███████▌  | 151/200 [09:26<02:52,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 150 evaluated IoU: 0.8531318938431713\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  76%|███████▌  | 152/200 [09:29<02:48,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 151 evaluated IoU: 0.8859628217349858\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  76%|███████▋  | 153/200 [09:33<02:44,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 152 evaluated IoU: 0.9145971152803384\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  77%|███████▋  | 154/200 [09:36<02:41,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 153 evaluated IoU: 0.828636454916661\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  78%|███████▊  | 155/200 [09:40<02:39,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 154 evaluated IoU: 0.8964517998583296\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  78%|███████▊  | 156/200 [09:43<02:35,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 155 evaluated IoU: 0.8291127005606032\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  78%|███████▊  | 157/200 [09:47<02:29,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 156 evaluated IoU: 0.8458745874587459\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  79%|███████▉  | 158/200 [09:50<02:26,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 157 evaluated IoU: 0.850700375811411\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  80%|███████▉  | 159/200 [09:54<02:25,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 158 evaluated IoU: 0.4650274893097129\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  80%|████████  | 160/200 [09:57<02:20,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 159 evaluated IoU: 0.882404181184669\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  80%|████████  | 161/200 [10:01<02:17,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 160 evaluated IoU: 0.8249481327800829\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  81%|████████  | 162/200 [10:04<02:12,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 161 evaluated IoU: 0.8154606219122348\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  82%|████████▏ | 163/200 [10:08<02:09,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 162 evaluated IoU: 0.7449225141977092\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  82%|████████▏ | 164/200 [10:11<02:05,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 163 evaluated IoU: 0.7976486173207484\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  82%|████████▎ | 165/200 [10:15<02:01,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 164 evaluated IoU: 0.8618851222211045\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  83%|████████▎ | 166/200 [10:18<01:58,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 165 evaluated IoU: 0.8464775561097256\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  84%|████████▎ | 167/200 [10:22<01:54,  3.47s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 166 evaluated IoU: 0.8801237883919187\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  84%|████████▍ | 168/200 [10:25<01:50,  3.46s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 167 evaluated IoU: 0.7862050383941802\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  84%|████████▍ | 169/200 [10:29<01:47,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 168 evaluated IoU: 0.7443946188340808\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  85%|████████▌ | 170/200 [10:32<01:45,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 169 evaluated IoU: 0.7180370210934137\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  86%|████████▌ | 171/200 [10:36<01:41,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 170 evaluated IoU: 0.9383893430214956\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  86%|████████▌ | 172/200 [10:39<01:39,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 171 evaluated IoU: 0.8623298033282905\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  86%|████████▋ | 173/200 [10:43<01:35,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 172 evaluated IoU: 0.8523706187939765\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  87%|████████▋ | 174/200 [10:46<01:31,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 173 evaluated IoU: 0.7767031565522372\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  88%|████████▊ | 175/200 [10:50<01:27,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 174 evaluated IoU: 0.8849473742830094\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  88%|████████▊ | 176/200 [10:53<01:23,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 175 evaluated IoU: 0.8834317510788099\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  88%|████████▊ | 177/200 [10:57<01:20,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 176 evaluated IoU: 0.7277379733879222\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  89%|████████▉ | 178/200 [11:00<01:16,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 177 evaluated IoU: 0.8120567375886525\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  90%|████████▉ | 179/200 [11:04<01:13,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 178 evaluated IoU: 0.9184417040358744\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  90%|█████████ | 180/200 [11:07<01:10,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 179 evaluated IoU: 0.8539480949751519\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  90%|█████████ | 181/200 [11:11<01:06,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 180 evaluated IoU: 0.8915455897494566\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  91%|█████████ | 182/200 [11:14<01:03,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 181 evaluated IoU: 0.9148475909537856\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  92%|█████████▏| 183/200 [11:18<00:59,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 182 evaluated IoU: 0.7469601945475489\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  92%|█████████▏| 184/200 [11:21<00:56,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 183 evaluated IoU: 0.8553492021972273\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  92%|█████████▎| 185/200 [11:25<00:52,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 184 evaluated IoU: 0.8554137805322639\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  93%|█████████▎| 186/200 [11:29<00:50,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 185 evaluated IoU: 0.7896502156205079\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  94%|█████████▎| 187/200 [11:32<00:46,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 186 evaluated IoU: 0.8674511545293073\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  94%|█████████▍| 188/200 [11:36<00:42,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 187 evaluated IoU: 0.8165137614678899\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  94%|█████████▍| 189/200 [11:39<00:38,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 188 evaluated IoU: 0.8674489352455454\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  95%|█████████▌| 190/200 [11:43<00:35,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 189 evaluated IoU: 0.8571901483050848\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  96%|█████████▌| 191/200 [11:46<00:31,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 190 evaluated IoU: 0.5386573337575564\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  96%|█████████▌| 192/200 [11:50<00:28,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 191 evaluated IoU: 0.7554991539763113\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  96%|█████████▋| 193/200 [11:53<00:24,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 192 evaluated IoU: 0.7462532299741602\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  97%|█████████▋| 194/200 [11:57<00:21,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 193 evaluated IoU: 0.8350133717342111\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  98%|█████████▊| 195/200 [12:00<00:17,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 194 evaluated IoU: 0.7251390584723918\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  98%|█████████▊| 196/200 [12:03<00:13,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 195 evaluated IoU: 0.8793975761854336\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  98%|█████████▊| 197/200 [12:07<00:10,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 196 evaluated IoU: 0.8003907727215429\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images:  99%|█████████▉| 198/200 [12:10<00:06,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 197 evaluated IoU: 0.8190784155214228\n"]},{"output_type":"stream","name":"stderr","text":["\rTesting images: 100%|█████████▉| 199/200 [12:13<00:03,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 198 evaluated IoU: 0.8685521688159438\n"]},{"output_type":"stream","name":"stderr","text":["Testing images: 100%|██████████| 200/200 [12:17<00:00,  3.69s/it]"]},{"output_type":"stream","name":"stdout","text":[" | Case 199 evaluated IoU: 0.8547150078438208\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["#================== Testing Process ==================\n","def my_mkdir(paths):\n","    if not isinstance(paths, (list, tuple)):\n","        paths = [paths]\n","    for path in paths:\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","def test(dataset_dir, load_size, NUM_CHANNELS):\n","    # output_dir\n","    output_dir = os.path.join('Final_output')\n","    my_mkdir(output_dir)\n","\n","\n","    # ==============================================================================\n","    # =                                    metrics                                 =\n","    # ==============================================================================\n","\n","    def calc_IoU(mask_1, mask_2):\n","        mask_1 = mask_1 > 0.3\n","        mask_2 = mask_2 > 0.3\n","\n","        TP = mask_1 * mask_2\n","        TP = TP.sum()\n","\n","        FP = ((mask_1 * (1 - mask_2)) + ((1 - mask_1) * mask_2)) * mask_2\n","        FP = FP.sum()\n","\n","        FN = ((mask_1 * (1 - mask_2)) + ((1 - mask_1) * mask_2)) * mask_1\n","        FN = FN.sum()\n","\n","        return TP / (TP + FP + FN)\n","\n","    # ==============================================================================\n","    # =                                    data                                    =\n","    # ==============================================================================\n","\n","    # loss record path\n","    loss_path = '/content/drive/My Drive/Master_Project/TransUNet-single/loss_record'\n","    loss_gray = np.load(loss_path+'/loss_record_test_GaE_gray.npy', allow_pickle=True)\n","    loss_event = np.load(loss_path+'/loss_record_test_GaE_event.npy', allow_pickle=True)\n","    \n","\n","    pred_dir = \"/content/drive/My Drive/Master_Project/predictions/\"\n","    N_CH = NUM_CHANNELS // 2\n","\n","    def test_gen(BS=1):\n","\n","        gray_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","        gray_pred_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","        event_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","        event_pred_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","        test_gt_gen = tf.keras.preprocessing.image.ImageDataGenerator(dtype='float32', rescale=1. / 255)\n","\n","        gray_img_iterator = gray_image_gen.flow_from_directory(\n","            dataset_dir + \"Testing/Grayscale/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        gray_pred_iterator = gray_pred_gen.flow_from_directory(\n","            pred_dir + \"TU_GaE_final_Gray320/Testing\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","             batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        event_img_iterator = event_image_gen.flow_from_directory(\n","            dataset_dir + \"Testing/Events/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","        \n","        event_pred_iterator = event_pred_gen.flow_from_directory(\n","            pred_dir + \"TU_GaE_final_EvB320/Testing\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","             batch_size=BS, shuffle=True, seed=25,\n","            interpolation='bilinear')\n","\n","        test_gt_generator = test_gt_gen.flow_from_directory(\n","            dataset_dir + \"Testing/Masks/\",\n","            target_size=(320, 320),\n","            color_mode='grayscale', class_mode=None,\n","            batch_size=BS, shuffle=True, seed=25,\n","            interpolation='nearest')\n","\n","        while True:\n","            gray_img = gray_img_iterator.next()\n","            gray_pred = gray_pred_iterator.next()\n","            event_img = event_img_iterator.next()\n","            event_pred = event_pred_iterator.next()\n","            gt = test_gt_generator.next()\n","\n","            # channels concat\n","            idx = (gray_img_iterator.batch_index - 1) * gray_img_iterator.batch_size\n","            gray_slice_names = [gray_img_iterator.filenames[gray_img_iterator.index_array[i]] for i in range(idx, idx + gray_img_iterator.batch_size)]\n","            \n","            idx = (event_img_iterator.batch_index - 1) * event_img_iterator.batch_size\n","            event_slice_names = [event_img_iterator.filenames[event_img_iterator.index_array[i]] for i in range(idx, idx + event_img_iterator.batch_size)]\n","            \n","            images = []\n","\n","            for num in range(BS):\n","                idx_gray = np.where(loss_gray[0]==gray_slice_names[num][11:-4])\n","                idx_event = np.where(loss_event[0]==event_slice_names[num][11:-4])\n","                Loss_1 = float(loss_gray[2][idx_gray])\n","                Loss_2 = float(loss_event[2][idx_event])\n","                if (Loss_1+Loss_2) == 0 :\n","                    Loss_1 = 0.5\n","                    Loss_2 = 0.5\n","                N_Gray = round(N_CH * Loss_1 / (Loss_1+Loss_2))\n","                N_Event = N_CH - N_Gray\n","\n","                image_cc = np.zeros(shape=gray_img[num,:,:,:].shape)    # initial zero slice for concat convenience\n","\n","                for _ in range(N_Gray):\n","                    image_cc = np.concatenate((image_cc, gray_img[num,:,:,:], gray_pred[num,:,:,:]), axis=-1)    # concat grayscale\n","                for _ in range(N_Event):\n","                    image_cc = np.concatenate((image_cc, event_img[num,:,:,:], event_pred[num,:,:,:]), axis=-1)    # concat event\n","\n","                image_cc = image_cc[:,:,1:]    # remove zero slice\n","                images.append(image_cc)\n","\n","            yield np.array(images), gt\n","\n","\n","    # ==============================================================================\n","    # =                                   models                                   =\n","    # ==============================================================================\n","    len_test_set = 200\n","\n","    final_segmentation_model = xception_final((320, 320, NUM_CHANNELS), NUM_CHANNELS)\n","\n","    model_path = path + \"/Final_output/models\"\n","    all_models = os.listdir(model_path)\n","    all_models.sort()\n","\n","    final_segmentation_model.load_weights(model_path + '/' + all_models[-1], by_name=False)\n","\n","\n","\n","    # ==============================================================================\n","    # =                                 train step                                 =\n","    # ==============================================================================\n","\n","    @tf.function\n","    def evaluate(img):\n","        img_ = tf.convert_to_tensor(img)\n","        final_prediction = final_segmentation_model(img_)\n","\n","        return final_prediction\n","\n","\n","\n","    # ==============================================================================\n","    # =                                    run                                     =\n","    # ==============================================================================\n","\n","    te_generator = test_gen()\n","\n","\n","    # summary\n","    test_summary_writer = tf.summary.create_file_writer(os.path.join(output_dir, 'summaries', 'test'))\n","\n","    # sample\n","    evaluate_dir = os.path.join(output_dir, 'test_prediction')\n","    my_mkdir(evaluate_dir)\n","\n","    # main loop\n","    with test_summary_writer.as_default():\n","        iou_record_test = []\n","        for i in tqdm.trange(len_test_set, desc='Testing images'):\n","            img, gt = next(te_generator)\n","            prediction = evaluate(img).numpy()\n","            iou = calc_IoU(prediction, gt)\n","            iou_record_test.append(iou)\n","            print(\" | Case {} \".format(str(np.array(i))) + \"evaluated IoU: {}\".format(str(np.array(iou))))\n","\n","            img = np.concatenate(\n","                (cv2.cvtColor(img[0,:,:,0].astype('float32'), cv2.COLOR_GRAY2RGB), cv2.cvtColor(img[0,:,:,1].astype('float32'), cv2.COLOR_GRAY2RGB), cv2.cvtColor(prediction[0], cv2.COLOR_GRAY2RGB), cv2.cvtColor(gt[0], cv2.COLOR_GRAY2RGB)),\n","                axis=1) * 255\n","\n","            cv2.imwrite(os.path.join(evaluate_dir, 'Image Test Case_{}.jpg'.format(str(i).zfill(3))), img)\n","            \n","        np.save(\"/content/drive/My Drive/Master_Project/Xcep_iou_record_test_Final.npy\", iou_record_test)\n","\n","\n","dataset_dir = \"/content/drive/My Drive/Master_Project/TransUNet-single/datasets/GaE_Dataset_final/\"\n","load_size = [320, 320]\n","NUM_CHANNELS = 8\n","test(dataset_dir, load_size, NUM_CHANNELS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbN8r3NmS-DZ"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JChGWrRRS960"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Xception_Final_flowdir.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOQQAD6NJ8+/EqgWjkCxA7N"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}